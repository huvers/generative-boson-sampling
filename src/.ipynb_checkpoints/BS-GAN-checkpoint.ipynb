{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, save_img, img_to_array\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Conv2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.GAN import GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SECTION = 'gan'\n",
    "RUN_ID = '0001'\n",
    "DATA_NAME = 'boson/'\n",
    "RUN_FOLDER = '../run/{}/'.format(SECTION)\n",
    "RUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.mkdir(RUN_FOLDER)\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
    "\n",
    "mode =  'build' #'load' #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = '../data/data.sav'\n",
    "\n",
    "with open(data_file, \"rb\") as f:\n",
    "    X, Y = pickle.load(f)\n",
    "    \n",
    "X = np.asarray(X)\n",
    "Y = np.asarray(Y)\n",
    "\n",
    "split = round(len(X)*.9)\n",
    "\n",
    "x_train = X[:split]\n",
    "y_train = Y[:split]\n",
    "\n",
    "x_test  = X[split:]\n",
    "y_test  = Y[split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3600, 35)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Dense Layer GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_num = 16\n",
    "\n",
    "gan = GAN(input_dim = (y_train.shape[1],)\n",
    "        , discriminator_dense_layers = [64,64,32,128]\n",
    "        , discriminator_batch_norm_momentum = None\n",
    "        , discriminator_activation = 'relu'\n",
    "        , discriminator_dropout_rate = 0.4\n",
    "        , discriminator_learning_rate = 0.0008\n",
    "        , generator_dense_layers = [64,64,32,y_train.shape[1]]\n",
    "        , generator_batch_norm_momentum = 0.9\n",
    "        , generator_activation = 'relu'\n",
    "        , generator_dropout_rate = None\n",
    "        , generator_learning_rate = 0.0004\n",
    "        , optimiser = 'rmsprop'\n",
    "        , z_dim = z_num\n",
    "        )\n",
    "\n",
    "if mode == 'build':\n",
    "    gan.save(RUN_FOLDER)\n",
    "else:\n",
    "    gan.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "discriminator_input (InputLa [(None, 35)]              0         \n",
      "_________________________________________________________________\n",
      "discriminator_dense_0 (Dense (None, 64)                2304      \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "discriminator_dense_1 (Dense (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "discriminator_dense_2 (Dense (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "discriminator_dense_3 (Dense (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 12,897\n",
      "Trainable params: 12,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "generator_input (InputLayer) [(None, 16)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_g_layer_0 (Dense)      (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_g_layer_1 (Dense)      (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_g_layer_2 (Dense)      (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_g_layer_3 (Dense)      (None, 35)                1155      \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 35)                0         \n",
      "=================================================================\n",
      "Total params: 9,187\n",
      "Trainable params: 8,835\n",
      "Non-trainable params: 352\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCHS = 20000\n",
    "PRINT_EVERY_N_BATCHES = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 [D loss: (0.618)(R 0.568, F 0.667)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.838] [G acc: 0.688]\n",
      "10001 [D loss: (0.602)(R 0.580, F 0.623)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.897] [G acc: 0.438]\n",
      "10002 [D loss: (0.767)(R 0.814, F 0.719)] [D acc: (0.438)(0.625, 0.250)] [G loss: 1.069] [G acc: 0.375]\n",
      "10003 [D loss: (0.596)(R 0.599, F 0.592)] [D acc: (0.688)(0.938, 0.438)] [G loss: 1.280] [G acc: 0.250]\n",
      "10004 [D loss: (0.751)(R 0.746, F 0.757)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.826] [G acc: 0.688]\n",
      "10005 [D loss: (0.719)(R 0.698, F 0.740)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.867] [G acc: 0.500]\n",
      "10006 [D loss: (0.636)(R 0.626, F 0.645)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.806] [G acc: 0.562]\n",
      "10007 [D loss: (0.630)(R 0.624, F 0.636)] [D acc: (0.594)(0.812, 0.375)] [G loss: 1.420] [G acc: 0.188]\n",
      "10008 [D loss: (0.541)(R 0.764, F 0.317)] [D acc: (0.781)(0.688, 0.875)] [G loss: 2.318] [G acc: 0.250]\n",
      "10009 [D loss: (0.699)(R 0.679, F 0.719)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.831] [G acc: 0.438]\n",
      "10010 [D loss: (0.638)(R 0.544, F 0.732)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.814] [G acc: 0.562]\n",
      "10011 [D loss: (0.674)(R 0.686, F 0.662)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.831] [G acc: 0.438]\n",
      "10012 [D loss: (0.655)(R 0.607, F 0.703)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.825] [G acc: 0.438]\n",
      "10013 [D loss: (0.778)(R 0.845, F 0.710)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.746] [G acc: 0.625]\n",
      "10014 [D loss: (0.586)(R 0.571, F 0.601)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.949] [G acc: 0.375]\n",
      "10015 [D loss: (0.708)(R 0.625, F 0.791)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.821] [G acc: 0.688]\n",
      "10016 [D loss: (0.635)(R 0.596, F 0.673)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.841] [G acc: 0.312]\n",
      "10017 [D loss: (0.647)(R 0.592, F 0.701)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.933] [G acc: 0.500]\n",
      "10018 [D loss: (0.689)(R 0.790, F 0.588)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.921] [G acc: 0.625]\n",
      "10019 [D loss: (0.679)(R 0.605, F 0.754)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.793] [G acc: 0.500]\n",
      "10020 [D loss: (0.650)(R 0.610, F 0.691)] [D acc: (0.625)(0.875, 0.375)] [G loss: 1.019] [G acc: 0.438]\n",
      "10021 [D loss: (0.641)(R 0.627, F 0.656)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.960] [G acc: 0.188]\n",
      "10022 [D loss: (0.709)(R 0.765, F 0.653)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.896] [G acc: 0.625]\n",
      "10023 [D loss: (0.606)(R 0.607, F 0.605)] [D acc: (0.625)(0.812, 0.438)] [G loss: 1.036] [G acc: 0.625]\n",
      "10024 [D loss: (0.661)(R 0.653, F 0.669)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.855] [G acc: 0.688]\n",
      "10025 [D loss: (0.678)(R 0.673, F 0.683)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.897] [G acc: 0.500]\n",
      "10026 [D loss: (0.721)(R 0.813, F 0.629)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.831] [G acc: 0.688]\n",
      "10027 [D loss: (0.662)(R 0.610, F 0.714)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.946] [G acc: 0.375]\n",
      "10028 [D loss: (0.594)(R 0.620, F 0.568)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.962] [G acc: 0.500]\n",
      "10029 [D loss: (0.667)(R 0.669, F 0.664)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.829] [G acc: 0.500]\n",
      "10030 [D loss: (0.579)(R 0.537, F 0.621)] [D acc: (0.719)(1.000, 0.438)] [G loss: 0.860] [G acc: 0.688]\n",
      "10031 [D loss: (0.608)(R 0.608, F 0.609)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.962] [G acc: 0.500]\n",
      "10032 [D loss: (0.702)(R 0.673, F 0.730)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.941] [G acc: 0.375]\n",
      "10033 [D loss: (0.651)(R 0.611, F 0.691)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.818] [G acc: 0.688]\n",
      "10034 [D loss: (0.560)(R 0.556, F 0.565)] [D acc: (0.781)(0.938, 0.625)] [G loss: 0.922] [G acc: 0.500]\n",
      "10035 [D loss: (0.858)(R 1.037, F 0.679)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.807] [G acc: 0.625]\n",
      "10036 [D loss: (0.627)(R 0.603, F 0.652)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.922] [G acc: 0.500]\n",
      "10037 [D loss: (0.638)(R 0.574, F 0.702)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.778] [G acc: 0.688]\n",
      "10038 [D loss: (0.660)(R 0.574, F 0.746)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.999] [G acc: 0.438]\n",
      "10039 [D loss: (0.702)(R 0.659, F 0.744)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.781] [G acc: 0.625]\n",
      "10040 [D loss: (0.633)(R 0.579, F 0.686)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.884] [G acc: 0.500]\n",
      "10041 [D loss: (0.723)(R 0.655, F 0.790)] [D acc: (0.406)(0.625, 0.188)] [G loss: 1.157] [G acc: 0.250]\n",
      "10042 [D loss: (0.602)(R 0.589, F 0.615)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.936] [G acc: 0.438]\n",
      "10043 [D loss: (0.728)(R 0.757, F 0.699)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.957] [G acc: 0.500]\n",
      "10044 [D loss: (0.702)(R 0.759, F 0.645)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.908] [G acc: 0.375]\n",
      "10045 [D loss: (0.784)(R 0.827, F 0.741)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.888] [G acc: 0.562]\n",
      "10046 [D loss: (0.543)(R 0.601, F 0.485)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.767] [G acc: 0.500]\n",
      "10047 [D loss: (0.695)(R 0.785, F 0.606)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.784] [G acc: 0.625]\n",
      "10048 [D loss: (0.638)(R 0.590, F 0.687)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.853] [G acc: 0.438]\n",
      "10049 [D loss: (0.673)(R 0.672, F 0.673)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.842] [G acc: 0.562]\n",
      "10050 [D loss: (0.712)(R 0.827, F 0.596)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.949] [G acc: 0.438]\n",
      "10051 [D loss: (0.671)(R 0.748, F 0.595)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.736] [G acc: 0.625]\n",
      "10052 [D loss: (0.650)(R 0.634, F 0.665)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.760] [G acc: 0.688]\n",
      "10053 [D loss: (0.668)(R 0.660, F 0.677)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.869] [G acc: 0.500]\n",
      "10054 [D loss: (0.644)(R 0.626, F 0.661)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.894] [G acc: 0.438]\n",
      "10055 [D loss: (0.569)(R 0.587, F 0.550)] [D acc: (0.688)(0.875, 0.500)] [G loss: 1.481] [G acc: 0.375]\n",
      "10056 [D loss: (0.634)(R 0.664, F 0.603)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.780] [G acc: 0.688]\n",
      "10057 [D loss: (0.642)(R 0.609, F 0.674)] [D acc: (0.562)(0.625, 0.500)] [G loss: 1.146] [G acc: 0.312]\n",
      "10058 [D loss: (0.702)(R 0.735, F 0.669)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.900] [G acc: 0.438]\n",
      "10059 [D loss: (0.676)(R 0.650, F 0.703)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.856] [G acc: 0.500]\n",
      "10060 [D loss: (0.650)(R 0.622, F 0.678)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.821] [G acc: 0.375]\n",
      "10061 [D loss: (0.750)(R 0.648, F 0.853)] [D acc: (0.344)(0.688, 0.000)] [G loss: 0.679] [G acc: 0.875]\n",
      "10062 [D loss: (0.636)(R 0.626, F 0.646)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.752] [G acc: 0.688]\n",
      "10063 [D loss: (0.766)(R 0.726, F 0.805)] [D acc: (0.344)(0.562, 0.125)] [G loss: 0.736] [G acc: 0.812]\n",
      "10064 [D loss: (0.631)(R 0.603, F 0.659)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.896] [G acc: 0.625]\n",
      "10065 [D loss: (0.644)(R 0.630, F 0.658)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.805] [G acc: 0.562]\n",
      "10066 [D loss: (0.654)(R 0.626, F 0.682)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.846] [G acc: 0.625]\n",
      "10067 [D loss: (0.679)(R 0.664, F 0.694)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.850] [G acc: 0.750]\n",
      "10068 [D loss: (0.663)(R 0.578, F 0.747)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.845] [G acc: 0.688]\n",
      "10069 [D loss: (0.703)(R 0.635, F 0.770)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.745] [G acc: 0.688]\n",
      "10070 [D loss: (0.617)(R 0.591, F 0.642)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.898] [G acc: 0.625]\n",
      "10071 [D loss: (0.646)(R 0.609, F 0.684)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.948] [G acc: 0.625]\n",
      "10072 [D loss: (0.736)(R 0.692, F 0.780)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.764] [G acc: 0.812]\n",
      "10073 [D loss: (0.705)(R 0.798, F 0.612)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.873] [G acc: 0.688]\n",
      "10074 [D loss: (0.670)(R 0.611, F 0.729)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.744] [G acc: 0.688]\n",
      "10075 [D loss: (0.768)(R 0.741, F 0.796)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.751] [G acc: 0.750]\n",
      "10076 [D loss: (0.699)(R 0.684, F 0.714)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.841] [G acc: 0.438]\n",
      "10077 [D loss: (0.652)(R 0.587, F 0.717)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.781] [G acc: 0.688]\n",
      "10078 [D loss: (0.641)(R 0.532, F 0.751)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.745] [G acc: 0.688]\n",
      "10079 [D loss: (0.644)(R 0.601, F 0.688)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.921] [G acc: 0.625]\n",
      "10080 [D loss: (0.660)(R 0.602, F 0.719)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.944] [G acc: 0.688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10081 [D loss: (0.598)(R 0.606, F 0.590)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.967] [G acc: 0.625]\n",
      "10082 [D loss: (0.663)(R 0.628, F 0.697)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.960] [G acc: 0.562]\n",
      "10083 [D loss: (0.690)(R 0.709, F 0.671)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.913] [G acc: 0.562]\n",
      "10084 [D loss: (0.676)(R 0.684, F 0.668)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.767] [G acc: 0.750]\n",
      "10085 [D loss: (0.608)(R 0.599, F 0.616)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.812] [G acc: 0.688]\n",
      "10086 [D loss: (0.659)(R 0.661, F 0.657)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.818] [G acc: 0.625]\n",
      "10087 [D loss: (0.581)(R 0.702, F 0.459)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.897] [G acc: 0.562]\n",
      "10088 [D loss: (0.670)(R 0.641, F 0.699)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.759] [G acc: 0.750]\n",
      "10089 [D loss: (0.634)(R 0.676, F 0.592)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.842] [G acc: 0.688]\n",
      "10090 [D loss: (0.747)(R 0.846, F 0.648)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.919] [G acc: 0.562]\n",
      "10091 [D loss: (0.630)(R 0.654, F 0.607)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.904] [G acc: 0.438]\n",
      "10092 [D loss: (0.612)(R 0.552, F 0.671)] [D acc: (0.656)(0.938, 0.375)] [G loss: 0.960] [G acc: 0.562]\n",
      "10093 [D loss: (0.690)(R 0.660, F 0.721)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.783] [G acc: 0.688]\n",
      "10094 [D loss: (0.728)(R 0.752, F 0.703)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.974] [G acc: 0.688]\n",
      "10095 [D loss: (0.645)(R 0.608, F 0.683)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.883] [G acc: 0.500]\n",
      "10096 [D loss: (0.628)(R 0.627, F 0.629)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.863] [G acc: 0.625]\n",
      "10097 [D loss: (0.706)(R 0.592, F 0.821)] [D acc: (0.562)(0.938, 0.188)] [G loss: 0.800] [G acc: 0.688]\n",
      "10098 [D loss: (0.658)(R 0.588, F 0.729)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.986] [G acc: 0.500]\n",
      "10099 [D loss: (0.685)(R 0.649, F 0.720)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.745] [G acc: 0.812]\n",
      "10100 [D loss: (0.673)(R 0.582, F 0.763)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.913] [G acc: 0.562]\n",
      "10101 [D loss: (0.627)(R 0.615, F 0.640)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.842] [G acc: 0.688]\n",
      "10102 [D loss: (0.638)(R 0.622, F 0.654)] [D acc: (0.625)(0.812, 0.438)] [G loss: 1.043] [G acc: 0.438]\n",
      "10103 [D loss: (0.652)(R 0.679, F 0.625)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.696] [G acc: 0.750]\n",
      "10104 [D loss: (0.594)(R 0.589, F 0.599)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.843] [G acc: 0.625]\n",
      "10105 [D loss: (0.701)(R 0.596, F 0.806)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.867] [G acc: 0.688]\n",
      "10106 [D loss: (0.682)(R 0.666, F 0.699)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.750] [G acc: 0.688]\n",
      "10107 [D loss: (0.653)(R 0.539, F 0.767)] [D acc: (0.625)(1.000, 0.250)] [G loss: 0.983] [G acc: 0.562]\n",
      "10108 [D loss: (0.703)(R 0.657, F 0.749)] [D acc: (0.688)(0.812, 0.562)] [G loss: 1.068] [G acc: 0.500]\n",
      "10109 [D loss: (0.737)(R 0.685, F 0.789)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.854] [G acc: 0.562]\n",
      "10110 [D loss: (0.693)(R 0.704, F 0.681)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.810] [G acc: 0.625]\n",
      "10111 [D loss: (0.584)(R 0.547, F 0.621)] [D acc: (0.750)(1.000, 0.500)] [G loss: 0.771] [G acc: 0.625]\n",
      "10112 [D loss: (0.711)(R 0.730, F 0.692)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.846] [G acc: 0.750]\n",
      "10113 [D loss: (0.761)(R 0.778, F 0.744)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.761] [G acc: 0.750]\n",
      "10114 [D loss: (0.694)(R 0.713, F 0.675)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.827] [G acc: 0.562]\n",
      "10115 [D loss: (0.600)(R 0.572, F 0.627)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.884] [G acc: 0.375]\n",
      "10116 [D loss: (0.654)(R 0.635, F 0.672)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.809] [G acc: 0.688]\n",
      "10117 [D loss: (0.643)(R 0.635, F 0.651)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.756] [G acc: 0.750]\n",
      "10118 [D loss: (0.688)(R 0.638, F 0.738)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.745] [G acc: 0.812]\n",
      "10119 [D loss: (0.642)(R 0.681, F 0.602)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.710] [G acc: 0.812]\n",
      "10120 [D loss: (0.739)(R 0.710, F 0.768)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.791] [G acc: 0.750]\n",
      "10121 [D loss: (0.607)(R 0.586, F 0.627)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.668] [G acc: 0.812]\n",
      "10122 [D loss: (0.661)(R 0.727, F 0.594)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.790] [G acc: 0.750]\n",
      "10123 [D loss: (0.700)(R 0.691, F 0.710)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.805] [G acc: 0.688]\n",
      "10124 [D loss: (0.652)(R 0.598, F 0.706)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.735] [G acc: 0.750]\n",
      "10125 [D loss: (0.707)(R 0.752, F 0.662)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.874] [G acc: 0.312]\n",
      "10126 [D loss: (0.635)(R 0.583, F 0.688)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.909] [G acc: 0.562]\n",
      "10127 [D loss: (0.662)(R 0.684, F 0.639)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.955] [G acc: 0.562]\n",
      "10128 [D loss: (0.727)(R 0.683, F 0.771)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.782] [G acc: 0.688]\n",
      "10129 [D loss: (0.686)(R 0.581, F 0.791)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.703] [G acc: 0.688]\n",
      "10130 [D loss: (0.701)(R 0.685, F 0.717)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.811] [G acc: 0.562]\n",
      "10131 [D loss: (0.746)(R 0.666, F 0.826)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.748] [G acc: 0.625]\n",
      "10132 [D loss: (0.724)(R 0.642, F 0.806)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.665] [G acc: 0.750]\n",
      "10133 [D loss: (0.582)(R 0.591, F 0.574)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.944] [G acc: 0.438]\n",
      "10134 [D loss: (0.629)(R 0.629, F 0.628)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.925] [G acc: 0.375]\n",
      "10135 [D loss: (0.604)(R 0.611, F 0.596)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.725] [G acc: 0.625]\n",
      "10136 [D loss: (0.604)(R 0.595, F 0.614)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.909] [G acc: 0.562]\n",
      "10137 [D loss: (0.739)(R 0.803, F 0.675)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.846] [G acc: 0.750]\n",
      "10138 [D loss: (0.572)(R 0.572, F 0.572)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.751] [G acc: 0.500]\n",
      "10139 [D loss: (0.612)(R 0.581, F 0.644)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.888] [G acc: 0.438]\n",
      "10140 [D loss: (0.745)(R 0.780, F 0.711)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.749] [G acc: 0.625]\n",
      "10141 [D loss: (0.687)(R 0.565, F 0.808)] [D acc: (0.625)(1.000, 0.250)] [G loss: 0.765] [G acc: 0.625]\n",
      "10142 [D loss: (0.606)(R 0.631, F 0.582)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.759] [G acc: 0.812]\n",
      "10143 [D loss: (0.599)(R 0.599, F 0.599)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.853] [G acc: 0.562]\n",
      "10144 [D loss: (0.689)(R 0.594, F 0.784)] [D acc: (0.562)(0.938, 0.188)] [G loss: 0.851] [G acc: 0.500]\n",
      "10145 [D loss: (0.661)(R 0.600, F 0.721)] [D acc: (0.562)(0.938, 0.188)] [G loss: 0.816] [G acc: 0.625]\n",
      "10146 [D loss: (0.636)(R 0.664, F 0.609)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.740] [G acc: 0.688]\n",
      "10147 [D loss: (0.697)(R 0.712, F 0.682)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.852] [G acc: 0.562]\n",
      "10148 [D loss: (0.693)(R 0.630, F 0.756)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.976] [G acc: 0.562]\n",
      "10149 [D loss: (0.710)(R 0.661, F 0.758)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.952] [G acc: 0.625]\n",
      "10150 [D loss: (0.728)(R 0.695, F 0.760)] [D acc: (0.344)(0.500, 0.188)] [G loss: 0.703] [G acc: 0.750]\n",
      "10151 [D loss: (0.645)(R 0.586, F 0.703)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.787] [G acc: 0.812]\n",
      "10152 [D loss: (0.746)(R 0.751, F 0.740)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.649] [G acc: 0.812]\n",
      "10153 [D loss: (0.655)(R 0.596, F 0.715)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.835] [G acc: 0.562]\n",
      "10154 [D loss: (0.619)(R 0.577, F 0.660)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.894] [G acc: 0.562]\n",
      "10155 [D loss: (0.721)(R 0.756, F 0.686)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.890] [G acc: 0.688]\n",
      "10156 [D loss: (0.727)(R 0.736, F 0.717)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.788] [G acc: 0.750]\n",
      "10157 [D loss: (0.754)(R 0.719, F 0.789)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.805] [G acc: 0.438]\n",
      "10158 [D loss: (0.653)(R 0.571, F 0.735)] [D acc: (0.562)(0.938, 0.188)] [G loss: 0.728] [G acc: 0.562]\n",
      "10159 [D loss: (0.623)(R 0.600, F 0.647)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.732] [G acc: 0.750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10160 [D loss: (0.745)(R 0.700, F 0.791)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.727] [G acc: 0.688]\n",
      "10161 [D loss: (0.663)(R 0.558, F 0.769)] [D acc: (0.625)(1.000, 0.250)] [G loss: 0.833] [G acc: 0.688]\n",
      "10162 [D loss: (0.654)(R 0.637, F 0.672)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.931] [G acc: 0.500]\n",
      "10163 [D loss: (0.663)(R 0.665, F 0.660)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.922] [G acc: 0.562]\n",
      "10164 [D loss: (0.735)(R 0.720, F 0.751)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.810] [G acc: 0.500]\n",
      "10165 [D loss: (0.702)(R 0.601, F 0.803)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.832] [G acc: 0.625]\n",
      "10166 [D loss: (0.722)(R 0.653, F 0.791)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.729] [G acc: 0.688]\n",
      "10167 [D loss: (0.781)(R 0.845, F 0.717)] [D acc: (0.344)(0.500, 0.188)] [G loss: 0.655] [G acc: 0.812]\n",
      "10168 [D loss: (0.687)(R 0.615, F 0.759)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.730] [G acc: 0.625]\n",
      "10169 [D loss: (0.716)(R 0.674, F 0.758)] [D acc: (0.438)(0.688, 0.188)] [G loss: 0.930] [G acc: 0.312]\n",
      "10170 [D loss: (0.621)(R 0.611, F 0.631)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.883] [G acc: 0.500]\n",
      "10171 [D loss: (0.538)(R 0.693, F 0.382)] [D acc: (0.844)(0.750, 0.938)] [G loss: 2.880] [G acc: 0.312]\n",
      "10172 [D loss: (0.565)(R 0.641, F 0.489)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.909] [G acc: 0.375]\n",
      "10173 [D loss: (0.617)(R 0.572, F 0.662)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.841] [G acc: 0.562]\n",
      "10174 [D loss: (0.607)(R 0.686, F 0.528)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.725] [G acc: 0.688]\n",
      "10175 [D loss: (0.648)(R 0.630, F 0.666)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.895] [G acc: 0.625]\n",
      "10176 [D loss: (0.666)(R 0.665, F 0.667)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.915] [G acc: 0.500]\n",
      "10177 [D loss: (0.691)(R 0.810, F 0.572)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.751] [G acc: 0.562]\n",
      "10178 [D loss: (0.683)(R 0.808, F 0.558)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.975] [G acc: 0.562]\n",
      "10179 [D loss: (0.703)(R 0.653, F 0.752)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.714] [G acc: 0.688]\n",
      "10180 [D loss: (0.701)(R 0.777, F 0.624)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.799] [G acc: 0.562]\n",
      "10181 [D loss: (0.573)(R 0.590, F 0.556)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.741] [G acc: 0.688]\n",
      "10182 [D loss: (0.675)(R 0.677, F 0.672)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.825] [G acc: 0.688]\n",
      "10183 [D loss: (0.709)(R 0.737, F 0.681)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.848] [G acc: 0.625]\n",
      "10184 [D loss: (0.717)(R 0.812, F 0.621)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.827] [G acc: 0.562]\n",
      "10185 [D loss: (0.653)(R 0.627, F 0.678)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.867] [G acc: 0.375]\n",
      "10186 [D loss: (0.614)(R 0.622, F 0.606)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.818] [G acc: 0.562]\n",
      "10187 [D loss: (0.715)(R 0.786, F 0.644)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.822] [G acc: 0.625]\n",
      "10188 [D loss: (0.685)(R 0.765, F 0.605)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.897] [G acc: 0.438]\n",
      "10189 [D loss: (0.649)(R 0.675, F 0.624)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.840] [G acc: 0.625]\n",
      "10190 [D loss: (0.644)(R 0.626, F 0.661)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.969] [G acc: 0.438]\n",
      "10191 [D loss: (0.710)(R 0.648, F 0.771)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.749] [G acc: 0.312]\n",
      "10192 [D loss: (0.620)(R 0.595, F 0.645)] [D acc: (0.688)(1.000, 0.375)] [G loss: 0.810] [G acc: 0.375]\n",
      "10193 [D loss: (0.662)(R 0.655, F 0.668)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.803] [G acc: 0.438]\n",
      "10194 [D loss: (0.718)(R 0.725, F 0.711)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.783] [G acc: 0.500]\n",
      "10195 [D loss: (0.635)(R 0.625, F 0.646)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.896] [G acc: 0.312]\n",
      "10196 [D loss: (0.669)(R 0.650, F 0.689)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.818] [G acc: 0.375]\n",
      "10197 [D loss: (0.691)(R 0.694, F 0.688)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.987] [G acc: 0.375]\n",
      "10198 [D loss: (0.612)(R 0.614, F 0.610)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.975] [G acc: 0.250]\n",
      "10199 [D loss: (0.702)(R 0.763, F 0.641)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.806] [G acc: 0.312]\n",
      "10200 [D loss: (0.631)(R 0.578, F 0.683)] [D acc: (0.719)(1.000, 0.438)] [G loss: 0.917] [G acc: 0.188]\n",
      "10201 [D loss: (0.549)(R 0.573, F 0.525)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.858] [G acc: 0.438]\n",
      "10202 [D loss: (0.678)(R 0.708, F 0.649)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.944] [G acc: 0.312]\n",
      "10203 [D loss: (0.683)(R 0.679, F 0.688)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.860] [G acc: 0.250]\n",
      "10204 [D loss: (0.621)(R 0.601, F 0.642)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.951] [G acc: 0.312]\n",
      "10205 [D loss: (0.598)(R 0.608, F 0.587)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.996] [G acc: 0.250]\n",
      "10206 [D loss: (0.665)(R 0.699, F 0.632)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.960] [G acc: 0.438]\n",
      "10207 [D loss: (0.641)(R 0.713, F 0.569)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.933] [G acc: 0.438]\n",
      "10208 [D loss: (0.640)(R 0.662, F 0.618)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.932] [G acc: 0.500]\n",
      "10209 [D loss: (0.604)(R 0.568, F 0.640)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.876] [G acc: 0.562]\n",
      "10210 [D loss: (0.689)(R 0.729, F 0.649)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.872] [G acc: 0.375]\n",
      "10211 [D loss: (0.761)(R 0.759, F 0.763)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.879] [G acc: 0.375]\n",
      "10212 [D loss: (0.657)(R 0.681, F 0.632)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.914] [G acc: 0.500]\n",
      "10213 [D loss: (0.659)(R 0.685, F 0.632)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.820] [G acc: 0.312]\n",
      "10214 [D loss: (0.668)(R 0.634, F 0.702)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.840] [G acc: 0.562]\n",
      "10215 [D loss: (0.724)(R 0.772, F 0.677)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.873] [G acc: 0.312]\n",
      "10216 [D loss: (0.682)(R 0.695, F 0.668)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.819] [G acc: 0.500]\n",
      "10217 [D loss: (0.679)(R 0.784, F 0.573)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.759] [G acc: 0.312]\n",
      "10218 [D loss: (0.613)(R 0.590, F 0.636)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.840] [G acc: 0.375]\n",
      "10219 [D loss: (0.620)(R 0.567, F 0.673)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.819] [G acc: 0.438]\n",
      "10220 [D loss: (0.640)(R 0.616, F 0.665)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.878] [G acc: 0.375]\n",
      "10221 [D loss: (0.615)(R 0.616, F 0.615)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.872] [G acc: 0.438]\n",
      "10222 [D loss: (0.717)(R 0.817, F 0.618)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.837] [G acc: 0.438]\n",
      "10223 [D loss: (0.580)(R 0.636, F 0.525)] [D acc: (0.844)(0.875, 0.812)] [G loss: 0.978] [G acc: 0.188]\n",
      "10224 [D loss: (0.651)(R 0.632, F 0.671)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.753] [G acc: 0.688]\n",
      "10225 [D loss: (0.664)(R 0.707, F 0.621)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.849] [G acc: 0.438]\n",
      "10226 [D loss: (0.643)(R 0.586, F 0.701)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.884] [G acc: 0.562]\n",
      "10227 [D loss: (0.641)(R 0.666, F 0.616)] [D acc: (0.719)(0.875, 0.562)] [G loss: 1.298] [G acc: 0.000]\n",
      "10228 [D loss: (0.460)(R 0.660, F 0.259)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.932] [G acc: 0.250]\n",
      "10229 [D loss: (0.585)(R 0.548, F 0.622)] [D acc: (0.750)(0.938, 0.562)] [G loss: 1.370] [G acc: 0.375]\n",
      "10230 [D loss: (0.619)(R 0.607, F 0.630)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.929] [G acc: 0.562]\n",
      "10231 [D loss: (0.622)(R 0.664, F 0.581)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.778] [G acc: 0.500]\n",
      "10232 [D loss: (0.749)(R 0.842, F 0.655)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.696] [G acc: 0.688]\n",
      "10233 [D loss: (0.630)(R 0.698, F 0.563)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.016] [G acc: 0.188]\n",
      "10234 [D loss: (0.586)(R 0.625, F 0.546)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.940] [G acc: 0.500]\n",
      "10235 [D loss: (0.613)(R 0.586, F 0.641)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.877] [G acc: 0.375]\n",
      "10236 [D loss: (0.703)(R 0.776, F 0.631)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.881] [G acc: 0.500]\n",
      "10237 [D loss: (0.621)(R 0.554, F 0.688)] [D acc: (0.719)(0.875, 0.562)] [G loss: 1.082] [G acc: 0.125]\n",
      "10238 [D loss: (0.544)(R 0.556, F 0.532)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.084] [G acc: 0.375]\n",
      "10239 [D loss: (0.590)(R 0.518, F 0.662)] [D acc: (0.719)(1.000, 0.438)] [G loss: 0.887] [G acc: 0.438]\n",
      "10240 [D loss: (0.683)(R 0.630, F 0.735)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.911] [G acc: 0.438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10241 [D loss: (0.621)(R 0.637, F 0.604)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.910] [G acc: 0.438]\n",
      "10242 [D loss: (0.632)(R 0.645, F 0.619)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.840] [G acc: 0.375]\n",
      "10243 [D loss: (0.607)(R 0.608, F 0.607)] [D acc: (0.781)(0.938, 0.625)] [G loss: 0.785] [G acc: 0.625]\n",
      "10244 [D loss: (0.621)(R 0.540, F 0.702)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.888] [G acc: 0.375]\n",
      "10245 [D loss: (0.619)(R 0.538, F 0.700)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.846] [G acc: 0.562]\n",
      "10246 [D loss: (0.626)(R 0.665, F 0.586)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.058] [G acc: 0.250]\n",
      "10247 [D loss: (0.538)(R 0.540, F 0.535)] [D acc: (0.844)(0.938, 0.750)] [G loss: 0.867] [G acc: 0.500]\n",
      "10248 [D loss: (0.602)(R 0.611, F 0.593)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.850] [G acc: 0.250]\n",
      "10249 [D loss: (0.534)(R 0.566, F 0.503)] [D acc: (0.844)(0.875, 0.812)] [G loss: 0.881] [G acc: 0.375]\n",
      "10250 [D loss: (0.617)(R 0.576, F 0.659)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.854] [G acc: 0.438]\n",
      "10251 [D loss: (0.703)(R 0.860, F 0.546)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.969] [G acc: 0.250]\n",
      "10252 [D loss: (0.756)(R 0.864, F 0.647)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.769] [G acc: 0.438]\n",
      "10253 [D loss: (0.543)(R 0.542, F 0.544)] [D acc: (0.844)(0.938, 0.750)] [G loss: 0.808] [G acc: 0.438]\n",
      "10254 [D loss: (0.615)(R 0.616, F 0.613)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.907] [G acc: 0.375]\n",
      "10255 [D loss: (0.694)(R 0.710, F 0.678)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.829] [G acc: 0.312]\n",
      "10256 [D loss: (0.528)(R 0.553, F 0.503)] [D acc: (0.875)(0.938, 0.812)] [G loss: 0.885] [G acc: 0.375]\n",
      "10257 [D loss: (0.704)(R 0.626, F 0.782)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.958] [G acc: 0.312]\n",
      "10258 [D loss: (0.692)(R 0.724, F 0.659)] [D acc: (0.594)(0.750, 0.438)] [G loss: 1.026] [G acc: 0.125]\n",
      "10259 [D loss: (0.587)(R 0.607, F 0.567)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.025] [G acc: 0.062]\n",
      "10260 [D loss: (0.657)(R 0.705, F 0.609)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.931] [G acc: 0.125]\n",
      "10261 [D loss: (0.777)(R 0.862, F 0.691)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.991] [G acc: 0.125]\n",
      "10262 [D loss: (0.729)(R 0.860, F 0.599)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.967] [G acc: 0.250]\n",
      "10263 [D loss: (0.619)(R 0.614, F 0.624)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.884] [G acc: 0.250]\n",
      "10264 [D loss: (0.657)(R 0.692, F 0.623)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.817] [G acc: 0.500]\n",
      "10265 [D loss: (0.585)(R 0.574, F 0.595)] [D acc: (0.812)(0.938, 0.688)] [G loss: 0.830] [G acc: 0.312]\n",
      "10266 [D loss: (0.661)(R 0.586, F 0.736)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.861] [G acc: 0.312]\n",
      "10267 [D loss: (0.522)(R 0.561, F 0.483)] [D acc: (0.875)(0.875, 0.875)] [G loss: 0.790] [G acc: 0.500]\n",
      "10268 [D loss: (0.566)(R 0.575, F 0.557)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.978] [G acc: 0.500]\n",
      "10269 [D loss: (0.699)(R 0.656, F 0.741)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.897] [G acc: 0.438]\n",
      "10270 [D loss: (0.702)(R 0.695, F 0.709)] [D acc: (0.562)(0.750, 0.375)] [G loss: 1.037] [G acc: 0.125]\n",
      "10271 [D loss: (0.642)(R 0.689, F 0.595)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.785] [G acc: 0.500]\n",
      "10272 [D loss: (0.608)(R 0.606, F 0.609)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.042] [G acc: 0.250]\n",
      "10273 [D loss: (0.659)(R 0.687, F 0.631)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.736] [G acc: 0.562]\n",
      "10274 [D loss: (0.687)(R 0.727, F 0.646)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.917] [G acc: 0.500]\n",
      "10275 [D loss: (0.648)(R 0.606, F 0.690)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.947] [G acc: 0.438]\n",
      "10276 [D loss: (0.632)(R 0.659, F 0.604)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.914] [G acc: 0.375]\n",
      "10277 [D loss: (0.674)(R 0.695, F 0.652)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.884] [G acc: 0.500]\n",
      "10278 [D loss: (0.689)(R 0.745, F 0.632)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.718] [G acc: 0.688]\n",
      "10279 [D loss: (0.664)(R 0.661, F 0.667)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.933] [G acc: 0.375]\n",
      "10280 [D loss: (0.676)(R 0.599, F 0.754)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.939] [G acc: 0.375]\n",
      "10281 [D loss: (0.666)(R 0.620, F 0.713)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.874] [G acc: 0.500]\n",
      "10282 [D loss: (0.736)(R 0.784, F 0.688)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.949] [G acc: 0.375]\n",
      "10283 [D loss: (0.641)(R 0.667, F 0.614)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.873] [G acc: 0.375]\n",
      "10284 [D loss: (0.659)(R 0.580, F 0.738)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.820] [G acc: 0.438]\n",
      "10285 [D loss: (0.567)(R 0.621, F 0.513)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.958] [G acc: 0.375]\n",
      "10286 [D loss: (0.646)(R 0.604, F 0.688)] [D acc: (0.594)(0.750, 0.438)] [G loss: 1.061] [G acc: 0.500]\n",
      "10287 [D loss: (0.750)(R 0.729, F 0.771)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.974] [G acc: 0.438]\n",
      "10288 [D loss: (0.731)(R 0.768, F 0.693)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.858] [G acc: 0.500]\n",
      "10289 [D loss: (0.723)(R 0.764, F 0.681)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.721] [G acc: 0.625]\n",
      "10290 [D loss: (0.724)(R 0.654, F 0.795)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.956] [G acc: 0.375]\n",
      "10291 [D loss: (0.731)(R 0.713, F 0.748)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.805] [G acc: 0.500]\n",
      "10292 [D loss: (0.568)(R 0.521, F 0.616)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.806] [G acc: 0.500]\n",
      "10293 [D loss: (0.606)(R 0.639, F 0.574)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.922] [G acc: 0.625]\n",
      "10294 [D loss: (0.666)(R 0.662, F 0.669)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.888] [G acc: 0.625]\n",
      "10295 [D loss: (0.703)(R 0.744, F 0.662)] [D acc: (0.500)(0.562, 0.438)] [G loss: 1.121] [G acc: 0.250]\n",
      "10296 [D loss: (0.704)(R 0.763, F 0.645)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.730] [G acc: 0.688]\n",
      "10297 [D loss: (0.587)(R 0.660, F 0.515)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.993] [G acc: 0.375]\n",
      "10298 [D loss: (0.652)(R 0.713, F 0.591)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.916] [G acc: 0.562]\n",
      "10299 [D loss: (0.668)(R 0.637, F 0.699)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.887] [G acc: 0.625]\n",
      "10300 [D loss: (0.521)(R 0.650, F 0.393)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.917] [G acc: 0.375]\n",
      "10301 [D loss: (0.769)(R 0.787, F 0.750)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.915] [G acc: 0.375]\n",
      "10302 [D loss: (0.674)(R 0.674, F 0.673)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.810] [G acc: 0.625]\n",
      "10303 [D loss: (0.664)(R 0.619, F 0.708)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.698] [G acc: 0.750]\n",
      "10304 [D loss: (0.575)(R 0.539, F 0.612)] [D acc: (0.750)(0.938, 0.562)] [G loss: 0.936] [G acc: 0.375]\n",
      "10305 [D loss: (0.769)(R 0.735, F 0.803)] [D acc: (0.406)(0.625, 0.188)] [G loss: 0.818] [G acc: 0.688]\n",
      "10306 [D loss: (0.820)(R 0.916, F 0.725)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.782] [G acc: 0.500]\n",
      "10307 [D loss: (0.666)(R 0.623, F 0.709)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.765] [G acc: 0.688]\n",
      "10308 [D loss: (0.699)(R 0.595, F 0.802)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.711] [G acc: 0.625]\n",
      "10309 [D loss: (0.708)(R 0.631, F 0.784)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.787] [G acc: 0.438]\n",
      "10310 [D loss: (0.733)(R 0.738, F 0.728)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.759] [G acc: 0.500]\n",
      "10311 [D loss: (0.733)(R 0.793, F 0.673)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.913] [G acc: 0.312]\n",
      "10312 [D loss: (0.711)(R 0.650, F 0.772)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.886] [G acc: 0.312]\n",
      "10313 [D loss: (0.724)(R 0.766, F 0.683)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.912] [G acc: 0.312]\n",
      "10314 [D loss: (0.685)(R 0.685, F 0.685)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.941] [G acc: 0.250]\n",
      "10315 [D loss: (0.666)(R 0.648, F 0.685)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.786] [G acc: 0.438]\n",
      "10316 [D loss: (0.693)(R 0.628, F 0.758)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.903] [G acc: 0.375]\n",
      "10317 [D loss: (0.700)(R 0.778, F 0.623)] [D acc: (0.594)(0.500, 0.688)] [G loss: 1.842] [G acc: 0.125]\n",
      "10318 [D loss: (0.701)(R 0.833, F 0.569)] [D acc: (0.438)(0.250, 0.625)] [G loss: 1.088] [G acc: 0.188]\n",
      "10319 [D loss: (0.785)(R 0.852, F 0.718)] [D acc: (0.375)(0.375, 0.375)] [G loss: 0.819] [G acc: 0.375]\n",
      "10320 [D loss: (0.684)(R 0.684, F 0.684)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.836] [G acc: 0.562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10321 [D loss: (0.696)(R 0.701, F 0.691)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.774] [G acc: 0.500]\n",
      "10322 [D loss: (0.734)(R 0.736, F 0.733)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.747] [G acc: 0.625]\n",
      "10323 [D loss: (0.669)(R 0.713, F 0.624)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.807] [G acc: 0.375]\n",
      "10324 [D loss: (0.713)(R 0.618, F 0.808)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.770] [G acc: 0.438]\n",
      "10325 [D loss: (0.679)(R 0.742, F 0.615)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.906] [G acc: 0.188]\n",
      "10326 [D loss: (0.698)(R 0.675, F 0.721)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.745] [G acc: 0.500]\n",
      "10327 [D loss: (0.674)(R 0.658, F 0.690)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.836] [G acc: 0.188]\n",
      "10328 [D loss: (0.657)(R 0.702, F 0.611)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.776] [G acc: 0.438]\n",
      "10329 [D loss: (0.637)(R 0.724, F 0.550)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.891] [G acc: 0.188]\n",
      "10330 [D loss: (0.576)(R 0.623, F 0.529)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.896] [G acc: 0.125]\n",
      "10331 [D loss: (0.675)(R 0.650, F 0.699)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.714] [G acc: 0.562]\n",
      "10332 [D loss: (0.655)(R 0.647, F 0.663)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.827] [G acc: 0.500]\n",
      "10333 [D loss: (0.639)(R 0.701, F 0.577)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.871] [G acc: 0.375]\n",
      "10334 [D loss: (0.664)(R 0.706, F 0.621)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.822] [G acc: 0.438]\n",
      "10335 [D loss: (0.675)(R 0.659, F 0.690)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.768] [G acc: 0.625]\n",
      "10336 [D loss: (0.740)(R 0.808, F 0.672)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.794] [G acc: 0.625]\n",
      "10337 [D loss: (0.758)(R 0.837, F 0.679)] [D acc: (0.406)(0.500, 0.312)] [G loss: 0.837] [G acc: 0.375]\n",
      "10338 [D loss: (0.741)(R 0.703, F 0.779)] [D acc: (0.375)(0.438, 0.312)] [G loss: 0.816] [G acc: 0.438]\n",
      "10339 [D loss: (0.679)(R 0.663, F 0.694)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.819] [G acc: 0.438]\n",
      "10340 [D loss: (0.752)(R 0.789, F 0.715)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.743] [G acc: 0.500]\n",
      "10341 [D loss: (0.650)(R 0.613, F 0.687)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.801] [G acc: 0.375]\n",
      "10342 [D loss: (0.678)(R 0.662, F 0.695)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.897] [G acc: 0.438]\n",
      "10343 [D loss: (0.633)(R 0.622, F 0.645)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.878] [G acc: 0.250]\n",
      "10344 [D loss: (0.644)(R 0.642, F 0.647)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.784] [G acc: 0.500]\n",
      "10345 [D loss: (0.672)(R 0.652, F 0.692)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.825] [G acc: 0.500]\n",
      "10346 [D loss: (0.665)(R 0.698, F 0.632)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.901] [G acc: 0.188]\n",
      "10347 [D loss: (0.632)(R 0.648, F 0.615)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.787] [G acc: 0.438]\n",
      "10348 [D loss: (0.630)(R 0.659, F 0.600)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.823] [G acc: 0.188]\n",
      "10349 [D loss: (0.630)(R 0.658, F 0.602)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.912] [G acc: 0.250]\n",
      "10350 [D loss: (0.682)(R 0.686, F 0.678)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.810] [G acc: 0.438]\n",
      "10351 [D loss: (0.684)(R 0.713, F 0.655)] [D acc: (0.562)(0.562, 0.562)] [G loss: 1.024] [G acc: 0.125]\n",
      "10352 [D loss: (0.627)(R 0.728, F 0.525)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.939] [G acc: 0.375]\n",
      "10353 [D loss: (0.675)(R 0.597, F 0.753)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.806] [G acc: 0.375]\n",
      "10354 [D loss: (0.695)(R 0.749, F 0.642)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.750] [G acc: 0.688]\n",
      "10355 [D loss: (0.686)(R 0.639, F 0.734)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.949] [G acc: 0.438]\n",
      "10356 [D loss: (0.681)(R 0.753, F 0.610)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.812] [G acc: 0.438]\n",
      "10357 [D loss: (0.704)(R 0.816, F 0.592)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.929] [G acc: 0.438]\n",
      "10358 [D loss: (0.671)(R 0.644, F 0.698)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.774] [G acc: 0.500]\n",
      "10359 [D loss: (0.696)(R 0.675, F 0.716)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.911] [G acc: 0.250]\n",
      "10360 [D loss: (0.614)(R 0.564, F 0.664)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.897] [G acc: 0.125]\n",
      "10361 [D loss: (0.711)(R 0.742, F 0.679)] [D acc: (0.375)(0.250, 0.500)] [G loss: 0.883] [G acc: 0.312]\n",
      "10362 [D loss: (0.685)(R 0.667, F 0.703)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.774] [G acc: 0.312]\n",
      "10363 [D loss: (0.705)(R 0.675, F 0.735)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.766] [G acc: 0.500]\n",
      "10364 [D loss: (0.651)(R 0.780, F 0.521)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.846] [G acc: 0.375]\n",
      "10365 [D loss: (0.612)(R 0.581, F 0.643)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.721] [G acc: 0.500]\n",
      "10366 [D loss: (0.605)(R 0.597, F 0.612)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.853] [G acc: 0.250]\n",
      "10367 [D loss: (0.679)(R 0.711, F 0.647)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.951] [G acc: 0.188]\n",
      "10368 [D loss: (0.633)(R 0.631, F 0.635)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.820] [G acc: 0.312]\n",
      "10369 [D loss: (0.636)(R 0.602, F 0.671)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.920] [G acc: 0.125]\n",
      "10370 [D loss: (0.622)(R 0.652, F 0.591)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.888] [G acc: 0.062]\n",
      "10371 [D loss: (0.593)(R 0.595, F 0.591)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.899] [G acc: 0.250]\n",
      "10372 [D loss: (0.610)(R 0.640, F 0.581)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.850] [G acc: 0.438]\n",
      "10373 [D loss: (0.635)(R 0.649, F 0.622)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.935] [G acc: 0.250]\n",
      "10374 [D loss: (0.671)(R 0.788, F 0.554)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.871] [G acc: 0.188]\n",
      "10375 [D loss: (0.628)(R 0.672, F 0.584)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.001] [G acc: 0.312]\n",
      "10376 [D loss: (0.615)(R 0.637, F 0.594)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.838] [G acc: 0.500]\n",
      "10377 [D loss: (0.646)(R 0.666, F 0.626)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.887] [G acc: 0.375]\n",
      "10378 [D loss: (0.698)(R 0.806, F 0.590)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.891] [G acc: 0.312]\n",
      "10379 [D loss: (0.696)(R 0.632, F 0.759)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.910] [G acc: 0.312]\n",
      "10380 [D loss: (0.559)(R 0.561, F 0.556)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.207] [G acc: 0.062]\n",
      "10381 [D loss: (0.701)(R 0.787, F 0.615)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.914] [G acc: 0.250]\n",
      "10382 [D loss: (0.593)(R 0.593, F 0.592)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.972] [G acc: 0.188]\n",
      "10383 [D loss: (0.610)(R 0.654, F 0.567)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.168] [G acc: 0.125]\n",
      "10384 [D loss: (0.573)(R 0.670, F 0.475)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.424] [G acc: 0.312]\n",
      "10385 [D loss: (0.555)(R 0.757, F 0.353)] [D acc: (0.594)(0.438, 0.750)] [G loss: 1.812] [G acc: 0.188]\n",
      "10386 [D loss: (0.715)(R 0.759, F 0.672)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.938] [G acc: 0.500]\n",
      "10387 [D loss: (0.769)(R 0.717, F 0.821)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.765] [G acc: 0.500]\n",
      "10388 [D loss: (0.784)(R 0.731, F 0.838)] [D acc: (0.312)(0.438, 0.188)] [G loss: 0.735] [G acc: 0.500]\n",
      "10389 [D loss: (0.610)(R 0.609, F 0.612)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.992] [G acc: 0.312]\n",
      "10390 [D loss: (0.773)(R 0.744, F 0.802)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.822] [G acc: 0.500]\n",
      "10391 [D loss: (0.790)(R 0.739, F 0.841)] [D acc: (0.344)(0.500, 0.188)] [G loss: 0.766] [G acc: 0.625]\n",
      "10392 [D loss: (0.809)(R 0.752, F 0.866)] [D acc: (0.406)(0.625, 0.188)] [G loss: 0.715] [G acc: 0.625]\n",
      "10393 [D loss: (0.702)(R 0.612, F 0.792)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.818] [G acc: 0.500]\n",
      "10394 [D loss: (0.782)(R 0.765, F 0.798)] [D acc: (0.281)(0.375, 0.188)] [G loss: 0.838] [G acc: 0.500]\n",
      "10395 [D loss: (0.678)(R 0.663, F 0.692)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.779] [G acc: 0.562]\n",
      "10396 [D loss: (0.683)(R 0.602, F 0.765)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.748] [G acc: 0.562]\n",
      "10397 [D loss: (0.716)(R 0.579, F 0.854)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.784] [G acc: 0.562]\n",
      "10398 [D loss: (0.708)(R 0.629, F 0.787)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.839] [G acc: 0.500]\n",
      "10399 [D loss: (0.702)(R 0.557, F 0.847)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.704] [G acc: 0.688]\n",
      "10400 [D loss: (0.696)(R 0.667, F 0.726)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.774] [G acc: 0.562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10401 [D loss: (0.656)(R 0.607, F 0.705)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.754] [G acc: 0.750]\n",
      "10402 [D loss: (0.699)(R 0.705, F 0.693)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.737] [G acc: 0.812]\n",
      "10403 [D loss: (0.674)(R 0.603, F 0.746)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.815] [G acc: 0.562]\n",
      "10404 [D loss: (0.690)(R 0.640, F 0.741)] [D acc: (0.531)(0.688, 0.375)] [G loss: 1.007] [G acc: 0.562]\n",
      "10405 [D loss: (1.305)(R 1.863, F 0.747)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.797] [G acc: 0.625]\n",
      "10406 [D loss: (0.722)(R 0.660, F 0.784)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.752] [G acc: 0.625]\n",
      "10407 [D loss: (0.747)(R 0.674, F 0.819)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.807] [G acc: 0.688]\n",
      "10408 [D loss: (0.711)(R 0.596, F 0.825)] [D acc: (0.438)(0.688, 0.188)] [G loss: 0.759] [G acc: 0.688]\n",
      "10409 [D loss: (0.660)(R 0.583, F 0.738)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.804] [G acc: 0.500]\n",
      "10410 [D loss: (0.740)(R 0.713, F 0.767)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.731] [G acc: 0.688]\n",
      "10411 [D loss: (0.740)(R 0.675, F 0.806)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.723] [G acc: 0.750]\n",
      "10412 [D loss: (0.583)(R 0.566, F 0.599)] [D acc: (0.750)(0.938, 0.562)] [G loss: 0.833] [G acc: 0.688]\n",
      "10413 [D loss: (0.714)(R 0.673, F 0.755)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.738] [G acc: 0.625]\n",
      "10414 [D loss: (0.635)(R 0.551, F 0.720)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.810] [G acc: 0.625]\n",
      "10415 [D loss: (0.733)(R 0.671, F 0.795)] [D acc: (0.406)(0.688, 0.125)] [G loss: 0.782] [G acc: 0.500]\n",
      "10416 [D loss: (0.651)(R 0.615, F 0.687)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.762] [G acc: 0.688]\n",
      "10417 [D loss: (0.657)(R 0.605, F 0.708)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.784] [G acc: 0.750]\n",
      "10418 [D loss: (0.611)(R 0.545, F 0.676)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.709] [G acc: 0.750]\n",
      "10419 [D loss: (0.618)(R 0.588, F 0.648)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.740] [G acc: 0.688]\n",
      "10420 [D loss: (0.668)(R 0.574, F 0.762)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.872] [G acc: 0.625]\n",
      "10421 [D loss: (0.642)(R 0.652, F 0.632)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.850] [G acc: 0.438]\n",
      "10422 [D loss: (0.726)(R 0.703, F 0.749)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.828] [G acc: 0.625]\n",
      "10423 [D loss: (0.683)(R 0.704, F 0.663)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.789] [G acc: 0.688]\n",
      "10424 [D loss: (0.637)(R 0.643, F 0.632)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.760] [G acc: 0.688]\n",
      "10425 [D loss: (0.627)(R 0.570, F 0.684)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.825] [G acc: 0.688]\n",
      "10426 [D loss: (0.675)(R 0.677, F 0.673)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.704] [G acc: 0.812]\n",
      "10427 [D loss: (0.726)(R 0.752, F 0.699)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.760] [G acc: 0.438]\n",
      "10428 [D loss: (0.671)(R 0.659, F 0.684)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.834] [G acc: 0.625]\n",
      "10429 [D loss: (0.613)(R 0.544, F 0.681)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.724] [G acc: 0.688]\n",
      "10430 [D loss: (0.655)(R 0.645, F 0.664)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.698] [G acc: 0.750]\n",
      "10431 [D loss: (0.641)(R 0.559, F 0.723)] [D acc: (0.688)(1.000, 0.375)] [G loss: 0.752] [G acc: 0.688]\n",
      "10432 [D loss: (0.621)(R 0.593, F 0.649)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.790] [G acc: 0.625]\n",
      "10433 [D loss: (0.663)(R 0.580, F 0.746)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.734] [G acc: 0.812]\n",
      "10434 [D loss: (0.677)(R 0.640, F 0.715)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.797] [G acc: 0.438]\n",
      "10435 [D loss: (0.699)(R 0.631, F 0.767)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.773] [G acc: 0.625]\n",
      "10436 [D loss: (0.683)(R 0.724, F 0.643)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.851] [G acc: 0.625]\n",
      "10437 [D loss: (0.690)(R 0.615, F 0.765)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.769] [G acc: 0.750]\n",
      "10438 [D loss: (0.719)(R 0.718, F 0.721)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.727] [G acc: 0.688]\n",
      "10439 [D loss: (0.663)(R 0.604, F 0.722)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.704] [G acc: 0.750]\n",
      "10440 [D loss: (0.720)(R 0.756, F 0.684)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.739] [G acc: 0.750]\n",
      "10441 [D loss: (0.723)(R 0.738, F 0.709)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.818] [G acc: 0.500]\n",
      "10442 [D loss: (0.788)(R 0.957, F 0.619)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.727] [G acc: 0.688]\n",
      "10443 [D loss: (0.639)(R 0.601, F 0.678)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.720] [G acc: 0.625]\n",
      "10444 [D loss: (0.682)(R 0.557, F 0.806)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.747] [G acc: 0.562]\n",
      "10445 [D loss: (0.705)(R 0.603, F 0.806)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.710] [G acc: 0.625]\n",
      "10446 [D loss: (0.807)(R 0.710, F 0.905)] [D acc: (0.438)(0.688, 0.188)] [G loss: 0.762] [G acc: 0.625]\n",
      "10447 [D loss: (0.813)(R 0.777, F 0.850)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.704] [G acc: 0.688]\n",
      "10448 [D loss: (0.725)(R 0.556, F 0.893)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.684] [G acc: 0.812]\n",
      "10449 [D loss: (0.736)(R 0.746, F 0.726)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.592] [G acc: 0.750]\n",
      "10450 [D loss: (0.667)(R 0.594, F 0.741)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.663] [G acc: 0.812]\n",
      "10451 [D loss: (0.759)(R 0.695, F 0.823)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.719] [G acc: 0.688]\n",
      "10452 [D loss: (0.772)(R 0.589, F 0.955)] [D acc: (0.406)(0.812, 0.000)] [G loss: 0.604] [G acc: 0.812]\n",
      "10453 [D loss: (0.666)(R 0.500, F 0.833)] [D acc: (0.688)(1.000, 0.375)] [G loss: 0.627] [G acc: 0.562]\n",
      "10454 [D loss: (0.753)(R 0.607, F 0.899)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.614] [G acc: 0.750]\n",
      "10455 [D loss: (0.684)(R 0.610, F 0.758)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.620] [G acc: 0.625]\n",
      "10456 [D loss: (0.734)(R 0.640, F 0.828)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.609] [G acc: 0.812]\n",
      "10457 [D loss: (0.762)(R 0.580, F 0.944)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.748] [G acc: 0.688]\n",
      "10458 [D loss: (0.764)(R 0.588, F 0.940)] [D acc: (0.656)(0.938, 0.375)] [G loss: 0.684] [G acc: 0.750]\n",
      "10459 [D loss: (0.783)(R 0.659, F 0.907)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.667] [G acc: 0.688]\n",
      "10460 [D loss: (0.775)(R 0.568, F 0.982)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.752] [G acc: 0.625]\n",
      "10461 [D loss: (0.823)(R 0.610, F 1.036)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.686] [G acc: 0.688]\n",
      "10462 [D loss: (0.830)(R 0.785, F 0.874)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.690] [G acc: 0.625]\n",
      "10463 [D loss: (0.596)(R 0.544, F 0.648)] [D acc: (0.750)(0.938, 0.562)] [G loss: 0.776] [G acc: 0.562]\n",
      "10464 [D loss: (0.746)(R 0.626, F 0.867)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.691] [G acc: 0.750]\n",
      "10465 [D loss: (0.625)(R 0.563, F 0.686)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.713] [G acc: 0.500]\n",
      "10466 [D loss: (0.774)(R 0.650, F 0.898)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.662] [G acc: 0.750]\n",
      "10467 [D loss: (0.750)(R 0.735, F 0.764)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.670] [G acc: 0.750]\n",
      "10468 [D loss: (0.711)(R 0.606, F 0.815)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.735] [G acc: 0.625]\n",
      "10469 [D loss: (0.665)(R 0.540, F 0.790)] [D acc: (0.625)(1.000, 0.250)] [G loss: 0.626] [G acc: 0.688]\n",
      "10470 [D loss: (0.756)(R 0.615, F 0.896)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.701] [G acc: 0.625]\n",
      "10471 [D loss: (0.688)(R 0.566, F 0.810)] [D acc: (0.562)(0.938, 0.188)] [G loss: 0.681] [G acc: 0.625]\n",
      "10472 [D loss: (0.747)(R 0.652, F 0.842)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.691] [G acc: 0.625]\n",
      "10473 [D loss: (0.726)(R 0.627, F 0.824)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.629] [G acc: 0.562]\n",
      "10474 [D loss: (0.694)(R 0.565, F 0.822)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.700] [G acc: 0.688]\n",
      "10475 [D loss: (0.807)(R 0.661, F 0.953)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.637] [G acc: 0.750]\n",
      "10476 [D loss: (0.685)(R 0.551, F 0.819)] [D acc: (0.562)(0.938, 0.188)] [G loss: 0.672] [G acc: 0.625]\n",
      "10477 [D loss: (0.724)(R 0.602, F 0.847)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.623] [G acc: 0.750]\n",
      "10478 [D loss: (0.650)(R 0.542, F 0.757)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.673] [G acc: 0.625]\n",
      "10479 [D loss: (0.786)(R 0.689, F 0.883)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.635] [G acc: 0.750]\n",
      "10480 [D loss: (0.804)(R 0.679, F 0.929)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.665] [G acc: 0.688]\n",
      "10481 [D loss: (0.657)(R 0.539, F 0.775)] [D acc: (0.688)(1.000, 0.375)] [G loss: 0.658] [G acc: 0.688]\n",
      "10482 [D loss: (0.742)(R 0.663, F 0.820)] [D acc: (0.375)(0.625, 0.125)] [G loss: 0.604] [G acc: 0.812]\n",
      "10483 [D loss: (0.760)(R 0.670, F 0.850)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.656] [G acc: 0.688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10484 [D loss: (0.648)(R 0.549, F 0.747)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.603] [G acc: 0.750]\n",
      "10485 [D loss: (0.770)(R 0.692, F 0.847)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.571] [G acc: 0.812]\n",
      "10486 [D loss: (0.712)(R 0.560, F 0.863)] [D acc: (0.500)(0.938, 0.062)] [G loss: 0.669] [G acc: 0.562]\n",
      "10487 [D loss: (0.787)(R 0.750, F 0.825)] [D acc: (0.438)(0.688, 0.188)] [G loss: 0.623] [G acc: 0.688]\n",
      "10488 [D loss: (0.733)(R 0.598, F 0.869)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.571] [G acc: 0.750]\n",
      "10489 [D loss: (0.692)(R 0.623, F 0.761)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.572] [G acc: 0.750]\n",
      "10490 [D loss: (0.631)(R 0.560, F 0.702)] [D acc: (0.719)(0.938, 0.500)] [G loss: 1.537] [G acc: 0.312]\n",
      "10491 [D loss: (0.638)(R 0.744, F 0.531)] [D acc: (0.562)(0.562, 0.562)] [G loss: 1.209] [G acc: 0.375]\n",
      "10492 [D loss: (0.800)(R 0.750, F 0.850)] [D acc: (0.344)(0.625, 0.062)] [G loss: 0.677] [G acc: 0.688]\n",
      "10493 [D loss: (0.681)(R 0.592, F 0.771)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.781] [G acc: 0.375]\n",
      "10494 [D loss: (0.729)(R 0.674, F 0.783)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.683] [G acc: 0.500]\n",
      "10495 [D loss: (0.755)(R 0.647, F 0.863)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.634] [G acc: 0.625]\n",
      "10496 [D loss: (0.686)(R 0.639, F 0.733)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.612] [G acc: 0.938]\n",
      "10497 [D loss: (0.720)(R 0.737, F 0.703)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.724] [G acc: 0.625]\n",
      "10498 [D loss: (0.668)(R 0.641, F 0.695)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.847] [G acc: 0.312]\n",
      "10499 [D loss: (0.628)(R 0.546, F 0.710)] [D acc: (0.719)(1.000, 0.438)] [G loss: 0.708] [G acc: 0.625]\n",
      "10500 [D loss: (0.688)(R 0.700, F 0.677)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.746] [G acc: 0.375]\n",
      "10501 [D loss: (0.654)(R 0.636, F 0.673)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.871] [G acc: 0.188]\n",
      "10502 [D loss: (0.635)(R 0.615, F 0.656)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.752] [G acc: 0.562]\n",
      "10503 [D loss: (0.653)(R 0.609, F 0.697)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.780] [G acc: 0.500]\n",
      "10504 [D loss: (0.672)(R 0.594, F 0.750)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.794] [G acc: 0.375]\n",
      "10505 [D loss: (0.681)(R 0.636, F 0.726)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.699] [G acc: 0.625]\n",
      "10506 [D loss: (0.664)(R 0.567, F 0.761)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.806] [G acc: 0.375]\n",
      "10507 [D loss: (0.672)(R 0.628, F 0.715)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.746] [G acc: 0.438]\n",
      "10508 [D loss: (0.660)(R 0.657, F 0.662)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.672] [G acc: 0.625]\n",
      "10509 [D loss: (0.683)(R 0.642, F 0.723)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.771] [G acc: 0.500]\n",
      "10510 [D loss: (0.640)(R 0.603, F 0.678)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.773] [G acc: 0.438]\n",
      "10511 [D loss: (0.654)(R 0.578, F 0.730)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.724] [G acc: 0.688]\n",
      "10512 [D loss: (0.665)(R 0.673, F 0.658)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.841] [G acc: 0.375]\n",
      "10513 [D loss: (0.661)(R 0.589, F 0.734)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.801] [G acc: 0.438]\n",
      "10514 [D loss: (0.624)(R 0.554, F 0.695)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.828] [G acc: 0.375]\n",
      "10515 [D loss: (0.628)(R 0.615, F 0.642)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.749] [G acc: 0.688]\n",
      "10516 [D loss: (0.656)(R 0.650, F 0.662)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.789] [G acc: 0.438]\n",
      "10517 [D loss: (0.668)(R 0.676, F 0.661)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.734] [G acc: 0.625]\n",
      "10518 [D loss: (0.648)(R 0.664, F 0.633)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.745] [G acc: 0.562]\n",
      "10519 [D loss: (0.684)(R 0.667, F 0.701)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.762] [G acc: 0.438]\n",
      "10520 [D loss: (0.687)(R 0.629, F 0.745)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.746] [G acc: 0.625]\n",
      "10521 [D loss: (0.694)(R 0.662, F 0.726)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.777] [G acc: 0.500]\n",
      "10522 [D loss: (0.607)(R 0.560, F 0.654)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.690] [G acc: 0.688]\n",
      "10523 [D loss: (0.719)(R 0.723, F 0.715)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.795] [G acc: 0.375]\n",
      "10524 [D loss: (0.653)(R 0.614, F 0.693)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.869] [G acc: 0.188]\n",
      "10525 [D loss: (0.649)(R 0.635, F 0.663)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.671] [G acc: 0.625]\n",
      "10526 [D loss: (0.677)(R 0.669, F 0.685)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.753] [G acc: 0.438]\n",
      "10527 [D loss: (0.646)(R 0.576, F 0.715)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.841] [G acc: 0.312]\n",
      "10528 [D loss: (0.627)(R 0.604, F 0.650)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.816] [G acc: 0.312]\n",
      "10529 [D loss: (0.690)(R 0.652, F 0.727)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.792] [G acc: 0.438]\n",
      "10530 [D loss: (0.626)(R 0.599, F 0.654)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.811] [G acc: 0.312]\n",
      "10531 [D loss: (0.616)(R 0.546, F 0.686)] [D acc: (0.750)(1.000, 0.500)] [G loss: 0.801] [G acc: 0.188]\n",
      "10532 [D loss: (0.671)(R 0.686, F 0.655)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.796] [G acc: 0.375]\n",
      "10533 [D loss: (0.676)(R 0.702, F 0.650)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.904] [G acc: 0.375]\n",
      "10534 [D loss: (0.674)(R 0.703, F 0.645)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.888] [G acc: 0.312]\n",
      "10535 [D loss: (0.596)(R 0.640, F 0.553)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.351] [G acc: 0.188]\n",
      "10536 [D loss: (0.514)(R 0.542, F 0.485)] [D acc: (0.938)(1.000, 0.875)] [G loss: 1.002] [G acc: 0.188]\n",
      "10537 [D loss: (0.597)(R 0.640, F 0.553)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.861] [G acc: 0.250]\n",
      "10538 [D loss: (0.598)(R 0.616, F 0.580)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.887] [G acc: 0.250]\n",
      "10539 [D loss: (0.605)(R 0.631, F 0.579)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.894] [G acc: 0.188]\n",
      "10540 [D loss: (0.590)(R 0.556, F 0.625)] [D acc: (0.875)(0.938, 0.812)] [G loss: 0.763] [G acc: 0.625]\n",
      "10541 [D loss: (0.661)(R 0.667, F 0.656)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.891] [G acc: 0.250]\n",
      "10542 [D loss: (0.647)(R 0.660, F 0.633)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.908] [G acc: 0.188]\n",
      "10543 [D loss: (0.616)(R 0.604, F 0.629)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.907] [G acc: 0.312]\n",
      "10544 [D loss: (0.663)(R 0.588, F 0.738)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.743] [G acc: 0.500]\n",
      "10545 [D loss: (0.609)(R 0.602, F 0.616)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.858] [G acc: 0.188]\n",
      "10546 [D loss: (0.606)(R 0.618, F 0.593)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.770] [G acc: 0.312]\n",
      "10547 [D loss: (0.670)(R 0.717, F 0.622)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.837] [G acc: 0.250]\n",
      "10548 [D loss: (0.609)(R 0.573, F 0.644)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.846] [G acc: 0.312]\n",
      "10549 [D loss: (0.645)(R 0.674, F 0.617)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.840] [G acc: 0.250]\n",
      "10550 [D loss: (0.732)(R 0.775, F 0.688)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.926] [G acc: 0.250]\n",
      "10551 [D loss: (0.605)(R 0.626, F 0.584)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.654] [G acc: 0.625]\n",
      "10552 [D loss: (0.595)(R 0.591, F 0.599)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.879] [G acc: 0.188]\n",
      "10553 [D loss: (0.666)(R 0.638, F 0.693)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.732] [G acc: 0.750]\n",
      "10554 [D loss: (0.599)(R 0.569, F 0.629)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.667] [G acc: 0.750]\n",
      "10555 [D loss: (0.629)(R 0.551, F 0.707)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.917] [G acc: 0.250]\n",
      "10556 [D loss: (0.605)(R 0.616, F 0.594)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.964] [G acc: 0.250]\n",
      "10557 [D loss: (0.668)(R 0.660, F 0.676)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.846] [G acc: 0.438]\n",
      "10558 [D loss: (0.637)(R 0.600, F 0.674)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.845] [G acc: 0.438]\n",
      "10559 [D loss: (0.648)(R 0.628, F 0.667)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.829] [G acc: 0.375]\n",
      "10560 [D loss: (0.640)(R 0.610, F 0.670)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.830] [G acc: 0.375]\n",
      "10561 [D loss: (0.649)(R 0.637, F 0.660)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.927] [G acc: 0.250]\n",
      "10562 [D loss: (0.633)(R 0.671, F 0.595)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.850] [G acc: 0.250]\n",
      "10563 [D loss: (0.604)(R 0.602, F 0.605)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.802] [G acc: 0.250]\n",
      "10564 [D loss: (0.580)(R 0.588, F 0.571)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.959] [G acc: 0.188]\n",
      "10565 [D loss: (0.584)(R 0.559, F 0.608)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.818] [G acc: 0.562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10566 [D loss: (0.646)(R 0.645, F 0.648)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.887] [G acc: 0.375]\n",
      "10567 [D loss: (0.645)(R 0.627, F 0.663)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.782] [G acc: 0.500]\n",
      "10568 [D loss: (0.643)(R 0.529, F 0.757)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.882] [G acc: 0.250]\n",
      "10569 [D loss: (0.586)(R 0.591, F 0.581)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.948] [G acc: 0.062]\n",
      "10570 [D loss: (0.613)(R 0.565, F 0.662)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.832] [G acc: 0.188]\n",
      "10571 [D loss: (0.627)(R 0.588, F 0.666)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.839] [G acc: 0.250]\n",
      "10572 [D loss: (0.659)(R 0.655, F 0.664)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.763] [G acc: 0.375]\n",
      "10573 [D loss: (0.654)(R 0.586, F 0.723)] [D acc: (0.719)(0.875, 0.562)] [G loss: 1.058] [G acc: 0.125]\n",
      "10574 [D loss: (0.577)(R 0.688, F 0.466)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.092] [G acc: 0.250]\n",
      "10575 [D loss: (0.580)(R 0.605, F 0.555)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.035] [G acc: 0.250]\n",
      "10576 [D loss: (0.663)(R 0.660, F 0.666)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.685] [G acc: 0.625]\n",
      "10577 [D loss: (0.721)(R 0.699, F 0.742)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.637] [G acc: 0.688]\n",
      "10578 [D loss: (0.676)(R 0.701, F 0.651)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.896] [G acc: 0.312]\n",
      "10579 [D loss: (0.656)(R 0.657, F 0.656)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.996] [G acc: 0.188]\n",
      "10580 [D loss: (0.710)(R 0.713, F 0.707)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.824] [G acc: 0.438]\n",
      "10581 [D loss: (0.739)(R 0.737, F 0.741)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.744] [G acc: 0.375]\n",
      "10582 [D loss: (0.627)(R 0.574, F 0.681)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.963] [G acc: 0.125]\n",
      "10583 [D loss: (0.718)(R 0.740, F 0.697)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.822] [G acc: 0.438]\n",
      "10584 [D loss: (0.638)(R 0.628, F 0.649)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.901] [G acc: 0.188]\n",
      "10585 [D loss: (0.662)(R 0.678, F 0.645)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.868] [G acc: 0.312]\n",
      "10586 [D loss: (0.733)(R 0.808, F 0.658)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.841] [G acc: 0.375]\n",
      "10587 [D loss: (0.722)(R 0.692, F 0.752)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.814] [G acc: 0.312]\n",
      "10588 [D loss: (0.629)(R 0.599, F 0.660)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.864] [G acc: 0.250]\n",
      "10589 [D loss: (0.712)(R 0.737, F 0.686)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.843] [G acc: 0.250]\n",
      "10590 [D loss: (0.658)(R 0.684, F 0.631)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.648] [G acc: 0.688]\n",
      "10591 [D loss: (0.654)(R 0.658, F 0.649)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.975] [G acc: 0.188]\n",
      "10592 [D loss: (0.659)(R 0.722, F 0.597)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.886] [G acc: 0.312]\n",
      "10593 [D loss: (0.616)(R 0.584, F 0.648)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.723] [G acc: 0.625]\n",
      "10594 [D loss: (0.679)(R 0.656, F 0.701)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.830] [G acc: 0.250]\n",
      "10595 [D loss: (0.714)(R 0.657, F 0.771)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.908] [G acc: 0.312]\n",
      "10596 [D loss: (0.645)(R 0.655, F 0.635)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.630] [G acc: 0.812]\n",
      "10597 [D loss: (0.643)(R 0.594, F 0.692)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.802] [G acc: 0.438]\n",
      "10598 [D loss: (0.683)(R 0.653, F 0.714)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.763] [G acc: 0.562]\n",
      "10599 [D loss: (0.660)(R 0.617, F 0.704)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.953] [G acc: 0.312]\n",
      "10600 [D loss: (0.697)(R 0.661, F 0.734)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.737] [G acc: 0.625]\n",
      "10601 [D loss: (0.662)(R 0.678, F 0.646)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.762] [G acc: 0.500]\n",
      "10602 [D loss: (0.738)(R 0.708, F 0.768)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.749] [G acc: 0.625]\n",
      "10603 [D loss: (0.739)(R 0.755, F 0.722)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.911] [G acc: 0.375]\n",
      "10604 [D loss: (0.628)(R 0.627, F 0.628)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.784] [G acc: 0.500]\n",
      "10605 [D loss: (0.614)(R 0.653, F 0.576)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.812] [G acc: 0.688]\n",
      "10606 [D loss: (0.635)(R 0.719, F 0.550)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.832] [G acc: 0.375]\n",
      "10607 [D loss: (0.681)(R 0.637, F 0.725)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.811] [G acc: 0.562]\n",
      "10608 [D loss: (0.582)(R 0.571, F 0.593)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.986] [G acc: 0.250]\n",
      "10609 [D loss: (0.587)(R 0.669, F 0.504)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.870] [G acc: 0.312]\n",
      "10610 [D loss: (0.672)(R 0.753, F 0.590)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.915] [G acc: 0.375]\n",
      "10611 [D loss: (0.554)(R 0.555, F 0.553)] [D acc: (0.781)(0.938, 0.625)] [G loss: 0.689] [G acc: 0.688]\n",
      "10612 [D loss: (0.707)(R 0.746, F 0.669)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.825] [G acc: 0.500]\n",
      "10613 [D loss: (0.674)(R 0.616, F 0.733)] [D acc: (0.531)(0.688, 0.375)] [G loss: 1.183] [G acc: 0.125]\n",
      "10614 [D loss: (0.537)(R 0.809, F 0.264)] [D acc: (0.719)(0.562, 0.875)] [G loss: 7.513] [G acc: 0.125]\n",
      "10615 [D loss: (0.633)(R 0.625, F 0.641)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.750] [G acc: 0.500]\n",
      "10616 [D loss: (0.643)(R 0.697, F 0.590)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.949] [G acc: 0.375]\n",
      "10617 [D loss: (0.644)(R 0.663, F 0.626)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.818] [G acc: 0.625]\n",
      "10618 [D loss: (0.724)(R 0.640, F 0.808)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.837] [G acc: 0.438]\n",
      "10619 [D loss: (0.788)(R 0.802, F 0.773)] [D acc: (0.375)(0.438, 0.312)] [G loss: 0.848] [G acc: 0.438]\n",
      "10620 [D loss: (0.734)(R 0.717, F 0.750)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.842] [G acc: 0.438]\n",
      "10621 [D loss: (0.668)(R 0.586, F 0.749)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.839] [G acc: 0.562]\n",
      "10622 [D loss: (0.654)(R 0.665, F 0.642)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.888] [G acc: 0.375]\n",
      "10623 [D loss: (0.674)(R 0.614, F 0.735)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.739] [G acc: 0.625]\n",
      "10624 [D loss: (0.654)(R 0.651, F 0.657)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.858] [G acc: 0.625]\n",
      "10625 [D loss: (0.682)(R 0.679, F 0.684)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.747] [G acc: 0.625]\n",
      "10626 [D loss: (0.637)(R 0.592, F 0.683)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.846] [G acc: 0.562]\n",
      "10627 [D loss: (0.633)(R 0.644, F 0.623)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.854] [G acc: 0.500]\n",
      "10628 [D loss: (0.710)(R 0.714, F 0.707)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.767] [G acc: 0.625]\n",
      "10629 [D loss: (0.765)(R 0.707, F 0.823)] [D acc: (0.406)(0.688, 0.125)] [G loss: 0.829] [G acc: 0.375]\n",
      "10630 [D loss: (0.724)(R 0.693, F 0.755)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.815] [G acc: 0.438]\n",
      "10631 [D loss: (0.682)(R 0.641, F 0.724)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.824] [G acc: 0.438]\n",
      "10632 [D loss: (0.733)(R 0.745, F 0.720)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.827] [G acc: 0.688]\n",
      "10633 [D loss: (0.673)(R 0.655, F 0.691)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.795] [G acc: 0.625]\n",
      "10634 [D loss: (0.670)(R 0.629, F 0.711)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.747] [G acc: 0.625]\n",
      "10635 [D loss: (0.627)(R 0.594, F 0.659)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.756] [G acc: 0.625]\n",
      "10636 [D loss: (0.638)(R 0.581, F 0.695)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.990] [G acc: 0.625]\n",
      "10637 [D loss: (0.701)(R 0.722, F 0.680)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.818] [G acc: 0.438]\n",
      "10638 [D loss: (0.594)(R 0.598, F 0.590)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.967] [G acc: 0.312]\n",
      "10639 [D loss: (0.716)(R 0.645, F 0.786)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.853] [G acc: 0.562]\n",
      "10640 [D loss: (0.623)(R 0.629, F 0.616)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.828] [G acc: 0.562]\n",
      "10641 [D loss: (0.665)(R 0.630, F 0.700)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.897] [G acc: 0.500]\n",
      "10642 [D loss: (0.704)(R 0.738, F 0.671)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.710] [G acc: 0.750]\n",
      "10643 [D loss: (0.631)(R 0.556, F 0.706)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.904] [G acc: 0.312]\n",
      "10644 [D loss: (0.599)(R 0.580, F 0.617)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.792] [G acc: 0.625]\n",
      "10645 [D loss: (0.621)(R 0.574, F 0.668)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.759] [G acc: 0.688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10646 [D loss: (0.760)(R 0.703, F 0.817)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.678] [G acc: 0.812]\n",
      "10647 [D loss: (0.671)(R 0.601, F 0.742)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.887] [G acc: 0.625]\n",
      "10648 [D loss: (0.717)(R 0.663, F 0.772)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.701] [G acc: 0.625]\n",
      "10649 [D loss: (0.791)(R 0.756, F 0.825)] [D acc: (0.375)(0.562, 0.188)] [G loss: 0.931] [G acc: 0.438]\n",
      "10650 [D loss: (0.844)(R 0.993, F 0.695)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.758] [G acc: 0.750]\n",
      "10651 [D loss: (0.624)(R 0.576, F 0.672)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.744] [G acc: 0.625]\n",
      "10652 [D loss: (0.670)(R 0.725, F 0.614)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.768] [G acc: 0.562]\n",
      "10653 [D loss: (0.739)(R 0.728, F 0.750)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.677] [G acc: 0.812]\n",
      "10654 [D loss: (0.729)(R 0.611, F 0.847)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.783] [G acc: 0.688]\n",
      "10655 [D loss: (0.435)(R 0.540, F 0.331)] [D acc: (0.844)(0.938, 0.750)] [G loss: 2.040] [G acc: 0.188]\n",
      "10656 [D loss: (0.532)(R 0.513, F 0.550)] [D acc: (0.781)(0.938, 0.625)] [G loss: 0.633] [G acc: 0.688]\n",
      "10657 [D loss: (0.543)(R 0.524, F 0.563)] [D acc: (0.812)(0.938, 0.688)] [G loss: 0.856] [G acc: 0.562]\n",
      "10658 [D loss: (0.635)(R 0.622, F 0.648)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.686] [G acc: 0.812]\n",
      "10659 [D loss: (0.672)(R 0.616, F 0.727)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.943] [G acc: 0.500]\n",
      "10660 [D loss: (0.617)(R 0.544, F 0.690)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.658] [G acc: 0.688]\n",
      "10661 [D loss: (0.587)(R 0.527, F 0.647)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.739] [G acc: 0.688]\n",
      "10662 [D loss: (0.576)(R 0.571, F 0.580)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.718] [G acc: 0.750]\n",
      "10663 [D loss: (0.658)(R 0.650, F 0.666)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.836] [G acc: 0.625]\n",
      "10664 [D loss: (0.691)(R 0.621, F 0.762)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.948] [G acc: 0.438]\n",
      "10665 [D loss: (0.635)(R 0.605, F 0.664)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.799] [G acc: 0.688]\n",
      "10666 [D loss: (0.612)(R 0.535, F 0.689)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.707] [G acc: 0.750]\n",
      "10667 [D loss: (0.620)(R 0.533, F 0.707)] [D acc: (0.625)(0.938, 0.312)] [G loss: 1.911] [G acc: 0.125]\n",
      "10668 [D loss: (0.612)(R 0.727, F 0.497)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.219] [G acc: 0.312]\n",
      "10669 [D loss: (0.654)(R 0.700, F 0.608)] [D acc: (0.594)(0.688, 0.500)] [G loss: 1.122] [G acc: 0.375]\n",
      "10670 [D loss: (0.621)(R 0.592, F 0.649)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.844] [G acc: 0.688]\n",
      "10671 [D loss: (0.749)(R 0.694, F 0.804)] [D acc: (0.406)(0.625, 0.188)] [G loss: 0.717] [G acc: 0.750]\n",
      "10672 [D loss: (0.631)(R 0.530, F 0.733)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.806] [G acc: 0.688]\n",
      "10673 [D loss: (0.629)(R 0.577, F 0.680)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.805] [G acc: 0.625]\n",
      "10674 [D loss: (0.743)(R 0.624, F 0.861)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.845] [G acc: 0.625]\n",
      "10675 [D loss: (0.656)(R 0.554, F 0.758)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.938] [G acc: 0.312]\n",
      "10676 [D loss: (0.538)(R 0.551, F 0.524)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.835] [G acc: 0.500]\n",
      "10677 [D loss: (0.716)(R 0.651, F 0.781)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.746] [G acc: 0.688]\n",
      "10678 [D loss: (0.670)(R 0.559, F 0.781)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.700] [G acc: 0.688]\n",
      "10679 [D loss: (0.614)(R 0.549, F 0.680)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.794] [G acc: 0.438]\n",
      "10680 [D loss: (0.606)(R 0.602, F 0.610)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.860] [G acc: 0.562]\n",
      "10681 [D loss: (0.609)(R 0.543, F 0.674)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.825] [G acc: 0.562]\n",
      "10682 [D loss: (0.665)(R 0.598, F 0.732)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.834] [G acc: 0.625]\n",
      "10683 [D loss: (0.592)(R 0.544, F 0.640)] [D acc: (0.656)(0.875, 0.438)] [G loss: 1.034] [G acc: 0.375]\n",
      "10684 [D loss: (0.708)(R 0.659, F 0.758)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.774] [G acc: 0.750]\n",
      "10685 [D loss: (0.655)(R 0.553, F 0.758)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.983] [G acc: 0.438]\n",
      "10686 [D loss: (0.559)(R 0.510, F 0.608)] [D acc: (0.719)(1.000, 0.438)] [G loss: 0.909] [G acc: 0.625]\n",
      "10687 [D loss: (0.675)(R 0.620, F 0.731)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.705] [G acc: 0.625]\n",
      "10688 [D loss: (0.601)(R 0.596, F 0.606)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.823] [G acc: 0.625]\n",
      "10689 [D loss: (0.555)(R 0.534, F 0.575)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.817] [G acc: 0.625]\n",
      "10690 [D loss: (0.621)(R 0.547, F 0.695)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.917] [G acc: 0.688]\n",
      "10691 [D loss: (0.793)(R 0.809, F 0.777)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.988] [G acc: 0.562]\n",
      "10692 [D loss: (0.681)(R 0.555, F 0.808)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.865] [G acc: 0.625]\n",
      "10693 [D loss: (0.639)(R 0.568, F 0.710)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.829] [G acc: 0.688]\n",
      "10694 [D loss: (0.671)(R 0.661, F 0.680)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.848] [G acc: 0.562]\n",
      "10695 [D loss: (0.577)(R 0.544, F 0.609)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.655] [G acc: 0.812]\n",
      "10696 [D loss: (0.703)(R 0.635, F 0.770)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.749] [G acc: 0.750]\n",
      "10697 [D loss: (0.651)(R 0.535, F 0.766)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.803] [G acc: 0.688]\n",
      "10698 [D loss: (0.725)(R 0.734, F 0.716)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.740] [G acc: 0.688]\n",
      "10699 [D loss: (0.719)(R 0.709, F 0.729)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.703] [G acc: 0.812]\n",
      "10700 [D loss: (0.697)(R 0.645, F 0.749)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.796] [G acc: 0.750]\n",
      "10701 [D loss: (0.669)(R 0.539, F 0.799)] [D acc: (0.625)(1.000, 0.250)] [G loss: 0.716] [G acc: 0.688]\n",
      "10702 [D loss: (0.753)(R 0.655, F 0.850)] [D acc: (0.375)(0.625, 0.125)] [G loss: 0.998] [G acc: 0.438]\n",
      "10703 [D loss: (0.634)(R 0.730, F 0.538)] [D acc: (0.688)(0.812, 0.562)] [G loss: 1.979] [G acc: 0.375]\n",
      "10704 [D loss: (0.550)(R 0.569, F 0.531)] [D acc: (0.719)(0.875, 0.562)] [G loss: 1.620] [G acc: 0.375]\n",
      "10705 [D loss: (0.614)(R 0.536, F 0.692)] [D acc: (0.656)(0.938, 0.375)] [G loss: 0.820] [G acc: 0.500]\n",
      "10706 [D loss: (0.591)(R 0.519, F 0.663)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.864] [G acc: 0.438]\n",
      "10707 [D loss: (0.652)(R 0.603, F 0.700)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.756] [G acc: 0.562]\n",
      "10708 [D loss: (0.658)(R 0.628, F 0.688)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.976] [G acc: 0.688]\n",
      "10709 [D loss: (0.642)(R 0.554, F 0.730)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.846] [G acc: 0.500]\n",
      "10710 [D loss: (0.609)(R 0.665, F 0.553)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.868] [G acc: 0.500]\n",
      "10711 [D loss: (0.605)(R 0.598, F 0.611)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.800] [G acc: 0.562]\n",
      "10712 [D loss: (0.677)(R 0.659, F 0.695)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.947] [G acc: 0.562]\n",
      "10713 [D loss: (0.601)(R 0.656, F 0.547)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.831] [G acc: 0.562]\n",
      "10714 [D loss: (0.705)(R 0.669, F 0.741)] [D acc: (0.531)(0.750, 0.312)] [G loss: 1.013] [G acc: 0.250]\n",
      "10715 [D loss: (0.638)(R 0.657, F 0.619)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.841] [G acc: 0.688]\n",
      "10716 [D loss: (0.623)(R 0.613, F 0.633)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.675] [G acc: 0.812]\n",
      "10717 [D loss: (0.580)(R 0.574, F 0.585)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.789] [G acc: 0.625]\n",
      "10718 [D loss: (0.645)(R 0.658, F 0.631)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.663] [G acc: 0.812]\n",
      "10719 [D loss: (0.660)(R 0.636, F 0.683)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.930] [G acc: 0.438]\n",
      "10720 [D loss: (0.567)(R 0.531, F 0.603)] [D acc: (0.750)(0.938, 0.562)] [G loss: 0.828] [G acc: 0.625]\n",
      "10721 [D loss: (0.622)(R 0.588, F 0.657)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.804] [G acc: 0.688]\n",
      "10722 [D loss: (0.605)(R 0.610, F 0.600)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.880] [G acc: 0.625]\n",
      "10723 [D loss: (0.675)(R 0.638, F 0.711)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.875] [G acc: 0.625]\n",
      "10724 [D loss: (0.704)(R 0.749, F 0.660)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.807] [G acc: 0.625]\n",
      "10725 [D loss: (0.657)(R 0.556, F 0.759)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.785] [G acc: 0.625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10726 [D loss: (0.707)(R 0.719, F 0.695)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.905] [G acc: 0.625]\n",
      "10727 [D loss: (0.623)(R 0.645, F 0.602)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.802] [G acc: 0.625]\n",
      "10728 [D loss: (0.632)(R 0.543, F 0.721)] [D acc: (0.562)(0.938, 0.188)] [G loss: 0.856] [G acc: 0.375]\n",
      "10729 [D loss: (0.618)(R 0.598, F 0.639)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.881] [G acc: 0.500]\n",
      "10730 [D loss: (0.657)(R 0.665, F 0.650)] [D acc: (0.594)(0.750, 0.438)] [G loss: 1.079] [G acc: 0.312]\n",
      "10731 [D loss: (0.642)(R 0.529, F 0.755)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.896] [G acc: 0.688]\n",
      "10732 [D loss: (0.591)(R 0.587, F 0.596)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.957] [G acc: 0.562]\n",
      "10733 [D loss: (0.689)(R 0.680, F 0.697)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.856] [G acc: 0.688]\n",
      "10734 [D loss: (0.709)(R 0.657, F 0.761)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.860] [G acc: 0.625]\n",
      "10735 [D loss: (0.798)(R 0.765, F 0.830)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.892] [G acc: 0.312]\n",
      "10736 [D loss: (0.591)(R 0.589, F 0.594)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.907] [G acc: 0.500]\n",
      "10737 [D loss: (0.668)(R 0.644, F 0.691)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.770] [G acc: 0.562]\n",
      "10738 [D loss: (0.673)(R 0.623, F 0.723)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.665] [G acc: 0.812]\n",
      "10739 [D loss: (0.727)(R 0.654, F 0.799)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.740] [G acc: 0.625]\n",
      "10740 [D loss: (0.704)(R 0.628, F 0.781)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.713] [G acc: 0.562]\n",
      "10741 [D loss: (0.652)(R 0.609, F 0.695)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.805] [G acc: 0.562]\n",
      "10742 [D loss: (0.703)(R 0.618, F 0.787)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.762] [G acc: 0.625]\n",
      "10743 [D loss: (0.660)(R 0.550, F 0.770)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.725] [G acc: 0.812]\n",
      "10744 [D loss: (0.631)(R 0.520, F 0.741)] [D acc: (0.625)(1.000, 0.250)] [G loss: 0.974] [G acc: 0.625]\n",
      "10745 [D loss: (0.750)(R 0.716, F 0.785)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.882] [G acc: 0.562]\n",
      "10746 [D loss: (0.675)(R 0.673, F 0.678)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.773] [G acc: 0.750]\n",
      "10747 [D loss: (0.648)(R 0.619, F 0.678)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.785] [G acc: 0.750]\n",
      "10748 [D loss: (0.857)(R 0.934, F 0.781)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.733] [G acc: 0.688]\n",
      "10749 [D loss: (0.679)(R 0.589, F 0.768)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.701] [G acc: 0.750]\n",
      "10750 [D loss: (0.752)(R 0.696, F 0.807)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.903] [G acc: 0.688]\n",
      "10751 [D loss: (0.670)(R 0.569, F 0.770)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.816] [G acc: 0.688]\n",
      "10752 [D loss: (0.612)(R 0.515, F 0.709)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.739] [G acc: 0.688]\n",
      "10753 [D loss: (0.696)(R 0.721, F 0.670)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.710] [G acc: 0.812]\n",
      "10754 [D loss: (0.649)(R 0.551, F 0.746)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.904] [G acc: 0.500]\n",
      "10755 [D loss: (0.372)(R 0.583, F 0.161)] [D acc: (0.844)(0.812, 0.875)] [G loss: 2.491] [G acc: 0.250]\n",
      "10756 [D loss: (0.556)(R 0.567, F 0.545)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.090] [G acc: 0.375]\n",
      "10757 [D loss: (0.683)(R 0.678, F 0.687)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.931] [G acc: 0.438]\n",
      "10758 [D loss: (0.599)(R 0.522, F 0.676)] [D acc: (0.688)(1.000, 0.375)] [G loss: 0.814] [G acc: 0.562]\n",
      "10759 [D loss: (0.689)(R 0.644, F 0.734)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.842] [G acc: 0.688]\n",
      "10760 [D loss: (0.621)(R 0.502, F 0.740)] [D acc: (0.719)(1.000, 0.438)] [G loss: 0.893] [G acc: 0.562]\n",
      "10761 [D loss: (0.571)(R 0.476, F 0.665)] [D acc: (0.719)(1.000, 0.438)] [G loss: 1.005] [G acc: 0.625]\n",
      "10762 [D loss: (0.692)(R 0.613, F 0.770)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.944] [G acc: 0.688]\n",
      "10763 [D loss: (0.653)(R 0.600, F 0.705)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.808] [G acc: 0.750]\n",
      "10764 [D loss: (0.667)(R 0.580, F 0.754)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.880] [G acc: 0.500]\n",
      "10765 [D loss: (0.700)(R 0.584, F 0.816)] [D acc: (0.469)(0.875, 0.062)] [G loss: 1.022] [G acc: 0.562]\n",
      "10766 [D loss: (0.837)(R 0.906, F 0.768)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.875] [G acc: 0.688]\n",
      "10767 [D loss: (0.645)(R 0.614, F 0.676)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.925] [G acc: 0.375]\n",
      "10768 [D loss: (0.624)(R 0.652, F 0.596)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.828] [G acc: 0.562]\n",
      "10769 [D loss: (0.645)(R 0.498, F 0.792)] [D acc: (0.688)(1.000, 0.375)] [G loss: 0.986] [G acc: 0.312]\n",
      "10770 [D loss: (0.602)(R 0.588, F 0.616)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.759] [G acc: 0.812]\n",
      "10771 [D loss: (0.618)(R 0.717, F 0.520)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.989] [G acc: 0.625]\n",
      "10772 [D loss: (0.722)(R 0.674, F 0.769)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.805] [G acc: 0.625]\n",
      "10773 [D loss: (0.697)(R 0.587, F 0.807)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.905] [G acc: 0.625]\n",
      "10774 [D loss: (0.656)(R 0.635, F 0.676)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.851] [G acc: 0.625]\n",
      "10775 [D loss: (0.676)(R 0.576, F 0.777)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.674] [G acc: 0.875]\n",
      "10776 [D loss: (0.633)(R 0.664, F 0.602)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.965] [G acc: 0.500]\n",
      "10777 [D loss: (0.697)(R 0.706, F 0.687)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.875] [G acc: 0.562]\n",
      "10778 [D loss: (0.686)(R 0.614, F 0.758)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.852] [G acc: 0.438]\n",
      "10779 [D loss: (0.617)(R 0.583, F 0.651)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.948] [G acc: 0.625]\n",
      "10780 [D loss: (0.667)(R 0.577, F 0.756)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.737] [G acc: 0.812]\n",
      "10781 [D loss: (0.658)(R 0.581, F 0.735)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.989] [G acc: 0.625]\n",
      "10782 [D loss: (0.683)(R 0.687, F 0.678)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.843] [G acc: 0.625]\n",
      "10783 [D loss: (0.605)(R 0.537, F 0.672)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.865] [G acc: 0.688]\n",
      "10784 [D loss: (0.627)(R 0.589, F 0.666)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.845] [G acc: 0.500]\n",
      "10785 [D loss: (0.682)(R 0.710, F 0.654)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.849] [G acc: 0.562]\n",
      "10786 [D loss: (0.776)(R 0.635, F 0.917)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.807] [G acc: 0.688]\n",
      "10787 [D loss: (0.666)(R 0.534, F 0.799)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.742] [G acc: 0.812]\n",
      "10788 [D loss: (0.601)(R 0.538, F 0.665)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.739] [G acc: 0.688]\n",
      "10789 [D loss: (0.664)(R 0.553, F 0.774)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.832] [G acc: 0.562]\n",
      "10790 [D loss: (0.649)(R 0.588, F 0.710)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.988] [G acc: 0.625]\n",
      "10791 [D loss: (0.671)(R 0.597, F 0.746)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.906] [G acc: 0.562]\n",
      "10792 [D loss: (0.728)(R 0.626, F 0.830)] [D acc: (0.469)(0.875, 0.062)] [G loss: 0.915] [G acc: 0.625]\n",
      "10793 [D loss: (0.652)(R 0.577, F 0.728)] [D acc: (0.594)(0.875, 0.312)] [G loss: 1.062] [G acc: 0.562]\n",
      "10794 [D loss: (0.652)(R 0.618, F 0.685)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.741] [G acc: 0.688]\n",
      "10795 [D loss: (0.768)(R 0.699, F 0.838)] [D acc: (0.375)(0.625, 0.125)] [G loss: 0.840] [G acc: 0.562]\n",
      "10796 [D loss: (0.956)(R 1.146, F 0.766)] [D acc: (0.406)(0.500, 0.312)] [G loss: 0.927] [G acc: 0.625]\n",
      "10797 [D loss: (0.576)(R 0.558, F 0.595)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.713] [G acc: 0.750]\n",
      "10798 [D loss: (0.710)(R 0.672, F 0.749)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.737] [G acc: 0.812]\n",
      "10799 [D loss: (0.652)(R 0.622, F 0.682)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.745] [G acc: 0.562]\n",
      "10800 [D loss: (0.759)(R 0.785, F 0.734)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.756] [G acc: 0.625]\n",
      "10801 [D loss: (0.725)(R 0.698, F 0.752)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.743] [G acc: 0.750]\n",
      "10802 [D loss: (0.482)(R 0.628, F 0.335)] [D acc: (0.781)(0.812, 0.750)] [G loss: 3.432] [G acc: 0.312]\n",
      "10803 [D loss: (0.553)(R 0.585, F 0.521)] [D acc: (0.781)(0.938, 0.625)] [G loss: 1.905] [G acc: 0.438]\n",
      "10804 [D loss: (0.735)(R 0.745, F 0.724)] [D acc: (0.500)(0.750, 0.250)] [G loss: 3.440] [G acc: 0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10805 [D loss: (0.651)(R 0.511, F 0.791)] [D acc: (0.594)(1.000, 0.188)] [G loss: 0.843] [G acc: 0.500]\n",
      "10806 [D loss: (0.822)(R 0.751, F 0.894)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.904] [G acc: 0.375]\n",
      "10807 [D loss: (0.611)(R 0.536, F 0.687)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.877] [G acc: 0.500]\n",
      "10808 [D loss: (0.647)(R 0.606, F 0.688)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.725] [G acc: 0.688]\n",
      "10809 [D loss: (0.591)(R 0.587, F 0.595)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.982] [G acc: 0.312]\n",
      "10810 [D loss: (0.647)(R 0.571, F 0.724)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.882] [G acc: 0.500]\n",
      "10811 [D loss: (0.703)(R 0.706, F 0.699)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.003] [G acc: 0.250]\n",
      "10812 [D loss: (0.681)(R 0.645, F 0.717)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.752] [G acc: 0.625]\n",
      "10813 [D loss: (0.651)(R 0.613, F 0.688)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.926] [G acc: 0.375]\n",
      "10814 [D loss: (0.642)(R 0.593, F 0.692)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.885] [G acc: 0.375]\n",
      "10815 [D loss: (0.646)(R 0.609, F 0.684)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.872] [G acc: 0.375]\n",
      "10816 [D loss: (0.663)(R 0.612, F 0.715)] [D acc: (0.531)(0.750, 0.312)] [G loss: 1.134] [G acc: 0.250]\n",
      "10817 [D loss: (0.619)(R 0.598, F 0.639)] [D acc: (0.625)(0.750, 0.500)] [G loss: 1.017] [G acc: 0.375]\n",
      "10818 [D loss: (0.636)(R 0.700, F 0.571)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.019] [G acc: 0.375]\n",
      "10819 [D loss: (0.589)(R 0.635, F 0.543)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.165] [G acc: 0.312]\n",
      "10820 [D loss: (0.612)(R 0.608, F 0.615)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.974] [G acc: 0.250]\n",
      "10821 [D loss: (0.609)(R 0.618, F 0.599)] [D acc: (0.812)(0.938, 0.688)] [G loss: 0.888] [G acc: 0.312]\n",
      "10822 [D loss: (0.649)(R 0.683, F 0.614)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.913] [G acc: 0.438]\n",
      "10823 [D loss: (0.605)(R 0.691, F 0.519)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.040] [G acc: 0.188]\n",
      "10824 [D loss: (0.667)(R 0.668, F 0.666)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.070] [G acc: 0.312]\n",
      "10825 [D loss: (0.714)(R 0.653, F 0.776)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.936] [G acc: 0.125]\n",
      "10826 [D loss: (0.586)(R 0.618, F 0.554)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.780] [G acc: 0.438]\n",
      "10827 [D loss: (0.560)(R 0.646, F 0.473)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.911] [G acc: 0.250]\n",
      "10828 [D loss: (0.623)(R 0.661, F 0.586)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.974] [G acc: 0.312]\n",
      "10829 [D loss: (0.618)(R 0.670, F 0.565)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.913] [G acc: 0.438]\n",
      "10830 [D loss: (0.512)(R 0.568, F 0.456)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.999] [G acc: 0.250]\n",
      "10831 [D loss: (0.567)(R 0.623, F 0.510)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.963] [G acc: 0.500]\n",
      "10832 [D loss: (0.582)(R 0.634, F 0.530)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.053] [G acc: 0.188]\n",
      "10833 [D loss: (0.675)(R 0.649, F 0.701)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.988] [G acc: 0.250]\n",
      "10834 [D loss: (0.587)(R 0.631, F 0.544)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.057] [G acc: 0.312]\n",
      "10835 [D loss: (0.770)(R 0.791, F 0.748)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.980] [G acc: 0.438]\n",
      "10836 [D loss: (0.645)(R 0.738, F 0.552)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.885] [G acc: 0.625]\n",
      "10837 [D loss: (0.663)(R 0.682, F 0.645)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.813] [G acc: 0.688]\n",
      "10838 [D loss: (0.632)(R 0.674, F 0.591)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.044] [G acc: 0.188]\n",
      "10839 [D loss: (0.621)(R 0.573, F 0.670)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.960] [G acc: 0.188]\n",
      "10840 [D loss: (0.655)(R 0.701, F 0.609)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.665] [G acc: 0.562]\n",
      "10841 [D loss: (0.588)(R 0.549, F 0.626)] [D acc: (0.781)(1.000, 0.562)] [G loss: 0.978] [G acc: 0.312]\n",
      "10842 [D loss: (0.584)(R 0.589, F 0.579)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.836] [G acc: 0.375]\n",
      "10843 [D loss: (0.649)(R 0.722, F 0.576)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.904] [G acc: 0.250]\n",
      "10844 [D loss: (0.707)(R 0.743, F 0.671)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.922] [G acc: 0.500]\n",
      "10845 [D loss: (0.709)(R 0.722, F 0.695)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.961] [G acc: 0.312]\n",
      "10846 [D loss: (0.673)(R 0.705, F 0.641)] [D acc: (0.562)(0.562, 0.562)] [G loss: 1.082] [G acc: 0.250]\n",
      "10847 [D loss: (0.542)(R 0.688, F 0.396)] [D acc: (0.750)(0.688, 0.812)] [G loss: 3.942] [G acc: 0.375]\n",
      "10848 [D loss: (0.595)(R 0.827, F 0.363)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.281] [G acc: 0.188]\n",
      "10849 [D loss: (0.685)(R 0.776, F 0.594)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.743] [G acc: 0.500]\n",
      "10850 [D loss: (0.644)(R 0.624, F 0.665)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.926] [G acc: 0.250]\n",
      "10851 [D loss: (0.724)(R 0.734, F 0.714)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.994] [G acc: 0.062]\n",
      "10852 [D loss: (0.659)(R 0.711, F 0.607)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.923] [G acc: 0.500]\n",
      "10853 [D loss: (0.609)(R 0.635, F 0.583)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.043] [G acc: 0.312]\n",
      "10854 [D loss: (0.849)(R 1.093, F 0.606)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.994] [G acc: 0.250]\n",
      "10855 [D loss: (0.617)(R 0.647, F 0.587)] [D acc: (0.688)(0.812, 0.562)] [G loss: 1.007] [G acc: 0.250]\n",
      "10856 [D loss: (0.624)(R 0.679, F 0.569)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.981] [G acc: 0.250]\n",
      "10857 [D loss: (0.597)(R 0.575, F 0.619)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.835] [G acc: 0.438]\n",
      "10858 [D loss: (0.632)(R 0.601, F 0.663)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.194] [G acc: 0.125]\n",
      "10859 [D loss: (0.588)(R 0.707, F 0.469)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.103] [G acc: 0.188]\n",
      "10860 [D loss: (0.583)(R 0.616, F 0.550)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.998] [G acc: 0.188]\n",
      "10861 [D loss: (0.640)(R 0.692, F 0.588)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.855] [G acc: 0.250]\n",
      "10862 [D loss: (0.626)(R 0.673, F 0.579)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.265] [G acc: 0.125]\n",
      "10863 [D loss: (0.574)(R 0.622, F 0.526)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.786] [G acc: 0.500]\n",
      "10864 [D loss: (0.609)(R 0.630, F 0.589)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.006] [G acc: 0.312]\n",
      "10865 [D loss: (0.654)(R 0.738, F 0.571)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.110] [G acc: 0.188]\n",
      "10866 [D loss: (0.718)(R 0.799, F 0.637)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.923] [G acc: 0.312]\n",
      "10867 [D loss: (0.729)(R 0.833, F 0.626)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.946] [G acc: 0.188]\n",
      "10868 [D loss: (0.656)(R 0.707, F 0.604)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.839] [G acc: 0.438]\n",
      "10869 [D loss: (0.684)(R 0.727, F 0.641)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.754] [G acc: 0.625]\n",
      "10870 [D loss: (0.622)(R 0.721, F 0.523)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.908] [G acc: 0.250]\n",
      "10871 [D loss: (0.729)(R 0.708, F 0.749)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.941] [G acc: 0.375]\n",
      "10872 [D loss: (0.699)(R 0.764, F 0.635)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.929] [G acc: 0.375]\n",
      "10873 [D loss: (0.730)(R 0.805, F 0.656)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.917] [G acc: 0.312]\n",
      "10874 [D loss: (0.779)(R 0.880, F 0.679)] [D acc: (0.406)(0.312, 0.500)] [G loss: 1.099] [G acc: 0.250]\n",
      "10875 [D loss: (0.669)(R 0.776, F 0.561)] [D acc: (0.688)(0.500, 0.875)] [G loss: 1.007] [G acc: 0.188]\n",
      "10876 [D loss: (0.655)(R 0.764, F 0.545)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.918] [G acc: 0.188]\n",
      "10877 [D loss: (0.809)(R 0.982, F 0.636)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.837] [G acc: 0.500]\n",
      "10878 [D loss: (0.721)(R 0.801, F 0.640)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.846] [G acc: 0.500]\n",
      "10879 [D loss: (0.635)(R 0.618, F 0.652)] [D acc: (0.625)(0.750, 0.500)] [G loss: 1.020] [G acc: 0.188]\n",
      "10880 [D loss: (0.729)(R 0.775, F 0.682)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.756] [G acc: 0.562]\n",
      "10881 [D loss: (0.672)(R 0.686, F 0.658)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.870] [G acc: 0.312]\n",
      "10882 [D loss: (0.624)(R 0.625, F 0.622)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.956] [G acc: 0.125]\n",
      "10883 [D loss: (0.678)(R 0.649, F 0.706)] [D acc: (0.625)(0.750, 0.500)] [G loss: 1.004] [G acc: 0.062]\n",
      "10884 [D loss: (0.731)(R 0.713, F 0.749)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.816] [G acc: 0.500]\n",
      "10885 [D loss: (0.709)(R 0.701, F 0.717)] [D acc: (0.500)(0.562, 0.438)] [G loss: 1.012] [G acc: 0.188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10886 [D loss: (0.688)(R 0.745, F 0.630)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.876] [G acc: 0.375]\n",
      "10887 [D loss: (0.707)(R 0.732, F 0.682)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.971] [G acc: 0.125]\n",
      "10888 [D loss: (0.723)(R 0.757, F 0.689)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.919] [G acc: 0.250]\n",
      "10889 [D loss: (0.680)(R 0.648, F 0.713)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.822] [G acc: 0.438]\n",
      "10890 [D loss: (0.642)(R 0.735, F 0.549)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.882] [G acc: 0.312]\n",
      "10891 [D loss: (0.612)(R 0.647, F 0.577)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.998] [G acc: 0.438]\n",
      "10892 [D loss: (0.703)(R 0.750, F 0.657)] [D acc: (0.562)(0.625, 0.500)] [G loss: 1.035] [G acc: 0.562]\n",
      "10893 [D loss: (0.541)(R 0.615, F 0.466)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.866] [G acc: 0.375]\n",
      "10894 [D loss: (0.567)(R 0.611, F 0.523)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.012] [G acc: 0.375]\n",
      "10895 [D loss: (0.594)(R 0.629, F 0.560)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.869] [G acc: 0.500]\n",
      "10896 [D loss: (0.632)(R 0.667, F 0.597)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.996] [G acc: 0.375]\n",
      "10897 [D loss: (0.706)(R 0.761, F 0.652)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.942] [G acc: 0.562]\n",
      "10898 [D loss: (0.624)(R 0.614, F 0.635)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.827] [G acc: 0.500]\n",
      "10899 [D loss: (0.621)(R 0.609, F 0.633)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.845] [G acc: 0.312]\n",
      "10900 [D loss: (0.679)(R 0.608, F 0.749)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.998] [G acc: 0.188]\n",
      "10901 [D loss: (0.788)(R 0.767, F 0.808)] [D acc: (0.312)(0.500, 0.125)] [G loss: 0.809] [G acc: 0.438]\n",
      "10902 [D loss: (0.960)(R 1.233, F 0.687)] [D acc: (0.500)(0.562, 0.438)] [G loss: 1.045] [G acc: 0.250]\n",
      "10903 [D loss: (0.660)(R 0.710, F 0.610)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.877] [G acc: 0.438]\n",
      "10904 [D loss: (0.699)(R 0.673, F 0.724)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.896] [G acc: 0.312]\n",
      "10905 [D loss: (0.669)(R 0.672, F 0.665)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.913] [G acc: 0.562]\n",
      "10906 [D loss: (0.751)(R 0.724, F 0.778)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.786] [G acc: 0.438]\n",
      "10907 [D loss: (0.745)(R 0.728, F 0.763)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.836] [G acc: 0.625]\n",
      "10908 [D loss: (0.655)(R 0.571, F 0.740)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.712] [G acc: 0.688]\n",
      "10909 [D loss: (0.717)(R 0.708, F 0.725)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.797] [G acc: 0.625]\n",
      "10910 [D loss: (0.683)(R 0.620, F 0.745)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.933] [G acc: 0.438]\n",
      "10911 [D loss: (0.675)(R 0.638, F 0.711)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.697] [G acc: 0.688]\n",
      "10912 [D loss: (0.705)(R 0.701, F 0.708)] [D acc: (0.500)(0.688, 0.312)] [G loss: 1.013] [G acc: 0.562]\n",
      "10913 [D loss: (0.662)(R 0.587, F 0.737)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.855] [G acc: 0.688]\n",
      "10914 [D loss: (0.672)(R 0.683, F 0.660)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.787] [G acc: 0.688]\n",
      "10915 [D loss: (0.679)(R 0.618, F 0.740)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.843] [G acc: 0.625]\n",
      "10916 [D loss: (0.717)(R 0.697, F 0.737)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.913] [G acc: 0.625]\n",
      "10917 [D loss: (0.791)(R 0.791, F 0.791)] [D acc: (0.312)(0.438, 0.188)] [G loss: 0.835] [G acc: 0.750]\n",
      "10918 [D loss: (0.684)(R 0.647, F 0.721)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.812] [G acc: 0.812]\n",
      "10919 [D loss: (0.738)(R 0.682, F 0.795)] [D acc: (0.375)(0.562, 0.188)] [G loss: 0.727] [G acc: 0.812]\n",
      "10920 [D loss: (0.710)(R 0.647, F 0.773)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.655] [G acc: 0.812]\n",
      "10921 [D loss: (0.693)(R 0.632, F 0.755)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.811] [G acc: 0.688]\n",
      "10922 [D loss: (0.683)(R 0.605, F 0.760)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.722] [G acc: 0.750]\n",
      "10923 [D loss: (0.673)(R 0.667, F 0.679)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.816] [G acc: 0.812]\n",
      "10924 [D loss: (0.680)(R 0.626, F 0.734)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.783] [G acc: 0.812]\n",
      "10925 [D loss: (0.603)(R 0.554, F 0.652)] [D acc: (0.656)(0.938, 0.375)] [G loss: 0.764] [G acc: 0.812]\n",
      "10926 [D loss: (0.669)(R 0.697, F 0.641)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.856] [G acc: 0.562]\n",
      "10927 [D loss: (0.606)(R 0.589, F 0.622)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.896] [G acc: 0.750]\n",
      "10928 [D loss: (0.664)(R 0.605, F 0.723)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.814] [G acc: 0.750]\n",
      "10929 [D loss: (0.685)(R 0.712, F 0.657)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.933] [G acc: 0.625]\n",
      "10930 [D loss: (0.693)(R 0.640, F 0.747)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.796] [G acc: 0.750]\n",
      "10931 [D loss: (0.620)(R 0.608, F 0.632)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.772] [G acc: 0.750]\n",
      "10932 [D loss: (0.632)(R 0.544, F 0.721)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.993] [G acc: 0.562]\n",
      "10933 [D loss: (0.608)(R 0.532, F 0.684)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.998] [G acc: 0.750]\n",
      "10934 [D loss: (0.737)(R 0.650, F 0.824)] [D acc: (0.406)(0.688, 0.125)] [G loss: 0.770] [G acc: 0.812]\n",
      "10935 [D loss: (0.684)(R 0.554, F 0.814)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.904] [G acc: 0.562]\n",
      "10936 [D loss: (0.510)(R 0.585, F 0.436)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.583] [G acc: 0.375]\n",
      "10937 [D loss: (0.705)(R 0.684, F 0.726)] [D acc: (0.562)(0.875, 0.250)] [G loss: 1.012] [G acc: 0.625]\n",
      "10938 [D loss: (0.678)(R 0.574, F 0.783)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.621] [G acc: 0.875]\n",
      "10939 [D loss: (0.763)(R 0.767, F 0.758)] [D acc: (0.438)(0.688, 0.188)] [G loss: 0.903] [G acc: 0.625]\n",
      "10940 [D loss: (0.671)(R 0.573, F 0.769)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.915] [G acc: 0.812]\n",
      "10941 [D loss: (0.632)(R 0.566, F 0.697)] [D acc: (0.625)(0.938, 0.312)] [G loss: 1.041] [G acc: 0.562]\n",
      "10942 [D loss: (0.681)(R 0.551, F 0.812)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.774] [G acc: 0.812]\n",
      "10943 [D loss: (0.683)(R 0.547, F 0.820)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.897] [G acc: 0.688]\n",
      "10944 [D loss: (0.723)(R 0.651, F 0.795)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.909] [G acc: 0.750]\n",
      "10945 [D loss: (0.647)(R 0.566, F 0.727)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.953] [G acc: 0.688]\n",
      "10946 [D loss: (0.626)(R 0.617, F 0.635)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.748] [G acc: 0.875]\n",
      "10947 [D loss: (0.633)(R 0.631, F 0.635)] [D acc: (0.562)(0.750, 0.375)] [G loss: 1.043] [G acc: 0.500]\n",
      "10948 [D loss: (0.517)(R 0.591, F 0.443)] [D acc: (0.750)(0.875, 0.625)] [G loss: 1.001] [G acc: 0.750]\n",
      "10949 [D loss: (0.600)(R 0.576, F 0.623)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.917] [G acc: 0.688]\n",
      "10950 [D loss: (0.675)(R 0.589, F 0.761)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.927] [G acc: 0.625]\n",
      "10951 [D loss: (0.675)(R 0.586, F 0.764)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.813] [G acc: 0.750]\n",
      "10952 [D loss: (0.681)(R 0.583, F 0.778)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.860] [G acc: 0.688]\n",
      "10953 [D loss: (0.690)(R 0.653, F 0.728)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.868] [G acc: 0.750]\n",
      "10954 [D loss: (0.612)(R 0.507, F 0.718)] [D acc: (0.594)(1.000, 0.188)] [G loss: 1.005] [G acc: 0.688]\n",
      "10955 [D loss: (0.647)(R 0.570, F 0.724)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.974] [G acc: 0.688]\n",
      "10956 [D loss: (0.641)(R 0.561, F 0.720)] [D acc: (0.625)(1.000, 0.250)] [G loss: 0.984] [G acc: 0.812]\n",
      "10957 [D loss: (0.658)(R 0.571, F 0.746)] [D acc: (0.562)(0.938, 0.188)] [G loss: 0.927] [G acc: 0.688]\n",
      "10958 [D loss: (0.668)(R 0.653, F 0.684)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.812] [G acc: 0.688]\n",
      "10959 [D loss: (0.579)(R 0.493, F 0.665)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.940] [G acc: 0.812]\n",
      "10960 [D loss: (0.620)(R 0.575, F 0.664)] [D acc: (0.625)(0.938, 0.312)] [G loss: 1.303] [G acc: 0.625]\n",
      "10961 [D loss: (0.600)(R 0.511, F 0.689)] [D acc: (0.625)(1.000, 0.250)] [G loss: 0.726] [G acc: 0.875]\n",
      "10962 [D loss: (0.519)(R 0.507, F 0.531)] [D acc: (0.719)(1.000, 0.438)] [G loss: 0.856] [G acc: 0.688]\n",
      "10963 [D loss: (0.611)(R 0.606, F 0.616)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.747] [G acc: 0.875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10964 [D loss: (0.574)(R 0.500, F 0.647)] [D acc: (0.594)(0.938, 0.250)] [G loss: 1.033] [G acc: 0.688]\n",
      "10965 [D loss: (0.561)(R 0.545, F 0.577)] [D acc: (0.656)(0.938, 0.375)] [G loss: 0.839] [G acc: 0.875]\n",
      "10966 [D loss: (0.563)(R 0.542, F 0.584)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.733] [G acc: 0.812]\n",
      "10967 [D loss: (0.727)(R 0.721, F 0.733)] [D acc: (0.531)(0.938, 0.125)] [G loss: 1.190] [G acc: 0.688]\n",
      "10968 [D loss: (0.587)(R 0.517, F 0.658)] [D acc: (0.594)(0.938, 0.250)] [G loss: 1.081] [G acc: 0.688]\n",
      "10969 [D loss: (0.644)(R 0.657, F 0.631)] [D acc: (0.562)(0.750, 0.375)] [G loss: 1.187] [G acc: 0.562]\n",
      "10970 [D loss: (0.728)(R 0.751, F 0.705)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.856] [G acc: 0.688]\n",
      "10971 [D loss: (0.600)(R 0.503, F 0.697)] [D acc: (0.625)(0.938, 0.312)] [G loss: 1.061] [G acc: 0.500]\n",
      "10972 [D loss: (0.609)(R 0.610, F 0.608)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.931] [G acc: 0.750]\n",
      "10973 [D loss: (0.883)(R 0.847, F 0.920)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.956] [G acc: 0.750]\n",
      "10974 [D loss: (0.664)(R 0.626, F 0.701)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.819] [G acc: 0.688]\n",
      "10975 [D loss: (0.671)(R 0.640, F 0.702)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.850] [G acc: 0.750]\n",
      "10976 [D loss: (0.695)(R 0.756, F 0.634)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.946] [G acc: 0.750]\n",
      "10977 [D loss: (0.688)(R 0.565, F 0.810)] [D acc: (0.562)(0.938, 0.188)] [G loss: 0.885] [G acc: 0.812]\n",
      "10978 [D loss: (0.755)(R 0.697, F 0.812)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.899] [G acc: 0.625]\n",
      "10979 [D loss: (0.910)(R 0.744, F 1.075)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.989] [G acc: 0.562]\n",
      "10980 [D loss: (0.777)(R 0.746, F 0.808)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.687] [G acc: 0.812]\n",
      "10981 [D loss: (0.633)(R 0.463, F 0.804)] [D acc: (0.719)(1.000, 0.438)] [G loss: 0.948] [G acc: 0.625]\n",
      "10982 [D loss: (0.824)(R 0.679, F 0.968)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.834] [G acc: 0.750]\n",
      "10983 [D loss: (0.802)(R 0.625, F 0.979)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.934] [G acc: 0.625]\n",
      "10984 [D loss: (0.734)(R 0.594, F 0.873)] [D acc: (0.656)(0.938, 0.375)] [G loss: 0.729] [G acc: 0.750]\n",
      "10985 [D loss: (0.611)(R 0.593, F 0.630)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.967] [G acc: 0.688]\n",
      "10986 [D loss: (0.902)(R 0.697, F 1.107)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.940] [G acc: 0.688]\n",
      "10987 [D loss: (0.758)(R 0.599, F 0.918)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.800] [G acc: 0.625]\n",
      "10988 [D loss: (0.751)(R 0.513, F 0.988)] [D acc: (0.625)(1.000, 0.250)] [G loss: 1.104] [G acc: 0.688]\n",
      "10989 [D loss: (0.702)(R 0.571, F 0.834)] [D acc: (0.625)(1.000, 0.250)] [G loss: 0.841] [G acc: 0.812]\n",
      "10990 [D loss: (0.744)(R 0.533, F 0.955)] [D acc: (0.656)(1.000, 0.312)] [G loss: 1.020] [G acc: 0.688]\n",
      "10991 [D loss: (0.656)(R 0.731, F 0.581)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.896] [G acc: 0.688]\n",
      "10992 [D loss: (0.711)(R 0.578, F 0.844)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.881] [G acc: 0.625]\n",
      "10993 [D loss: (0.800)(R 0.528, F 1.072)] [D acc: (0.562)(0.938, 0.188)] [G loss: 0.721] [G acc: 0.750]\n",
      "10994 [D loss: (0.689)(R 0.652, F 0.725)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.994] [G acc: 0.438]\n",
      "10995 [D loss: (0.725)(R 0.674, F 0.776)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.950] [G acc: 0.500]\n",
      "10996 [D loss: (0.640)(R 0.583, F 0.697)] [D acc: (0.781)(0.938, 0.625)] [G loss: 0.800] [G acc: 0.562]\n",
      "10997 [D loss: (0.734)(R 0.732, F 0.737)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.809] [G acc: 0.562]\n",
      "10998 [D loss: (0.752)(R 0.541, F 0.963)] [D acc: (0.625)(1.000, 0.250)] [G loss: 1.475] [G acc: 0.375]\n",
      "10999 [D loss: (0.777)(R 0.612, F 0.941)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.854] [G acc: 0.750]\n",
      "11000 [D loss: (0.696)(R 0.549, F 0.844)] [D acc: (0.594)(0.938, 0.250)] [G loss: 1.055] [G acc: 0.375]\n",
      "11001 [D loss: (0.679)(R 0.574, F 0.785)] [D acc: (0.656)(0.938, 0.375)] [G loss: 0.898] [G acc: 0.500]\n",
      "11002 [D loss: (0.607)(R 0.579, F 0.635)] [D acc: (0.750)(0.875, 0.625)] [G loss: 1.096] [G acc: 0.562]\n",
      "11003 [D loss: (0.761)(R 0.698, F 0.823)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.844] [G acc: 0.562]\n",
      "11004 [D loss: (0.788)(R 0.610, F 0.966)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.989] [G acc: 0.438]\n",
      "11005 [D loss: (0.722)(R 0.770, F 0.675)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.837] [G acc: 0.438]\n",
      "11006 [D loss: (0.673)(R 0.596, F 0.750)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.800] [G acc: 0.625]\n",
      "11007 [D loss: (0.778)(R 0.535, F 1.022)] [D acc: (0.688)(1.000, 0.375)] [G loss: 0.784] [G acc: 0.562]\n",
      "11008 [D loss: (0.703)(R 0.607, F 0.798)] [D acc: (0.531)(0.812, 0.250)] [G loss: 1.110] [G acc: 0.375]\n",
      "11009 [D loss: (0.671)(R 0.598, F 0.743)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.700] [G acc: 0.750]\n",
      "11010 [D loss: (0.728)(R 0.619, F 0.837)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.814] [G acc: 0.562]\n",
      "11011 [D loss: (0.629)(R 0.530, F 0.728)] [D acc: (0.750)(1.000, 0.500)] [G loss: 0.924] [G acc: 0.562]\n",
      "11012 [D loss: (0.747)(R 0.719, F 0.776)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.801] [G acc: 0.625]\n",
      "11013 [D loss: (0.681)(R 0.631, F 0.731)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.985] [G acc: 0.500]\n",
      "11014 [D loss: (0.762)(R 0.699, F 0.826)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.877] [G acc: 0.438]\n",
      "11015 [D loss: (0.584)(R 0.621, F 0.548)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.925] [G acc: 0.438]\n",
      "11016 [D loss: (0.814)(R 0.914, F 0.715)] [D acc: (0.594)(0.688, 0.500)] [G loss: 1.034] [G acc: 0.250]\n",
      "11017 [D loss: (0.578)(R 0.580, F 0.576)] [D acc: (0.750)(0.938, 0.562)] [G loss: 1.189] [G acc: 0.312]\n",
      "11018 [D loss: (0.641)(R 0.597, F 0.685)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.981] [G acc: 0.188]\n",
      "11019 [D loss: (0.623)(R 0.636, F 0.611)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.085] [G acc: 0.188]\n",
      "11020 [D loss: (0.592)(R 0.586, F 0.597)] [D acc: (0.812)(0.938, 0.688)] [G loss: 0.888] [G acc: 0.375]\n",
      "11021 [D loss: (0.657)(R 0.676, F 0.638)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.808] [G acc: 0.625]\n",
      "11022 [D loss: (0.721)(R 0.792, F 0.650)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.122] [G acc: 0.312]\n",
      "11023 [D loss: (0.750)(R 0.793, F 0.707)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.930] [G acc: 0.188]\n",
      "11024 [D loss: (0.592)(R 0.591, F 0.594)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.825] [G acc: 0.625]\n",
      "11025 [D loss: (0.665)(R 0.637, F 0.693)] [D acc: (0.719)(0.875, 0.562)] [G loss: 1.037] [G acc: 0.250]\n",
      "11026 [D loss: (0.595)(R 0.553, F 0.636)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.830] [G acc: 0.812]\n",
      "11027 [D loss: (0.618)(R 0.552, F 0.683)] [D acc: (0.781)(0.938, 0.625)] [G loss: 1.252] [G acc: 0.188]\n",
      "11028 [D loss: (0.592)(R 0.653, F 0.532)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.004] [G acc: 0.375]\n",
      "11029 [D loss: (0.651)(R 0.607, F 0.695)] [D acc: (0.594)(0.750, 0.438)] [G loss: 1.057] [G acc: 0.438]\n",
      "11030 [D loss: (0.666)(R 0.732, F 0.600)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.049] [G acc: 0.312]\n",
      "11031 [D loss: (0.576)(R 0.551, F 0.601)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.012] [G acc: 0.188]\n",
      "11032 [D loss: (0.628)(R 0.710, F 0.546)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.135] [G acc: 0.250]\n",
      "11033 [D loss: (0.594)(R 0.612, F 0.576)] [D acc: (0.625)(0.750, 0.500)] [G loss: 1.057] [G acc: 0.312]\n",
      "11034 [D loss: (0.664)(R 0.750, F 0.578)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.170] [G acc: 0.188]\n",
      "11035 [D loss: (0.633)(R 0.772, F 0.495)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.028] [G acc: 0.188]\n",
      "11036 [D loss: (0.529)(R 0.593, F 0.466)] [D acc: (0.906)(0.875, 0.938)] [G loss: 0.995] [G acc: 0.250]\n",
      "11037 [D loss: (0.551)(R 0.599, F 0.503)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.235] [G acc: 0.250]\n",
      "11038 [D loss: (0.559)(R 0.631, F 0.487)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.075] [G acc: 0.250]\n",
      "11039 [D loss: (0.602)(R 0.621, F 0.583)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.003] [G acc: 0.188]\n",
      "11040 [D loss: (0.601)(R 0.704, F 0.498)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.988] [G acc: 0.312]\n",
      "11041 [D loss: (0.601)(R 0.701, F 0.500)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.930] [G acc: 0.250]\n",
      "11042 [D loss: (0.675)(R 0.732, F 0.617)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.116] [G acc: 0.250]\n",
      "11043 [D loss: (0.576)(R 0.644, F 0.508)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.043] [G acc: 0.188]\n",
      "11044 [D loss: (0.545)(R 0.602, F 0.487)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.098] [G acc: 0.250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11045 [D loss: (0.607)(R 0.687, F 0.528)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.011] [G acc: 0.375]\n",
      "11046 [D loss: (0.474)(R 0.633, F 0.315)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.523] [G acc: 0.188]\n",
      "11047 [D loss: (0.419)(R 0.701, F 0.136)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.979] [G acc: 0.188]\n",
      "11048 [D loss: (0.409)(R 0.557, F 0.261)] [D acc: (0.906)(0.875, 0.938)] [G loss: 1.193] [G acc: 0.062]\n",
      "11049 [D loss: (0.643)(R 0.902, F 0.384)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.518] [G acc: 0.125]\n",
      "11050 [D loss: (0.504)(R 0.515, F 0.493)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.149] [G acc: 0.188]\n",
      "11051 [D loss: (0.561)(R 0.542, F 0.579)] [D acc: (0.781)(0.938, 0.625)] [G loss: 0.964] [G acc: 0.438]\n",
      "11052 [D loss: (0.609)(R 0.529, F 0.688)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.972] [G acc: 0.438]\n",
      "11053 [D loss: (0.595)(R 0.592, F 0.597)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.944] [G acc: 0.375]\n",
      "11054 [D loss: (0.511)(R 0.518, F 0.505)] [D acc: (0.844)(0.938, 0.750)] [G loss: 1.305] [G acc: 0.000]\n",
      "11055 [D loss: (0.491)(R 0.521, F 0.461)] [D acc: (0.969)(1.000, 0.938)] [G loss: 1.140] [G acc: 0.312]\n",
      "11056 [D loss: (0.590)(R 0.660, F 0.519)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.138] [G acc: 0.062]\n",
      "11057 [D loss: (0.619)(R 0.557, F 0.681)] [D acc: (0.719)(0.938, 0.500)] [G loss: 1.189] [G acc: 0.438]\n",
      "11058 [D loss: (0.660)(R 0.854, F 0.465)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.092] [G acc: 0.312]\n",
      "11059 [D loss: (0.502)(R 0.525, F 0.478)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.213] [G acc: 0.188]\n",
      "11060 [D loss: (0.466)(R 0.457, F 0.476)] [D acc: (0.875)(0.938, 0.812)] [G loss: 1.094] [G acc: 0.125]\n",
      "11061 [D loss: (0.691)(R 0.737, F 0.645)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.100] [G acc: 0.125]\n",
      "11062 [D loss: (0.564)(R 0.666, F 0.462)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.882] [G acc: 0.250]\n",
      "11063 [D loss: (0.554)(R 0.623, F 0.484)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.110] [G acc: 0.375]\n",
      "11064 [D loss: (0.642)(R 0.654, F 0.630)] [D acc: (0.594)(0.688, 0.500)] [G loss: 1.088] [G acc: 0.375]\n",
      "11065 [D loss: (0.606)(R 0.636, F 0.576)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.118] [G acc: 0.188]\n",
      "11066 [D loss: (0.543)(R 0.540, F 0.545)] [D acc: (0.844)(0.938, 0.750)] [G loss: 1.004] [G acc: 0.312]\n",
      "11067 [D loss: (0.532)(R 0.555, F 0.509)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.869] [G acc: 0.312]\n",
      "11068 [D loss: (0.623)(R 0.628, F 0.618)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.031] [G acc: 0.375]\n",
      "11069 [D loss: (0.617)(R 0.622, F 0.613)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.857] [G acc: 0.500]\n",
      "11070 [D loss: (0.542)(R 0.644, F 0.440)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.067] [G acc: 0.250]\n",
      "11071 [D loss: (0.611)(R 0.582, F 0.639)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.899] [G acc: 0.500]\n",
      "11072 [D loss: (0.727)(R 0.715, F 0.739)] [D acc: (0.562)(0.750, 0.375)] [G loss: 1.452] [G acc: 0.062]\n",
      "11073 [D loss: (0.611)(R 0.692, F 0.531)] [D acc: (0.688)(0.625, 0.750)] [G loss: 2.358] [G acc: 0.125]\n",
      "11074 [D loss: (0.669)(R 0.661, F 0.677)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.983] [G acc: 0.375]\n",
      "11075 [D loss: (0.568)(R 0.551, F 0.585)] [D acc: (0.750)(0.875, 0.625)] [G loss: 1.264] [G acc: 0.125]\n",
      "11076 [D loss: (0.554)(R 0.668, F 0.441)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.165] [G acc: 0.312]\n",
      "11077 [D loss: (0.604)(R 0.716, F 0.493)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.196] [G acc: 0.312]\n",
      "11078 [D loss: (0.735)(R 0.898, F 0.572)] [D acc: (0.594)(0.500, 0.688)] [G loss: 1.029] [G acc: 0.500]\n",
      "11079 [D loss: (0.637)(R 0.584, F 0.689)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.969] [G acc: 0.562]\n",
      "11080 [D loss: (0.593)(R 0.642, F 0.545)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.923] [G acc: 0.500]\n",
      "11081 [D loss: (0.586)(R 0.620, F 0.552)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.068] [G acc: 0.312]\n",
      "11082 [D loss: (0.555)(R 0.511, F 0.599)] [D acc: (0.781)(0.938, 0.625)] [G loss: 1.045] [G acc: 0.562]\n",
      "11083 [D loss: (0.528)(R 0.507, F 0.548)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.837] [G acc: 0.625]\n",
      "11084 [D loss: (0.561)(R 0.604, F 0.519)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.075] [G acc: 0.312]\n",
      "11085 [D loss: (0.575)(R 0.654, F 0.496)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.077] [G acc: 0.188]\n",
      "11086 [D loss: (0.602)(R 0.584, F 0.619)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.122] [G acc: 0.375]\n",
      "11087 [D loss: (0.553)(R 0.564, F 0.542)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.939] [G acc: 0.625]\n",
      "11088 [D loss: (0.743)(R 0.773, F 0.713)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.929] [G acc: 0.438]\n",
      "11089 [D loss: (0.635)(R 0.682, F 0.587)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.886] [G acc: 0.625]\n",
      "11090 [D loss: (0.598)(R 0.581, F 0.615)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.069] [G acc: 0.688]\n",
      "11091 [D loss: (0.686)(R 0.746, F 0.625)] [D acc: (0.719)(0.875, 0.562)] [G loss: 1.096] [G acc: 0.250]\n",
      "11092 [D loss: (0.603)(R 0.564, F 0.641)] [D acc: (0.625)(0.812, 0.438)] [G loss: 1.125] [G acc: 0.438]\n",
      "11093 [D loss: (0.640)(R 0.596, F 0.685)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.100] [G acc: 0.312]\n",
      "11094 [D loss: (0.733)(R 0.677, F 0.788)] [D acc: (0.625)(0.812, 0.438)] [G loss: 1.032] [G acc: 0.250]\n",
      "11095 [D loss: (0.617)(R 0.601, F 0.632)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.649] [G acc: 0.688]\n",
      "11096 [D loss: (0.656)(R 0.573, F 0.738)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.769] [G acc: 0.375]\n",
      "11097 [D loss: (0.616)(R 0.652, F 0.580)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.876] [G acc: 0.438]\n",
      "11098 [D loss: (0.650)(R 0.600, F 0.700)] [D acc: (0.531)(0.688, 0.375)] [G loss: 1.056] [G acc: 0.438]\n",
      "11099 [D loss: (0.639)(R 0.564, F 0.714)] [D acc: (0.656)(0.812, 0.500)] [G loss: 1.109] [G acc: 0.625]\n",
      "11100 [D loss: (0.720)(R 0.755, F 0.684)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.741] [G acc: 0.625]\n",
      "11101 [D loss: (0.578)(R 0.594, F 0.562)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.884] [G acc: 0.500]\n",
      "11102 [D loss: (0.625)(R 0.583, F 0.667)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.885] [G acc: 0.250]\n",
      "11103 [D loss: (0.650)(R 0.595, F 0.705)] [D acc: (0.594)(0.688, 0.500)] [G loss: 1.037] [G acc: 0.688]\n",
      "11104 [D loss: (0.589)(R 0.564, F 0.615)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.899] [G acc: 0.438]\n",
      "11105 [D loss: (0.629)(R 0.583, F 0.676)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.793] [G acc: 0.812]\n",
      "11106 [D loss: (0.689)(R 0.530, F 0.849)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.698] [G acc: 0.750]\n",
      "11107 [D loss: (0.710)(R 0.668, F 0.752)] [D acc: (0.469)(0.625, 0.312)] [G loss: 1.142] [G acc: 0.625]\n",
      "11108 [D loss: (0.517)(R 0.596, F 0.439)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.936] [G acc: 0.625]\n",
      "11109 [D loss: (0.666)(R 0.592, F 0.739)] [D acc: (0.594)(0.812, 0.375)] [G loss: 1.074] [G acc: 0.500]\n",
      "11110 [D loss: (0.561)(R 0.534, F 0.587)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.776] [G acc: 0.688]\n",
      "11111 [D loss: (0.617)(R 0.520, F 0.713)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.779] [G acc: 0.875]\n",
      "11112 [D loss: (0.713)(R 0.626, F 0.801)] [D acc: (0.406)(0.625, 0.188)] [G loss: 1.017] [G acc: 0.688]\n",
      "11113 [D loss: (0.671)(R 0.596, F 0.746)] [D acc: (0.438)(0.625, 0.250)] [G loss: 1.117] [G acc: 0.625]\n",
      "11114 [D loss: (0.641)(R 0.509, F 0.774)] [D acc: (0.562)(0.938, 0.188)] [G loss: 1.310] [G acc: 0.312]\n",
      "11115 [D loss: (0.626)(R 0.626, F 0.626)] [D acc: (0.656)(0.875, 0.438)] [G loss: 1.261] [G acc: 0.375]\n",
      "11116 [D loss: (0.648)(R 0.703, F 0.593)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.889] [G acc: 0.812]\n",
      "11117 [D loss: (0.623)(R 0.603, F 0.643)] [D acc: (0.562)(0.750, 0.375)] [G loss: 1.429] [G acc: 0.562]\n",
      "11118 [D loss: (0.836)(R 0.763, F 0.910)] [D acc: (0.344)(0.625, 0.062)] [G loss: 0.841] [G acc: 0.688]\n",
      "11119 [D loss: (0.673)(R 0.600, F 0.746)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.847] [G acc: 0.812]\n",
      "11120 [D loss: (0.699)(R 0.637, F 0.761)] [D acc: (0.469)(0.688, 0.250)] [G loss: 1.410] [G acc: 0.500]\n",
      "11121 [D loss: (0.847)(R 1.027, F 0.667)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.861] [G acc: 0.812]\n",
      "11122 [D loss: (0.639)(R 0.542, F 0.736)] [D acc: (0.594)(0.812, 0.375)] [G loss: 1.223] [G acc: 0.688]\n",
      "11123 [D loss: (0.635)(R 0.530, F 0.739)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.910] [G acc: 0.750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11124 [D loss: (0.755)(R 0.808, F 0.701)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.897] [G acc: 0.812]\n",
      "11125 [D loss: (0.663)(R 0.531, F 0.795)] [D acc: (0.531)(0.812, 0.250)] [G loss: 1.094] [G acc: 0.750]\n",
      "11126 [D loss: (0.688)(R 0.628, F 0.749)] [D acc: (0.562)(0.812, 0.312)] [G loss: 1.100] [G acc: 0.625]\n",
      "11127 [D loss: (0.713)(R 0.734, F 0.692)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.681] [G acc: 0.812]\n",
      "11128 [D loss: (0.626)(R 0.575, F 0.677)] [D acc: (0.594)(0.750, 0.438)] [G loss: 1.112] [G acc: 0.562]\n",
      "11129 [D loss: (0.689)(R 0.495, F 0.883)] [D acc: (0.406)(0.750, 0.062)] [G loss: 0.806] [G acc: 0.812]\n",
      "11130 [D loss: (0.675)(R 0.557, F 0.793)] [D acc: (0.531)(0.875, 0.188)] [G loss: 1.168] [G acc: 0.562]\n",
      "11131 [D loss: (0.747)(R 0.594, F 0.900)] [D acc: (0.438)(0.750, 0.125)] [G loss: 1.069] [G acc: 0.688]\n",
      "11132 [D loss: (0.596)(R 0.502, F 0.689)] [D acc: (0.625)(0.875, 0.375)] [G loss: 1.198] [G acc: 0.688]\n",
      "11133 [D loss: (0.686)(R 0.552, F 0.820)] [D acc: (0.531)(0.938, 0.125)] [G loss: 0.866] [G acc: 0.812]\n",
      "11134 [D loss: (0.601)(R 0.575, F 0.627)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.902] [G acc: 0.750]\n",
      "11135 [D loss: (0.550)(R 0.530, F 0.571)] [D acc: (0.656)(0.875, 0.438)] [G loss: 1.047] [G acc: 0.750]\n",
      "11136 [D loss: (0.626)(R 0.572, F 0.679)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.823] [G acc: 0.875]\n",
      "11137 [D loss: (0.645)(R 0.510, F 0.781)] [D acc: (0.469)(0.750, 0.188)] [G loss: 1.206] [G acc: 0.750]\n",
      "11138 [D loss: (0.677)(R 0.522, F 0.832)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.727] [G acc: 0.812]\n",
      "11139 [D loss: (0.578)(R 0.496, F 0.660)] [D acc: (0.562)(0.812, 0.312)] [G loss: 1.610] [G acc: 0.625]\n",
      "11140 [D loss: (0.683)(R 0.513, F 0.853)] [D acc: (0.500)(0.938, 0.062)] [G loss: 0.900] [G acc: 0.750]\n",
      "11141 [D loss: (0.738)(R 0.663, F 0.814)] [D acc: (0.469)(0.812, 0.125)] [G loss: 1.055] [G acc: 0.750]\n",
      "11142 [D loss: (0.764)(R 0.778, F 0.750)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.969] [G acc: 0.625]\n",
      "11143 [D loss: (0.641)(R 0.489, F 0.793)] [D acc: (0.656)(1.000, 0.312)] [G loss: 0.992] [G acc: 0.750]\n",
      "11144 [D loss: (0.645)(R 0.508, F 0.781)] [D acc: (0.594)(1.000, 0.188)] [G loss: 1.223] [G acc: 0.688]\n",
      "11145 [D loss: (0.599)(R 0.479, F 0.719)] [D acc: (0.688)(1.000, 0.375)] [G loss: 1.426] [G acc: 0.500]\n",
      "11146 [D loss: (0.745)(R 0.611, F 0.879)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.742] [G acc: 0.812]\n",
      "11147 [D loss: (0.605)(R 0.545, F 0.664)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.802] [G acc: 0.750]\n",
      "11148 [D loss: (0.631)(R 0.600, F 0.662)] [D acc: (0.531)(0.688, 0.375)] [G loss: 1.052] [G acc: 0.750]\n",
      "11149 [D loss: (0.695)(R 0.709, F 0.681)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.969] [G acc: 0.688]\n",
      "11150 [D loss: (0.742)(R 0.641, F 0.844)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.876] [G acc: 0.750]\n",
      "11151 [D loss: (0.580)(R 0.446, F 0.713)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.919] [G acc: 0.688]\n",
      "11152 [D loss: (0.742)(R 0.500, F 0.984)] [D acc: (0.562)(1.000, 0.125)] [G loss: 1.006] [G acc: 0.625]\n",
      "11153 [D loss: (0.629)(R 0.542, F 0.717)] [D acc: (0.688)(0.938, 0.438)] [G loss: 1.020] [G acc: 0.750]\n",
      "11154 [D loss: (0.523)(R 0.432, F 0.614)] [D acc: (0.750)(1.000, 0.500)] [G loss: 1.297] [G acc: 0.688]\n",
      "11155 [D loss: (0.552)(R 0.503, F 0.601)] [D acc: (0.688)(0.875, 0.500)] [G loss: 1.271] [G acc: 0.562]\n",
      "11156 [D loss: (0.801)(R 0.737, F 0.866)] [D acc: (0.594)(0.812, 0.375)] [G loss: 1.303] [G acc: 0.562]\n",
      "11157 [D loss: (0.792)(R 0.714, F 0.871)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.911] [G acc: 0.562]\n",
      "11158 [D loss: (0.942)(R 0.907, F 0.977)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.850] [G acc: 0.500]\n",
      "11159 [D loss: (0.736)(R 0.578, F 0.894)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.708] [G acc: 0.750]\n",
      "11160 [D loss: (0.673)(R 0.532, F 0.814)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.734] [G acc: 0.625]\n",
      "11161 [D loss: (0.614)(R 0.543, F 0.685)] [D acc: (0.656)(0.938, 0.375)] [G loss: 1.077] [G acc: 0.500]\n",
      "11162 [D loss: (0.614)(R 0.531, F 0.697)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.856] [G acc: 0.562]\n",
      "11163 [D loss: (0.670)(R 0.595, F 0.746)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.940] [G acc: 0.375]\n",
      "11164 [D loss: (0.621)(R 0.516, F 0.726)] [D acc: (0.688)(0.938, 0.438)] [G loss: 1.036] [G acc: 0.562]\n",
      "11165 [D loss: (0.729)(R 0.566, F 0.892)] [D acc: (0.562)(0.938, 0.188)] [G loss: 0.984] [G acc: 0.625]\n",
      "11166 [D loss: (0.798)(R 0.779, F 0.817)] [D acc: (0.688)(0.875, 0.500)] [G loss: 1.022] [G acc: 0.500]\n",
      "11167 [D loss: (0.727)(R 0.660, F 0.795)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.783] [G acc: 0.688]\n",
      "11168 [D loss: (0.821)(R 0.633, F 1.009)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.823] [G acc: 0.625]\n",
      "11169 [D loss: (0.829)(R 0.843, F 0.816)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.857] [G acc: 0.562]\n",
      "11170 [D loss: (0.751)(R 0.614, F 0.887)] [D acc: (0.562)(0.938, 0.188)] [G loss: 0.698] [G acc: 0.750]\n",
      "11171 [D loss: (0.667)(R 0.536, F 0.798)] [D acc: (0.594)(0.875, 0.312)] [G loss: 1.071] [G acc: 0.562]\n",
      "11172 [D loss: (0.754)(R 0.794, F 0.714)] [D acc: (0.625)(0.750, 0.500)] [G loss: 2.619] [G acc: 0.438]\n",
      "11173 [D loss: (0.502)(R 0.635, F 0.368)] [D acc: (0.812)(0.938, 0.688)] [G loss: 3.530] [G acc: 0.188]\n",
      "11174 [D loss: (0.679)(R 0.695, F 0.662)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.762] [G acc: 0.688]\n",
      "11175 [D loss: (0.653)(R 0.588, F 0.719)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.965] [G acc: 0.625]\n",
      "11176 [D loss: (0.642)(R 0.610, F 0.675)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.127] [G acc: 0.375]\n",
      "11177 [D loss: (0.631)(R 0.520, F 0.743)] [D acc: (0.750)(1.000, 0.500)] [G loss: 0.908] [G acc: 0.625]\n",
      "11178 [D loss: (0.728)(R 0.721, F 0.734)] [D acc: (0.656)(0.875, 0.438)] [G loss: 1.130] [G acc: 0.562]\n",
      "11179 [D loss: (0.699)(R 0.552, F 0.847)] [D acc: (0.688)(0.938, 0.438)] [G loss: 1.076] [G acc: 0.438]\n",
      "11180 [D loss: (0.721)(R 0.665, F 0.778)] [D acc: (0.562)(0.625, 0.500)] [G loss: 1.081] [G acc: 0.500]\n",
      "11181 [D loss: (0.621)(R 0.598, F 0.643)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.358] [G acc: 0.500]\n",
      "11182 [D loss: (0.791)(R 0.958, F 0.625)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.023] [G acc: 0.562]\n",
      "11183 [D loss: (0.527)(R 0.540, F 0.514)] [D acc: (0.781)(0.938, 0.625)] [G loss: 1.066] [G acc: 0.312]\n",
      "11184 [D loss: (0.656)(R 0.658, F 0.653)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.957] [G acc: 0.438]\n",
      "11185 [D loss: (0.658)(R 0.816, F 0.500)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.923] [G acc: 0.562]\n",
      "11186 [D loss: (0.622)(R 0.614, F 0.630)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.837] [G acc: 0.812]\n",
      "11187 [D loss: (0.559)(R 0.568, F 0.550)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.844] [G acc: 0.500]\n",
      "11188 [D loss: (0.671)(R 0.629, F 0.713)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.939] [G acc: 0.312]\n",
      "11189 [D loss: (0.615)(R 0.584, F 0.645)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.716] [G acc: 0.750]\n",
      "11190 [D loss: (0.564)(R 0.543, F 0.585)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.726] [G acc: 0.750]\n",
      "11191 [D loss: (0.651)(R 0.649, F 0.653)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.803] [G acc: 0.625]\n",
      "11192 [D loss: (0.566)(R 0.531, F 0.600)] [D acc: (0.750)(0.938, 0.562)] [G loss: 1.014] [G acc: 0.375]\n",
      "11193 [D loss: (0.583)(R 0.569, F 0.598)] [D acc: (0.688)(0.812, 0.562)] [G loss: 1.065] [G acc: 0.375]\n",
      "11194 [D loss: (0.670)(R 0.553, F 0.787)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.909] [G acc: 0.562]\n",
      "11195 [D loss: (0.702)(R 0.739, F 0.665)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.973] [G acc: 0.375]\n",
      "11196 [D loss: (0.603)(R 0.550, F 0.656)] [D acc: (0.719)(0.875, 0.562)] [G loss: 1.104] [G acc: 0.312]\n",
      "11197 [D loss: (0.649)(R 0.599, F 0.700)] [D acc: (0.656)(0.875, 0.438)] [G loss: 1.069] [G acc: 0.500]\n",
      "11198 [D loss: (0.625)(R 0.579, F 0.671)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.951] [G acc: 0.688]\n",
      "11199 [D loss: (0.660)(R 0.673, F 0.646)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.840] [G acc: 0.812]\n",
      "11200 [D loss: (0.682)(R 0.696, F 0.668)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.874] [G acc: 0.562]\n",
      "11201 [D loss: (0.571)(R 0.618, F 0.525)] [D acc: (0.812)(0.938, 0.688)] [G loss: 1.022] [G acc: 0.438]\n",
      "11202 [D loss: (0.599)(R 0.582, F 0.615)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.876] [G acc: 0.562]\n",
      "11203 [D loss: (0.610)(R 0.578, F 0.643)] [D acc: (0.656)(0.812, 0.500)] [G loss: 1.254] [G acc: 0.250]\n",
      "11204 [D loss: (0.532)(R 0.489, F 0.575)] [D acc: (0.719)(0.938, 0.500)] [G loss: 1.045] [G acc: 0.750]\n",
      "11205 [D loss: (0.674)(R 0.690, F 0.658)] [D acc: (0.562)(0.688, 0.438)] [G loss: 1.237] [G acc: 0.562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11206 [D loss: (0.621)(R 0.513, F 0.729)] [D acc: (0.656)(1.000, 0.312)] [G loss: 1.211] [G acc: 0.375]\n",
      "11207 [D loss: (0.559)(R 0.586, F 0.531)] [D acc: (0.750)(0.875, 0.625)] [G loss: 1.095] [G acc: 0.688]\n",
      "11208 [D loss: (0.681)(R 0.653, F 0.709)] [D acc: (0.562)(0.812, 0.312)] [G loss: 1.232] [G acc: 0.562]\n",
      "11209 [D loss: (0.669)(R 0.632, F 0.706)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.889] [G acc: 0.562]\n",
      "11210 [D loss: (0.948)(R 1.108, F 0.787)] [D acc: (0.375)(0.625, 0.125)] [G loss: 0.669] [G acc: 0.875]\n",
      "11211 [D loss: (0.897)(R 1.057, F 0.737)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.978] [G acc: 0.562]\n",
      "11212 [D loss: (0.754)(R 0.756, F 0.751)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.905] [G acc: 0.375]\n",
      "11213 [D loss: (0.716)(R 0.636, F 0.796)] [D acc: (0.500)(0.562, 0.438)] [G loss: 1.099] [G acc: 0.562]\n",
      "11214 [D loss: (0.596)(R 0.511, F 0.681)] [D acc: (0.688)(1.000, 0.375)] [G loss: 0.800] [G acc: 0.438]\n",
      "11215 [D loss: (0.705)(R 0.673, F 0.738)] [D acc: (0.625)(0.812, 0.438)] [G loss: 1.039] [G acc: 0.312]\n",
      "11216 [D loss: (0.634)(R 0.635, F 0.632)] [D acc: (0.750)(0.938, 0.562)] [G loss: 1.106] [G acc: 0.375]\n",
      "11217 [D loss: (0.658)(R 0.675, F 0.642)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.949] [G acc: 0.562]\n",
      "11218 [D loss: (0.608)(R 0.545, F 0.670)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.909] [G acc: 0.438]\n",
      "11219 [D loss: (0.569)(R 0.561, F 0.578)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.780] [G acc: 0.562]\n",
      "11220 [D loss: (0.527)(R 0.496, F 0.558)] [D acc: (0.812)(1.000, 0.625)] [G loss: 2.290] [G acc: 0.188]\n",
      "11221 [D loss: (0.503)(R 0.710, F 0.296)] [D acc: (0.750)(0.812, 0.688)] [G loss: 2.430] [G acc: 0.125]\n",
      "11222 [D loss: (0.525)(R 0.555, F 0.496)] [D acc: (0.781)(0.875, 0.688)] [G loss: 4.154] [G acc: 0.062]\n",
      "11223 [D loss: (0.459)(R 0.719, F 0.199)] [D acc: (0.812)(0.625, 1.000)] [G loss: 1.984] [G acc: 0.062]\n",
      "11224 [D loss: (0.572)(R 0.582, F 0.562)] [D acc: (0.750)(0.875, 0.625)] [G loss: 1.005] [G acc: 0.500]\n",
      "11225 [D loss: (0.598)(R 0.682, F 0.515)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.326] [G acc: 0.250]\n",
      "11226 [D loss: (0.560)(R 0.568, F 0.552)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.793] [G acc: 0.562]\n",
      "11227 [D loss: (0.588)(R 0.595, F 0.581)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.135] [G acc: 0.250]\n",
      "11228 [D loss: (0.666)(R 0.714, F 0.617)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.138] [G acc: 0.188]\n",
      "11229 [D loss: (0.591)(R 0.714, F 0.468)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.177] [G acc: 0.250]\n",
      "11230 [D loss: (0.595)(R 0.720, F 0.470)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.996] [G acc: 0.312]\n",
      "11231 [D loss: (0.578)(R 0.586, F 0.571)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.495] [G acc: 0.312]\n",
      "11232 [D loss: (0.593)(R 0.710, F 0.476)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.814] [G acc: 0.500]\n",
      "11233 [D loss: (0.568)(R 0.584, F 0.551)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.183] [G acc: 0.250]\n",
      "11234 [D loss: (0.614)(R 0.626, F 0.602)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.897] [G acc: 0.375]\n",
      "11235 [D loss: (0.646)(R 0.617, F 0.676)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.970] [G acc: 0.375]\n",
      "11236 [D loss: (0.562)(R 0.629, F 0.494)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.226] [G acc: 0.062]\n",
      "11237 [D loss: (0.587)(R 0.728, F 0.446)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.097] [G acc: 0.500]\n",
      "11238 [D loss: (0.544)(R 0.543, F 0.546)] [D acc: (0.844)(0.938, 0.750)] [G loss: 1.106] [G acc: 0.625]\n",
      "11239 [D loss: (0.555)(R 0.551, F 0.559)] [D acc: (0.781)(0.938, 0.625)] [G loss: 0.679] [G acc: 0.750]\n",
      "11240 [D loss: (0.625)(R 0.627, F 0.624)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.254] [G acc: 0.375]\n",
      "11241 [D loss: (0.522)(R 0.518, F 0.526)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.775] [G acc: 0.500]\n",
      "11242 [D loss: (0.551)(R 0.561, F 0.540)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.650] [G acc: 0.188]\n",
      "11243 [D loss: (0.794)(R 0.989, F 0.599)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.862] [G acc: 0.500]\n",
      "11244 [D loss: (0.666)(R 0.696, F 0.637)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.006] [G acc: 0.250]\n",
      "11245 [D loss: (0.617)(R 0.690, F 0.544)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.932] [G acc: 0.125]\n",
      "11246 [D loss: (0.704)(R 0.742, F 0.667)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.909] [G acc: 0.500]\n",
      "11247 [D loss: (0.687)(R 0.694, F 0.680)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.053] [G acc: 0.438]\n",
      "11248 [D loss: (0.655)(R 0.622, F 0.687)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.984] [G acc: 0.188]\n",
      "11249 [D loss: (0.602)(R 0.641, F 0.563)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.049] [G acc: 0.438]\n",
      "11250 [D loss: (0.597)(R 0.564, F 0.629)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.913] [G acc: 0.625]\n",
      "11251 [D loss: (0.677)(R 0.657, F 0.697)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.807] [G acc: 0.562]\n",
      "11252 [D loss: (0.665)(R 0.583, F 0.747)] [D acc: (0.594)(0.812, 0.375)] [G loss: 1.228] [G acc: 0.312]\n",
      "11253 [D loss: (0.643)(R 0.550, F 0.737)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.963] [G acc: 0.625]\n",
      "11254 [D loss: (0.759)(R 0.813, F 0.706)] [D acc: (0.562)(0.688, 0.438)] [G loss: 1.206] [G acc: 0.438]\n",
      "11255 [D loss: (0.646)(R 0.551, F 0.741)] [D acc: (0.656)(0.938, 0.375)] [G loss: 0.876] [G acc: 0.500]\n",
      "11256 [D loss: (0.611)(R 0.615, F 0.608)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.942] [G acc: 0.125]\n",
      "11257 [D loss: (0.619)(R 0.694, F 0.544)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.981] [G acc: 0.625]\n",
      "11258 [D loss: (0.757)(R 0.691, F 0.823)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.746] [G acc: 0.875]\n",
      "11259 [D loss: (0.641)(R 0.581, F 0.702)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.868] [G acc: 0.750]\n",
      "11260 [D loss: (0.633)(R 0.595, F 0.671)] [D acc: (0.594)(0.812, 0.375)] [G loss: 1.028] [G acc: 0.562]\n",
      "11261 [D loss: (0.575)(R 0.538, F 0.612)] [D acc: (0.750)(0.938, 0.562)] [G loss: 0.814] [G acc: 0.562]\n",
      "11262 [D loss: (0.656)(R 0.667, F 0.645)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.775] [G acc: 0.562]\n",
      "11263 [D loss: (0.663)(R 0.617, F 0.708)] [D acc: (0.531)(0.688, 0.375)] [G loss: 1.089] [G acc: 0.438]\n",
      "11264 [D loss: (0.579)(R 0.550, F 0.608)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.940] [G acc: 0.500]\n",
      "11265 [D loss: (0.675)(R 0.655, F 0.695)] [D acc: (0.531)(0.750, 0.312)] [G loss: 1.197] [G acc: 0.375]\n",
      "11266 [D loss: (0.655)(R 0.576, F 0.734)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.822] [G acc: 0.688]\n",
      "11267 [D loss: (0.615)(R 0.563, F 0.668)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.931] [G acc: 0.625]\n",
      "11268 [D loss: (0.735)(R 0.647, F 0.823)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.990] [G acc: 0.375]\n",
      "11269 [D loss: (0.755)(R 0.813, F 0.698)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.837] [G acc: 0.562]\n",
      "11270 [D loss: (0.689)(R 0.587, F 0.791)] [D acc: (0.562)(0.938, 0.188)] [G loss: 0.845] [G acc: 0.750]\n",
      "11271 [D loss: (0.651)(R 0.620, F 0.682)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.796] [G acc: 0.562]\n",
      "11272 [D loss: (0.741)(R 0.689, F 0.793)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.746] [G acc: 0.812]\n",
      "11273 [D loss: (0.727)(R 0.685, F 0.769)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.656] [G acc: 0.812]\n",
      "11274 [D loss: (0.651)(R 0.581, F 0.722)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.833] [G acc: 0.750]\n",
      "11275 [D loss: (0.779)(R 0.743, F 0.814)] [D acc: (0.469)(0.688, 0.250)] [G loss: 1.030] [G acc: 0.688]\n",
      "11276 [D loss: (0.800)(R 0.689, F 0.912)] [D acc: (0.375)(0.750, 0.000)] [G loss: 0.789] [G acc: 0.750]\n",
      "11277 [D loss: (0.755)(R 0.551, F 0.958)] [D acc: (0.406)(0.812, 0.000)] [G loss: 0.614] [G acc: 0.812]\n",
      "11278 [D loss: (0.821)(R 0.801, F 0.841)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.679] [G acc: 0.812]\n",
      "11279 [D loss: (0.702)(R 0.564, F 0.840)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.754] [G acc: 0.625]\n",
      "11280 [D loss: (0.681)(R 0.612, F 0.751)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.688] [G acc: 0.750]\n",
      "11281 [D loss: (0.723)(R 0.642, F 0.804)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.714] [G acc: 0.688]\n",
      "11282 [D loss: (0.626)(R 0.498, F 0.754)] [D acc: (0.656)(1.000, 0.312)] [G loss: 0.667] [G acc: 0.688]\n",
      "11283 [D loss: (0.699)(R 0.524, F 0.874)] [D acc: (0.562)(1.000, 0.125)] [G loss: 0.688] [G acc: 0.812]\n",
      "11284 [D loss: (0.648)(R 0.596, F 0.699)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.662] [G acc: 0.562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11285 [D loss: (0.743)(R 0.691, F 0.795)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.675] [G acc: 0.812]\n",
      "11286 [D loss: (0.670)(R 0.556, F 0.785)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.787] [G acc: 0.750]\n",
      "11287 [D loss: (0.721)(R 0.648, F 0.795)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.591] [G acc: 0.875]\n",
      "11288 [D loss: (0.720)(R 0.633, F 0.807)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.833] [G acc: 0.688]\n",
      "11289 [D loss: (0.686)(R 0.518, F 0.854)] [D acc: (0.562)(1.000, 0.125)] [G loss: 0.727] [G acc: 0.812]\n",
      "11290 [D loss: (0.740)(R 0.638, F 0.842)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.823] [G acc: 0.688]\n",
      "11291 [D loss: (0.670)(R 0.527, F 0.812)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.633] [G acc: 0.750]\n",
      "11292 [D loss: (0.665)(R 0.530, F 0.800)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.687] [G acc: 0.812]\n",
      "11293 [D loss: (0.677)(R 0.532, F 0.823)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.781] [G acc: 0.750]\n",
      "11294 [D loss: (0.700)(R 0.652, F 0.747)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.722] [G acc: 0.812]\n",
      "11295 [D loss: (0.812)(R 0.865, F 0.759)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.711] [G acc: 0.812]\n",
      "11296 [D loss: (0.691)(R 0.568, F 0.813)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.817] [G acc: 0.688]\n",
      "11297 [D loss: (0.698)(R 0.618, F 0.777)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.864] [G acc: 0.625]\n",
      "11298 [D loss: (0.622)(R 0.589, F 0.654)] [D acc: (0.656)(0.875, 0.438)] [G loss: 1.026] [G acc: 0.438]\n",
      "11299 [D loss: (0.760)(R 0.754, F 0.766)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.912] [G acc: 0.750]\n",
      "11300 [D loss: (0.784)(R 0.656, F 0.912)] [D acc: (0.344)(0.688, 0.000)] [G loss: 0.633] [G acc: 0.875]\n",
      "11301 [D loss: (0.643)(R 0.506, F 0.780)] [D acc: (0.625)(1.000, 0.250)] [G loss: 0.679] [G acc: 0.812]\n",
      "11302 [D loss: (0.716)(R 0.615, F 0.818)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.739] [G acc: 0.750]\n",
      "11303 [D loss: (0.669)(R 0.545, F 0.794)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.641] [G acc: 0.812]\n",
      "11304 [D loss: (0.749)(R 0.658, F 0.839)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.646] [G acc: 0.875]\n",
      "11305 [D loss: (0.702)(R 0.637, F 0.768)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.751] [G acc: 0.625]\n",
      "11306 [D loss: (0.665)(R 0.586, F 0.744)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.789] [G acc: 0.562]\n",
      "11307 [D loss: (0.637)(R 0.509, F 0.766)] [D acc: (0.625)(1.000, 0.250)] [G loss: 0.723] [G acc: 0.812]\n",
      "11308 [D loss: (0.765)(R 0.698, F 0.832)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.752] [G acc: 0.812]\n",
      "11309 [D loss: (0.712)(R 0.602, F 0.822)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.656] [G acc: 0.812]\n",
      "11310 [D loss: (0.598)(R 0.543, F 0.652)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.823] [G acc: 0.750]\n",
      "11311 [D loss: (0.702)(R 0.599, F 0.805)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.662] [G acc: 0.812]\n",
      "11312 [D loss: (0.652)(R 0.558, F 0.746)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.796] [G acc: 0.750]\n",
      "11313 [D loss: (0.749)(R 0.676, F 0.821)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.778] [G acc: 0.688]\n",
      "11314 [D loss: (0.609)(R 0.450, F 0.768)] [D acc: (0.625)(1.000, 0.250)] [G loss: 0.868] [G acc: 0.750]\n",
      "11315 [D loss: (0.618)(R 0.579, F 0.658)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.844] [G acc: 0.750]\n",
      "11316 [D loss: (0.734)(R 0.665, F 0.802)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.852] [G acc: 0.625]\n",
      "11317 [D loss: (0.683)(R 0.551, F 0.814)] [D acc: (0.531)(0.938, 0.125)] [G loss: 0.769] [G acc: 0.688]\n",
      "11318 [D loss: (0.750)(R 0.739, F 0.761)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.718] [G acc: 0.812]\n",
      "11319 [D loss: (0.698)(R 0.631, F 0.766)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.638] [G acc: 0.812]\n",
      "11320 [D loss: (0.751)(R 0.664, F 0.837)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.705] [G acc: 0.812]\n",
      "11321 [D loss: (0.716)(R 0.578, F 0.855)] [D acc: (0.469)(0.875, 0.062)] [G loss: 0.663] [G acc: 0.688]\n",
      "11322 [D loss: (0.633)(R 0.510, F 0.755)] [D acc: (0.625)(1.000, 0.250)] [G loss: 0.683] [G acc: 0.875]\n",
      "11323 [D loss: (0.640)(R 0.553, F 0.727)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.792] [G acc: 0.688]\n",
      "11324 [D loss: (0.674)(R 0.546, F 0.801)] [D acc: (0.562)(0.938, 0.188)] [G loss: 0.793] [G acc: 0.750]\n",
      "11325 [D loss: (0.681)(R 0.573, F 0.790)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.686] [G acc: 0.812]\n",
      "11326 [D loss: (0.668)(R 0.560, F 0.777)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.807] [G acc: 0.625]\n",
      "11327 [D loss: (0.709)(R 0.596, F 0.822)] [D acc: (0.438)(0.812, 0.062)] [G loss: 0.709] [G acc: 0.688]\n",
      "11328 [D loss: (0.447)(R 0.543, F 0.351)] [D acc: (0.812)(0.938, 0.688)] [G loss: 3.452] [G acc: 0.312]\n",
      "11329 [D loss: (0.567)(R 0.566, F 0.568)] [D acc: (0.750)(0.875, 0.625)] [G loss: 1.539] [G acc: 0.438]\n",
      "11330 [D loss: (0.690)(R 0.634, F 0.745)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.717] [G acc: 0.812]\n",
      "11331 [D loss: (0.654)(R 0.594, F 0.713)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.713] [G acc: 0.812]\n",
      "11332 [D loss: (0.605)(R 0.516, F 0.693)] [D acc: (0.656)(1.000, 0.312)] [G loss: 0.737] [G acc: 0.750]\n",
      "11333 [D loss: (0.669)(R 0.533, F 0.805)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.821] [G acc: 0.750]\n",
      "11334 [D loss: (0.648)(R 0.591, F 0.705)] [D acc: (0.656)(0.938, 0.375)] [G loss: 1.052] [G acc: 0.688]\n",
      "11335 [D loss: (0.641)(R 0.571, F 0.711)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.740] [G acc: 0.750]\n",
      "11336 [D loss: (0.608)(R 0.568, F 0.647)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.802] [G acc: 0.688]\n",
      "11337 [D loss: (0.670)(R 0.593, F 0.747)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.815] [G acc: 0.625]\n",
      "11338 [D loss: (0.755)(R 0.839, F 0.671)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.894] [G acc: 0.625]\n",
      "11339 [D loss: (0.707)(R 0.743, F 0.670)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.831] [G acc: 0.688]\n",
      "11340 [D loss: (0.763)(R 0.706, F 0.820)] [D acc: (0.438)(0.812, 0.062)] [G loss: 0.737] [G acc: 0.750]\n",
      "11341 [D loss: (0.711)(R 0.614, F 0.808)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.735] [G acc: 0.562]\n",
      "11342 [D loss: (0.622)(R 0.449, F 0.795)] [D acc: (0.500)(0.938, 0.062)] [G loss: 0.676] [G acc: 0.625]\n",
      "11343 [D loss: (0.646)(R 0.584, F 0.708)] [D acc: (0.656)(0.938, 0.375)] [G loss: 0.652] [G acc: 0.812]\n",
      "11344 [D loss: (0.668)(R 0.567, F 0.768)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.779] [G acc: 0.625]\n",
      "11345 [D loss: (0.663)(R 0.641, F 0.686)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.769] [G acc: 0.750]\n",
      "11346 [D loss: (0.685)(R 0.638, F 0.733)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.850] [G acc: 0.438]\n",
      "11347 [D loss: (0.572)(R 0.503, F 0.641)] [D acc: (0.750)(1.000, 0.500)] [G loss: 0.844] [G acc: 0.688]\n",
      "11348 [D loss: (0.649)(R 0.592, F 0.706)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.803] [G acc: 0.688]\n",
      "11349 [D loss: (0.614)(R 0.562, F 0.666)] [D acc: (0.750)(1.000, 0.500)] [G loss: 1.058] [G acc: 0.562]\n",
      "11350 [D loss: (0.628)(R 0.654, F 0.602)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.734] [G acc: 0.688]\n",
      "11351 [D loss: (0.660)(R 0.611, F 0.709)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.735] [G acc: 0.812]\n",
      "11352 [D loss: (0.687)(R 0.580, F 0.793)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.697] [G acc: 0.688]\n",
      "11353 [D loss: (0.572)(R 0.563, F 0.580)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.785] [G acc: 0.688]\n",
      "11354 [D loss: (0.681)(R 0.587, F 0.775)] [D acc: (0.562)(0.938, 0.188)] [G loss: 0.700] [G acc: 0.750]\n",
      "11355 [D loss: (0.674)(R 0.586, F 0.761)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.709] [G acc: 0.812]\n",
      "11356 [D loss: (0.718)(R 0.635, F 0.802)] [D acc: (0.469)(0.875, 0.062)] [G loss: 0.856] [G acc: 0.562]\n",
      "11357 [D loss: (0.673)(R 0.575, F 0.771)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.727] [G acc: 0.625]\n",
      "11358 [D loss: (0.687)(R 0.637, F 0.738)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.732] [G acc: 0.812]\n",
      "11359 [D loss: (0.689)(R 0.653, F 0.725)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.754] [G acc: 0.562]\n",
      "11360 [D loss: (0.518)(R 0.493, F 0.543)] [D acc: (0.781)(1.000, 0.562)] [G loss: 0.939] [G acc: 0.750]\n",
      "11361 [D loss: (0.717)(R 0.651, F 0.784)] [D acc: (0.562)(0.875, 0.250)] [G loss: 1.100] [G acc: 0.562]\n",
      "11362 [D loss: (0.597)(R 0.582, F 0.611)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.737] [G acc: 0.750]\n",
      "11363 [D loss: (0.588)(R 0.611, F 0.565)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.683] [G acc: 0.812]\n",
      "11364 [D loss: (0.618)(R 0.563, F 0.673)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.824] [G acc: 0.688]\n",
      "11365 [D loss: (0.668)(R 0.604, F 0.732)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.844] [G acc: 0.688]\n",
      "11366 [D loss: (0.650)(R 0.523, F 0.777)] [D acc: (0.594)(1.000, 0.188)] [G loss: 1.063] [G acc: 0.500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11367 [D loss: (0.613)(R 0.429, F 0.797)] [D acc: (0.562)(1.000, 0.125)] [G loss: 0.906] [G acc: 0.688]\n",
      "11368 [D loss: (0.606)(R 0.531, F 0.680)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.851] [G acc: 0.688]\n",
      "11369 [D loss: (0.686)(R 0.696, F 0.676)] [D acc: (0.562)(0.812, 0.312)] [G loss: 1.217] [G acc: 0.625]\n",
      "11370 [D loss: (0.739)(R 0.679, F 0.798)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.833] [G acc: 0.500]\n",
      "11371 [D loss: (0.656)(R 0.617, F 0.694)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.767] [G acc: 0.625]\n",
      "11372 [D loss: (0.767)(R 0.863, F 0.670)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.735] [G acc: 0.750]\n",
      "11373 [D loss: (0.799)(R 0.829, F 0.770)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.788] [G acc: 0.688]\n",
      "11374 [D loss: (0.683)(R 0.530, F 0.837)] [D acc: (0.531)(0.938, 0.125)] [G loss: 1.095] [G acc: 0.562]\n",
      "11375 [D loss: (0.684)(R 0.561, F 0.807)] [D acc: (0.531)(0.938, 0.125)] [G loss: 0.789] [G acc: 0.750]\n",
      "11376 [D loss: (0.676)(R 0.594, F 0.759)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.881] [G acc: 0.750]\n",
      "11377 [D loss: (0.547)(R 0.534, F 0.560)] [D acc: (0.750)(1.000, 0.500)] [G loss: 0.919] [G acc: 0.500]\n",
      "11378 [D loss: (0.664)(R 0.600, F 0.727)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.709] [G acc: 0.875]\n",
      "11379 [D loss: (0.669)(R 0.628, F 0.709)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.868] [G acc: 0.688]\n",
      "11380 [D loss: (0.688)(R 0.588, F 0.787)] [D acc: (0.562)(0.938, 0.188)] [G loss: 0.868] [G acc: 0.750]\n",
      "11381 [D loss: (0.718)(R 0.673, F 0.763)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.864] [G acc: 0.688]\n",
      "11382 [D loss: (0.716)(R 0.704, F 0.728)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.864] [G acc: 0.625]\n",
      "11383 [D loss: (0.663)(R 0.568, F 0.759)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.775] [G acc: 0.625]\n",
      "11384 [D loss: (0.678)(R 0.660, F 0.697)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.768] [G acc: 0.625]\n",
      "11385 [D loss: (0.670)(R 0.589, F 0.751)] [D acc: (0.562)(0.938, 0.188)] [G loss: 0.754] [G acc: 0.812]\n",
      "11386 [D loss: (0.686)(R 0.672, F 0.701)] [D acc: (0.531)(0.812, 0.250)] [G loss: 1.077] [G acc: 0.562]\n",
      "11387 [D loss: (0.640)(R 0.622, F 0.658)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.800] [G acc: 0.750]\n",
      "11388 [D loss: (0.623)(R 0.596, F 0.650)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.720] [G acc: 0.875]\n",
      "11389 [D loss: (0.640)(R 0.628, F 0.652)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.640] [G acc: 0.812]\n",
      "11390 [D loss: (0.528)(R 0.504, F 0.552)] [D acc: (0.812)(1.000, 0.625)] [G loss: 0.909] [G acc: 0.625]\n",
      "11391 [D loss: (0.668)(R 0.586, F 0.750)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.812] [G acc: 0.688]\n",
      "11392 [D loss: (0.601)(R 0.605, F 0.597)] [D acc: (0.656)(0.875, 0.438)] [G loss: 1.033] [G acc: 0.625]\n",
      "11393 [D loss: (0.439)(R 0.564, F 0.314)] [D acc: (0.906)(0.938, 0.875)] [G loss: 1.558] [G acc: 0.250]\n",
      "11394 [D loss: (0.571)(R 0.703, F 0.438)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.764] [G acc: 0.625]\n",
      "11395 [D loss: (0.520)(R 0.526, F 0.515)] [D acc: (0.750)(1.000, 0.500)] [G loss: 1.104] [G acc: 0.500]\n",
      "11396 [D loss: (0.644)(R 0.523, F 0.764)] [D acc: (0.594)(1.000, 0.188)] [G loss: 0.939] [G acc: 0.438]\n",
      "11397 [D loss: (0.718)(R 0.658, F 0.777)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.722] [G acc: 0.750]\n",
      "11398 [D loss: (0.565)(R 0.549, F 0.580)] [D acc: (0.781)(1.000, 0.562)] [G loss: 0.990] [G acc: 0.500]\n",
      "11399 [D loss: (0.582)(R 0.593, F 0.571)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.912] [G acc: 0.625]\n",
      "11400 [D loss: (0.616)(R 0.609, F 0.623)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.864] [G acc: 0.562]\n",
      "11401 [D loss: (0.658)(R 0.625, F 0.690)] [D acc: (0.656)(0.938, 0.375)] [G loss: 0.863] [G acc: 0.750]\n",
      "11402 [D loss: (0.784)(R 0.707, F 0.861)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.778] [G acc: 0.438]\n",
      "11403 [D loss: (0.673)(R 0.624, F 0.722)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.849] [G acc: 0.562]\n",
      "11404 [D loss: (0.632)(R 0.566, F 0.698)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.664] [G acc: 0.625]\n",
      "11405 [D loss: (0.684)(R 0.614, F 0.754)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.723] [G acc: 0.688]\n",
      "11406 [D loss: (0.657)(R 0.591, F 0.724)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.813] [G acc: 0.438]\n",
      "11407 [D loss: (0.698)(R 0.689, F 0.707)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.877] [G acc: 0.625]\n",
      "11408 [D loss: (0.983)(R 0.885, F 1.082)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.757] [G acc: 0.625]\n",
      "11409 [D loss: (0.667)(R 0.575, F 0.758)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.813] [G acc: 0.562]\n",
      "11410 [D loss: (0.573)(R 0.556, F 0.590)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.833] [G acc: 0.562]\n",
      "11411 [D loss: (0.628)(R 0.587, F 0.668)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.790] [G acc: 0.750]\n",
      "11412 [D loss: (0.628)(R 0.573, F 0.683)] [D acc: (0.562)(0.938, 0.188)] [G loss: 0.939] [G acc: 0.500]\n",
      "11413 [D loss: (0.672)(R 0.648, F 0.695)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.836] [G acc: 0.688]\n",
      "11414 [D loss: (0.663)(R 0.567, F 0.758)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.876] [G acc: 0.688]\n",
      "11415 [D loss: (0.589)(R 0.607, F 0.572)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.773] [G acc: 0.438]\n",
      "11416 [D loss: (0.775)(R 0.746, F 0.805)] [D acc: (0.469)(0.875, 0.062)] [G loss: 0.789] [G acc: 0.438]\n",
      "11417 [D loss: (0.613)(R 0.536, F 0.690)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.882] [G acc: 0.375]\n",
      "11418 [D loss: (0.583)(R 0.566, F 0.600)] [D acc: (0.719)(1.000, 0.438)] [G loss: 0.958] [G acc: 0.625]\n",
      "11419 [D loss: (0.612)(R 0.562, F 0.663)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.933] [G acc: 0.500]\n",
      "11420 [D loss: (0.599)(R 0.546, F 0.651)] [D acc: (0.750)(0.938, 0.562)] [G loss: 0.823] [G acc: 0.688]\n",
      "11421 [D loss: (0.690)(R 0.793, F 0.587)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.927] [G acc: 0.438]\n",
      "11422 [D loss: (0.659)(R 0.662, F 0.655)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.888] [G acc: 0.438]\n",
      "11423 [D loss: (0.616)(R 0.529, F 0.702)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.673] [G acc: 0.688]\n",
      "11424 [D loss: (0.663)(R 0.718, F 0.609)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.892] [G acc: 0.688]\n",
      "11425 [D loss: (0.683)(R 0.591, F 0.775)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.824] [G acc: 0.625]\n",
      "11426 [D loss: (0.677)(R 0.646, F 0.709)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.742] [G acc: 0.625]\n",
      "11427 [D loss: (0.630)(R 0.622, F 0.638)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.703] [G acc: 0.812]\n",
      "11428 [D loss: (0.647)(R 0.690, F 0.604)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.827] [G acc: 0.500]\n",
      "11429 [D loss: (0.593)(R 0.615, F 0.570)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.888] [G acc: 0.562]\n",
      "11430 [D loss: (0.644)(R 0.561, F 0.727)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.797] [G acc: 0.625]\n",
      "11431 [D loss: (0.596)(R 0.593, F 0.598)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.890] [G acc: 0.750]\n",
      "11432 [D loss: (0.676)(R 0.716, F 0.635)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.739] [G acc: 0.688]\n",
      "11433 [D loss: (0.700)(R 0.765, F 0.634)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.660] [G acc: 0.812]\n",
      "11434 [D loss: (0.673)(R 0.628, F 0.717)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.684] [G acc: 0.812]\n",
      "11435 [D loss: (0.609)(R 0.554, F 0.663)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.788] [G acc: 0.812]\n",
      "11436 [D loss: (0.651)(R 0.607, F 0.696)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.863] [G acc: 0.375]\n",
      "11437 [D loss: (0.635)(R 0.541, F 0.729)] [D acc: (0.656)(1.000, 0.312)] [G loss: 0.802] [G acc: 0.625]\n",
      "11438 [D loss: (0.665)(R 0.675, F 0.656)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.838] [G acc: 0.562]\n",
      "11439 [D loss: (0.611)(R 0.556, F 0.666)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.723] [G acc: 0.750]\n",
      "11440 [D loss: (0.686)(R 0.703, F 0.669)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.714] [G acc: 0.688]\n",
      "11441 [D loss: (0.595)(R 0.475, F 0.715)] [D acc: (0.625)(1.000, 0.250)] [G loss: 0.851] [G acc: 0.500]\n",
      "11442 [D loss: (0.682)(R 0.641, F 0.723)] [D acc: (0.469)(0.688, 0.250)] [G loss: 1.435] [G acc: 0.188]\n",
      "11443 [D loss: (0.545)(R 0.748, F 0.343)] [D acc: (0.781)(0.875, 0.688)] [G loss: 5.669] [G acc: 0.188]\n",
      "11444 [D loss: (0.752)(R 0.706, F 0.797)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.714] [G acc: 0.625]\n",
      "11445 [D loss: (0.658)(R 0.623, F 0.694)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.857] [G acc: 0.750]\n",
      "11446 [D loss: (0.702)(R 0.661, F 0.742)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.922] [G acc: 0.438]\n",
      "11447 [D loss: (0.632)(R 0.591, F 0.673)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.858] [G acc: 0.375]\n",
      "11448 [D loss: (0.705)(R 0.768, F 0.642)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.894] [G acc: 0.625]\n",
      "11449 [D loss: (0.645)(R 0.558, F 0.731)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.867] [G acc: 0.625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11450 [D loss: (0.652)(R 0.594, F 0.709)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.877] [G acc: 0.625]\n",
      "11451 [D loss: (0.723)(R 0.677, F 0.769)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.807] [G acc: 0.688]\n",
      "11452 [D loss: (0.653)(R 0.585, F 0.721)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.668] [G acc: 0.750]\n",
      "11453 [D loss: (0.579)(R 0.597, F 0.561)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.968] [G acc: 0.562]\n",
      "11454 [D loss: (0.744)(R 0.834, F 0.654)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.701] [G acc: 0.688]\n",
      "11455 [D loss: (0.623)(R 0.569, F 0.677)] [D acc: (0.750)(0.938, 0.562)] [G loss: 0.720] [G acc: 0.688]\n",
      "11456 [D loss: (0.554)(R 0.529, F 0.579)] [D acc: (0.719)(1.000, 0.438)] [G loss: 0.709] [G acc: 0.688]\n",
      "11457 [D loss: (0.615)(R 0.529, F 0.701)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.755] [G acc: 0.562]\n",
      "11458 [D loss: (0.640)(R 0.700, F 0.579)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.844] [G acc: 0.562]\n",
      "11459 [D loss: (0.597)(R 0.593, F 0.600)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.854] [G acc: 0.500]\n",
      "11460 [D loss: (0.639)(R 0.551, F 0.727)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.802] [G acc: 0.500]\n",
      "11461 [D loss: (0.674)(R 0.653, F 0.694)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.992] [G acc: 0.688]\n",
      "11462 [D loss: (0.773)(R 0.883, F 0.663)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.843] [G acc: 0.750]\n",
      "11463 [D loss: (0.681)(R 0.639, F 0.722)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.727] [G acc: 0.688]\n",
      "11464 [D loss: (0.668)(R 0.603, F 0.733)] [D acc: (0.656)(1.000, 0.312)] [G loss: 0.859] [G acc: 0.688]\n",
      "11465 [D loss: (0.699)(R 0.734, F 0.664)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.899] [G acc: 0.500]\n",
      "11466 [D loss: (0.633)(R 0.592, F 0.673)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.745] [G acc: 0.688]\n",
      "11467 [D loss: (0.643)(R 0.709, F 0.578)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.768] [G acc: 0.625]\n",
      "11468 [D loss: (0.632)(R 0.556, F 0.708)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.912] [G acc: 0.500]\n",
      "11469 [D loss: (0.688)(R 0.613, F 0.763)] [D acc: (0.406)(0.750, 0.062)] [G loss: 0.914] [G acc: 0.625]\n",
      "11470 [D loss: (0.611)(R 0.560, F 0.662)] [D acc: (0.625)(1.000, 0.250)] [G loss: 0.925] [G acc: 0.562]\n",
      "11471 [D loss: (0.575)(R 0.591, F 0.558)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.922] [G acc: 0.438]\n",
      "11472 [D loss: (0.661)(R 0.589, F 0.734)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.765] [G acc: 0.562]\n",
      "11473 [D loss: (0.701)(R 0.713, F 0.690)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.847] [G acc: 0.625]\n",
      "11474 [D loss: (0.605)(R 0.658, F 0.552)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.817] [G acc: 0.625]\n",
      "11475 [D loss: (0.660)(R 0.648, F 0.672)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.841] [G acc: 0.500]\n",
      "11476 [D loss: (0.630)(R 0.602, F 0.659)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.776] [G acc: 0.562]\n",
      "11477 [D loss: (0.653)(R 0.741, F 0.566)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.842] [G acc: 0.500]\n",
      "11478 [D loss: (0.599)(R 0.620, F 0.577)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.868] [G acc: 0.625]\n",
      "11479 [D loss: (0.698)(R 0.715, F 0.681)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.903] [G acc: 0.562]\n",
      "11480 [D loss: (0.695)(R 0.646, F 0.744)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.844] [G acc: 0.438]\n",
      "11481 [D loss: (0.614)(R 0.595, F 0.633)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.844] [G acc: 0.500]\n",
      "11482 [D loss: (0.663)(R 0.585, F 0.741)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.844] [G acc: 0.625]\n",
      "11483 [D loss: (0.675)(R 0.725, F 0.624)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.802] [G acc: 0.562]\n",
      "11484 [D loss: (0.673)(R 0.629, F 0.717)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.911] [G acc: 0.375]\n",
      "11485 [D loss: (0.604)(R 0.532, F 0.675)] [D acc: (0.781)(1.000, 0.562)] [G loss: 0.843] [G acc: 0.500]\n",
      "11486 [D loss: (0.664)(R 0.696, F 0.632)] [D acc: (0.562)(0.750, 0.375)] [G loss: 1.247] [G acc: 0.250]\n",
      "11487 [D loss: (0.474)(R 0.571, F 0.377)] [D acc: (0.781)(0.812, 0.750)] [G loss: 5.061] [G acc: 0.125]\n",
      "11488 [D loss: (0.670)(R 0.714, F 0.625)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.855] [G acc: 0.438]\n",
      "11489 [D loss: (0.686)(R 0.707, F 0.666)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.903] [G acc: 0.375]\n",
      "11490 [D loss: (0.614)(R 0.639, F 0.589)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.672] [G acc: 0.688]\n",
      "11491 [D loss: (0.701)(R 0.769, F 0.633)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.843] [G acc: 0.438]\n",
      "11492 [D loss: (0.687)(R 0.731, F 0.643)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.849] [G acc: 0.500]\n",
      "11493 [D loss: (0.648)(R 0.647, F 0.649)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.927] [G acc: 0.438]\n",
      "11494 [D loss: (0.562)(R 0.549, F 0.576)] [D acc: (0.812)(1.000, 0.625)] [G loss: 0.833] [G acc: 0.438]\n",
      "11495 [D loss: (0.596)(R 0.573, F 0.619)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.863] [G acc: 0.375]\n",
      "11496 [D loss: (0.583)(R 0.664, F 0.502)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.874] [G acc: 0.312]\n",
      "11497 [D loss: (0.663)(R 0.623, F 0.702)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.814] [G acc: 0.562]\n",
      "11498 [D loss: (0.693)(R 0.642, F 0.744)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.897] [G acc: 0.375]\n",
      "11499 [D loss: (0.610)(R 0.616, F 0.604)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.778] [G acc: 0.562]\n",
      "11500 [D loss: (0.727)(R 0.734, F 0.719)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.897] [G acc: 0.250]\n",
      "11501 [D loss: (0.632)(R 0.566, F 0.698)] [D acc: (0.656)(1.000, 0.312)] [G loss: 0.819] [G acc: 0.500]\n",
      "11502 [D loss: (0.648)(R 0.571, F 0.724)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.903] [G acc: 0.438]\n",
      "11503 [D loss: (0.721)(R 0.746, F 0.696)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.764] [G acc: 0.688]\n",
      "11504 [D loss: (0.704)(R 0.701, F 0.706)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.753] [G acc: 0.625]\n",
      "11505 [D loss: (0.649)(R 0.595, F 0.702)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.738] [G acc: 0.688]\n",
      "11506 [D loss: (0.645)(R 0.572, F 0.717)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.848] [G acc: 0.438]\n",
      "11507 [D loss: (0.629)(R 0.577, F 0.682)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.894] [G acc: 0.312]\n",
      "11508 [D loss: (0.619)(R 0.607, F 0.632)] [D acc: (0.781)(0.938, 0.625)] [G loss: 0.872] [G acc: 0.312]\n",
      "11509 [D loss: (0.710)(R 0.766, F 0.655)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.784] [G acc: 0.562]\n",
      "11510 [D loss: (0.634)(R 0.591, F 0.676)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.818] [G acc: 0.438]\n",
      "11511 [D loss: (0.590)(R 0.606, F 0.574)] [D acc: (0.750)(0.938, 0.562)] [G loss: 0.823] [G acc: 0.375]\n",
      "11512 [D loss: (0.594)(R 0.605, F 0.582)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.866] [G acc: 0.562]\n",
      "11513 [D loss: (0.632)(R 0.724, F 0.540)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.943] [G acc: 0.562]\n",
      "11514 [D loss: (0.515)(R 0.514, F 0.516)] [D acc: (0.812)(0.938, 0.688)] [G loss: 0.963] [G acc: 0.438]\n",
      "11515 [D loss: (0.634)(R 0.626, F 0.642)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.943] [G acc: 0.312]\n",
      "11516 [D loss: (0.567)(R 0.557, F 0.577)] [D acc: (0.750)(0.938, 0.562)] [G loss: 1.091] [G acc: 0.500]\n",
      "11517 [D loss: (0.722)(R 0.733, F 0.711)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.830] [G acc: 0.500]\n",
      "11518 [D loss: (0.613)(R 0.559, F 0.668)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.949] [G acc: 0.562]\n",
      "11519 [D loss: (0.615)(R 0.582, F 0.648)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.903] [G acc: 0.688]\n",
      "11520 [D loss: (0.717)(R 0.722, F 0.711)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.887] [G acc: 0.625]\n",
      "11521 [D loss: (0.792)(R 0.788, F 0.795)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.905] [G acc: 0.688]\n",
      "11522 [D loss: (0.651)(R 0.634, F 0.669)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.773] [G acc: 0.438]\n",
      "11523 [D loss: (0.692)(R 0.601, F 0.783)] [D acc: (0.562)(0.938, 0.188)] [G loss: 0.825] [G acc: 0.500]\n",
      "11524 [D loss: (0.589)(R 0.554, F 0.625)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.810] [G acc: 0.688]\n",
      "11525 [D loss: (0.637)(R 0.576, F 0.697)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.776] [G acc: 0.812]\n",
      "11526 [D loss: (0.652)(R 0.543, F 0.760)] [D acc: (0.562)(0.938, 0.188)] [G loss: 0.811] [G acc: 0.562]\n",
      "11527 [D loss: (0.724)(R 0.624, F 0.824)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.701] [G acc: 0.750]\n",
      "11528 [D loss: (0.719)(R 0.710, F 0.727)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.877] [G acc: 0.688]\n",
      "11529 [D loss: (0.718)(R 0.689, F 0.746)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.801] [G acc: 0.750]\n",
      "11530 [D loss: (0.670)(R 0.690, F 0.650)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.851] [G acc: 0.688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11531 [D loss: (0.670)(R 0.604, F 0.735)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.691] [G acc: 0.875]\n",
      "11532 [D loss: (0.738)(R 0.733, F 0.743)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.723] [G acc: 0.688]\n",
      "11533 [D loss: (0.684)(R 0.604, F 0.764)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.790] [G acc: 0.750]\n",
      "11534 [D loss: (0.718)(R 0.656, F 0.781)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.697] [G acc: 0.750]\n",
      "11535 [D loss: (0.753)(R 0.675, F 0.831)] [D acc: (0.531)(0.938, 0.125)] [G loss: 0.665] [G acc: 0.875]\n",
      "11536 [D loss: (0.687)(R 0.579, F 0.795)] [D acc: (0.438)(0.750, 0.125)] [G loss: 1.235] [G acc: 0.438]\n",
      "11537 [D loss: (0.688)(R 0.624, F 0.753)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.804] [G acc: 0.750]\n",
      "11538 [D loss: (0.734)(R 0.704, F 0.764)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.654] [G acc: 0.688]\n",
      "11539 [D loss: (0.661)(R 0.612, F 0.710)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.817] [G acc: 0.750]\n",
      "11540 [D loss: (0.723)(R 0.606, F 0.840)] [D acc: (0.469)(0.875, 0.062)] [G loss: 0.773] [G acc: 0.625]\n",
      "11541 [D loss: (0.666)(R 0.589, F 0.743)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.831] [G acc: 0.625]\n",
      "11542 [D loss: (0.643)(R 0.526, F 0.760)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.778] [G acc: 0.562]\n",
      "11543 [D loss: (0.679)(R 0.704, F 0.654)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.706] [G acc: 0.688]\n",
      "11544 [D loss: (0.595)(R 0.615, F 0.574)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.977] [G acc: 0.562]\n",
      "11545 [D loss: (0.650)(R 0.608, F 0.691)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.912] [G acc: 0.562]\n",
      "11546 [D loss: (0.589)(R 0.593, F 0.584)] [D acc: (0.750)(0.875, 0.625)] [G loss: 1.456] [G acc: 0.188]\n",
      "11547 [D loss: (0.446)(R 0.558, F 0.334)] [D acc: (0.812)(0.938, 0.688)] [G loss: 3.205] [G acc: 0.188]\n",
      "11548 [D loss: (0.691)(R 0.636, F 0.746)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.828] [G acc: 0.562]\n",
      "11549 [D loss: (0.694)(R 0.668, F 0.720)] [D acc: (0.531)(0.875, 0.188)] [G loss: 1.671] [G acc: 0.250]\n",
      "11550 [D loss: (0.577)(R 0.620, F 0.533)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.832] [G acc: 0.562]\n",
      "11551 [D loss: (0.599)(R 0.528, F 0.670)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.841] [G acc: 0.625]\n",
      "11552 [D loss: (0.616)(R 0.550, F 0.682)] [D acc: (0.625)(0.812, 0.438)] [G loss: 2.054] [G acc: 0.625]\n",
      "11553 [D loss: (0.694)(R 0.710, F 0.678)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.900] [G acc: 0.562]\n",
      "11554 [D loss: (0.668)(R 0.567, F 0.769)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.923] [G acc: 0.562]\n",
      "11555 [D loss: (0.730)(R 0.742, F 0.718)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.747] [G acc: 0.688]\n",
      "11556 [D loss: (0.617)(R 0.553, F 0.682)] [D acc: (0.656)(1.000, 0.312)] [G loss: 0.942] [G acc: 0.688]\n",
      "11557 [D loss: (0.611)(R 0.563, F 0.658)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.812] [G acc: 0.688]\n",
      "11558 [D loss: (0.665)(R 0.619, F 0.711)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.984] [G acc: 0.625]\n",
      "11559 [D loss: (0.615)(R 0.585, F 0.645)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.837] [G acc: 0.750]\n",
      "11560 [D loss: (0.592)(R 0.535, F 0.649)] [D acc: (0.656)(1.000, 0.312)] [G loss: 1.059] [G acc: 0.688]\n",
      "11561 [D loss: (0.551)(R 0.526, F 0.575)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.840] [G acc: 0.625]\n",
      "11562 [D loss: (0.596)(R 0.568, F 0.624)] [D acc: (0.625)(0.938, 0.312)] [G loss: 1.030] [G acc: 0.562]\n",
      "11563 [D loss: (0.558)(R 0.551, F 0.565)] [D acc: (0.656)(0.938, 0.375)] [G loss: 1.045] [G acc: 0.625]\n",
      "11564 [D loss: (0.659)(R 0.748, F 0.571)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.852] [G acc: 0.750]\n",
      "11565 [D loss: (0.641)(R 0.553, F 0.730)] [D acc: (0.625)(1.000, 0.250)] [G loss: 0.910] [G acc: 0.688]\n",
      "11566 [D loss: (0.635)(R 0.640, F 0.630)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.940] [G acc: 0.438]\n",
      "11567 [D loss: (0.665)(R 0.676, F 0.655)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.785] [G acc: 0.500]\n",
      "11568 [D loss: (0.612)(R 0.548, F 0.677)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.902] [G acc: 0.562]\n",
      "11569 [D loss: (0.666)(R 0.637, F 0.695)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.918] [G acc: 0.562]\n",
      "11570 [D loss: (0.700)(R 0.685, F 0.716)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.844] [G acc: 0.688]\n",
      "11571 [D loss: (0.802)(R 0.712, F 0.891)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.783] [G acc: 0.688]\n",
      "11572 [D loss: (0.684)(R 0.648, F 0.720)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.951] [G acc: 0.562]\n",
      "11573 [D loss: (0.625)(R 0.598, F 0.652)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.805] [G acc: 0.562]\n",
      "11574 [D loss: (0.587)(R 0.581, F 0.592)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.847] [G acc: 0.688]\n",
      "11575 [D loss: (0.542)(R 0.505, F 0.578)] [D acc: (0.656)(0.875, 0.438)] [G loss: 1.053] [G acc: 0.438]\n",
      "11576 [D loss: (0.635)(R 0.606, F 0.664)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.899] [G acc: 0.625]\n",
      "11577 [D loss: (0.703)(R 0.729, F 0.677)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.893] [G acc: 0.438]\n",
      "11578 [D loss: (0.700)(R 0.682, F 0.719)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.822] [G acc: 0.562]\n",
      "11579 [D loss: (0.634)(R 0.592, F 0.675)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.916] [G acc: 0.562]\n",
      "11580 [D loss: (0.677)(R 0.687, F 0.667)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.975] [G acc: 0.500]\n",
      "11581 [D loss: (0.631)(R 0.633, F 0.629)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.877] [G acc: 0.500]\n",
      "11582 [D loss: (0.731)(R 0.795, F 0.666)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.855] [G acc: 0.625]\n",
      "11583 [D loss: (0.720)(R 0.787, F 0.653)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.852] [G acc: 0.500]\n",
      "11584 [D loss: (0.596)(R 0.516, F 0.677)] [D acc: (0.594)(0.812, 0.375)] [G loss: 1.036] [G acc: 0.562]\n",
      "11585 [D loss: (0.705)(R 0.766, F 0.644)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.959] [G acc: 0.625]\n",
      "11586 [D loss: (0.656)(R 0.590, F 0.723)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.853] [G acc: 0.562]\n",
      "11587 [D loss: (0.633)(R 0.631, F 0.635)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.985] [G acc: 0.625]\n",
      "11588 [D loss: (0.653)(R 0.585, F 0.722)] [D acc: (0.656)(0.938, 0.375)] [G loss: 0.957] [G acc: 0.438]\n",
      "11589 [D loss: (0.641)(R 0.613, F 0.669)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.814] [G acc: 0.688]\n",
      "11590 [D loss: (0.643)(R 0.614, F 0.672)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.940] [G acc: 0.625]\n",
      "11591 [D loss: (0.606)(R 0.567, F 0.645)] [D acc: (0.656)(0.875, 0.438)] [G loss: 1.035] [G acc: 0.500]\n",
      "11592 [D loss: (0.792)(R 0.682, F 0.902)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.864] [G acc: 0.562]\n",
      "11593 [D loss: (0.633)(R 0.507, F 0.759)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.855] [G acc: 0.438]\n",
      "11594 [D loss: (0.742)(R 0.763, F 0.721)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.720] [G acc: 0.750]\n",
      "11595 [D loss: (0.570)(R 0.558, F 0.582)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.688] [G acc: 0.812]\n",
      "11596 [D loss: (0.762)(R 0.813, F 0.710)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.736] [G acc: 0.750]\n",
      "11597 [D loss: (0.685)(R 0.628, F 0.742)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.806] [G acc: 0.812]\n",
      "11598 [D loss: (0.792)(R 0.833, F 0.752)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.821] [G acc: 0.625]\n",
      "11599 [D loss: (0.569)(R 0.514, F 0.623)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.769] [G acc: 0.750]\n",
      "11600 [D loss: (0.619)(R 0.684, F 0.555)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.759] [G acc: 0.750]\n",
      "11601 [D loss: (0.623)(R 0.561, F 0.684)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.725] [G acc: 0.688]\n",
      "11602 [D loss: (0.628)(R 0.573, F 0.683)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.919] [G acc: 0.688]\n",
      "11603 [D loss: (0.700)(R 0.657, F 0.742)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.806] [G acc: 0.750]\n",
      "11604 [D loss: (0.631)(R 0.545, F 0.718)] [D acc: (0.562)(0.938, 0.188)] [G loss: 0.954] [G acc: 0.375]\n",
      "11605 [D loss: (0.537)(R 0.692, F 0.382)] [D acc: (0.719)(0.750, 0.688)] [G loss: 2.540] [G acc: 0.375]\n",
      "11606 [D loss: (0.553)(R 0.555, F 0.552)] [D acc: (0.750)(0.938, 0.562)] [G loss: 0.774] [G acc: 0.812]\n",
      "11607 [D loss: (0.607)(R 0.572, F 0.643)] [D acc: (0.656)(0.875, 0.438)] [G loss: 2.384] [G acc: 0.250]\n",
      "11608 [D loss: (0.664)(R 0.696, F 0.632)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.884] [G acc: 0.562]\n",
      "11609 [D loss: (0.811)(R 0.843, F 0.780)] [D acc: (0.438)(0.688, 0.188)] [G loss: 0.829] [G acc: 0.562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11610 [D loss: (0.727)(R 0.712, F 0.743)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.776] [G acc: 0.625]\n",
      "11611 [D loss: (0.598)(R 0.506, F 0.691)] [D acc: (0.719)(1.000, 0.438)] [G loss: 0.698] [G acc: 0.750]\n",
      "11612 [D loss: (0.755)(R 0.738, F 0.773)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.798] [G acc: 0.438]\n",
      "11613 [D loss: (0.639)(R 0.611, F 0.666)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.745] [G acc: 0.625]\n",
      "11614 [D loss: (0.613)(R 0.631, F 0.596)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.753] [G acc: 0.625]\n",
      "11615 [D loss: (0.613)(R 0.581, F 0.645)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.925] [G acc: 0.562]\n",
      "11616 [D loss: (0.740)(R 0.723, F 0.757)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.785] [G acc: 0.562]\n",
      "11617 [D loss: (0.569)(R 0.605, F 0.533)] [D acc: (0.844)(0.875, 0.812)] [G loss: 0.787] [G acc: 0.375]\n",
      "11618 [D loss: (0.683)(R 0.637, F 0.729)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.899] [G acc: 0.438]\n",
      "11619 [D loss: (0.696)(R 0.810, F 0.581)] [D acc: (0.812)(0.938, 0.688)] [G loss: 0.787] [G acc: 0.562]\n",
      "11620 [D loss: (0.673)(R 0.647, F 0.698)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.757] [G acc: 0.625]\n",
      "11621 [D loss: (0.627)(R 0.628, F 0.626)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.745] [G acc: 0.562]\n",
      "11622 [D loss: (0.648)(R 0.670, F 0.626)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.858] [G acc: 0.438]\n",
      "11623 [D loss: (0.563)(R 0.598, F 0.528)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.030] [G acc: 0.250]\n",
      "11624 [D loss: (0.627)(R 0.579, F 0.674)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.718] [G acc: 0.688]\n",
      "11625 [D loss: (0.727)(R 0.681, F 0.773)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.763] [G acc: 0.562]\n",
      "11626 [D loss: (0.637)(R 0.630, F 0.644)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.787] [G acc: 0.438]\n",
      "11627 [D loss: (0.700)(R 0.810, F 0.589)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.960] [G acc: 0.125]\n",
      "11628 [D loss: (0.627)(R 0.592, F 0.661)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.814] [G acc: 0.312]\n",
      "11629 [D loss: (0.582)(R 0.594, F 0.569)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.788] [G acc: 0.438]\n",
      "11630 [D loss: (0.595)(R 0.616, F 0.574)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.905] [G acc: 0.312]\n",
      "11631 [D loss: (0.627)(R 0.661, F 0.592)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.875] [G acc: 0.375]\n",
      "11632 [D loss: (0.642)(R 0.760, F 0.523)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.897] [G acc: 0.312]\n",
      "11633 [D loss: (0.776)(R 0.914, F 0.639)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.911] [G acc: 0.312]\n",
      "11634 [D loss: (0.575)(R 0.526, F 0.624)] [D acc: (0.750)(0.938, 0.562)] [G loss: 0.816] [G acc: 0.312]\n",
      "11635 [D loss: (0.699)(R 0.694, F 0.705)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.835] [G acc: 0.125]\n",
      "11636 [D loss: (0.617)(R 0.618, F 0.616)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.774] [G acc: 0.438]\n",
      "11637 [D loss: (0.701)(R 0.776, F 0.626)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.755] [G acc: 0.438]\n",
      "11638 [D loss: (0.616)(R 0.561, F 0.671)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.787] [G acc: 0.500]\n",
      "11639 [D loss: (0.681)(R 0.635, F 0.728)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.863] [G acc: 0.188]\n",
      "11640 [D loss: (0.589)(R 0.568, F 0.611)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.970] [G acc: 0.375]\n",
      "11641 [D loss: (0.572)(R 0.606, F 0.537)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.840] [G acc: 0.500]\n",
      "11642 [D loss: (0.558)(R 0.677, F 0.439)] [D acc: (0.875)(0.812, 0.938)] [G loss: 0.954] [G acc: 0.312]\n",
      "11643 [D loss: (0.600)(R 0.590, F 0.609)] [D acc: (0.781)(0.938, 0.625)] [G loss: 0.834] [G acc: 0.625]\n",
      "11644 [D loss: (0.553)(R 0.554, F 0.551)] [D acc: (0.938)(0.938, 0.938)] [G loss: 0.955] [G acc: 0.312]\n",
      "11645 [D loss: (0.591)(R 0.631, F 0.551)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.834] [G acc: 0.562]\n",
      "11646 [D loss: (0.582)(R 0.645, F 0.520)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.860] [G acc: 0.375]\n",
      "11647 [D loss: (0.658)(R 0.691, F 0.625)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.902] [G acc: 0.438]\n",
      "11648 [D loss: (0.688)(R 0.618, F 0.759)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.818] [G acc: 0.312]\n",
      "11649 [D loss: (0.634)(R 0.638, F 0.630)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.880] [G acc: 0.625]\n",
      "11650 [D loss: (0.626)(R 0.639, F 0.613)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.087] [G acc: 0.188]\n",
      "11651 [D loss: (0.707)(R 0.764, F 0.650)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.873] [G acc: 0.312]\n",
      "11652 [D loss: (0.656)(R 0.675, F 0.637)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.799] [G acc: 0.312]\n",
      "11653 [D loss: (0.705)(R 0.741, F 0.668)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.824] [G acc: 0.250]\n",
      "11654 [D loss: (0.529)(R 0.539, F 0.519)] [D acc: (0.875)(0.812, 0.938)] [G loss: 0.840] [G acc: 0.375]\n",
      "11655 [D loss: (0.561)(R 0.650, F 0.473)] [D acc: (0.938)(0.875, 1.000)] [G loss: 0.893] [G acc: 0.375]\n",
      "11656 [D loss: (0.573)(R 0.674, F 0.473)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.345] [G acc: 0.125]\n",
      "11657 [D loss: (0.559)(R 0.512, F 0.605)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.008] [G acc: 0.250]\n",
      "11658 [D loss: (0.597)(R 0.560, F 0.634)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.760] [G acc: 0.250]\n",
      "11659 [D loss: (0.684)(R 0.843, F 0.525)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.838] [G acc: 0.250]\n",
      "11660 [D loss: (0.616)(R 0.577, F 0.656)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.928] [G acc: 0.000]\n",
      "11661 [D loss: (0.643)(R 0.624, F 0.662)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.904] [G acc: 0.438]\n",
      "11662 [D loss: (0.653)(R 0.615, F 0.691)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.884] [G acc: 0.375]\n",
      "11663 [D loss: (0.623)(R 0.567, F 0.679)] [D acc: (0.625)(0.812, 0.438)] [G loss: 2.214] [G acc: 0.125]\n",
      "11664 [D loss: (0.478)(R 0.630, F 0.326)] [D acc: (0.875)(0.875, 0.875)] [G loss: 4.602] [G acc: 0.062]\n",
      "11665 [D loss: (0.594)(R 0.641, F 0.548)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.027] [G acc: 0.438]\n",
      "11666 [D loss: (0.626)(R 0.661, F 0.591)] [D acc: (0.844)(0.875, 0.812)] [G loss: 0.975] [G acc: 0.188]\n",
      "11667 [D loss: (0.658)(R 0.751, F 0.565)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.973] [G acc: 0.125]\n",
      "11668 [D loss: (0.601)(R 0.614, F 0.589)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.090] [G acc: 0.188]\n",
      "11669 [D loss: (0.552)(R 0.649, F 0.455)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.946] [G acc: 0.188]\n",
      "11670 [D loss: (0.519)(R 0.576, F 0.462)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.089] [G acc: 0.250]\n",
      "11671 [D loss: (0.570)(R 0.586, F 0.553)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.189] [G acc: 0.312]\n",
      "11672 [D loss: (0.599)(R 0.547, F 0.650)] [D acc: (0.750)(0.938, 0.562)] [G loss: 0.791] [G acc: 0.438]\n",
      "11673 [D loss: (0.698)(R 0.762, F 0.635)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.973] [G acc: 0.312]\n",
      "11674 [D loss: (0.616)(R 0.572, F 0.660)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.779] [G acc: 0.438]\n",
      "11675 [D loss: (0.642)(R 0.640, F 0.643)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.193] [G acc: 0.250]\n",
      "11676 [D loss: (0.593)(R 0.615, F 0.572)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.774] [G acc: 0.312]\n",
      "11677 [D loss: (0.623)(R 0.602, F 0.644)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.847] [G acc: 0.438]\n",
      "11678 [D loss: (0.563)(R 0.555, F 0.572)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.992] [G acc: 0.375]\n",
      "11679 [D loss: (0.689)(R 0.758, F 0.621)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.786] [G acc: 0.375]\n",
      "11680 [D loss: (0.693)(R 0.837, F 0.549)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.901] [G acc: 0.375]\n",
      "11681 [D loss: (0.523)(R 0.525, F 0.522)] [D acc: (0.906)(1.000, 0.812)] [G loss: 0.936] [G acc: 0.125]\n",
      "11682 [D loss: (0.580)(R 0.635, F 0.526)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.869] [G acc: 0.438]\n",
      "11683 [D loss: (0.627)(R 0.560, F 0.693)] [D acc: (0.688)(0.812, 0.562)] [G loss: 1.040] [G acc: 0.312]\n",
      "11684 [D loss: (0.613)(R 0.611, F 0.615)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.004] [G acc: 0.062]\n",
      "11685 [D loss: (0.699)(R 0.765, F 0.633)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.930] [G acc: 0.188]\n",
      "11686 [D loss: (0.546)(R 0.544, F 0.547)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.977] [G acc: 0.125]\n",
      "11687 [D loss: (0.603)(R 0.570, F 0.635)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.047] [G acc: 0.062]\n",
      "11688 [D loss: (0.561)(R 0.624, F 0.499)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.834] [G acc: 0.375]\n",
      "11689 [D loss: (0.556)(R 0.584, F 0.529)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.084] [G acc: 0.250]\n",
      "11690 [D loss: (0.565)(R 0.593, F 0.537)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.048] [G acc: 0.000]\n",
      "11691 [D loss: (0.579)(R 0.617, F 0.541)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.899] [G acc: 0.312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11692 [D loss: (0.649)(R 0.584, F 0.715)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.938] [G acc: 0.188]\n",
      "11693 [D loss: (0.549)(R 0.595, F 0.503)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.035] [G acc: 0.188]\n",
      "11694 [D loss: (0.595)(R 0.652, F 0.537)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.819] [G acc: 0.312]\n",
      "11695 [D loss: (0.631)(R 0.617, F 0.645)] [D acc: (0.688)(0.812, 0.562)] [G loss: 1.102] [G acc: 0.250]\n",
      "11696 [D loss: (0.504)(R 0.761, F 0.246)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.591] [G acc: 0.062]\n",
      "11697 [D loss: (0.572)(R 0.674, F 0.471)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.051] [G acc: 0.125]\n",
      "11698 [D loss: (0.532)(R 0.518, F 0.545)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.028] [G acc: 0.312]\n",
      "11699 [D loss: (0.574)(R 0.611, F 0.538)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.039] [G acc: 0.375]\n",
      "11700 [D loss: (0.608)(R 0.564, F 0.653)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.963] [G acc: 0.125]\n",
      "11701 [D loss: (0.671)(R 0.738, F 0.604)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.971] [G acc: 0.312]\n",
      "11702 [D loss: (0.649)(R 0.684, F 0.613)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.009] [G acc: 0.312]\n",
      "11703 [D loss: (0.615)(R 0.621, F 0.610)] [D acc: (0.719)(0.875, 0.562)] [G loss: 1.349] [G acc: 0.188]\n",
      "11704 [D loss: (0.666)(R 0.673, F 0.659)] [D acc: (0.562)(0.688, 0.438)] [G loss: 1.245] [G acc: 0.188]\n",
      "11705 [D loss: (0.554)(R 0.654, F 0.455)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.788] [G acc: 0.500]\n",
      "11706 [D loss: (0.611)(R 0.821, F 0.401)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.449] [G acc: 0.062]\n",
      "11707 [D loss: (0.587)(R 0.652, F 0.522)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.823] [G acc: 0.438]\n",
      "11708 [D loss: (0.606)(R 0.655, F 0.556)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.008] [G acc: 0.250]\n",
      "11709 [D loss: (0.562)(R 0.603, F 0.522)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.071] [G acc: 0.312]\n",
      "11710 [D loss: (0.564)(R 0.545, F 0.583)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.097] [G acc: 0.312]\n",
      "11711 [D loss: (0.623)(R 0.589, F 0.657)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.981] [G acc: 0.375]\n",
      "11712 [D loss: (0.636)(R 0.808, F 0.465)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.855] [G acc: 0.438]\n",
      "11713 [D loss: (0.636)(R 0.681, F 0.592)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.051] [G acc: 0.250]\n",
      "11714 [D loss: (0.603)(R 0.540, F 0.666)] [D acc: (0.688)(0.875, 0.500)] [G loss: 1.047] [G acc: 0.188]\n",
      "11715 [D loss: (0.549)(R 0.545, F 0.553)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.124] [G acc: 0.312]\n",
      "11716 [D loss: (0.581)(R 0.584, F 0.578)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.920] [G acc: 0.312]\n",
      "11717 [D loss: (0.528)(R 0.538, F 0.517)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.846] [G acc: 0.188]\n",
      "11718 [D loss: (0.623)(R 0.786, F 0.460)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.272] [G acc: 0.062]\n",
      "11719 [D loss: (0.550)(R 0.617, F 0.483)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.970] [G acc: 0.438]\n",
      "11720 [D loss: (0.606)(R 0.679, F 0.533)] [D acc: (0.688)(0.750, 0.625)] [G loss: 2.254] [G acc: 0.000]\n",
      "11721 [D loss: (0.438)(R 0.525, F 0.351)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.703] [G acc: 0.562]\n",
      "11722 [D loss: (0.581)(R 0.781, F 0.381)] [D acc: (0.750)(0.625, 0.875)] [G loss: 2.753] [G acc: 0.250]\n",
      "11723 [D loss: (0.686)(R 0.793, F 0.579)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.201] [G acc: 0.188]\n",
      "11724 [D loss: (0.609)(R 0.623, F 0.596)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.891] [G acc: 0.375]\n",
      "11725 [D loss: (0.634)(R 0.677, F 0.590)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.975] [G acc: 0.375]\n",
      "11726 [D loss: (0.627)(R 0.645, F 0.609)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.053] [G acc: 0.312]\n",
      "11727 [D loss: (0.641)(R 0.637, F 0.644)] [D acc: (0.594)(0.750, 0.438)] [G loss: 1.283] [G acc: 0.188]\n",
      "11728 [D loss: (0.662)(R 0.786, F 0.538)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.174] [G acc: 0.250]\n",
      "11729 [D loss: (0.634)(R 0.636, F 0.633)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.966] [G acc: 0.312]\n",
      "11730 [D loss: (0.550)(R 0.607, F 0.494)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.924] [G acc: 0.375]\n",
      "11731 [D loss: (0.562)(R 0.570, F 0.555)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.993] [G acc: 0.250]\n",
      "11732 [D loss: (0.577)(R 0.591, F 0.563)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.875] [G acc: 0.438]\n",
      "11733 [D loss: (0.580)(R 0.626, F 0.533)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.074] [G acc: 0.250]\n",
      "11734 [D loss: (0.630)(R 0.691, F 0.569)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.994] [G acc: 0.562]\n",
      "11735 [D loss: (0.510)(R 0.502, F 0.519)] [D acc: (0.875)(1.000, 0.750)] [G loss: 0.995] [G acc: 0.500]\n",
      "11736 [D loss: (0.557)(R 0.532, F 0.582)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.959] [G acc: 0.562]\n",
      "11737 [D loss: (0.589)(R 0.570, F 0.608)] [D acc: (0.688)(0.812, 0.562)] [G loss: 1.057] [G acc: 0.438]\n",
      "11738 [D loss: (0.735)(R 0.711, F 0.758)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.948] [G acc: 0.625]\n",
      "11739 [D loss: (0.661)(R 0.708, F 0.614)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.953] [G acc: 0.438]\n",
      "11740 [D loss: (0.765)(R 0.778, F 0.752)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.969] [G acc: 0.438]\n",
      "11741 [D loss: (0.794)(R 0.786, F 0.802)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.853] [G acc: 0.375]\n",
      "11742 [D loss: (0.641)(R 0.621, F 0.661)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.971] [G acc: 0.375]\n",
      "11743 [D loss: (0.577)(R 0.626, F 0.527)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.931] [G acc: 0.562]\n",
      "11744 [D loss: (0.707)(R 0.694, F 0.719)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.900] [G acc: 0.562]\n",
      "11745 [D loss: (0.591)(R 0.499, F 0.682)] [D acc: (0.656)(0.938, 0.375)] [G loss: 1.098] [G acc: 0.562]\n",
      "11746 [D loss: (0.782)(R 0.921, F 0.644)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.959] [G acc: 0.562]\n",
      "11747 [D loss: (0.697)(R 0.702, F 0.691)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.805] [G acc: 0.688]\n",
      "11748 [D loss: (0.692)(R 0.625, F 0.759)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.825] [G acc: 0.688]\n",
      "11749 [D loss: (0.660)(R 0.492, F 0.829)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.890] [G acc: 0.625]\n",
      "11750 [D loss: (0.780)(R 0.782, F 0.778)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.790] [G acc: 0.562]\n",
      "11751 [D loss: (0.868)(R 0.935, F 0.802)] [D acc: (0.375)(0.438, 0.312)] [G loss: 0.656] [G acc: 0.812]\n",
      "11752 [D loss: (0.779)(R 0.811, F 0.747)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.688] [G acc: 0.688]\n",
      "11753 [D loss: (0.634)(R 0.585, F 0.682)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.858] [G acc: 0.562]\n",
      "11754 [D loss: (0.681)(R 0.665, F 0.698)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.741] [G acc: 0.500]\n",
      "11755 [D loss: (0.608)(R 0.584, F 0.632)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.106] [G acc: 0.438]\n",
      "11756 [D loss: (0.641)(R 0.564, F 0.718)] [D acc: (0.656)(0.938, 0.375)] [G loss: 0.961] [G acc: 0.438]\n",
      "11757 [D loss: (0.602)(R 0.483, F 0.720)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.914] [G acc: 0.562]\n",
      "11758 [D loss: (0.742)(R 0.693, F 0.791)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.722] [G acc: 0.812]\n",
      "11759 [D loss: (0.591)(R 0.563, F 0.619)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.757] [G acc: 0.688]\n",
      "11760 [D loss: (0.711)(R 0.618, F 0.803)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.876] [G acc: 0.625]\n",
      "11761 [D loss: (0.765)(R 0.624, F 0.906)] [D acc: (0.531)(0.938, 0.125)] [G loss: 0.971] [G acc: 0.562]\n",
      "11762 [D loss: (0.733)(R 0.570, F 0.896)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.754] [G acc: 0.750]\n",
      "11763 [D loss: (0.594)(R 0.464, F 0.723)] [D acc: (0.656)(0.938, 0.375)] [G loss: 0.655] [G acc: 0.750]\n",
      "11764 [D loss: (0.569)(R 0.477, F 0.662)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.724] [G acc: 0.812]\n",
      "11765 [D loss: (0.597)(R 0.536, F 0.659)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.774] [G acc: 0.812]\n",
      "11766 [D loss: (0.721)(R 0.586, F 0.856)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.806] [G acc: 0.688]\n",
      "11767 [D loss: (0.629)(R 0.509, F 0.749)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.788] [G acc: 0.750]\n",
      "11768 [D loss: (0.614)(R 0.487, F 0.740)] [D acc: (0.656)(1.000, 0.312)] [G loss: 0.897] [G acc: 0.750]\n",
      "11769 [D loss: (0.686)(R 0.556, F 0.815)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.936] [G acc: 0.625]\n",
      "11770 [D loss: (0.732)(R 0.705, F 0.760)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.817] [G acc: 0.688]\n",
      "11771 [D loss: (0.600)(R 0.523, F 0.676)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.795] [G acc: 0.750]\n",
      "11772 [D loss: (0.641)(R 0.630, F 0.652)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.713] [G acc: 0.750]\n",
      "11773 [D loss: (0.669)(R 0.659, F 0.678)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.829] [G acc: 0.688]\n",
      "11774 [D loss: (0.635)(R 0.493, F 0.777)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.990] [G acc: 0.812]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11775 [D loss: (0.773)(R 0.743, F 0.802)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.791] [G acc: 0.812]\n",
      "11776 [D loss: (0.595)(R 0.467, F 0.722)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.703] [G acc: 0.812]\n",
      "11777 [D loss: (0.680)(R 0.529, F 0.830)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.769] [G acc: 0.812]\n",
      "11778 [D loss: (0.660)(R 0.598, F 0.721)] [D acc: (0.594)(0.812, 0.375)] [G loss: 1.083] [G acc: 0.438]\n",
      "11779 [D loss: (0.703)(R 0.656, F 0.750)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.956] [G acc: 0.562]\n",
      "11780 [D loss: (0.583)(R 0.529, F 0.637)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.719] [G acc: 0.750]\n",
      "11781 [D loss: (0.681)(R 0.489, F 0.874)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.859] [G acc: 0.750]\n",
      "11782 [D loss: (0.645)(R 0.445, F 0.844)] [D acc: (0.562)(1.000, 0.125)] [G loss: 0.631] [G acc: 0.750]\n",
      "11783 [D loss: (0.727)(R 0.694, F 0.760)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.801] [G acc: 0.750]\n",
      "11784 [D loss: (0.811)(R 0.867, F 0.756)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.831] [G acc: 0.625]\n",
      "11785 [D loss: (0.622)(R 0.515, F 0.729)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.897] [G acc: 0.562]\n",
      "11786 [D loss: (0.485)(R 0.609, F 0.361)] [D acc: (0.844)(0.938, 0.750)] [G loss: 3.553] [G acc: 0.188]\n",
      "11787 [D loss: (0.498)(R 0.561, F 0.434)] [D acc: (0.844)(0.938, 0.750)] [G loss: 0.967] [G acc: 0.625]\n",
      "11788 [D loss: (0.612)(R 0.525, F 0.699)] [D acc: (0.656)(1.000, 0.312)] [G loss: 0.977] [G acc: 0.625]\n",
      "11789 [D loss: (0.594)(R 0.517, F 0.671)] [D acc: (0.719)(1.000, 0.438)] [G loss: 0.897] [G acc: 0.750]\n",
      "11790 [D loss: (0.668)(R 0.521, F 0.814)] [D acc: (0.625)(1.000, 0.250)] [G loss: 0.864] [G acc: 0.625]\n",
      "11791 [D loss: (0.659)(R 0.618, F 0.701)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.776] [G acc: 0.812]\n",
      "11792 [D loss: (0.670)(R 0.681, F 0.658)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.700] [G acc: 0.812]\n",
      "11793 [D loss: (0.695)(R 0.646, F 0.744)] [D acc: (0.594)(0.875, 0.312)] [G loss: 1.334] [G acc: 0.500]\n",
      "11794 [D loss: (0.604)(R 0.571, F 0.637)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.710] [G acc: 0.812]\n",
      "11795 [D loss: (0.754)(R 0.739, F 0.769)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.934] [G acc: 0.688]\n",
      "11796 [D loss: (0.691)(R 0.524, F 0.858)] [D acc: (0.531)(0.938, 0.125)] [G loss: 0.829] [G acc: 0.750]\n",
      "11797 [D loss: (0.661)(R 0.612, F 0.711)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.790] [G acc: 0.750]\n",
      "11798 [D loss: (0.615)(R 0.462, F 0.769)] [D acc: (0.594)(1.000, 0.188)] [G loss: 0.725] [G acc: 0.750]\n",
      "11799 [D loss: (0.760)(R 0.700, F 0.819)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.967] [G acc: 0.625]\n",
      "11800 [D loss: (0.595)(R 0.519, F 0.670)] [D acc: (0.688)(1.000, 0.375)] [G loss: 0.948] [G acc: 0.688]\n",
      "11801 [D loss: (0.541)(R 0.534, F 0.547)] [D acc: (0.750)(0.938, 0.562)] [G loss: 0.882] [G acc: 0.562]\n",
      "11802 [D loss: (0.665)(R 0.545, F 0.785)] [D acc: (0.562)(0.938, 0.188)] [G loss: 1.058] [G acc: 0.750]\n",
      "11803 [D loss: (0.582)(R 0.536, F 0.629)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.888] [G acc: 0.812]\n",
      "11804 [D loss: (1.234)(R 1.594, F 0.873)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.894] [G acc: 0.688]\n",
      "11805 [D loss: (0.739)(R 0.597, F 0.881)] [D acc: (0.438)(0.812, 0.062)] [G loss: 0.830] [G acc: 0.688]\n",
      "11806 [D loss: (0.541)(R 0.497, F 0.584)] [D acc: (0.750)(1.000, 0.500)] [G loss: 0.650] [G acc: 0.875]\n",
      "11807 [D loss: (0.802)(R 0.867, F 0.736)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.791] [G acc: 0.812]\n",
      "11808 [D loss: (0.678)(R 0.665, F 0.692)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.942] [G acc: 0.750]\n",
      "11809 [D loss: (0.648)(R 0.535, F 0.761)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.744] [G acc: 0.812]\n",
      "11810 [D loss: (0.712)(R 0.574, F 0.850)] [D acc: (0.344)(0.625, 0.062)] [G loss: 0.692] [G acc: 0.750]\n",
      "11811 [D loss: (0.597)(R 0.564, F 0.629)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.817] [G acc: 0.688]\n",
      "11812 [D loss: (0.650)(R 0.642, F 0.658)] [D acc: (0.562)(0.812, 0.312)] [G loss: 1.008] [G acc: 0.750]\n",
      "11813 [D loss: (0.659)(R 0.540, F 0.779)] [D acc: (0.531)(0.938, 0.125)] [G loss: 0.657] [G acc: 0.875]\n",
      "11814 [D loss: (0.613)(R 0.436, F 0.790)] [D acc: (0.594)(1.000, 0.188)] [G loss: 0.776] [G acc: 0.625]\n",
      "11815 [D loss: (0.661)(R 0.683, F 0.639)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.762] [G acc: 0.750]\n",
      "11816 [D loss: (0.636)(R 0.497, F 0.775)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.699] [G acc: 0.812]\n",
      "11817 [D loss: (0.713)(R 0.609, F 0.817)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.855] [G acc: 0.688]\n",
      "11818 [D loss: (0.675)(R 0.617, F 0.733)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.904] [G acc: 0.688]\n",
      "11819 [D loss: (0.691)(R 0.571, F 0.811)] [D acc: (0.531)(0.938, 0.125)] [G loss: 0.726] [G acc: 0.750]\n",
      "11820 [D loss: (0.717)(R 0.632, F 0.803)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.758] [G acc: 0.812]\n",
      "11821 [D loss: (0.818)(R 0.685, F 0.951)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.809] [G acc: 0.688]\n",
      "11822 [D loss: (0.561)(R 0.451, F 0.671)] [D acc: (0.688)(1.000, 0.375)] [G loss: 0.802] [G acc: 0.688]\n",
      "11823 [D loss: (0.742)(R 0.759, F 0.724)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.745] [G acc: 0.750]\n",
      "11824 [D loss: (0.618)(R 0.542, F 0.695)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.633] [G acc: 0.875]\n",
      "11825 [D loss: (0.653)(R 0.596, F 0.710)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.730] [G acc: 0.812]\n",
      "11826 [D loss: (0.673)(R 0.563, F 0.782)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.758] [G acc: 0.812]\n",
      "11827 [D loss: (0.611)(R 0.495, F 0.727)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.739] [G acc: 0.688]\n",
      "11828 [D loss: (0.723)(R 0.750, F 0.696)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.864] [G acc: 0.688]\n",
      "11829 [D loss: (0.662)(R 0.529, F 0.794)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.827] [G acc: 0.750]\n",
      "11830 [D loss: (0.696)(R 0.544, F 0.849)] [D acc: (0.469)(0.938, 0.000)] [G loss: 0.865] [G acc: 0.750]\n",
      "11831 [D loss: (0.668)(R 0.577, F 0.759)] [D acc: (0.562)(0.938, 0.188)] [G loss: 0.941] [G acc: 0.688]\n",
      "11832 [D loss: (0.642)(R 0.549, F 0.735)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.904] [G acc: 0.750]\n",
      "11833 [D loss: (0.721)(R 0.700, F 0.741)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.684] [G acc: 0.750]\n",
      "11834 [D loss: (0.686)(R 0.541, F 0.830)] [D acc: (0.469)(0.875, 0.062)] [G loss: 0.727] [G acc: 0.750]\n",
      "11835 [D loss: (0.707)(R 0.640, F 0.775)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.654] [G acc: 0.750]\n",
      "11836 [D loss: (0.727)(R 0.653, F 0.801)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.596] [G acc: 1.000]\n",
      "11837 [D loss: (0.771)(R 0.652, F 0.889)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.718] [G acc: 0.750]\n",
      "11838 [D loss: (0.749)(R 0.724, F 0.773)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.651] [G acc: 0.750]\n",
      "11839 [D loss: (0.662)(R 0.587, F 0.736)] [D acc: (0.562)(0.938, 0.188)] [G loss: 0.755] [G acc: 0.688]\n",
      "11840 [D loss: (0.770)(R 0.717, F 0.823)] [D acc: (0.438)(0.812, 0.062)] [G loss: 0.731] [G acc: 0.688]\n",
      "11841 [D loss: (0.574)(R 0.518, F 0.630)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.884] [G acc: 0.438]\n",
      "11842 [D loss: (0.710)(R 0.744, F 0.675)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.778] [G acc: 0.625]\n",
      "11843 [D loss: (0.655)(R 0.549, F 0.760)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.833] [G acc: 0.500]\n",
      "11844 [D loss: (0.526)(R 0.622, F 0.430)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.884] [G acc: 0.500]\n",
      "11845 [D loss: (0.513)(R 0.563, F 0.464)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.627] [G acc: 0.438]\n",
      "11846 [D loss: (0.581)(R 0.620, F 0.542)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.915] [G acc: 0.500]\n",
      "11847 [D loss: (0.656)(R 0.649, F 0.663)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.836] [G acc: 0.688]\n",
      "11848 [D loss: (0.655)(R 0.616, F 0.695)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.754] [G acc: 0.625]\n",
      "11849 [D loss: (0.703)(R 0.653, F 0.753)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.668] [G acc: 0.688]\n",
      "11850 [D loss: (0.656)(R 0.603, F 0.710)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.855] [G acc: 0.562]\n",
      "11851 [D loss: (0.709)(R 0.709, F 0.710)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.700] [G acc: 0.750]\n",
      "11852 [D loss: (0.649)(R 0.572, F 0.727)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.750] [G acc: 0.750]\n",
      "11853 [D loss: (0.693)(R 0.597, F 0.790)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.690] [G acc: 0.750]\n",
      "11854 [D loss: (0.646)(R 0.574, F 0.718)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.674] [G acc: 0.812]\n",
      "11855 [D loss: (0.630)(R 0.541, F 0.719)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.838] [G acc: 0.688]\n",
      "11856 [D loss: (0.666)(R 0.598, F 0.734)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.871] [G acc: 0.750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11857 [D loss: (0.684)(R 0.544, F 0.824)] [D acc: (0.531)(0.875, 0.188)] [G loss: 1.554] [G acc: 0.125]\n",
      "11858 [D loss: (0.570)(R 0.692, F 0.448)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.163] [G acc: 0.375]\n",
      "11859 [D loss: (0.730)(R 0.923, F 0.536)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.129] [G acc: 0.250]\n",
      "11860 [D loss: (0.653)(R 0.588, F 0.718)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.696] [G acc: 0.812]\n",
      "11861 [D loss: (0.786)(R 0.773, F 0.798)] [D acc: (0.469)(0.875, 0.062)] [G loss: 0.920] [G acc: 0.688]\n",
      "11862 [D loss: (0.636)(R 0.539, F 0.734)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.846] [G acc: 0.688]\n",
      "11863 [D loss: (0.736)(R 0.709, F 0.763)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.802] [G acc: 0.750]\n",
      "11864 [D loss: (0.681)(R 0.591, F 0.771)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.740] [G acc: 0.750]\n",
      "11865 [D loss: (0.757)(R 0.722, F 0.792)] [D acc: (0.406)(0.812, 0.000)] [G loss: 0.704] [G acc: 0.812]\n",
      "11866 [D loss: (0.620)(R 0.555, F 0.684)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.748] [G acc: 0.750]\n",
      "11867 [D loss: (0.797)(R 0.857, F 0.738)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.672] [G acc: 0.812]\n",
      "11868 [D loss: (0.667)(R 0.683, F 0.652)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.831] [G acc: 0.688]\n",
      "11869 [D loss: (0.620)(R 0.570, F 0.670)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.738] [G acc: 0.562]\n",
      "11870 [D loss: (0.742)(R 0.741, F 0.742)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.765] [G acc: 0.625]\n",
      "11871 [D loss: (0.591)(R 0.594, F 0.588)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.777] [G acc: 0.750]\n",
      "11872 [D loss: (0.627)(R 0.568, F 0.686)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.647] [G acc: 0.812]\n",
      "11873 [D loss: (0.654)(R 0.601, F 0.706)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.793] [G acc: 0.562]\n",
      "11874 [D loss: (0.682)(R 0.716, F 0.648)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.740] [G acc: 0.812]\n",
      "11875 [D loss: (0.738)(R 0.732, F 0.745)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.746] [G acc: 0.688]\n",
      "11876 [D loss: (0.762)(R 0.700, F 0.824)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.688] [G acc: 0.688]\n",
      "11877 [D loss: (0.668)(R 0.605, F 0.732)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.710] [G acc: 0.750]\n",
      "11878 [D loss: (0.688)(R 0.594, F 0.781)] [D acc: (0.438)(0.812, 0.062)] [G loss: 0.795] [G acc: 0.625]\n",
      "11879 [D loss: (0.598)(R 0.573, F 0.624)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.728] [G acc: 0.750]\n",
      "11880 [D loss: (0.647)(R 0.598, F 0.696)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.720] [G acc: 0.812]\n",
      "11881 [D loss: (0.665)(R 0.625, F 0.704)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.748] [G acc: 0.688]\n",
      "11882 [D loss: (0.694)(R 0.690, F 0.697)] [D acc: (0.438)(0.688, 0.188)] [G loss: 0.769] [G acc: 0.625]\n",
      "11883 [D loss: (0.719)(R 0.660, F 0.778)] [D acc: (0.344)(0.625, 0.062)] [G loss: 0.765] [G acc: 0.688]\n",
      "11884 [D loss: (0.654)(R 0.567, F 0.740)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.777] [G acc: 0.500]\n",
      "11885 [D loss: (0.591)(R 0.570, F 0.611)] [D acc: (0.781)(0.938, 0.625)] [G loss: 0.795] [G acc: 0.562]\n",
      "11886 [D loss: (0.676)(R 0.724, F 0.628)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.706] [G acc: 0.750]\n",
      "11887 [D loss: (0.630)(R 0.582, F 0.678)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.735] [G acc: 0.688]\n",
      "11888 [D loss: (0.631)(R 0.605, F 0.656)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.837] [G acc: 0.688]\n",
      "11889 [D loss: (0.712)(R 0.582, F 0.843)] [D acc: (0.469)(0.875, 0.062)] [G loss: 0.860] [G acc: 0.562]\n",
      "11890 [D loss: (0.661)(R 0.613, F 0.710)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.723] [G acc: 0.688]\n",
      "11891 [D loss: (0.645)(R 0.583, F 0.707)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.752] [G acc: 0.812]\n",
      "11892 [D loss: (0.659)(R 0.605, F 0.713)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.789] [G acc: 0.688]\n",
      "11893 [D loss: (0.645)(R 0.621, F 0.670)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.805] [G acc: 0.625]\n",
      "11894 [D loss: (0.635)(R 0.595, F 0.676)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.772] [G acc: 0.750]\n",
      "11895 [D loss: (0.803)(R 0.965, F 0.641)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.834] [G acc: 0.500]\n",
      "11896 [D loss: (0.651)(R 0.619, F 0.684)] [D acc: (0.656)(0.938, 0.375)] [G loss: 0.903] [G acc: 0.562]\n",
      "11897 [D loss: (0.688)(R 0.717, F 0.659)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.737] [G acc: 0.688]\n",
      "11898 [D loss: (0.686)(R 0.707, F 0.664)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.758] [G acc: 0.688]\n",
      "11899 [D loss: (0.698)(R 0.679, F 0.717)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.674] [G acc: 0.688]\n",
      "11900 [D loss: (0.624)(R 0.685, F 0.563)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.757] [G acc: 0.562]\n",
      "11901 [D loss: (0.638)(R 0.632, F 0.644)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.786] [G acc: 0.500]\n",
      "11902 [D loss: (0.690)(R 0.604, F 0.776)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.818] [G acc: 0.438]\n",
      "11903 [D loss: (0.605)(R 0.523, F 0.688)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.810] [G acc: 0.500]\n",
      "11904 [D loss: (0.406)(R 0.588, F 0.224)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.141] [G acc: 0.250]\n",
      "11905 [D loss: (0.543)(R 0.535, F 0.552)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.173] [G acc: 0.438]\n",
      "11906 [D loss: (0.574)(R 0.536, F 0.613)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.784] [G acc: 0.500]\n",
      "11907 [D loss: (0.667)(R 0.731, F 0.603)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.733] [G acc: 0.562]\n",
      "11908 [D loss: (0.628)(R 0.651, F 0.606)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.714] [G acc: 0.688]\n",
      "11909 [D loss: (0.644)(R 0.625, F 0.662)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.746] [G acc: 0.625]\n",
      "11910 [D loss: (0.662)(R 0.674, F 0.650)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.776] [G acc: 0.562]\n",
      "11911 [D loss: (0.596)(R 0.546, F 0.646)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.855] [G acc: 0.500]\n",
      "11912 [D loss: (0.599)(R 0.560, F 0.637)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.900] [G acc: 0.375]\n",
      "11913 [D loss: (0.626)(R 0.605, F 0.647)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.957] [G acc: 0.500]\n",
      "11914 [D loss: (0.677)(R 0.612, F 0.743)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.800] [G acc: 0.688]\n",
      "11915 [D loss: (0.585)(R 0.588, F 0.582)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.834] [G acc: 0.438]\n",
      "11916 [D loss: (0.680)(R 0.703, F 0.656)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.749] [G acc: 0.625]\n",
      "11917 [D loss: (0.663)(R 0.686, F 0.639)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.766] [G acc: 0.625]\n",
      "11918 [D loss: (0.806)(R 0.758, F 0.853)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.783] [G acc: 0.688]\n",
      "11919 [D loss: (0.642)(R 0.616, F 0.667)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.850] [G acc: 0.375]\n",
      "11920 [D loss: (0.666)(R 0.632, F 0.700)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.797] [G acc: 0.562]\n",
      "11921 [D loss: (0.702)(R 0.698, F 0.706)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.704] [G acc: 0.562]\n",
      "11922 [D loss: (0.737)(R 0.574, F 0.899)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.746] [G acc: 0.625]\n",
      "11923 [D loss: (0.649)(R 0.579, F 0.719)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.909] [G acc: 0.438]\n",
      "11924 [D loss: (0.605)(R 0.582, F 0.628)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.828] [G acc: 0.438]\n",
      "11925 [D loss: (0.666)(R 0.661, F 0.671)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.755] [G acc: 0.625]\n",
      "11926 [D loss: (0.685)(R 0.635, F 0.735)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.817] [G acc: 0.312]\n",
      "11927 [D loss: (0.638)(R 0.676, F 0.600)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.869] [G acc: 0.500]\n",
      "11928 [D loss: (0.613)(R 0.605, F 0.621)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.848] [G acc: 0.688]\n",
      "11929 [D loss: (0.833)(R 1.000, F 0.667)] [D acc: (0.562)(0.688, 0.438)] [G loss: 1.047] [G acc: 0.188]\n",
      "11930 [D loss: (0.602)(R 0.638, F 0.566)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.863] [G acc: 0.438]\n",
      "11931 [D loss: (0.669)(R 0.721, F 0.618)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.880] [G acc: 0.312]\n",
      "11932 [D loss: (0.682)(R 0.685, F 0.679)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.946] [G acc: 0.188]\n",
      "11933 [D loss: (0.672)(R 0.653, F 0.691)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.776] [G acc: 0.438]\n",
      "11934 [D loss: (0.678)(R 0.652, F 0.705)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.973] [G acc: 0.250]\n",
      "11935 [D loss: (0.619)(R 0.612, F 0.627)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.847] [G acc: 0.375]\n",
      "11936 [D loss: (0.680)(R 0.670, F 0.689)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.880] [G acc: 0.438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11937 [D loss: (0.620)(R 0.628, F 0.612)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.743] [G acc: 0.500]\n",
      "11938 [D loss: (0.643)(R 0.587, F 0.700)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.916] [G acc: 0.375]\n",
      "11939 [D loss: (0.628)(R 0.653, F 0.603)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.867] [G acc: 0.562]\n",
      "11940 [D loss: (0.614)(R 0.566, F 0.661)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.870] [G acc: 0.312]\n",
      "11941 [D loss: (0.663)(R 0.675, F 0.651)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.796] [G acc: 0.562]\n",
      "11942 [D loss: (0.690)(R 0.710, F 0.670)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.701] [G acc: 0.625]\n",
      "11943 [D loss: (0.648)(R 0.663, F 0.633)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.791] [G acc: 0.562]\n",
      "11944 [D loss: (0.693)(R 0.673, F 0.714)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.822] [G acc: 0.562]\n",
      "11945 [D loss: (0.778)(R 0.843, F 0.714)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.803] [G acc: 0.562]\n",
      "11946 [D loss: (0.654)(R 0.620, F 0.689)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.835] [G acc: 0.562]\n",
      "11947 [D loss: (0.647)(R 0.671, F 0.622)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.718] [G acc: 0.688]\n",
      "11948 [D loss: (0.647)(R 0.668, F 0.626)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.754] [G acc: 0.562]\n",
      "11949 [D loss: (0.735)(R 0.695, F 0.776)] [D acc: (0.375)(0.625, 0.125)] [G loss: 0.782] [G acc: 0.438]\n",
      "11950 [D loss: (0.629)(R 0.595, F 0.664)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.741] [G acc: 0.625]\n",
      "11951 [D loss: (0.722)(R 0.747, F 0.697)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.860] [G acc: 0.562]\n",
      "11952 [D loss: (0.667)(R 0.534, F 0.800)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.736] [G acc: 0.625]\n",
      "11953 [D loss: (0.607)(R 0.613, F 0.601)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.895] [G acc: 0.438]\n",
      "11954 [D loss: (0.643)(R 0.651, F 0.635)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.791] [G acc: 0.438]\n",
      "11955 [D loss: (0.615)(R 0.694, F 0.537)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.799] [G acc: 0.500]\n",
      "11956 [D loss: (0.619)(R 0.625, F 0.613)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.883] [G acc: 0.438]\n",
      "11957 [D loss: (0.659)(R 0.731, F 0.588)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.919] [G acc: 0.312]\n",
      "11958 [D loss: (0.897)(R 0.655, F 1.139)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.842] [G acc: 0.375]\n",
      "11959 [D loss: (0.602)(R 0.609, F 0.596)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.820] [G acc: 0.438]\n",
      "11960 [D loss: (0.757)(R 0.766, F 0.749)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.815] [G acc: 0.375]\n",
      "11961 [D loss: (0.695)(R 0.692, F 0.698)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.765] [G acc: 0.500]\n",
      "11962 [D loss: (0.705)(R 0.738, F 0.672)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.774] [G acc: 0.625]\n",
      "11963 [D loss: (0.653)(R 0.668, F 0.637)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.957] [G acc: 0.500]\n",
      "11964 [D loss: (0.628)(R 0.628, F 0.628)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.708] [G acc: 0.750]\n",
      "11965 [D loss: (0.648)(R 0.657, F 0.640)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.807] [G acc: 0.562]\n",
      "11966 [D loss: (0.633)(R 0.551, F 0.714)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.835] [G acc: 0.500]\n",
      "11967 [D loss: (0.711)(R 0.787, F 0.634)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.869] [G acc: 0.562]\n",
      "11968 [D loss: (0.606)(R 0.613, F 0.600)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.908] [G acc: 0.438]\n",
      "11969 [D loss: (0.662)(R 0.649, F 0.675)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.809] [G acc: 0.625]\n",
      "11970 [D loss: (0.668)(R 0.674, F 0.662)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.885] [G acc: 0.625]\n",
      "11971 [D loss: (0.624)(R 0.536, F 0.712)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.815] [G acc: 0.438]\n",
      "11972 [D loss: (0.658)(R 0.623, F 0.693)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.811] [G acc: 0.750]\n",
      "11973 [D loss: (0.694)(R 0.732, F 0.655)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.829] [G acc: 0.625]\n",
      "11974 [D loss: (0.658)(R 0.652, F 0.664)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.723] [G acc: 0.688]\n",
      "11975 [D loss: (0.657)(R 0.665, F 0.650)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.726] [G acc: 0.750]\n",
      "11976 [D loss: (0.687)(R 0.701, F 0.673)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.938] [G acc: 0.375]\n",
      "11977 [D loss: (0.659)(R 0.631, F 0.687)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.859] [G acc: 0.625]\n",
      "11978 [D loss: (0.736)(R 0.802, F 0.670)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.843] [G acc: 0.625]\n",
      "11979 [D loss: (0.647)(R 0.604, F 0.690)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.914] [G acc: 0.188]\n",
      "11980 [D loss: (0.636)(R 0.616, F 0.656)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.887] [G acc: 0.562]\n",
      "11981 [D loss: (0.678)(R 0.671, F 0.685)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.755] [G acc: 0.625]\n",
      "11982 [D loss: (0.680)(R 0.657, F 0.703)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.880] [G acc: 0.625]\n",
      "11983 [D loss: (0.737)(R 0.760, F 0.714)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.768] [G acc: 0.625]\n",
      "11984 [D loss: (0.716)(R 0.686, F 0.747)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.756] [G acc: 0.625]\n",
      "11985 [D loss: (0.628)(R 0.670, F 0.587)] [D acc: (0.594)(0.750, 0.438)] [G loss: 1.020] [G acc: 0.312]\n",
      "11986 [D loss: (0.459)(R 0.545, F 0.373)] [D acc: (0.750)(0.875, 0.625)] [G loss: 5.416] [G acc: 0.125]\n",
      "11987 [D loss: (0.701)(R 0.692, F 0.711)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.699] [G acc: 0.500]\n",
      "11988 [D loss: (0.613)(R 0.640, F 0.585)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.014] [G acc: 0.438]\n",
      "11989 [D loss: (0.713)(R 0.523, F 0.903)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.768] [G acc: 0.625]\n",
      "11990 [D loss: (0.509)(R 0.543, F 0.476)] [D acc: (0.812)(0.938, 0.688)] [G loss: 0.727] [G acc: 0.500]\n",
      "11991 [D loss: (0.637)(R 0.629, F 0.645)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.718] [G acc: 0.688]\n",
      "11992 [D loss: (0.596)(R 0.554, F 0.638)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.767] [G acc: 0.625]\n",
      "11993 [D loss: (0.745)(R 0.765, F 0.726)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.647] [G acc: 0.875]\n",
      "11994 [D loss: (0.686)(R 0.651, F 0.722)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.978] [G acc: 0.375]\n",
      "11995 [D loss: (0.601)(R 0.565, F 0.637)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.898] [G acc: 0.500]\n",
      "11996 [D loss: (0.770)(R 0.784, F 0.755)] [D acc: (0.375)(0.562, 0.188)] [G loss: 0.832] [G acc: 0.500]\n",
      "11997 [D loss: (0.687)(R 0.726, F 0.647)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.816] [G acc: 0.688]\n",
      "11998 [D loss: (0.623)(R 0.583, F 0.663)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.879] [G acc: 0.562]\n",
      "11999 [D loss: (0.708)(R 0.694, F 0.722)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.745] [G acc: 0.562]\n",
      "12000 [D loss: (0.550)(R 0.489, F 0.610)] [D acc: (0.750)(0.938, 0.562)] [G loss: 0.956] [G acc: 0.438]\n",
      "12001 [D loss: (0.574)(R 0.589, F 0.559)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.927] [G acc: 0.375]\n",
      "12002 [D loss: (0.594)(R 0.606, F 0.581)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.874] [G acc: 0.562]\n",
      "12003 [D loss: (0.629)(R 0.592, F 0.666)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.740] [G acc: 0.750]\n",
      "12004 [D loss: (0.688)(R 0.533, F 0.844)] [D acc: (0.656)(0.938, 0.375)] [G loss: 0.910] [G acc: 0.438]\n",
      "12005 [D loss: (0.690)(R 0.700, F 0.680)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.928] [G acc: 0.500]\n",
      "12006 [D loss: (0.586)(R 0.691, F 0.481)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.814] [G acc: 0.688]\n",
      "12007 [D loss: (0.626)(R 0.581, F 0.671)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.743] [G acc: 0.500]\n",
      "12008 [D loss: (0.700)(R 0.631, F 0.770)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.749] [G acc: 0.812]\n",
      "12009 [D loss: (0.654)(R 0.666, F 0.643)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.840] [G acc: 0.562]\n",
      "12010 [D loss: (0.622)(R 0.642, F 0.602)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.863] [G acc: 0.500]\n",
      "12011 [D loss: (0.586)(R 0.607, F 0.564)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.750] [G acc: 0.625]\n",
      "12012 [D loss: (0.730)(R 0.720, F 0.740)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.979] [G acc: 0.562]\n",
      "12013 [D loss: (0.613)(R 0.657, F 0.570)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.994] [G acc: 0.312]\n",
      "12014 [D loss: (0.480)(R 0.609, F 0.352)] [D acc: (0.812)(0.938, 0.688)] [G loss: 1.855] [G acc: 0.188]\n",
      "12015 [D loss: (0.515)(R 0.645, F 0.384)] [D acc: (0.875)(0.875, 0.875)] [G loss: 0.985] [G acc: 0.188]\n",
      "12016 [D loss: (0.558)(R 0.566, F 0.550)] [D acc: (0.781)(0.938, 0.625)] [G loss: 1.066] [G acc: 0.375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12017 [D loss: (0.587)(R 0.638, F 0.536)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.079] [G acc: 0.250]\n",
      "12018 [D loss: (0.610)(R 0.583, F 0.637)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.050] [G acc: 0.250]\n",
      "12019 [D loss: (0.611)(R 0.596, F 0.625)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.958] [G acc: 0.438]\n",
      "12020 [D loss: (0.666)(R 0.642, F 0.690)] [D acc: (0.562)(0.750, 0.375)] [G loss: 1.006] [G acc: 0.250]\n",
      "12021 [D loss: (0.585)(R 0.593, F 0.577)] [D acc: (0.625)(0.750, 0.500)] [G loss: 1.555] [G acc: 0.188]\n",
      "12022 [D loss: (0.577)(R 0.665, F 0.490)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.123] [G acc: 0.375]\n",
      "12023 [D loss: (0.537)(R 0.549, F 0.525)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.103] [G acc: 0.312]\n",
      "12024 [D loss: (0.617)(R 0.638, F 0.596)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.069] [G acc: 0.375]\n",
      "12025 [D loss: (0.578)(R 0.728, F 0.427)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.923] [G acc: 0.438]\n",
      "12026 [D loss: (0.557)(R 0.596, F 0.519)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.989] [G acc: 0.438]\n",
      "12027 [D loss: (0.643)(R 0.725, F 0.561)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.089] [G acc: 0.250]\n",
      "12028 [D loss: (0.913)(R 1.304, F 0.523)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.081] [G acc: 0.188]\n",
      "12029 [D loss: (0.620)(R 0.681, F 0.559)] [D acc: (0.719)(0.875, 0.562)] [G loss: 1.149] [G acc: 0.188]\n",
      "12030 [D loss: (0.684)(R 0.710, F 0.658)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.994] [G acc: 0.250]\n",
      "12031 [D loss: (0.592)(R 0.686, F 0.498)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.994] [G acc: 0.250]\n",
      "12032 [D loss: (0.610)(R 0.630, F 0.590)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.991] [G acc: 0.250]\n",
      "12033 [D loss: (0.582)(R 0.530, F 0.635)] [D acc: (0.781)(0.938, 0.625)] [G loss: 1.028] [G acc: 0.375]\n",
      "12034 [D loss: (0.576)(R 0.584, F 0.568)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.912] [G acc: 0.375]\n",
      "12035 [D loss: (0.676)(R 0.757, F 0.596)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.782] [G acc: 0.562]\n",
      "12036 [D loss: (0.585)(R 0.555, F 0.614)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.918] [G acc: 0.188]\n",
      "12037 [D loss: (0.601)(R 0.633, F 0.569)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.860] [G acc: 0.375]\n",
      "12038 [D loss: (0.829)(R 1.104, F 0.553)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.136] [G acc: 0.000]\n",
      "12039 [D loss: (0.622)(R 0.683, F 0.562)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.931] [G acc: 0.375]\n",
      "12040 [D loss: (0.582)(R 0.541, F 0.623)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.069] [G acc: 0.188]\n",
      "12041 [D loss: (0.625)(R 0.675, F 0.574)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.036] [G acc: 0.125]\n",
      "12042 [D loss: (0.561)(R 0.595, F 0.528)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.047] [G acc: 0.438]\n",
      "12043 [D loss: (0.603)(R 0.540, F 0.667)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.887] [G acc: 0.500]\n",
      "12044 [D loss: (0.612)(R 0.530, F 0.694)] [D acc: (0.656)(0.812, 0.500)] [G loss: 1.005] [G acc: 0.375]\n",
      "12045 [D loss: (0.737)(R 0.883, F 0.591)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.734] [G acc: 0.625]\n",
      "12046 [D loss: (0.585)(R 0.665, F 0.505)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.743] [G acc: 0.562]\n",
      "12047 [D loss: (0.574)(R 0.494, F 0.653)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.868] [G acc: 0.500]\n",
      "12048 [D loss: (0.586)(R 0.638, F 0.534)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.858] [G acc: 0.625]\n",
      "12049 [D loss: (0.659)(R 0.723, F 0.594)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.786] [G acc: 0.500]\n",
      "12050 [D loss: (0.650)(R 0.652, F 0.647)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.879] [G acc: 0.250]\n",
      "12051 [D loss: (0.674)(R 0.699, F 0.649)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.818] [G acc: 0.438]\n",
      "12052 [D loss: (0.793)(R 0.697, F 0.889)] [D acc: (0.375)(0.562, 0.188)] [G loss: 0.853] [G acc: 0.375]\n",
      "12053 [D loss: (0.561)(R 0.572, F 0.550)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.850] [G acc: 0.500]\n",
      "12054 [D loss: (0.744)(R 0.675, F 0.813)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.756] [G acc: 0.438]\n",
      "12055 [D loss: (0.532)(R 0.519, F 0.546)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.316] [G acc: 0.375]\n",
      "12056 [D loss: (0.406)(R 0.632, F 0.179)] [D acc: (0.875)(0.812, 0.938)] [G loss: 4.924] [G acc: 0.000]\n",
      "12057 [D loss: (0.682)(R 0.516, F 0.848)] [D acc: (0.750)(1.000, 0.500)] [G loss: 0.915] [G acc: 0.500]\n",
      "12058 [D loss: (0.637)(R 0.583, F 0.690)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.898] [G acc: 0.375]\n",
      "12059 [D loss: (0.656)(R 0.691, F 0.622)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.944] [G acc: 0.312]\n",
      "12060 [D loss: (0.601)(R 0.598, F 0.603)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.846] [G acc: 0.562]\n",
      "12061 [D loss: (0.706)(R 0.581, F 0.831)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.919] [G acc: 0.375]\n",
      "12062 [D loss: (0.607)(R 0.641, F 0.574)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.874] [G acc: 0.438]\n",
      "12063 [D loss: (0.573)(R 0.498, F 0.648)] [D acc: (0.656)(0.938, 0.375)] [G loss: 0.765] [G acc: 0.500]\n",
      "12064 [D loss: (0.736)(R 0.722, F 0.749)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.912] [G acc: 0.562]\n",
      "12065 [D loss: (0.640)(R 0.658, F 0.622)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.837] [G acc: 0.375]\n",
      "12066 [D loss: (0.601)(R 0.612, F 0.590)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.900] [G acc: 0.312]\n",
      "12067 [D loss: (0.632)(R 0.572, F 0.693)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.919] [G acc: 0.375]\n",
      "12068 [D loss: (0.533)(R 0.488, F 0.577)] [D acc: (0.750)(0.938, 0.562)] [G loss: 0.870] [G acc: 0.438]\n",
      "12069 [D loss: (0.629)(R 0.613, F 0.646)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.883] [G acc: 0.375]\n",
      "12070 [D loss: (0.605)(R 0.562, F 0.648)] [D acc: (0.656)(0.938, 0.375)] [G loss: 0.851] [G acc: 0.500]\n",
      "12071 [D loss: (0.900)(R 0.655, F 1.145)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.905] [G acc: 0.312]\n",
      "12072 [D loss: (0.607)(R 0.682, F 0.533)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.894] [G acc: 0.562]\n",
      "12073 [D loss: (0.812)(R 0.864, F 0.760)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.876] [G acc: 0.500]\n",
      "12074 [D loss: (0.618)(R 0.550, F 0.686)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.918] [G acc: 0.438]\n",
      "12075 [D loss: (0.744)(R 0.771, F 0.717)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.811] [G acc: 0.688]\n",
      "12076 [D loss: (0.700)(R 0.689, F 0.712)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.709] [G acc: 0.562]\n",
      "12077 [D loss: (0.682)(R 0.657, F 0.707)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.707] [G acc: 0.625]\n",
      "12078 [D loss: (0.652)(R 0.707, F 0.597)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.844] [G acc: 0.375]\n",
      "12079 [D loss: (0.630)(R 0.598, F 0.661)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.921] [G acc: 0.312]\n",
      "12080 [D loss: (0.697)(R 0.636, F 0.757)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.711] [G acc: 0.562]\n",
      "12081 [D loss: (0.629)(R 0.566, F 0.692)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.824] [G acc: 0.562]\n",
      "12082 [D loss: (0.696)(R 0.715, F 0.677)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.737] [G acc: 0.562]\n",
      "12083 [D loss: (0.601)(R 0.538, F 0.664)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.778] [G acc: 0.688]\n",
      "12084 [D loss: (0.627)(R 0.636, F 0.619)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.769] [G acc: 0.688]\n",
      "12085 [D loss: (0.677)(R 0.710, F 0.643)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.698] [G acc: 0.750]\n",
      "12086 [D loss: (0.653)(R 0.691, F 0.615)] [D acc: (0.562)(0.625, 0.500)] [G loss: 1.193] [G acc: 0.375]\n",
      "12087 [D loss: (0.481)(R 0.538, F 0.423)] [D acc: (0.750)(0.875, 0.625)] [G loss: 4.785] [G acc: 0.125]\n",
      "12088 [D loss: (0.481)(R 0.593, F 0.370)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.010] [G acc: 0.312]\n",
      "12089 [D loss: (0.618)(R 0.630, F 0.606)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.933] [G acc: 0.625]\n",
      "12090 [D loss: (0.637)(R 0.519, F 0.755)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.750] [G acc: 0.688]\n",
      "12091 [D loss: (0.743)(R 0.751, F 0.734)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.820] [G acc: 0.625]\n",
      "12092 [D loss: (0.654)(R 0.533, F 0.776)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.795] [G acc: 0.562]\n",
      "12093 [D loss: (0.607)(R 0.529, F 0.686)] [D acc: (0.656)(0.938, 0.375)] [G loss: 0.950] [G acc: 0.438]\n",
      "12094 [D loss: (0.635)(R 0.617, F 0.652)] [D acc: (0.750)(0.938, 0.562)] [G loss: 0.883] [G acc: 0.562]\n",
      "12095 [D loss: (0.582)(R 0.671, F 0.493)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.844] [G acc: 0.562]\n",
      "12096 [D loss: (0.646)(R 0.644, F 0.647)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.817] [G acc: 0.500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12097 [D loss: (0.696)(R 0.702, F 0.689)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.877] [G acc: 0.500]\n",
      "12098 [D loss: (0.624)(R 0.575, F 0.672)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.925] [G acc: 0.688]\n",
      "12099 [D loss: (0.672)(R 0.555, F 0.789)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.838] [G acc: 0.438]\n",
      "12100 [D loss: (0.701)(R 0.695, F 0.708)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.860] [G acc: 0.375]\n",
      "12101 [D loss: (0.681)(R 0.638, F 0.724)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.739] [G acc: 0.625]\n",
      "12102 [D loss: (0.569)(R 0.551, F 0.587)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.826] [G acc: 0.500]\n",
      "12103 [D loss: (0.655)(R 0.630, F 0.681)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.830] [G acc: 0.625]\n",
      "12104 [D loss: (0.585)(R 0.549, F 0.620)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.780] [G acc: 0.562]\n",
      "12105 [D loss: (0.648)(R 0.640, F 0.655)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.877] [G acc: 0.562]\n",
      "12106 [D loss: (0.608)(R 0.650, F 0.567)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.853] [G acc: 0.500]\n",
      "12107 [D loss: (0.629)(R 0.553, F 0.706)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.817] [G acc: 0.625]\n",
      "12108 [D loss: (0.692)(R 0.609, F 0.775)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.951] [G acc: 0.500]\n",
      "12109 [D loss: (0.633)(R 0.510, F 0.756)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.792] [G acc: 0.500]\n",
      "12110 [D loss: (0.655)(R 0.636, F 0.674)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.748] [G acc: 0.500]\n",
      "12111 [D loss: (0.649)(R 0.680, F 0.618)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.823] [G acc: 0.625]\n",
      "12112 [D loss: (0.642)(R 0.602, F 0.682)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.843] [G acc: 0.688]\n",
      "12113 [D loss: (0.532)(R 0.525, F 0.539)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.751] [G acc: 0.562]\n",
      "12114 [D loss: (0.692)(R 0.634, F 0.750)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.744] [G acc: 0.625]\n",
      "12115 [D loss: (0.649)(R 0.652, F 0.645)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.753] [G acc: 0.500]\n",
      "12116 [D loss: (0.567)(R 0.505, F 0.628)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.796] [G acc: 0.438]\n",
      "12117 [D loss: (0.643)(R 0.582, F 0.703)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.792] [G acc: 0.562]\n",
      "12118 [D loss: (0.632)(R 0.577, F 0.688)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.742] [G acc: 0.688]\n",
      "12119 [D loss: (0.641)(R 0.613, F 0.670)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.778] [G acc: 0.500]\n",
      "12120 [D loss: (0.612)(R 0.609, F 0.616)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.762] [G acc: 0.625]\n",
      "12121 [D loss: (0.635)(R 0.549, F 0.721)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.804] [G acc: 0.625]\n",
      "12122 [D loss: (0.670)(R 0.559, F 0.781)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.799] [G acc: 0.688]\n",
      "12123 [D loss: (0.624)(R 0.575, F 0.674)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.758] [G acc: 0.750]\n",
      "12124 [D loss: (0.649)(R 0.554, F 0.743)] [D acc: (0.594)(0.812, 0.375)] [G loss: 1.056] [G acc: 0.375]\n",
      "12125 [D loss: (0.437)(R 0.638, F 0.235)] [D acc: (0.844)(0.875, 0.812)] [G loss: 5.287] [G acc: 0.188]\n",
      "12126 [D loss: (0.573)(R 0.512, F 0.635)] [D acc: (0.719)(0.938, 0.500)] [G loss: 1.194] [G acc: 0.438]\n",
      "12127 [D loss: (0.581)(R 0.571, F 0.591)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.852] [G acc: 0.625]\n",
      "12128 [D loss: (0.717)(R 0.743, F 0.691)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.918] [G acc: 0.500]\n",
      "12129 [D loss: (0.569)(R 0.512, F 0.627)] [D acc: (0.750)(0.938, 0.562)] [G loss: 0.987] [G acc: 0.375]\n",
      "12130 [D loss: (0.950)(R 1.279, F 0.621)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.883] [G acc: 0.625]\n",
      "12131 [D loss: (0.654)(R 0.619, F 0.689)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.896] [G acc: 0.500]\n",
      "12132 [D loss: (0.594)(R 0.551, F 0.638)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.976] [G acc: 0.438]\n",
      "12133 [D loss: (0.616)(R 0.582, F 0.650)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.921] [G acc: 0.500]\n",
      "12134 [D loss: (0.671)(R 0.623, F 0.719)] [D acc: (0.562)(0.812, 0.312)] [G loss: 1.015] [G acc: 0.438]\n",
      "12135 [D loss: (0.663)(R 0.701, F 0.624)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.976] [G acc: 0.500]\n",
      "12136 [D loss: (0.540)(R 0.645, F 0.435)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.611] [G acc: 0.062]\n",
      "12137 [D loss: (0.501)(R 0.724, F 0.278)] [D acc: (0.781)(0.688, 0.875)] [G loss: 4.581] [G acc: 0.250]\n",
      "12138 [D loss: (0.637)(R 0.698, F 0.576)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.919] [G acc: 0.500]\n",
      "12139 [D loss: (0.588)(R 0.702, F 0.474)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.309] [G acc: 0.312]\n",
      "12140 [D loss: (0.646)(R 0.729, F 0.562)] [D acc: (0.688)(0.750, 0.625)] [G loss: 3.183] [G acc: 0.062]\n",
      "12141 [D loss: (0.581)(R 0.596, F 0.567)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.905] [G acc: 0.625]\n",
      "12142 [D loss: (0.622)(R 0.665, F 0.580)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.885] [G acc: 0.438]\n",
      "12143 [D loss: (0.522)(R 0.526, F 0.519)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.159] [G acc: 0.250]\n",
      "12144 [D loss: (0.610)(R 0.671, F 0.549)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.943] [G acc: 0.375]\n",
      "12145 [D loss: (0.553)(R 0.602, F 0.505)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.164] [G acc: 0.250]\n",
      "12146 [D loss: (0.513)(R 0.498, F 0.528)] [D acc: (0.875)(1.000, 0.750)] [G loss: 1.096] [G acc: 0.125]\n",
      "12147 [D loss: (0.560)(R 0.581, F 0.540)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.094] [G acc: 0.375]\n",
      "12148 [D loss: (0.618)(R 0.698, F 0.538)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.104] [G acc: 0.312]\n",
      "12149 [D loss: (0.718)(R 0.618, F 0.817)] [D acc: (0.719)(0.875, 0.562)] [G loss: 1.479] [G acc: 0.125]\n",
      "12150 [D loss: (0.716)(R 0.726, F 0.706)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.921] [G acc: 0.562]\n",
      "12151 [D loss: (0.590)(R 0.554, F 0.626)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.901] [G acc: 0.562]\n",
      "12152 [D loss: (0.611)(R 0.587, F 0.634)] [D acc: (0.688)(0.938, 0.438)] [G loss: 1.043] [G acc: 0.500]\n",
      "12153 [D loss: (0.668)(R 0.664, F 0.672)] [D acc: (0.625)(0.812, 0.438)] [G loss: 1.278] [G acc: 0.312]\n",
      "12154 [D loss: (0.542)(R 0.591, F 0.494)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.043] [G acc: 0.375]\n",
      "12155 [D loss: (0.657)(R 0.814, F 0.501)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.948] [G acc: 0.438]\n",
      "12156 [D loss: (0.565)(R 0.556, F 0.573)] [D acc: (0.781)(0.938, 0.625)] [G loss: 1.190] [G acc: 0.312]\n",
      "12157 [D loss: (0.571)(R 0.511, F 0.630)] [D acc: (0.625)(0.812, 0.438)] [G loss: 1.244] [G acc: 0.250]\n",
      "12158 [D loss: (0.498)(R 0.523, F 0.473)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.802] [G acc: 0.125]\n",
      "12159 [D loss: (0.656)(R 0.734, F 0.579)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.236] [G acc: 0.000]\n",
      "12160 [D loss: (0.610)(R 0.764, F 0.456)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.051] [G acc: 0.438]\n",
      "12161 [D loss: (0.587)(R 0.591, F 0.582)] [D acc: (0.688)(0.812, 0.562)] [G loss: 1.000] [G acc: 0.312]\n",
      "12162 [D loss: (0.651)(R 0.657, F 0.646)] [D acc: (0.656)(0.812, 0.500)] [G loss: 1.160] [G acc: 0.188]\n",
      "12163 [D loss: (0.703)(R 0.756, F 0.650)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.660] [G acc: 0.750]\n",
      "12164 [D loss: (0.592)(R 0.632, F 0.551)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.896] [G acc: 0.562]\n",
      "12165 [D loss: (0.608)(R 0.611, F 0.604)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.811] [G acc: 0.500]\n",
      "12166 [D loss: (0.686)(R 0.677, F 0.694)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.902] [G acc: 0.500]\n",
      "12167 [D loss: (0.674)(R 0.612, F 0.735)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.954] [G acc: 0.438]\n",
      "12168 [D loss: (0.639)(R 0.599, F 0.678)] [D acc: (0.656)(0.875, 0.438)] [G loss: 1.008] [G acc: 0.438]\n",
      "12169 [D loss: (0.970)(R 1.247, F 0.693)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.816] [G acc: 0.688]\n",
      "12170 [D loss: (0.697)(R 0.603, F 0.792)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.965] [G acc: 0.562]\n",
      "12171 [D loss: (0.671)(R 0.711, F 0.632)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.846] [G acc: 0.625]\n",
      "12172 [D loss: (0.655)(R 0.587, F 0.724)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.987] [G acc: 0.375]\n",
      "12173 [D loss: (0.611)(R 0.592, F 0.630)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.996] [G acc: 0.250]\n",
      "12174 [D loss: (0.636)(R 0.536, F 0.737)] [D acc: (0.656)(0.938, 0.375)] [G loss: 0.912] [G acc: 0.500]\n",
      "12175 [D loss: (0.684)(R 0.635, F 0.733)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.957] [G acc: 0.438]\n",
      "12176 [D loss: (0.621)(R 0.623, F 0.619)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.881] [G acc: 0.438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12177 [D loss: (0.580)(R 0.538, F 0.622)] [D acc: (0.750)(0.938, 0.562)] [G loss: 0.781] [G acc: 0.562]\n",
      "12178 [D loss: (0.611)(R 0.572, F 0.649)] [D acc: (0.562)(0.750, 0.375)] [G loss: 1.118] [G acc: 0.250]\n",
      "12179 [D loss: (0.763)(R 0.778, F 0.748)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.976] [G acc: 0.500]\n",
      "12180 [D loss: (0.634)(R 0.597, F 0.671)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.760] [G acc: 0.625]\n",
      "12181 [D loss: (0.658)(R 0.618, F 0.697)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.853] [G acc: 0.625]\n",
      "12182 [D loss: (0.787)(R 0.741, F 0.832)] [D acc: (0.406)(0.625, 0.188)] [G loss: 0.781] [G acc: 0.688]\n",
      "12183 [D loss: (0.665)(R 0.601, F 0.728)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.918] [G acc: 0.625]\n",
      "12184 [D loss: (0.631)(R 0.631, F 0.630)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.954] [G acc: 0.625]\n",
      "12185 [D loss: (0.663)(R 0.600, F 0.726)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.818] [G acc: 0.625]\n",
      "12186 [D loss: (0.624)(R 0.541, F 0.707)] [D acc: (0.656)(0.938, 0.375)] [G loss: 0.889] [G acc: 0.625]\n",
      "12187 [D loss: (0.670)(R 0.546, F 0.794)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.730] [G acc: 0.625]\n",
      "12188 [D loss: (0.673)(R 0.544, F 0.802)] [D acc: (0.469)(0.875, 0.062)] [G loss: 0.825] [G acc: 0.562]\n",
      "12189 [D loss: (0.663)(R 0.607, F 0.718)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.807] [G acc: 0.500]\n",
      "12190 [D loss: (0.720)(R 0.751, F 0.688)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.719] [G acc: 0.688]\n",
      "12191 [D loss: (0.575)(R 0.591, F 0.558)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.812] [G acc: 0.188]\n",
      "12192 [D loss: (0.673)(R 0.884, F 0.462)] [D acc: (0.562)(0.562, 0.562)] [G loss: 2.538] [G acc: 0.438]\n",
      "12193 [D loss: (0.590)(R 0.605, F 0.574)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.684] [G acc: 0.688]\n",
      "12194 [D loss: (0.663)(R 0.721, F 0.605)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.649] [G acc: 0.750]\n",
      "12195 [D loss: (0.635)(R 0.614, F 0.655)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.823] [G acc: 0.438]\n",
      "12196 [D loss: (0.661)(R 0.698, F 0.625)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.861] [G acc: 0.625]\n",
      "12197 [D loss: (1.081)(R 0.732, F 1.430)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.740] [G acc: 0.562]\n",
      "12198 [D loss: (0.729)(R 0.659, F 0.799)] [D acc: (0.406)(0.688, 0.125)] [G loss: 1.080] [G acc: 0.312]\n",
      "12199 [D loss: (0.669)(R 0.614, F 0.723)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.735] [G acc: 0.625]\n",
      "12200 [D loss: (0.625)(R 0.565, F 0.686)] [D acc: (0.656)(0.938, 0.375)] [G loss: 0.879] [G acc: 0.562]\n",
      "12201 [D loss: (0.617)(R 0.538, F 0.695)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.718] [G acc: 0.688]\n",
      "12202 [D loss: (0.753)(R 0.730, F 0.776)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.857] [G acc: 0.500]\n",
      "12203 [D loss: (0.648)(R 0.672, F 0.625)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.865] [G acc: 0.625]\n",
      "12204 [D loss: (0.610)(R 0.613, F 0.608)] [D acc: (0.750)(0.938, 0.562)] [G loss: 0.758] [G acc: 0.750]\n",
      "12205 [D loss: (0.671)(R 0.663, F 0.679)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.776] [G acc: 0.625]\n",
      "12206 [D loss: (0.601)(R 0.541, F 0.662)] [D acc: (0.688)(0.938, 0.438)] [G loss: 1.019] [G acc: 0.438]\n",
      "12207 [D loss: (0.740)(R 0.731, F 0.748)] [D acc: (0.438)(0.625, 0.250)] [G loss: 1.110] [G acc: 0.438]\n",
      "12208 [D loss: (0.650)(R 0.599, F 0.702)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.763] [G acc: 0.562]\n",
      "12209 [D loss: (0.598)(R 0.572, F 0.624)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.954] [G acc: 0.500]\n",
      "12210 [D loss: (0.657)(R 0.522, F 0.791)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.849] [G acc: 0.750]\n",
      "12211 [D loss: (0.771)(R 0.876, F 0.665)] [D acc: (0.469)(0.562, 0.375)] [G loss: 1.068] [G acc: 0.250]\n",
      "12212 [D loss: (0.589)(R 0.582, F 0.596)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.036] [G acc: 0.312]\n",
      "12213 [D loss: (0.555)(R 0.594, F 0.515)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.023] [G acc: 0.625]\n",
      "12214 [D loss: (0.651)(R 0.619, F 0.684)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.761] [G acc: 0.625]\n",
      "12215 [D loss: (0.745)(R 0.731, F 0.758)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.826] [G acc: 0.625]\n",
      "12216 [D loss: (0.646)(R 0.586, F 0.706)] [D acc: (0.625)(0.875, 0.375)] [G loss: 1.017] [G acc: 0.438]\n",
      "12217 [D loss: (0.749)(R 0.873, F 0.624)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.821] [G acc: 0.562]\n",
      "12218 [D loss: (0.612)(R 0.604, F 0.619)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.752] [G acc: 0.812]\n",
      "12219 [D loss: (0.601)(R 0.542, F 0.660)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.951] [G acc: 0.438]\n",
      "12220 [D loss: (0.706)(R 0.739, F 0.672)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.831] [G acc: 0.562]\n",
      "12221 [D loss: (0.556)(R 0.589, F 0.522)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.995] [G acc: 0.375]\n",
      "12222 [D loss: (0.634)(R 0.666, F 0.602)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.789] [G acc: 0.562]\n",
      "12223 [D loss: (0.583)(R 0.585, F 0.581)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.041] [G acc: 0.438]\n",
      "12224 [D loss: (0.605)(R 0.637, F 0.572)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.881] [G acc: 0.438]\n",
      "12225 [D loss: (0.629)(R 0.667, F 0.591)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.819] [G acc: 0.562]\n",
      "12226 [D loss: (0.700)(R 0.748, F 0.651)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.970] [G acc: 0.375]\n",
      "12227 [D loss: (0.671)(R 0.715, F 0.627)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.881] [G acc: 0.500]\n",
      "12228 [D loss: (0.637)(R 0.659, F 0.614)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.031] [G acc: 0.250]\n",
      "12229 [D loss: (0.651)(R 0.533, F 0.769)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.905] [G acc: 0.438]\n",
      "12230 [D loss: (0.745)(R 0.601, F 0.889)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.908] [G acc: 0.312]\n",
      "12231 [D loss: (0.755)(R 0.753, F 0.757)] [D acc: (0.500)(0.562, 0.438)] [G loss: 1.042] [G acc: 0.250]\n",
      "12232 [D loss: (0.754)(R 0.783, F 0.725)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.001] [G acc: 0.188]\n",
      "12233 [D loss: (0.640)(R 0.679, F 0.602)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.901] [G acc: 0.375]\n",
      "12234 [D loss: (0.592)(R 0.551, F 0.633)] [D acc: (0.656)(0.812, 0.500)] [G loss: 1.041] [G acc: 0.312]\n",
      "12235 [D loss: (0.569)(R 0.592, F 0.546)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.265] [G acc: 0.125]\n",
      "12236 [D loss: (0.500)(R 0.706, F 0.293)] [D acc: (0.750)(0.625, 0.875)] [G loss: 4.754] [G acc: 0.125]\n",
      "12237 [D loss: (0.852)(R 1.106, F 0.598)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.900] [G acc: 0.250]\n",
      "12238 [D loss: (0.562)(R 0.598, F 0.525)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.738] [G acc: 0.562]\n",
      "12239 [D loss: (0.574)(R 0.595, F 0.554)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.940] [G acc: 0.250]\n",
      "12240 [D loss: (0.645)(R 0.637, F 0.653)] [D acc: (0.531)(0.562, 0.500)] [G loss: 1.039] [G acc: 0.250]\n",
      "12241 [D loss: (0.710)(R 0.694, F 0.726)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.891] [G acc: 0.438]\n",
      "12242 [D loss: (0.726)(R 0.709, F 0.743)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.813] [G acc: 0.375]\n",
      "12243 [D loss: (0.664)(R 0.662, F 0.666)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.929] [G acc: 0.312]\n",
      "12244 [D loss: (0.592)(R 0.543, F 0.641)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.056] [G acc: 0.312]\n",
      "12245 [D loss: (0.658)(R 0.712, F 0.603)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.745] [G acc: 0.375]\n",
      "12246 [D loss: (0.729)(R 0.786, F 0.671)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.884] [G acc: 0.250]\n",
      "12247 [D loss: (0.675)(R 0.589, F 0.761)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.913] [G acc: 0.312]\n",
      "12248 [D loss: (0.559)(R 0.539, F 0.578)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.993] [G acc: 0.188]\n",
      "12249 [D loss: (0.618)(R 0.651, F 0.586)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.181] [G acc: 0.188]\n",
      "12250 [D loss: (0.644)(R 0.686, F 0.601)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.108] [G acc: 0.250]\n",
      "12251 [D loss: (0.680)(R 0.841, F 0.520)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.032] [G acc: 0.250]\n",
      "12252 [D loss: (0.576)(R 0.555, F 0.598)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.041] [G acc: 0.312]\n",
      "12253 [D loss: (0.591)(R 0.605, F 0.577)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.025] [G acc: 0.188]\n",
      "12254 [D loss: (0.646)(R 0.636, F 0.655)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.939] [G acc: 0.312]\n",
      "12255 [D loss: (0.654)(R 0.677, F 0.631)] [D acc: (0.594)(0.688, 0.500)] [G loss: 1.175] [G acc: 0.250]\n",
      "12256 [D loss: (0.709)(R 0.830, F 0.588)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.859] [G acc: 0.375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12257 [D loss: (0.827)(R 0.644, F 1.011)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.851] [G acc: 0.312]\n",
      "12258 [D loss: (0.683)(R 0.588, F 0.778)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.678] [G acc: 0.438]\n",
      "12259 [D loss: (0.633)(R 0.642, F 0.624)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.871] [G acc: 0.250]\n",
      "12260 [D loss: (0.709)(R 0.833, F 0.584)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.794] [G acc: 0.438]\n",
      "12261 [D loss: (0.588)(R 0.633, F 0.543)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.982] [G acc: 0.188]\n",
      "12262 [D loss: (0.994)(R 0.585, F 1.402)] [D acc: (0.719)(0.938, 0.500)] [G loss: 1.023] [G acc: 0.250]\n",
      "12263 [D loss: (0.638)(R 0.642, F 0.633)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.967] [G acc: 0.188]\n",
      "12264 [D loss: (0.856)(R 0.582, F 1.129)] [D acc: (0.594)(0.812, 0.375)] [G loss: 1.242] [G acc: 0.250]\n",
      "12265 [D loss: (0.508)(R 0.597, F 0.418)] [D acc: (0.844)(0.812, 0.875)] [G loss: 4.990] [G acc: 0.125]\n",
      "12266 [D loss: (0.473)(R 0.591, F 0.354)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.660] [G acc: 0.125]\n",
      "12267 [D loss: (0.735)(R 0.546, F 0.924)] [D acc: (0.750)(0.938, 0.562)] [G loss: 0.882] [G acc: 0.312]\n",
      "12268 [D loss: (1.357)(R 0.661, F 2.052)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.984] [G acc: 0.188]\n",
      "12269 [D loss: (0.622)(R 0.552, F 0.691)] [D acc: (0.719)(0.938, 0.500)] [G loss: 1.112] [G acc: 0.250]\n",
      "12270 [D loss: (0.624)(R 0.718, F 0.529)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.051] [G acc: 0.250]\n",
      "12271 [D loss: (0.642)(R 0.561, F 0.722)] [D acc: (0.844)(0.938, 0.750)] [G loss: 0.991] [G acc: 0.312]\n",
      "12272 [D loss: (0.787)(R 0.657, F 0.916)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.170] [G acc: 0.125]\n",
      "12273 [D loss: (0.817)(R 0.746, F 0.889)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.118] [G acc: 0.188]\n",
      "12274 [D loss: (0.591)(R 0.672, F 0.511)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.063] [G acc: 0.125]\n",
      "12275 [D loss: (0.558)(R 0.609, F 0.507)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.123] [G acc: 0.250]\n",
      "12276 [D loss: (0.814)(R 0.724, F 0.905)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.115] [G acc: 0.312]\n",
      "12277 [D loss: (1.122)(R 0.743, F 1.501)] [D acc: (0.531)(0.625, 0.438)] [G loss: 1.110] [G acc: 0.000]\n",
      "12278 [D loss: (0.625)(R 0.553, F 0.697)] [D acc: (0.719)(0.875, 0.562)] [G loss: 1.175] [G acc: 0.125]\n",
      "12279 [D loss: (0.580)(R 0.560, F 0.601)] [D acc: (0.844)(0.938, 0.750)] [G loss: 2.587] [G acc: 0.188]\n",
      "12280 [D loss: (0.526)(R 0.642, F 0.410)] [D acc: (0.781)(0.750, 0.812)] [G loss: 3.177] [G acc: 0.312]\n",
      "12281 [D loss: (0.338)(R 0.489, F 0.187)] [D acc: (0.969)(0.938, 1.000)] [G loss: 1.670] [G acc: 0.250]\n",
      "12282 [D loss: (0.639)(R 0.588, F 0.691)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.964] [G acc: 0.375]\n",
      "12283 [D loss: (0.628)(R 0.526, F 0.730)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.061] [G acc: 0.312]\n",
      "12284 [D loss: (0.793)(R 0.762, F 0.823)] [D acc: (0.531)(0.750, 0.312)] [G loss: 1.345] [G acc: 0.250]\n",
      "12285 [D loss: (0.880)(R 0.698, F 1.062)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.959] [G acc: 0.250]\n",
      "12286 [D loss: (0.598)(R 0.598, F 0.599)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.062] [G acc: 0.188]\n",
      "12287 [D loss: (0.630)(R 0.815, F 0.444)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.482] [G acc: 0.062]\n",
      "12288 [D loss: (0.532)(R 0.651, F 0.413)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.969] [G acc: 0.125]\n",
      "12289 [D loss: (0.487)(R 0.590, F 0.384)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.893] [G acc: 0.125]\n",
      "12290 [D loss: (0.560)(R 0.651, F 0.470)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.052] [G acc: 0.188]\n",
      "12291 [D loss: (0.496)(R 0.589, F 0.404)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.413] [G acc: 0.250]\n",
      "12292 [D loss: (0.538)(R 0.674, F 0.401)] [D acc: (0.844)(0.688, 1.000)] [G loss: 1.308] [G acc: 0.062]\n",
      "12293 [D loss: (0.584)(R 0.671, F 0.497)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.950] [G acc: 0.312]\n",
      "12294 [D loss: (0.472)(R 0.519, F 0.426)] [D acc: (0.875)(0.875, 0.875)] [G loss: 0.994] [G acc: 0.250]\n",
      "12295 [D loss: (0.508)(R 0.605, F 0.410)] [D acc: (0.938)(0.875, 1.000)] [G loss: 1.097] [G acc: 0.188]\n",
      "12296 [D loss: (0.542)(R 0.639, F 0.445)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.032] [G acc: 0.250]\n",
      "12297 [D loss: (0.549)(R 0.559, F 0.538)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.266] [G acc: 0.062]\n",
      "12298 [D loss: (0.448)(R 0.473, F 0.422)] [D acc: (0.875)(0.938, 0.812)] [G loss: 1.168] [G acc: 0.188]\n",
      "12299 [D loss: (0.414)(R 0.511, F 0.316)] [D acc: (0.969)(0.938, 1.000)] [G loss: 1.345] [G acc: 0.000]\n",
      "12300 [D loss: (0.447)(R 0.520, F 0.374)] [D acc: (0.938)(0.938, 0.938)] [G loss: 1.373] [G acc: 0.062]\n",
      "12301 [D loss: (0.543)(R 0.670, F 0.416)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.566] [G acc: 0.312]\n",
      "12302 [D loss: (0.586)(R 0.765, F 0.406)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.443] [G acc: 0.062]\n",
      "12303 [D loss: (0.534)(R 0.707, F 0.361)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.483] [G acc: 0.188]\n",
      "12304 [D loss: (0.509)(R 0.640, F 0.378)] [D acc: (0.875)(0.750, 1.000)] [G loss: 1.244] [G acc: 0.250]\n",
      "12305 [D loss: (0.546)(R 0.738, F 0.353)] [D acc: (0.906)(0.812, 1.000)] [G loss: 1.661] [G acc: 0.062]\n",
      "12306 [D loss: (0.546)(R 0.665, F 0.428)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.275] [G acc: 0.250]\n",
      "12307 [D loss: (0.482)(R 0.607, F 0.356)] [D acc: (0.906)(0.875, 0.938)] [G loss: 1.600] [G acc: 0.188]\n",
      "12308 [D loss: (0.560)(R 0.811, F 0.308)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.265] [G acc: 0.188]\n",
      "12309 [D loss: (0.429)(R 0.493, F 0.365)] [D acc: (0.906)(0.938, 0.875)] [G loss: 1.553] [G acc: 0.125]\n",
      "12310 [D loss: (0.491)(R 0.588, F 0.394)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.545] [G acc: 0.062]\n",
      "12311 [D loss: (0.505)(R 0.792, F 0.219)] [D acc: (0.781)(0.750, 0.812)] [G loss: 2.088] [G acc: 0.188]\n",
      "12312 [D loss: (0.354)(R 0.519, F 0.189)] [D acc: (0.906)(0.875, 0.938)] [G loss: 7.399] [G acc: 0.125]\n",
      "12313 [D loss: (0.672)(R 0.594, F 0.749)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.920] [G acc: 0.000]\n",
      "12314 [D loss: (0.667)(R 0.739, F 0.595)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.352] [G acc: 0.125]\n",
      "12315 [D loss: (0.429)(R 0.575, F 0.284)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.715] [G acc: 0.312]\n",
      "12316 [D loss: (0.504)(R 0.564, F 0.444)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.376] [G acc: 0.062]\n",
      "12317 [D loss: (0.437)(R 0.521, F 0.353)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.530] [G acc: 0.125]\n",
      "12318 [D loss: (0.550)(R 0.748, F 0.351)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.732] [G acc: 0.062]\n",
      "12319 [D loss: (0.485)(R 0.569, F 0.400)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.680] [G acc: 0.062]\n",
      "12320 [D loss: (0.672)(R 0.834, F 0.511)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.565] [G acc: 0.062]\n",
      "12321 [D loss: (0.494)(R 0.569, F 0.418)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.482] [G acc: 0.125]\n",
      "12322 [D loss: (0.465)(R 0.493, F 0.437)] [D acc: (0.844)(0.938, 0.750)] [G loss: 1.348] [G acc: 0.250]\n",
      "12323 [D loss: (0.510)(R 0.611, F 0.408)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.152] [G acc: 0.188]\n",
      "12324 [D loss: (0.553)(R 0.739, F 0.366)] [D acc: (0.844)(0.688, 1.000)] [G loss: 1.452] [G acc: 0.125]\n",
      "12325 [D loss: (0.421)(R 0.562, F 0.280)] [D acc: (0.906)(0.812, 1.000)] [G loss: 1.594] [G acc: 0.062]\n",
      "12326 [D loss: (0.450)(R 0.530, F 0.371)] [D acc: (0.906)(0.875, 0.938)] [G loss: 1.442] [G acc: 0.125]\n",
      "12327 [D loss: (0.548)(R 0.611, F 0.484)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.691] [G acc: 0.000]\n",
      "12328 [D loss: (0.483)(R 0.598, F 0.367)] [D acc: (0.844)(0.875, 0.812)] [G loss: 2.159] [G acc: 0.000]\n",
      "12329 [D loss: (0.439)(R 0.816, F 0.063)] [D acc: (0.844)(0.688, 1.000)] [G loss: 8.397] [G acc: 0.000]\n",
      "12330 [D loss: (0.400)(R 0.448, F 0.352)] [D acc: (0.906)(0.938, 0.875)] [G loss: 1.598] [G acc: 0.062]\n",
      "12331 [D loss: (0.502)(R 0.648, F 0.356)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.840] [G acc: 0.188]\n",
      "12332 [D loss: (0.413)(R 0.577, F 0.249)] [D acc: (0.906)(0.875, 0.938)] [G loss: 1.318] [G acc: 0.062]\n",
      "12333 [D loss: (0.430)(R 0.602, F 0.258)] [D acc: (0.938)(0.875, 1.000)] [G loss: 1.248] [G acc: 0.000]\n",
      "12334 [D loss: (0.515)(R 0.614, F 0.416)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.301] [G acc: 0.188]\n",
      "12335 [D loss: (0.495)(R 0.604, F 0.386)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.776] [G acc: 0.188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12336 [D loss: (0.481)(R 0.617, F 0.345)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.575] [G acc: 0.062]\n",
      "12337 [D loss: (0.343)(R 0.440, F 0.247)] [D acc: (0.969)(0.938, 1.000)] [G loss: 1.343] [G acc: 0.000]\n",
      "12338 [D loss: (0.554)(R 0.739, F 0.368)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.308] [G acc: 0.062]\n",
      "12339 [D loss: (0.496)(R 0.539, F 0.452)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.590] [G acc: 0.188]\n",
      "12340 [D loss: (0.522)(R 0.663, F 0.381)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.440] [G acc: 0.125]\n",
      "12341 [D loss: (0.648)(R 0.846, F 0.449)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.537] [G acc: 0.062]\n",
      "12342 [D loss: (0.496)(R 0.551, F 0.441)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.318] [G acc: 0.125]\n",
      "12343 [D loss: (0.481)(R 0.515, F 0.447)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.414] [G acc: 0.125]\n",
      "12344 [D loss: (0.564)(R 0.672, F 0.456)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.326] [G acc: 0.125]\n",
      "12345 [D loss: (0.409)(R 0.385, F 0.434)] [D acc: (0.875)(0.938, 0.812)] [G loss: 1.794] [G acc: 0.062]\n",
      "12346 [D loss: (0.570)(R 0.608, F 0.531)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.726] [G acc: 0.125]\n",
      "12347 [D loss: (0.577)(R 0.966, F 0.188)] [D acc: (0.781)(0.562, 1.000)] [G loss: 2.126] [G acc: 0.250]\n",
      "12348 [D loss: (0.550)(R 0.810, F 0.291)] [D acc: (0.812)(0.688, 0.938)] [G loss: 2.235] [G acc: 0.062]\n",
      "12349 [D loss: (0.441)(R 0.548, F 0.334)] [D acc: (0.906)(0.812, 1.000)] [G loss: 1.424] [G acc: 0.062]\n",
      "12350 [D loss: (0.544)(R 0.672, F 0.416)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.042] [G acc: 0.250]\n",
      "12351 [D loss: (0.496)(R 0.483, F 0.509)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.593] [G acc: 0.062]\n",
      "12352 [D loss: (0.460)(R 0.485, F 0.435)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.419] [G acc: 0.125]\n",
      "12353 [D loss: (0.533)(R 0.745, F 0.322)] [D acc: (0.906)(0.812, 1.000)] [G loss: 2.255] [G acc: 0.188]\n",
      "12354 [D loss: (0.571)(R 0.709, F 0.432)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.242] [G acc: 0.188]\n",
      "12355 [D loss: (0.763)(R 1.038, F 0.488)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.179] [G acc: 0.062]\n",
      "12356 [D loss: (0.591)(R 0.603, F 0.579)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.142] [G acc: 0.188]\n",
      "12357 [D loss: (0.594)(R 0.713, F 0.476)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.033] [G acc: 0.438]\n",
      "12358 [D loss: (0.571)(R 0.607, F 0.534)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.219] [G acc: 0.125]\n",
      "12359 [D loss: (0.514)(R 0.733, F 0.295)] [D acc: (0.781)(0.688, 0.875)] [G loss: 3.253] [G acc: 0.188]\n",
      "12360 [D loss: (0.442)(R 0.644, F 0.241)] [D acc: (0.781)(0.688, 0.875)] [G loss: 5.675] [G acc: 0.125]\n",
      "12361 [D loss: (0.524)(R 0.640, F 0.409)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.943] [G acc: 0.312]\n",
      "12362 [D loss: (0.504)(R 0.493, F 0.514)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.846] [G acc: 0.500]\n",
      "12363 [D loss: (0.458)(R 0.520, F 0.396)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.222] [G acc: 0.062]\n",
      "12364 [D loss: (0.638)(R 0.795, F 0.481)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.034] [G acc: 0.312]\n",
      "12365 [D loss: (0.493)(R 0.547, F 0.440)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.222] [G acc: 0.188]\n",
      "12366 [D loss: (0.615)(R 0.514, F 0.717)] [D acc: (0.688)(0.812, 0.562)] [G loss: 1.405] [G acc: 0.125]\n",
      "12367 [D loss: (0.707)(R 0.745, F 0.668)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.630] [G acc: 0.062]\n",
      "12368 [D loss: (0.580)(R 0.474, F 0.686)] [D acc: (0.688)(0.875, 0.500)] [G loss: 1.149] [G acc: 0.188]\n",
      "12369 [D loss: (0.627)(R 0.647, F 0.607)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.998] [G acc: 0.312]\n",
      "12370 [D loss: (0.793)(R 0.948, F 0.638)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.853] [G acc: 0.438]\n",
      "12371 [D loss: (0.533)(R 0.572, F 0.494)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.358] [G acc: 0.250]\n",
      "12372 [D loss: (0.860)(R 1.028, F 0.693)] [D acc: (0.531)(0.625, 0.438)] [G loss: 1.044] [G acc: 0.250]\n",
      "12373 [D loss: (0.678)(R 0.755, F 0.601)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.102] [G acc: 0.312]\n",
      "12374 [D loss: (0.611)(R 0.662, F 0.561)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.106] [G acc: 0.125]\n",
      "12375 [D loss: (0.700)(R 0.762, F 0.638)] [D acc: (0.469)(0.438, 0.500)] [G loss: 1.062] [G acc: 0.375]\n",
      "12376 [D loss: (0.551)(R 0.607, F 0.495)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.042] [G acc: 0.250]\n",
      "12377 [D loss: (0.701)(R 0.866, F 0.536)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.952] [G acc: 0.188]\n",
      "12378 [D loss: (0.630)(R 0.491, F 0.769)] [D acc: (0.594)(0.812, 0.375)] [G loss: 1.018] [G acc: 0.312]\n",
      "12379 [D loss: (0.771)(R 0.825, F 0.716)] [D acc: (0.531)(0.500, 0.562)] [G loss: 1.111] [G acc: 0.250]\n",
      "12380 [D loss: (0.580)(R 0.598, F 0.562)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.042] [G acc: 0.188]\n",
      "12381 [D loss: (0.636)(R 0.517, F 0.755)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.872] [G acc: 0.375]\n",
      "12382 [D loss: (0.652)(R 0.699, F 0.605)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.732] [G acc: 0.562]\n",
      "12383 [D loss: (0.718)(R 0.725, F 0.710)] [D acc: (0.562)(0.625, 0.500)] [G loss: 1.117] [G acc: 0.250]\n",
      "12384 [D loss: (0.572)(R 0.627, F 0.517)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.889] [G acc: 0.312]\n",
      "12385 [D loss: (0.682)(R 0.700, F 0.664)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.966] [G acc: 0.312]\n",
      "12386 [D loss: (0.621)(R 0.631, F 0.612)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.112] [G acc: 0.125]\n",
      "12387 [D loss: (0.626)(R 0.539, F 0.713)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.983] [G acc: 0.250]\n",
      "12388 [D loss: (0.681)(R 0.761, F 0.601)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.013] [G acc: 0.250]\n",
      "12389 [D loss: (0.743)(R 0.693, F 0.793)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.947] [G acc: 0.438]\n",
      "12390 [D loss: (0.685)(R 0.681, F 0.688)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.826] [G acc: 0.438]\n",
      "12391 [D loss: (0.697)(R 0.757, F 0.636)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.420] [G acc: 0.250]\n",
      "12392 [D loss: (0.657)(R 0.651, F 0.663)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.843] [G acc: 0.375]\n",
      "12393 [D loss: (0.618)(R 0.568, F 0.668)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.844] [G acc: 0.250]\n",
      "12394 [D loss: (0.576)(R 0.614, F 0.538)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.004] [G acc: 0.125]\n",
      "12395 [D loss: (0.661)(R 0.670, F 0.652)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.952] [G acc: 0.188]\n",
      "12396 [D loss: (0.732)(R 0.742, F 0.721)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.806] [G acc: 0.562]\n",
      "12397 [D loss: (0.758)(R 0.765, F 0.751)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.848] [G acc: 0.312]\n",
      "12398 [D loss: (0.671)(R 0.617, F 0.726)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.907] [G acc: 0.438]\n",
      "12399 [D loss: (0.725)(R 0.674, F 0.776)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.717] [G acc: 0.500]\n",
      "12400 [D loss: (0.661)(R 0.616, F 0.707)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.695] [G acc: 0.562]\n",
      "12401 [D loss: (0.626)(R 0.631, F 0.621)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.938] [G acc: 0.312]\n",
      "12402 [D loss: (0.721)(R 0.667, F 0.774)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.913] [G acc: 0.500]\n",
      "12403 [D loss: (0.539)(R 0.463, F 0.616)] [D acc: (0.812)(1.000, 0.625)] [G loss: 0.887] [G acc: 0.250]\n",
      "12404 [D loss: (0.559)(R 0.489, F 0.629)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.861] [G acc: 0.375]\n",
      "12405 [D loss: (0.647)(R 0.584, F 0.709)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.747] [G acc: 0.375]\n",
      "12406 [D loss: (0.685)(R 0.653, F 0.717)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.910] [G acc: 0.312]\n",
      "12407 [D loss: (0.549)(R 0.482, F 0.617)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.971] [G acc: 0.438]\n",
      "12408 [D loss: (0.719)(R 0.718, F 0.720)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.918] [G acc: 0.438]\n",
      "12409 [D loss: (0.693)(R 0.647, F 0.740)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.053] [G acc: 0.250]\n",
      "12410 [D loss: (0.636)(R 0.546, F 0.726)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.993] [G acc: 0.250]\n",
      "12411 [D loss: (0.637)(R 0.642, F 0.632)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.730] [G acc: 0.500]\n",
      "12412 [D loss: (0.623)(R 0.723, F 0.523)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.109] [G acc: 0.188]\n",
      "12413 [D loss: (0.588)(R 0.672, F 0.503)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.866] [G acc: 0.375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12414 [D loss: (0.615)(R 0.556, F 0.673)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.967] [G acc: 0.312]\n",
      "12415 [D loss: (0.572)(R 0.580, F 0.565)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.957] [G acc: 0.188]\n",
      "12416 [D loss: (0.709)(R 0.724, F 0.694)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.060] [G acc: 0.062]\n",
      "12417 [D loss: (0.462)(R 0.671, F 0.252)] [D acc: (0.844)(0.688, 1.000)] [G loss: 1.441] [G acc: 0.062]\n",
      "12418 [D loss: (0.590)(R 0.576, F 0.605)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.962] [G acc: 0.312]\n",
      "12419 [D loss: (0.662)(R 0.709, F 0.614)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.825] [G acc: 0.375]\n",
      "12420 [D loss: (0.518)(R 0.543, F 0.493)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.259] [G acc: 0.188]\n",
      "12421 [D loss: (0.725)(R 0.782, F 0.667)] [D acc: (0.438)(0.375, 0.500)] [G loss: 1.055] [G acc: 0.250]\n",
      "12422 [D loss: (0.555)(R 0.584, F 0.527)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.984] [G acc: 0.375]\n",
      "12423 [D loss: (0.598)(R 0.524, F 0.673)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.914] [G acc: 0.250]\n",
      "12424 [D loss: (0.610)(R 0.620, F 0.601)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.810] [G acc: 0.500]\n",
      "12425 [D loss: (0.603)(R 0.583, F 0.622)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.837] [G acc: 0.375]\n",
      "12426 [D loss: (0.642)(R 0.732, F 0.552)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.874] [G acc: 0.375]\n",
      "12427 [D loss: (0.700)(R 0.791, F 0.610)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.016] [G acc: 0.375]\n",
      "12428 [D loss: (0.686)(R 0.774, F 0.599)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.959] [G acc: 0.188]\n",
      "12429 [D loss: (0.588)(R 0.589, F 0.587)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.940] [G acc: 0.312]\n",
      "12430 [D loss: (0.685)(R 0.828, F 0.542)] [D acc: (0.688)(0.438, 0.938)] [G loss: 1.115] [G acc: 0.188]\n",
      "12431 [D loss: (0.823)(R 1.045, F 0.601)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.890] [G acc: 0.375]\n",
      "12432 [D loss: (0.621)(R 0.566, F 0.676)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.825] [G acc: 0.438]\n",
      "12433 [D loss: (0.707)(R 0.625, F 0.788)] [D acc: (0.562)(0.688, 0.438)] [G loss: 1.038] [G acc: 0.250]\n",
      "12434 [D loss: (0.598)(R 0.586, F 0.611)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.975] [G acc: 0.250]\n",
      "12435 [D loss: (0.610)(R 0.590, F 0.629)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.749] [G acc: 0.438]\n",
      "12436 [D loss: (0.553)(R 0.524, F 0.583)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.027] [G acc: 0.250]\n",
      "12437 [D loss: (0.788)(R 0.591, F 0.984)] [D acc: (0.375)(0.625, 0.125)] [G loss: 0.936] [G acc: 0.438]\n",
      "12438 [D loss: (0.582)(R 0.495, F 0.669)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.665] [G acc: 0.625]\n",
      "12439 [D loss: (0.674)(R 0.752, F 0.596)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.737] [G acc: 0.562]\n",
      "12440 [D loss: (0.757)(R 0.640, F 0.875)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.797] [G acc: 0.625]\n",
      "12441 [D loss: (0.807)(R 0.883, F 0.731)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.792] [G acc: 0.625]\n",
      "12442 [D loss: (0.846)(R 0.685, F 1.007)] [D acc: (0.406)(0.625, 0.188)] [G loss: 0.613] [G acc: 0.750]\n",
      "12443 [D loss: (0.902)(R 0.793, F 1.010)] [D acc: (0.281)(0.438, 0.125)] [G loss: 0.596] [G acc: 0.688]\n",
      "12444 [D loss: (0.866)(R 0.858, F 0.874)] [D acc: (0.312)(0.438, 0.188)] [G loss: 0.757] [G acc: 0.625]\n",
      "12445 [D loss: (0.808)(R 0.712, F 0.903)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.677] [G acc: 0.688]\n",
      "12446 [D loss: (0.779)(R 0.655, F 0.904)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.669] [G acc: 0.750]\n",
      "12447 [D loss: (0.633)(R 0.554, F 0.712)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.975] [G acc: 0.438]\n",
      "12448 [D loss: (0.760)(R 0.698, F 0.822)] [D acc: (0.375)(0.438, 0.312)] [G loss: 0.608] [G acc: 0.750]\n",
      "12449 [D loss: (0.641)(R 0.517, F 0.764)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.822] [G acc: 0.438]\n",
      "12450 [D loss: (0.743)(R 0.613, F 0.873)] [D acc: (0.438)(0.688, 0.188)] [G loss: 1.489] [G acc: 0.375]\n",
      "12451 [D loss: (0.811)(R 0.836, F 0.787)] [D acc: (0.406)(0.438, 0.375)] [G loss: 1.260] [G acc: 0.375]\n",
      "12452 [D loss: (0.820)(R 0.697, F 0.942)] [D acc: (0.344)(0.500, 0.188)] [G loss: 0.826] [G acc: 0.562]\n",
      "12453 [D loss: (0.724)(R 0.657, F 0.791)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.731] [G acc: 0.688]\n",
      "12454 [D loss: (0.663)(R 0.630, F 0.695)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.678] [G acc: 0.688]\n",
      "12455 [D loss: (0.729)(R 0.753, F 0.705)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.775] [G acc: 0.562]\n",
      "12456 [D loss: (0.766)(R 0.782, F 0.751)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.656] [G acc: 0.688]\n",
      "12457 [D loss: (0.776)(R 0.800, F 0.751)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.692] [G acc: 0.562]\n",
      "12458 [D loss: (0.702)(R 0.693, F 0.712)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.711] [G acc: 0.625]\n",
      "12459 [D loss: (0.715)(R 0.622, F 0.807)] [D acc: (0.406)(0.500, 0.312)] [G loss: 0.726] [G acc: 0.688]\n",
      "12460 [D loss: (0.674)(R 0.643, F 0.706)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.764] [G acc: 0.562]\n",
      "12461 [D loss: (0.611)(R 0.511, F 0.710)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.796] [G acc: 0.562]\n",
      "12462 [D loss: (0.645)(R 0.675, F 0.614)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.761] [G acc: 0.688]\n",
      "12463 [D loss: (0.752)(R 0.742, F 0.761)] [D acc: (0.375)(0.500, 0.250)] [G loss: 0.721] [G acc: 0.688]\n",
      "12464 [D loss: (0.743)(R 0.751, F 0.735)] [D acc: (0.312)(0.312, 0.312)] [G loss: 0.703] [G acc: 0.625]\n",
      "12465 [D loss: (0.674)(R 0.659, F 0.689)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.762] [G acc: 0.562]\n",
      "12466 [D loss: (0.731)(R 0.730, F 0.731)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.768] [G acc: 0.688]\n",
      "12467 [D loss: (0.658)(R 0.658, F 0.659)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.733] [G acc: 0.562]\n",
      "12468 [D loss: (0.677)(R 0.604, F 0.749)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.723] [G acc: 0.812]\n",
      "12469 [D loss: (0.656)(R 0.673, F 0.639)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.748] [G acc: 0.625]\n",
      "12470 [D loss: (0.713)(R 0.699, F 0.728)] [D acc: (0.375)(0.500, 0.250)] [G loss: 0.811] [G acc: 0.562]\n",
      "12471 [D loss: (0.616)(R 0.568, F 0.665)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.742] [G acc: 0.500]\n",
      "12472 [D loss: (0.632)(R 0.559, F 0.706)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.713] [G acc: 0.750]\n",
      "12473 [D loss: (0.689)(R 0.644, F 0.733)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.850] [G acc: 0.625]\n",
      "12474 [D loss: (0.710)(R 0.736, F 0.685)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.719] [G acc: 0.625]\n",
      "12475 [D loss: (0.655)(R 0.622, F 0.688)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.802] [G acc: 0.438]\n",
      "12476 [D loss: (0.666)(R 0.603, F 0.728)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.788] [G acc: 0.438]\n",
      "12477 [D loss: (0.710)(R 0.758, F 0.661)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.777] [G acc: 0.438]\n",
      "12478 [D loss: (0.724)(R 0.666, F 0.781)] [D acc: (0.312)(0.438, 0.188)] [G loss: 0.825] [G acc: 0.562]\n",
      "12479 [D loss: (0.628)(R 0.623, F 0.634)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.779] [G acc: 0.438]\n",
      "12480 [D loss: (0.738)(R 0.745, F 0.731)] [D acc: (0.375)(0.438, 0.312)] [G loss: 0.721] [G acc: 0.375]\n",
      "12481 [D loss: (0.663)(R 0.660, F 0.666)] [D acc: (0.438)(0.312, 0.562)] [G loss: 0.861] [G acc: 0.250]\n",
      "12482 [D loss: (0.710)(R 0.656, F 0.764)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.740] [G acc: 0.438]\n",
      "12483 [D loss: (0.696)(R 0.621, F 0.771)] [D acc: (0.344)(0.375, 0.312)] [G loss: 0.778] [G acc: 0.438]\n",
      "12484 [D loss: (0.637)(R 0.600, F 0.674)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.787] [G acc: 0.438]\n",
      "12485 [D loss: (0.673)(R 0.707, F 0.638)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.889] [G acc: 0.375]\n",
      "12486 [D loss: (0.601)(R 0.569, F 0.634)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.839] [G acc: 0.438]\n",
      "12487 [D loss: (0.645)(R 0.602, F 0.688)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.721] [G acc: 0.688]\n",
      "12488 [D loss: (0.642)(R 0.664, F 0.621)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.937] [G acc: 0.312]\n",
      "12489 [D loss: (0.668)(R 0.661, F 0.674)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.856] [G acc: 0.250]\n",
      "12490 [D loss: (0.581)(R 0.540, F 0.623)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.816] [G acc: 0.438]\n",
      "12491 [D loss: (0.692)(R 0.750, F 0.634)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.830] [G acc: 0.125]\n",
      "12492 [D loss: (0.580)(R 0.528, F 0.632)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.893] [G acc: 0.312]\n",
      "12493 [D loss: (0.689)(R 0.708, F 0.669)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.762] [G acc: 0.375]\n",
      "12494 [D loss: (0.683)(R 0.724, F 0.641)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.767] [G acc: 0.250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12495 [D loss: (0.683)(R 0.608, F 0.757)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.740] [G acc: 0.438]\n",
      "12496 [D loss: (0.682)(R 0.620, F 0.745)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.780] [G acc: 0.375]\n",
      "12497 [D loss: (0.634)(R 0.539, F 0.728)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.799] [G acc: 0.500]\n",
      "12498 [D loss: (0.631)(R 0.663, F 0.600)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.885] [G acc: 0.125]\n",
      "12499 [D loss: (0.726)(R 0.801, F 0.651)] [D acc: (0.438)(0.188, 0.688)] [G loss: 0.892] [G acc: 0.188]\n",
      "12500 [D loss: (0.718)(R 0.819, F 0.616)] [D acc: (0.531)(0.250, 0.812)] [G loss: 0.802] [G acc: 0.375]\n",
      "12501 [D loss: (0.647)(R 0.699, F 0.595)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.855] [G acc: 0.375]\n",
      "12502 [D loss: (0.875)(R 0.661, F 1.089)] [D acc: (0.375)(0.438, 0.312)] [G loss: 0.746] [G acc: 0.312]\n",
      "12503 [D loss: (0.702)(R 0.728, F 0.676)] [D acc: (0.438)(0.312, 0.562)] [G loss: 0.787] [G acc: 0.375]\n",
      "12504 [D loss: (0.571)(R 0.623, F 0.519)] [D acc: (0.625)(0.438, 0.812)] [G loss: 1.099] [G acc: 0.250]\n",
      "12505 [D loss: (0.619)(R 0.644, F 0.593)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.836] [G acc: 0.250]\n",
      "12506 [D loss: (0.659)(R 0.675, F 0.642)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.820] [G acc: 0.375]\n",
      "12507 [D loss: (0.699)(R 0.702, F 0.696)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.791] [G acc: 0.375]\n",
      "12508 [D loss: (0.573)(R 0.515, F 0.630)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.827] [G acc: 0.375]\n",
      "12509 [D loss: (0.596)(R 0.521, F 0.671)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.911] [G acc: 0.125]\n",
      "12510 [D loss: (0.643)(R 0.666, F 0.621)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.793] [G acc: 0.375]\n",
      "12511 [D loss: (0.646)(R 0.680, F 0.611)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.887] [G acc: 0.062]\n",
      "12512 [D loss: (0.694)(R 0.751, F 0.638)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.873] [G acc: 0.438]\n",
      "12513 [D loss: (0.659)(R 0.695, F 0.623)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.907] [G acc: 0.125]\n",
      "12514 [D loss: (0.627)(R 0.613, F 0.641)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.829] [G acc: 0.312]\n",
      "12515 [D loss: (0.661)(R 0.684, F 0.639)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.940] [G acc: 0.188]\n",
      "12516 [D loss: (0.581)(R 0.650, F 0.512)] [D acc: (0.625)(0.375, 0.875)] [G loss: 1.014] [G acc: 0.188]\n",
      "12517 [D loss: (0.527)(R 0.520, F 0.535)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.761] [G acc: 0.188]\n",
      "12518 [D loss: (0.641)(R 0.687, F 0.594)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.024] [G acc: 0.125]\n",
      "12519 [D loss: (0.619)(R 0.651, F 0.588)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.873] [G acc: 0.125]\n",
      "12520 [D loss: (0.624)(R 0.653, F 0.595)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.777] [G acc: 0.188]\n",
      "12521 [D loss: (0.645)(R 0.723, F 0.567)] [D acc: (0.531)(0.375, 0.688)] [G loss: 1.142] [G acc: 0.250]\n",
      "12522 [D loss: (0.557)(R 0.613, F 0.500)] [D acc: (0.719)(0.500, 0.938)] [G loss: 0.810] [G acc: 0.312]\n",
      "12523 [D loss: (0.600)(R 0.557, F 0.643)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.924] [G acc: 0.188]\n",
      "12524 [D loss: (0.711)(R 0.818, F 0.603)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.798] [G acc: 0.250]\n",
      "12525 [D loss: (0.643)(R 0.653, F 0.633)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.744] [G acc: 0.312]\n",
      "12526 [D loss: (0.610)(R 0.627, F 0.592)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.873] [G acc: 0.125]\n",
      "12527 [D loss: (0.566)(R 0.524, F 0.608)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.860] [G acc: 0.312]\n",
      "12528 [D loss: (0.582)(R 0.547, F 0.617)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.787] [G acc: 0.250]\n",
      "12529 [D loss: (0.812)(R 0.692, F 0.932)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.885] [G acc: 0.250]\n",
      "12530 [D loss: (0.667)(R 0.730, F 0.604)] [D acc: (0.500)(0.312, 0.688)] [G loss: 0.870] [G acc: 0.250]\n",
      "12531 [D loss: (0.585)(R 0.517, F 0.653)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.805] [G acc: 0.062]\n",
      "12532 [D loss: (0.713)(R 0.778, F 0.647)] [D acc: (0.406)(0.250, 0.562)] [G loss: 0.859] [G acc: 0.188]\n",
      "12533 [D loss: (0.555)(R 0.467, F 0.642)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.948] [G acc: 0.125]\n",
      "12534 [D loss: (0.779)(R 0.796, F 0.763)] [D acc: (0.469)(0.250, 0.688)] [G loss: 0.821] [G acc: 0.312]\n",
      "12535 [D loss: (0.629)(R 0.651, F 0.607)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.034] [G acc: 0.188]\n",
      "12536 [D loss: (0.626)(R 0.680, F 0.573)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.916] [G acc: 0.375]\n",
      "12537 [D loss: (0.773)(R 0.783, F 0.764)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.816] [G acc: 0.375]\n",
      "12538 [D loss: (0.600)(R 0.618, F 0.583)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.942] [G acc: 0.250]\n",
      "12539 [D loss: (0.642)(R 0.659, F 0.624)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.879] [G acc: 0.375]\n",
      "12540 [D loss: (0.693)(R 0.789, F 0.597)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.876] [G acc: 0.312]\n",
      "12541 [D loss: (0.612)(R 0.626, F 0.598)] [D acc: (0.719)(0.500, 0.938)] [G loss: 0.836] [G acc: 0.250]\n",
      "12542 [D loss: (0.683)(R 0.716, F 0.650)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.944] [G acc: 0.312]\n",
      "12543 [D loss: (0.592)(R 0.529, F 0.655)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.974] [G acc: 0.250]\n",
      "12544 [D loss: (0.624)(R 0.645, F 0.603)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.965] [G acc: 0.250]\n",
      "12545 [D loss: (0.625)(R 0.570, F 0.680)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.777] [G acc: 0.312]\n",
      "12546 [D loss: (0.594)(R 0.506, F 0.682)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.832] [G acc: 0.312]\n",
      "12547 [D loss: (0.612)(R 0.536, F 0.689)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.893] [G acc: 0.250]\n",
      "12548 [D loss: (0.644)(R 0.490, F 0.799)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.884] [G acc: 0.062]\n",
      "12549 [D loss: (0.613)(R 0.617, F 0.609)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.809] [G acc: 0.438]\n",
      "12550 [D loss: (0.604)(R 0.448, F 0.760)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.874] [G acc: 0.125]\n",
      "12551 [D loss: (0.677)(R 0.840, F 0.514)] [D acc: (0.594)(0.312, 0.875)] [G loss: 0.930] [G acc: 0.125]\n",
      "12552 [D loss: (0.682)(R 0.767, F 0.598)] [D acc: (0.469)(0.250, 0.688)] [G loss: 0.874] [G acc: 0.062]\n",
      "12553 [D loss: (0.651)(R 0.733, F 0.570)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.932] [G acc: 0.125]\n",
      "12554 [D loss: (0.637)(R 0.769, F 0.506)] [D acc: (0.625)(0.312, 0.938)] [G loss: 0.919] [G acc: 0.125]\n",
      "12555 [D loss: (0.636)(R 0.707, F 0.564)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.959] [G acc: 0.188]\n",
      "12556 [D loss: (0.555)(R 0.632, F 0.478)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.188] [G acc: 0.125]\n",
      "12557 [D loss: (0.630)(R 0.679, F 0.581)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.896] [G acc: 0.312]\n",
      "12558 [D loss: (0.657)(R 0.767, F 0.547)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.787] [G acc: 0.438]\n",
      "12559 [D loss: (0.648)(R 0.702, F 0.595)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.907] [G acc: 0.250]\n",
      "12560 [D loss: (0.690)(R 0.653, F 0.728)] [D acc: (0.562)(0.625, 0.500)] [G loss: 1.169] [G acc: 0.062]\n",
      "12561 [D loss: (0.694)(R 0.807, F 0.580)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.889] [G acc: 0.188]\n",
      "12562 [D loss: (0.570)(R 0.537, F 0.602)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.968] [G acc: 0.125]\n",
      "12563 [D loss: (0.632)(R 0.701, F 0.563)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.887] [G acc: 0.188]\n",
      "12564 [D loss: (0.577)(R 0.607, F 0.546)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.987] [G acc: 0.188]\n",
      "12565 [D loss: (0.671)(R 0.768, F 0.574)] [D acc: (0.562)(0.312, 0.812)] [G loss: 0.924] [G acc: 0.125]\n",
      "12566 [D loss: (0.620)(R 0.716, F 0.523)] [D acc: (0.562)(0.312, 0.812)] [G loss: 0.928] [G acc: 0.250]\n",
      "12567 [D loss: (0.555)(R 0.600, F 0.510)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.939] [G acc: 0.188]\n",
      "12568 [D loss: (0.933)(R 0.683, F 1.183)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.819] [G acc: 0.250]\n",
      "12569 [D loss: (0.623)(R 0.630, F 0.617)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.976] [G acc: 0.125]\n",
      "12570 [D loss: (0.642)(R 0.688, F 0.597)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.883] [G acc: 0.125]\n",
      "12571 [D loss: (0.748)(R 0.750, F 0.747)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.811] [G acc: 0.375]\n",
      "12572 [D loss: (0.597)(R 0.566, F 0.629)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.948] [G acc: 0.250]\n",
      "12573 [D loss: (0.621)(R 0.683, F 0.559)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.797] [G acc: 0.438]\n",
      "12574 [D loss: (0.614)(R 0.489, F 0.739)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.835] [G acc: 0.312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12575 [D loss: (0.759)(R 0.567, F 0.952)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.796] [G acc: 0.312]\n",
      "12576 [D loss: (0.645)(R 0.680, F 0.611)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.867] [G acc: 0.188]\n",
      "12577 [D loss: (0.644)(R 0.700, F 0.587)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.008] [G acc: 0.000]\n",
      "12578 [D loss: (0.829)(R 0.620, F 1.038)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.103] [G acc: 0.125]\n",
      "12579 [D loss: (0.614)(R 0.603, F 0.625)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.874] [G acc: 0.188]\n",
      "12580 [D loss: (0.717)(R 0.809, F 0.624)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.834] [G acc: 0.375]\n",
      "12581 [D loss: (0.630)(R 0.629, F 0.631)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.921] [G acc: 0.188]\n",
      "12582 [D loss: (0.622)(R 0.692, F 0.551)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.948] [G acc: 0.000]\n",
      "12583 [D loss: (0.591)(R 0.578, F 0.605)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.934] [G acc: 0.188]\n",
      "12584 [D loss: (0.609)(R 0.513, F 0.706)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.801] [G acc: 0.438]\n",
      "12585 [D loss: (0.613)(R 0.617, F 0.610)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.909] [G acc: 0.125]\n",
      "12586 [D loss: (0.737)(R 0.746, F 0.727)] [D acc: (0.562)(0.500, 0.625)] [G loss: 4.765] [G acc: 0.188]\n",
      "12587 [D loss: (0.594)(R 0.672, F 0.516)] [D acc: (0.688)(0.625, 0.750)] [G loss: 4.162] [G acc: 0.000]\n",
      "12588 [D loss: (0.399)(R 0.587, F 0.211)] [D acc: (0.844)(0.688, 1.000)] [G loss: 0.981] [G acc: 0.188]\n",
      "12589 [D loss: (0.495)(R 0.543, F 0.447)] [D acc: (0.875)(0.812, 0.938)] [G loss: 0.624] [G acc: 0.438]\n",
      "12590 [D loss: (0.448)(R 0.545, F 0.351)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.257] [G acc: 0.062]\n",
      "12591 [D loss: (0.824)(R 0.972, F 0.676)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.723] [G acc: 0.500]\n",
      "12592 [D loss: (0.552)(R 0.476, F 0.628)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.820] [G acc: 0.312]\n",
      "12593 [D loss: (0.502)(R 0.409, F 0.595)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.006] [G acc: 0.250]\n",
      "12594 [D loss: (0.635)(R 0.586, F 0.685)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.801] [G acc: 0.375]\n",
      "12595 [D loss: (0.602)(R 0.635, F 0.570)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.720] [G acc: 0.438]\n",
      "12596 [D loss: (0.587)(R 0.559, F 0.614)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.767] [G acc: 0.562]\n",
      "12597 [D loss: (0.589)(R 0.603, F 0.575)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.854] [G acc: 0.250]\n",
      "12598 [D loss: (0.668)(R 0.666, F 0.671)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.735] [G acc: 0.438]\n",
      "12599 [D loss: (0.583)(R 0.625, F 0.541)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.146] [G acc: 0.250]\n",
      "12600 [D loss: (0.486)(R 0.471, F 0.501)] [D acc: (0.906)(0.875, 0.938)] [G loss: 0.830] [G acc: 0.375]\n",
      "12601 [D loss: (0.568)(R 0.623, F 0.513)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.945] [G acc: 0.250]\n",
      "12602 [D loss: (0.584)(R 0.518, F 0.649)] [D acc: (0.688)(0.875, 0.500)] [G loss: 1.130] [G acc: 0.125]\n",
      "12603 [D loss: (0.619)(R 0.559, F 0.680)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.115] [G acc: 0.250]\n",
      "12604 [D loss: (0.835)(R 0.737, F 0.933)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.922] [G acc: 0.188]\n",
      "12605 [D loss: (0.621)(R 0.628, F 0.614)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.038] [G acc: 0.125]\n",
      "12606 [D loss: (0.548)(R 0.535, F 0.561)] [D acc: (0.875)(0.875, 0.875)] [G loss: 2.750] [G acc: 0.000]\n",
      "12607 [D loss: (0.523)(R 0.615, F 0.431)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.954] [G acc: 0.000]\n",
      "12608 [D loss: (0.502)(R 0.561, F 0.443)] [D acc: (0.906)(0.875, 0.938)] [G loss: 1.530] [G acc: 0.062]\n",
      "12609 [D loss: (0.592)(R 0.623, F 0.561)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.090] [G acc: 0.062]\n",
      "12610 [D loss: (0.577)(R 0.578, F 0.577)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.029] [G acc: 0.188]\n",
      "12611 [D loss: (0.711)(R 0.564, F 0.857)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.932] [G acc: 0.375]\n",
      "12612 [D loss: (0.520)(R 0.564, F 0.476)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.951] [G acc: 0.375]\n",
      "12613 [D loss: (0.572)(R 0.550, F 0.595)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.972] [G acc: 0.250]\n",
      "12614 [D loss: (0.612)(R 0.546, F 0.679)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.918] [G acc: 0.188]\n",
      "12615 [D loss: (0.563)(R 0.624, F 0.502)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.962] [G acc: 0.125]\n",
      "12616 [D loss: (0.597)(R 0.652, F 0.541)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.768] [G acc: 0.375]\n",
      "12617 [D loss: (0.571)(R 0.589, F 0.553)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.856] [G acc: 0.188]\n",
      "12618 [D loss: (0.525)(R 0.579, F 0.471)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.973] [G acc: 0.125]\n",
      "12619 [D loss: (0.710)(R 0.695, F 0.725)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.954] [G acc: 0.188]\n",
      "12620 [D loss: (0.562)(R 0.587, F 0.537)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.759] [G acc: 0.500]\n",
      "12621 [D loss: (0.513)(R 0.513, F 0.512)] [D acc: (0.844)(0.875, 0.812)] [G loss: 0.995] [G acc: 0.125]\n",
      "12622 [D loss: (0.565)(R 0.495, F 0.634)] [D acc: (0.812)(1.000, 0.625)] [G loss: 2.815] [G acc: 0.250]\n",
      "12623 [D loss: (0.539)(R 0.563, F 0.514)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.983] [G acc: 0.250]\n",
      "12624 [D loss: (0.536)(R 0.634, F 0.438)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.074] [G acc: 0.125]\n",
      "12625 [D loss: (0.614)(R 0.706, F 0.521)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.112] [G acc: 0.062]\n",
      "12626 [D loss: (0.492)(R 0.504, F 0.480)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.093] [G acc: 0.000]\n",
      "12627 [D loss: (0.615)(R 0.653, F 0.577)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.256] [G acc: 0.000]\n",
      "12628 [D loss: (0.470)(R 0.501, F 0.439)] [D acc: (0.906)(0.875, 0.938)] [G loss: 1.121] [G acc: 0.250]\n",
      "12629 [D loss: (0.558)(R 0.641, F 0.475)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.227] [G acc: 0.125]\n",
      "12630 [D loss: (0.528)(R 0.648, F 0.409)] [D acc: (0.844)(0.688, 1.000)] [G loss: 1.140] [G acc: 0.125]\n",
      "12631 [D loss: (0.553)(R 0.593, F 0.512)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.930] [G acc: 0.188]\n",
      "12632 [D loss: (0.662)(R 0.772, F 0.552)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.155] [G acc: 0.062]\n",
      "12633 [D loss: (0.588)(R 0.702, F 0.474)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.071] [G acc: 0.125]\n",
      "12634 [D loss: (0.484)(R 0.537, F 0.432)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.996] [G acc: 0.312]\n",
      "12635 [D loss: (0.533)(R 0.547, F 0.520)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.087] [G acc: 0.062]\n",
      "12636 [D loss: (0.495)(R 0.598, F 0.391)] [D acc: (0.906)(0.875, 0.938)] [G loss: 1.086] [G acc: 0.312]\n",
      "12637 [D loss: (0.522)(R 0.510, F 0.534)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.888] [G acc: 0.188]\n",
      "12638 [D loss: (0.556)(R 0.629, F 0.484)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.066] [G acc: 0.188]\n",
      "12639 [D loss: (0.465)(R 0.454, F 0.476)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.115] [G acc: 0.125]\n",
      "12640 [D loss: (0.581)(R 0.493, F 0.669)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.238] [G acc: 0.062]\n",
      "12641 [D loss: (0.509)(R 0.552, F 0.467)] [D acc: (0.875)(0.812, 0.938)] [G loss: 0.903] [G acc: 0.375]\n",
      "12642 [D loss: (0.593)(R 0.705, F 0.481)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.226] [G acc: 0.125]\n",
      "12643 [D loss: (0.466)(R 0.479, F 0.453)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.156] [G acc: 0.125]\n",
      "12644 [D loss: (0.463)(R 0.395, F 0.531)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.054] [G acc: 0.188]\n",
      "12645 [D loss: (0.489)(R 0.604, F 0.373)] [D acc: (0.906)(0.812, 1.000)] [G loss: 1.102] [G acc: 0.188]\n",
      "12646 [D loss: (0.581)(R 0.693, F 0.468)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.110] [G acc: 0.312]\n",
      "12647 [D loss: (0.588)(R 0.673, F 0.502)] [D acc: (0.844)(0.750, 0.938)] [G loss: 0.868] [G acc: 0.375]\n",
      "12648 [D loss: (0.679)(R 0.740, F 0.618)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.039] [G acc: 0.250]\n",
      "12649 [D loss: (0.453)(R 0.461, F 0.444)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.214] [G acc: 0.062]\n",
      "12650 [D loss: (0.503)(R 0.503, F 0.502)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.145] [G acc: 0.250]\n",
      "12651 [D loss: (0.683)(R 0.854, F 0.513)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.179] [G acc: 0.188]\n",
      "12652 [D loss: (0.549)(R 0.606, F 0.492)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.199] [G acc: 0.062]\n",
      "12653 [D loss: (0.533)(R 0.539, F 0.526)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.154] [G acc: 0.000]\n",
      "12654 [D loss: (0.604)(R 0.646, F 0.562)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.548] [G acc: 0.125]\n",
      "12655 [D loss: (0.463)(R 0.615, F 0.310)] [D acc: (0.875)(0.750, 1.000)] [G loss: 1.159] [G acc: 0.188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12656 [D loss: (0.421)(R 0.404, F 0.438)] [D acc: (0.938)(0.938, 0.938)] [G loss: 1.058] [G acc: 0.188]\n",
      "12657 [D loss: (0.423)(R 0.404, F 0.443)] [D acc: (0.906)(0.938, 0.875)] [G loss: 1.205] [G acc: 0.062]\n",
      "12658 [D loss: (0.467)(R 0.548, F 0.386)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.261] [G acc: 0.062]\n",
      "12659 [D loss: (0.518)(R 0.542, F 0.494)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.277] [G acc: 0.000]\n",
      "12660 [D loss: (0.597)(R 0.663, F 0.532)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.041] [G acc: 0.312]\n",
      "12661 [D loss: (0.565)(R 0.627, F 0.503)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.169] [G acc: 0.312]\n",
      "12662 [D loss: (0.546)(R 0.473, F 0.618)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.094] [G acc: 0.188]\n",
      "12663 [D loss: (0.549)(R 0.523, F 0.574)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.222] [G acc: 0.250]\n",
      "12664 [D loss: (0.486)(R 0.457, F 0.514)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.024] [G acc: 0.312]\n",
      "12665 [D loss: (0.557)(R 0.567, F 0.546)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.276] [G acc: 0.062]\n",
      "12666 [D loss: (0.394)(R 0.352, F 0.437)] [D acc: (0.875)(0.938, 0.812)] [G loss: 1.061] [G acc: 0.250]\n",
      "12667 [D loss: (0.502)(R 0.533, F 0.471)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.127] [G acc: 0.188]\n",
      "12668 [D loss: (0.650)(R 0.749, F 0.552)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.290] [G acc: 0.250]\n",
      "12669 [D loss: (0.563)(R 0.516, F 0.610)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.526] [G acc: 0.188]\n",
      "12670 [D loss: (0.573)(R 0.690, F 0.457)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.197] [G acc: 0.188]\n",
      "12671 [D loss: (0.441)(R 0.510, F 0.373)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.883] [G acc: 0.312]\n",
      "12672 [D loss: (0.485)(R 0.476, F 0.494)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.385] [G acc: 0.125]\n",
      "12673 [D loss: (0.641)(R 0.663, F 0.618)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.522] [G acc: 0.125]\n",
      "12674 [D loss: (0.625)(R 0.621, F 0.629)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.479] [G acc: 0.000]\n",
      "12675 [D loss: (0.747)(R 0.841, F 0.653)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.183] [G acc: 0.188]\n",
      "12676 [D loss: (0.620)(R 0.549, F 0.691)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.234] [G acc: 0.250]\n",
      "12677 [D loss: (0.600)(R 0.528, F 0.673)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.964] [G acc: 0.438]\n",
      "12678 [D loss: (0.565)(R 0.545, F 0.585)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.879] [G acc: 0.375]\n",
      "12679 [D loss: (0.559)(R 0.634, F 0.484)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.843] [G acc: 0.375]\n",
      "12680 [D loss: (0.516)(R 0.448, F 0.584)] [D acc: (0.750)(0.875, 0.625)] [G loss: 1.155] [G acc: 0.188]\n",
      "12681 [D loss: (0.543)(R 0.411, F 0.676)] [D acc: (0.719)(0.938, 0.500)] [G loss: 1.027] [G acc: 0.250]\n",
      "12682 [D loss: (0.623)(R 0.619, F 0.626)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.990] [G acc: 0.250]\n",
      "12683 [D loss: (0.707)(R 0.634, F 0.779)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.084] [G acc: 0.125]\n",
      "12684 [D loss: (0.533)(R 0.589, F 0.477)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.194] [G acc: 0.188]\n",
      "12685 [D loss: (0.669)(R 0.743, F 0.595)] [D acc: (0.594)(0.500, 0.688)] [G loss: 1.020] [G acc: 0.188]\n",
      "12686 [D loss: (0.567)(R 0.592, F 0.542)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.196] [G acc: 0.062]\n",
      "12687 [D loss: (0.636)(R 0.611, F 0.661)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.187] [G acc: 0.188]\n",
      "12688 [D loss: (0.625)(R 0.616, F 0.634)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.055] [G acc: 0.250]\n",
      "12689 [D loss: (0.531)(R 0.594, F 0.469)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.062] [G acc: 0.438]\n",
      "12690 [D loss: (0.622)(R 0.716, F 0.529)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.951] [G acc: 0.312]\n",
      "12691 [D loss: (0.600)(R 0.561, F 0.639)] [D acc: (0.719)(0.875, 0.562)] [G loss: 1.058] [G acc: 0.188]\n",
      "12692 [D loss: (0.543)(R 0.531, F 0.555)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.177] [G acc: 0.125]\n",
      "12693 [D loss: (0.637)(R 0.763, F 0.510)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.176] [G acc: 0.125]\n",
      "12694 [D loss: (0.590)(R 0.626, F 0.555)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.053] [G acc: 0.250]\n",
      "12695 [D loss: (0.532)(R 0.506, F 0.559)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.050] [G acc: 0.250]\n",
      "12696 [D loss: (0.555)(R 0.607, F 0.503)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.011] [G acc: 0.312]\n",
      "12697 [D loss: (0.681)(R 0.752, F 0.609)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.918] [G acc: 0.375]\n",
      "12698 [D loss: (0.862)(R 1.116, F 0.608)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.172] [G acc: 0.062]\n",
      "12699 [D loss: (0.676)(R 0.683, F 0.668)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.944] [G acc: 0.250]\n",
      "12700 [D loss: (0.685)(R 0.588, F 0.783)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.084] [G acc: 0.250]\n",
      "12701 [D loss: (0.814)(R 0.680, F 0.949)] [D acc: (0.531)(0.500, 0.562)] [G loss: 1.063] [G acc: 0.188]\n",
      "12702 [D loss: (0.586)(R 0.601, F 0.572)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.886] [G acc: 0.375]\n",
      "12703 [D loss: (0.720)(R 0.822, F 0.618)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.830] [G acc: 0.375]\n",
      "12704 [D loss: (0.617)(R 0.615, F 0.618)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.021] [G acc: 0.250]\n",
      "12705 [D loss: (0.916)(R 0.472, F 1.359)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.902] [G acc: 0.375]\n",
      "12706 [D loss: (0.518)(R 0.480, F 0.555)] [D acc: (0.750)(0.875, 0.625)] [G loss: 1.073] [G acc: 0.250]\n",
      "12707 [D loss: (0.660)(R 0.693, F 0.628)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.896] [G acc: 0.312]\n",
      "12708 [D loss: (0.637)(R 0.608, F 0.667)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.922] [G acc: 0.312]\n",
      "12709 [D loss: (0.824)(R 0.951, F 0.697)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.785] [G acc: 0.250]\n",
      "12710 [D loss: (0.653)(R 0.647, F 0.660)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.741] [G acc: 0.500]\n",
      "12711 [D loss: (0.733)(R 0.808, F 0.658)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.599] [G acc: 0.625]\n",
      "12712 [D loss: (0.765)(R 0.762, F 0.768)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.721] [G acc: 0.688]\n",
      "12713 [D loss: (0.636)(R 0.669, F 0.602)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.830] [G acc: 0.438]\n",
      "12714 [D loss: (0.463)(R 0.380, F 0.545)] [D acc: (0.875)(0.938, 0.812)] [G loss: 0.971] [G acc: 0.250]\n",
      "12715 [D loss: (0.941)(R 1.259, F 0.622)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.038] [G acc: 0.188]\n",
      "12716 [D loss: (0.709)(R 0.641, F 0.776)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.905] [G acc: 0.250]\n",
      "12717 [D loss: (0.604)(R 0.607, F 0.602)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.610] [G acc: 0.625]\n",
      "12718 [D loss: (0.668)(R 0.545, F 0.791)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.795] [G acc: 0.438]\n",
      "12719 [D loss: (0.822)(R 0.593, F 1.052)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.784] [G acc: 0.438]\n",
      "12720 [D loss: (0.624)(R 0.499, F 0.750)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.875] [G acc: 0.312]\n",
      "12721 [D loss: (0.561)(R 0.515, F 0.608)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.894] [G acc: 0.375]\n",
      "12722 [D loss: (1.045)(R 0.655, F 1.435)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.868] [G acc: 0.375]\n",
      "12723 [D loss: (0.693)(R 0.660, F 0.727)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.023] [G acc: 0.250]\n",
      "12724 [D loss: (0.754)(R 0.637, F 0.871)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.875] [G acc: 0.500]\n",
      "12725 [D loss: (0.698)(R 0.648, F 0.747)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.504] [G acc: 0.625]\n",
      "12726 [D loss: (0.969)(R 0.593, F 1.345)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.666] [G acc: 0.500]\n",
      "12727 [D loss: (0.863)(R 0.482, F 1.243)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.924] [G acc: 0.250]\n",
      "12728 [D loss: (0.677)(R 0.590, F 0.765)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.628] [G acc: 0.562]\n",
      "12729 [D loss: (0.897)(R 0.788, F 1.006)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.983] [G acc: 0.312]\n",
      "12730 [D loss: (0.610)(R 0.468, F 0.752)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.888] [G acc: 0.500]\n",
      "12731 [D loss: (0.718)(R 0.669, F 0.768)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.027] [G acc: 0.312]\n",
      "12732 [D loss: (0.640)(R 0.585, F 0.695)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.783] [G acc: 0.375]\n",
      "12733 [D loss: (0.803)(R 0.633, F 0.973)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.587] [G acc: 0.688]\n",
      "12734 [D loss: (0.713)(R 0.617, F 0.809)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.774] [G acc: 0.438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12735 [D loss: (0.527)(R 0.453, F 0.602)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.009] [G acc: 0.312]\n",
      "12736 [D loss: (0.729)(R 0.596, F 0.861)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.644] [G acc: 0.562]\n",
      "12737 [D loss: (0.634)(R 0.591, F 0.676)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.820] [G acc: 0.375]\n",
      "12738 [D loss: (0.601)(R 0.474, F 0.727)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.911] [G acc: 0.375]\n",
      "12739 [D loss: (0.714)(R 0.620, F 0.807)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.737] [G acc: 0.438]\n",
      "12740 [D loss: (0.647)(R 0.558, F 0.736)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.647] [G acc: 0.562]\n",
      "12741 [D loss: (0.531)(R 0.453, F 0.609)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.893] [G acc: 0.312]\n",
      "12742 [D loss: (0.640)(R 0.605, F 0.675)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.997] [G acc: 0.438]\n",
      "12743 [D loss: (0.596)(R 0.553, F 0.639)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.379] [G acc: 0.188]\n",
      "12744 [D loss: (0.465)(R 0.490, F 0.441)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.537] [G acc: 0.062]\n",
      "12745 [D loss: (0.604)(R 0.567, F 0.641)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.213] [G acc: 0.375]\n",
      "12746 [D loss: (0.606)(R 0.468, F 0.744)] [D acc: (0.688)(0.875, 0.500)] [G loss: 1.746] [G acc: 0.562]\n",
      "12747 [D loss: (0.609)(R 0.635, F 0.584)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.969] [G acc: 0.375]\n",
      "12748 [D loss: (0.615)(R 0.489, F 0.741)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.759] [G acc: 0.438]\n",
      "12749 [D loss: (0.607)(R 0.462, F 0.753)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.655] [G acc: 0.625]\n",
      "12750 [D loss: (0.553)(R 0.487, F 0.620)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.774] [G acc: 0.438]\n",
      "12751 [D loss: (0.608)(R 0.581, F 0.635)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.909] [G acc: 0.375]\n",
      "12752 [D loss: (0.489)(R 0.427, F 0.550)] [D acc: (0.812)(0.938, 0.688)] [G loss: 0.869] [G acc: 0.312]\n",
      "12753 [D loss: (0.578)(R 0.567, F 0.588)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.031] [G acc: 0.312]\n",
      "12754 [D loss: (0.450)(R 0.378, F 0.521)] [D acc: (0.906)(1.000, 0.812)] [G loss: 0.860] [G acc: 0.438]\n",
      "12755 [D loss: (0.541)(R 0.565, F 0.516)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.928] [G acc: 0.438]\n",
      "12756 [D loss: (0.531)(R 0.510, F 0.552)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.723] [G acc: 0.375]\n",
      "12757 [D loss: (0.535)(R 0.508, F 0.563)] [D acc: (0.844)(0.875, 0.812)] [G loss: 0.969] [G acc: 0.312]\n",
      "12758 [D loss: (0.621)(R 0.696, F 0.545)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.888] [G acc: 0.375]\n",
      "12759 [D loss: (0.520)(R 0.416, F 0.623)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.895] [G acc: 0.375]\n",
      "12760 [D loss: (0.615)(R 0.603, F 0.626)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.056] [G acc: 0.250]\n",
      "12761 [D loss: (0.630)(R 0.633, F 0.626)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.136] [G acc: 0.125]\n",
      "12762 [D loss: (0.624)(R 0.538, F 0.709)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.063] [G acc: 0.188]\n",
      "12763 [D loss: (0.540)(R 0.536, F 0.545)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.078] [G acc: 0.250]\n",
      "12764 [D loss: (0.539)(R 0.552, F 0.527)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.262] [G acc: 0.250]\n",
      "12765 [D loss: (0.625)(R 0.530, F 0.720)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.961] [G acc: 0.312]\n",
      "12766 [D loss: (0.628)(R 0.666, F 0.591)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.895] [G acc: 0.438]\n",
      "12767 [D loss: (0.579)(R 0.562, F 0.597)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.054] [G acc: 0.250]\n",
      "12768 [D loss: (0.538)(R 0.483, F 0.593)] [D acc: (0.750)(0.875, 0.625)] [G loss: 1.063] [G acc: 0.250]\n",
      "12769 [D loss: (0.725)(R 0.733, F 0.718)] [D acc: (0.500)(0.500, 0.500)] [G loss: 1.021] [G acc: 0.312]\n",
      "12770 [D loss: (0.488)(R 0.411, F 0.565)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.951] [G acc: 0.188]\n",
      "12771 [D loss: (0.752)(R 0.679, F 0.825)] [D acc: (0.625)(0.812, 0.438)] [G loss: 1.029] [G acc: 0.375]\n",
      "12772 [D loss: (0.620)(R 0.578, F 0.662)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.900] [G acc: 0.312]\n",
      "12773 [D loss: (0.758)(R 0.592, F 0.924)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.673] [G acc: 0.625]\n",
      "12774 [D loss: (0.797)(R 0.690, F 0.903)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.608] [G acc: 0.750]\n",
      "12775 [D loss: (0.750)(R 0.775, F 0.725)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.906] [G acc: 0.500]\n",
      "12776 [D loss: (0.451)(R 0.511, F 0.390)] [D acc: (0.750)(0.812, 0.688)] [G loss: 2.688] [G acc: 0.438]\n",
      "12777 [D loss: (0.560)(R 0.532, F 0.589)] [D acc: (0.625)(0.750, 0.500)] [G loss: 1.879] [G acc: 0.312]\n",
      "12778 [D loss: (0.905)(R 0.918, F 0.891)] [D acc: (0.375)(0.625, 0.125)] [G loss: 1.058] [G acc: 0.500]\n",
      "12779 [D loss: (0.710)(R 0.534, F 0.886)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.937] [G acc: 0.438]\n",
      "12780 [D loss: (0.644)(R 0.514, F 0.774)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.917] [G acc: 0.438]\n",
      "12781 [D loss: (0.689)(R 0.548, F 0.830)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.809] [G acc: 0.500]\n",
      "12782 [D loss: (0.654)(R 0.545, F 0.764)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.949] [G acc: 0.375]\n",
      "12783 [D loss: (0.643)(R 0.498, F 0.789)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.695] [G acc: 0.688]\n",
      "12784 [D loss: (0.726)(R 0.683, F 0.770)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.785] [G acc: 0.562]\n",
      "12785 [D loss: (0.728)(R 0.569, F 0.887)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.502] [G acc: 0.938]\n",
      "12786 [D loss: (0.702)(R 0.588, F 0.816)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.774] [G acc: 0.625]\n",
      "12787 [D loss: (0.638)(R 0.554, F 0.721)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.691] [G acc: 0.625]\n",
      "12788 [D loss: (0.705)(R 0.663, F 0.748)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.656] [G acc: 0.688]\n",
      "12789 [D loss: (0.651)(R 0.539, F 0.763)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.597] [G acc: 0.750]\n",
      "12790 [D loss: (0.882)(R 0.879, F 0.885)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.745] [G acc: 0.438]\n",
      "12791 [D loss: (0.765)(R 0.638, F 0.893)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.771] [G acc: 0.562]\n",
      "12792 [D loss: (0.789)(R 0.623, F 0.955)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.619] [G acc: 0.688]\n",
      "12793 [D loss: (0.711)(R 0.609, F 0.812)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.977] [G acc: 0.438]\n",
      "12794 [D loss: (0.727)(R 0.649, F 0.805)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.626] [G acc: 0.812]\n",
      "12795 [D loss: (0.655)(R 0.451, F 0.859)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.689] [G acc: 0.625]\n",
      "12796 [D loss: (0.715)(R 0.632, F 0.798)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.758] [G acc: 0.500]\n",
      "12797 [D loss: (0.664)(R 0.563, F 0.765)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.778] [G acc: 0.688]\n",
      "12798 [D loss: (0.764)(R 0.660, F 0.869)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.634] [G acc: 0.750]\n",
      "12799 [D loss: (0.801)(R 0.658, F 0.944)] [D acc: (0.406)(0.688, 0.125)] [G loss: 0.625] [G acc: 0.562]\n",
      "12800 [D loss: (0.684)(R 0.512, F 0.856)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.679] [G acc: 0.562]\n",
      "12801 [D loss: (0.741)(R 0.631, F 0.852)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.795] [G acc: 0.500]\n",
      "12802 [D loss: (0.596)(R 0.562, F 0.630)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.817] [G acc: 0.500]\n",
      "12803 [D loss: (0.654)(R 0.704, F 0.604)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.890] [G acc: 0.438]\n",
      "12804 [D loss: (0.621)(R 0.503, F 0.740)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.870] [G acc: 0.375]\n",
      "12805 [D loss: (0.676)(R 0.620, F 0.733)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.727] [G acc: 0.500]\n",
      "12806 [D loss: (0.679)(R 0.617, F 0.742)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.873] [G acc: 0.438]\n",
      "12807 [D loss: (0.658)(R 0.650, F 0.666)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.853] [G acc: 0.375]\n",
      "12808 [D loss: (0.751)(R 0.741, F 0.761)] [D acc: (0.375)(0.562, 0.188)] [G loss: 0.734] [G acc: 0.562]\n",
      "12809 [D loss: (0.715)(R 0.780, F 0.650)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.741] [G acc: 0.438]\n",
      "12810 [D loss: (0.732)(R 0.711, F 0.753)] [D acc: (0.344)(0.500, 0.188)] [G loss: 0.773] [G acc: 0.500]\n",
      "12811 [D loss: (0.760)(R 0.769, F 0.751)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.692] [G acc: 0.562]\n",
      "12812 [D loss: (0.670)(R 0.564, F 0.776)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.738] [G acc: 0.312]\n",
      "12813 [D loss: (0.682)(R 0.590, F 0.774)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.624] [G acc: 0.750]\n",
      "12814 [D loss: (0.775)(R 0.755, F 0.794)] [D acc: (0.344)(0.438, 0.250)] [G loss: 0.751] [G acc: 0.500]\n",
      "12815 [D loss: (0.742)(R 0.692, F 0.792)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.750] [G acc: 0.375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12816 [D loss: (0.795)(R 0.745, F 0.845)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.621] [G acc: 0.688]\n",
      "12817 [D loss: (0.733)(R 0.641, F 0.825)] [D acc: (0.406)(0.500, 0.312)] [G loss: 0.683] [G acc: 0.688]\n",
      "12818 [D loss: (0.764)(R 0.705, F 0.823)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.716] [G acc: 0.375]\n",
      "12819 [D loss: (0.672)(R 0.575, F 0.769)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.753] [G acc: 0.375]\n",
      "12820 [D loss: (0.778)(R 0.773, F 0.783)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.636] [G acc: 0.625]\n",
      "12821 [D loss: (0.683)(R 0.614, F 0.752)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.717] [G acc: 0.562]\n",
      "12822 [D loss: (0.762)(R 0.777, F 0.746)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.616] [G acc: 0.812]\n",
      "12823 [D loss: (0.688)(R 0.577, F 0.799)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.632] [G acc: 0.625]\n",
      "12824 [D loss: (0.739)(R 0.703, F 0.776)] [D acc: (0.375)(0.438, 0.312)] [G loss: 0.733] [G acc: 0.562]\n",
      "12825 [D loss: (0.757)(R 0.608, F 0.907)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.643] [G acc: 0.688]\n",
      "12826 [D loss: (0.768)(R 0.745, F 0.791)] [D acc: (0.375)(0.438, 0.312)] [G loss: 0.551] [G acc: 0.688]\n",
      "12827 [D loss: (0.765)(R 0.776, F 0.753)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.660] [G acc: 0.750]\n",
      "12828 [D loss: (0.690)(R 0.592, F 0.788)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.751] [G acc: 0.500]\n",
      "12829 [D loss: (0.642)(R 0.759, F 0.525)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.640] [G acc: 0.688]\n",
      "12830 [D loss: (0.604)(R 0.612, F 0.595)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.663] [G acc: 0.688]\n",
      "12831 [D loss: (0.609)(R 0.627, F 0.591)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.585] [G acc: 0.750]\n",
      "12832 [D loss: (0.705)(R 0.575, F 0.836)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.645] [G acc: 0.750]\n",
      "12833 [D loss: (0.687)(R 0.585, F 0.790)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.578] [G acc: 0.875]\n",
      "12834 [D loss: (0.703)(R 0.644, F 0.761)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.619] [G acc: 0.688]\n",
      "12835 [D loss: (0.797)(R 0.739, F 0.855)] [D acc: (0.344)(0.500, 0.188)] [G loss: 0.652] [G acc: 0.688]\n",
      "12836 [D loss: (0.684)(R 0.535, F 0.833)] [D acc: (0.438)(0.688, 0.188)] [G loss: 0.613] [G acc: 0.750]\n",
      "12837 [D loss: (0.686)(R 0.579, F 0.793)] [D acc: (0.406)(0.625, 0.188)] [G loss: 0.704] [G acc: 0.500]\n",
      "12838 [D loss: (0.773)(R 0.748, F 0.797)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.706] [G acc: 0.438]\n",
      "12839 [D loss: (0.735)(R 0.666, F 0.804)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.565] [G acc: 0.875]\n",
      "12840 [D loss: (0.779)(R 0.726, F 0.832)] [D acc: (0.344)(0.500, 0.188)] [G loss: 0.567] [G acc: 0.875]\n",
      "12841 [D loss: (0.667)(R 0.530, F 0.804)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.552] [G acc: 0.938]\n",
      "12842 [D loss: (0.733)(R 0.598, F 0.869)] [D acc: (0.406)(0.688, 0.125)] [G loss: 0.614] [G acc: 0.750]\n",
      "12843 [D loss: (0.624)(R 0.473, F 0.774)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.724] [G acc: 0.438]\n",
      "12844 [D loss: (0.714)(R 0.613, F 0.816)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.628] [G acc: 0.812]\n",
      "12845 [D loss: (0.764)(R 0.770, F 0.758)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.683] [G acc: 0.562]\n",
      "12846 [D loss: (0.766)(R 0.741, F 0.791)] [D acc: (0.344)(0.562, 0.125)] [G loss: 0.732] [G acc: 0.312]\n",
      "12847 [D loss: (0.641)(R 0.600, F 0.683)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.630] [G acc: 0.812]\n",
      "12848 [D loss: (0.755)(R 0.820, F 0.689)] [D acc: (0.406)(0.375, 0.438)] [G loss: 0.595] [G acc: 0.750]\n",
      "12849 [D loss: (0.719)(R 0.654, F 0.784)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.643] [G acc: 0.750]\n",
      "12850 [D loss: (0.666)(R 0.605, F 0.727)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.716] [G acc: 0.500]\n",
      "12851 [D loss: (0.777)(R 0.757, F 0.797)] [D acc: (0.312)(0.375, 0.250)] [G loss: 0.678] [G acc: 0.562]\n",
      "12852 [D loss: (0.715)(R 0.659, F 0.770)] [D acc: (0.344)(0.500, 0.188)] [G loss: 0.673] [G acc: 0.688]\n",
      "12853 [D loss: (0.720)(R 0.658, F 0.782)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.693] [G acc: 0.500]\n",
      "12854 [D loss: (0.679)(R 0.604, F 0.755)] [D acc: (0.375)(0.438, 0.312)] [G loss: 0.632] [G acc: 0.688]\n",
      "12855 [D loss: (0.680)(R 0.592, F 0.768)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.730] [G acc: 0.375]\n",
      "12856 [D loss: (0.663)(R 0.603, F 0.723)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.789] [G acc: 0.312]\n",
      "12857 [D loss: (0.550)(R 0.601, F 0.500)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.161] [G acc: 0.438]\n",
      "12858 [D loss: (0.696)(R 0.638, F 0.754)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.686] [G acc: 0.438]\n",
      "12859 [D loss: (0.657)(R 0.651, F 0.663)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.693] [G acc: 0.625]\n",
      "12860 [D loss: (0.640)(R 0.582, F 0.698)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.720] [G acc: 0.562]\n",
      "12861 [D loss: (0.653)(R 0.597, F 0.710)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.673] [G acc: 0.750]\n",
      "12862 [D loss: (0.719)(R 0.722, F 0.716)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.665] [G acc: 0.625]\n",
      "12863 [D loss: (0.698)(R 0.629, F 0.768)] [D acc: (0.406)(0.688, 0.125)] [G loss: 0.690] [G acc: 0.500]\n",
      "12864 [D loss: (0.732)(R 0.713, F 0.752)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.735] [G acc: 0.188]\n",
      "12865 [D loss: (0.705)(R 0.635, F 0.776)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.745] [G acc: 0.375]\n",
      "12866 [D loss: (0.718)(R 0.727, F 0.709)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.767] [G acc: 0.500]\n",
      "12867 [D loss: (0.666)(R 0.612, F 0.720)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.679] [G acc: 0.625]\n",
      "12868 [D loss: (0.695)(R 0.702, F 0.688)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.690] [G acc: 0.375]\n",
      "12869 [D loss: (0.638)(R 0.607, F 0.668)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.751] [G acc: 0.375]\n",
      "12870 [D loss: (0.676)(R 0.621, F 0.732)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.649] [G acc: 0.625]\n",
      "12871 [D loss: (0.622)(R 0.611, F 0.634)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.781] [G acc: 0.375]\n",
      "12872 [D loss: (0.650)(R 0.648, F 0.651)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.668] [G acc: 0.688]\n",
      "12873 [D loss: (0.670)(R 0.618, F 0.722)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.734] [G acc: 0.500]\n",
      "12874 [D loss: (0.709)(R 0.705, F 0.712)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.844] [G acc: 0.250]\n",
      "12875 [D loss: (0.643)(R 0.651, F 0.634)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.709] [G acc: 0.562]\n",
      "12876 [D loss: (0.643)(R 0.619, F 0.667)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.768] [G acc: 0.188]\n",
      "12877 [D loss: (0.749)(R 0.827, F 0.671)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.712] [G acc: 0.625]\n",
      "12878 [D loss: (0.791)(R 0.796, F 0.787)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.816] [G acc: 0.688]\n",
      "12879 [D loss: (0.697)(R 0.671, F 0.723)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.888] [G acc: 0.312]\n",
      "12880 [D loss: (0.629)(R 0.609, F 0.649)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.750] [G acc: 0.500]\n",
      "12881 [D loss: (0.640)(R 0.598, F 0.683)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.831] [G acc: 0.250]\n",
      "12882 [D loss: (0.658)(R 0.665, F 0.650)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.819] [G acc: 0.312]\n",
      "12883 [D loss: (0.682)(R 0.680, F 0.684)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.706] [G acc: 0.438]\n",
      "12884 [D loss: (0.652)(R 0.666, F 0.638)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.807] [G acc: 0.188]\n",
      "12885 [D loss: (0.675)(R 0.628, F 0.721)] [D acc: (0.344)(0.438, 0.250)] [G loss: 0.795] [G acc: 0.312]\n",
      "12886 [D loss: (0.693)(R 0.727, F 0.660)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.738] [G acc: 0.375]\n",
      "12887 [D loss: (0.675)(R 0.646, F 0.704)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.719] [G acc: 0.500]\n",
      "12888 [D loss: (0.656)(R 0.640, F 0.673)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.732] [G acc: 0.438]\n",
      "12889 [D loss: (0.590)(R 0.517, F 0.663)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.703] [G acc: 0.375]\n",
      "12890 [D loss: (0.651)(R 0.599, F 0.704)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.759] [G acc: 0.375]\n",
      "12891 [D loss: (0.628)(R 0.600, F 0.656)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.779] [G acc: 0.250]\n",
      "12892 [D loss: (0.682)(R 0.647, F 0.718)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.784] [G acc: 0.312]\n",
      "12893 [D loss: (0.701)(R 0.725, F 0.676)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.710] [G acc: 0.500]\n",
      "12894 [D loss: (0.734)(R 0.694, F 0.774)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.861] [G acc: 0.250]\n",
      "12895 [D loss: (0.634)(R 0.653, F 0.615)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.818] [G acc: 0.375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12896 [D loss: (0.687)(R 0.703, F 0.670)] [D acc: (0.406)(0.188, 0.625)] [G loss: 0.724] [G acc: 0.625]\n",
      "12897 [D loss: (0.616)(R 0.607, F 0.625)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.773] [G acc: 0.375]\n",
      "12898 [D loss: (0.661)(R 0.693, F 0.628)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.710] [G acc: 0.500]\n",
      "12899 [D loss: (0.641)(R 0.638, F 0.645)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.798] [G acc: 0.438]\n",
      "12900 [D loss: (0.687)(R 0.698, F 0.676)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.798] [G acc: 0.312]\n",
      "12901 [D loss: (0.722)(R 0.739, F 0.705)] [D acc: (0.375)(0.375, 0.375)] [G loss: 0.704] [G acc: 0.438]\n",
      "12902 [D loss: (0.658)(R 0.619, F 0.697)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.768] [G acc: 0.312]\n",
      "12903 [D loss: (0.620)(R 0.581, F 0.660)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.664] [G acc: 0.625]\n",
      "12904 [D loss: (0.713)(R 0.653, F 0.773)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.730] [G acc: 0.500]\n",
      "12905 [D loss: (0.626)(R 0.559, F 0.693)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.799] [G acc: 0.250]\n",
      "12906 [D loss: (0.660)(R 0.583, F 0.736)] [D acc: (0.406)(0.500, 0.312)] [G loss: 0.645] [G acc: 0.500]\n",
      "12907 [D loss: (0.981)(R 0.675, F 1.286)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.686] [G acc: 0.500]\n",
      "12908 [D loss: (0.738)(R 0.712, F 0.764)] [D acc: (0.375)(0.312, 0.438)] [G loss: 0.479] [G acc: 0.625]\n",
      "12909 [D loss: (0.929)(R 0.652, F 1.205)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.474] [G acc: 0.750]\n",
      "12910 [D loss: (0.829)(R 0.534, F 1.124)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.646] [G acc: 0.562]\n",
      "12911 [D loss: (0.879)(R 0.606, F 1.151)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.734] [G acc: 0.375]\n",
      "12912 [D loss: (0.648)(R 0.516, F 0.780)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.643] [G acc: 0.500]\n",
      "12913 [D loss: (1.017)(R 0.612, F 1.421)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.796] [G acc: 0.375]\n",
      "12914 [D loss: (1.073)(R 0.710, F 1.435)] [D acc: (0.312)(0.438, 0.188)] [G loss: 0.490] [G acc: 0.750]\n",
      "12915 [D loss: (1.110)(R 0.602, F 1.618)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.684] [G acc: 0.438]\n",
      "12916 [D loss: (1.058)(R 0.741, F 1.374)] [D acc: (0.438)(0.250, 0.625)] [G loss: 0.822] [G acc: 0.562]\n",
      "12917 [D loss: (1.319)(R 0.716, F 1.923)] [D acc: (0.406)(0.625, 0.188)] [G loss: 0.614] [G acc: 0.438]\n",
      "12918 [D loss: (1.226)(R 0.689, F 1.763)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.711] [G acc: 0.500]\n",
      "12919 [D loss: (0.894)(R 0.650, F 1.138)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.837] [G acc: 0.375]\n",
      "12920 [D loss: (0.680)(R 0.648, F 0.711)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.745] [G acc: 0.312]\n",
      "12921 [D loss: (0.853)(R 0.661, F 1.044)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.685] [G acc: 0.625]\n",
      "12922 [D loss: (1.173)(R 0.627, F 1.718)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.690] [G acc: 0.562]\n",
      "12923 [D loss: (0.741)(R 0.725, F 0.756)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.966] [G acc: 0.500]\n",
      "12924 [D loss: (0.754)(R 0.718, F 0.790)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.765] [G acc: 0.312]\n",
      "12925 [D loss: (1.110)(R 0.686, F 1.534)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.720] [G acc: 0.500]\n",
      "12926 [D loss: (1.106)(R 0.609, F 1.602)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.633] [G acc: 0.625]\n",
      "12927 [D loss: (1.153)(R 0.807, F 1.498)] [D acc: (0.281)(0.375, 0.188)] [G loss: 0.780] [G acc: 0.312]\n",
      "12928 [D loss: (1.240)(R 0.648, F 1.831)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.857] [G acc: 0.250]\n",
      "12929 [D loss: (0.649)(R 0.631, F 0.666)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.982] [G acc: 0.500]\n",
      "12930 [D loss: (0.756)(R 0.664, F 0.848)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.862] [G acc: 0.250]\n",
      "12931 [D loss: (0.585)(R 0.571, F 0.599)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.798] [G acc: 0.375]\n",
      "12932 [D loss: (0.637)(R 0.618, F 0.657)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.999] [G acc: 0.625]\n",
      "12933 [D loss: (0.751)(R 0.667, F 0.835)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.290] [G acc: 0.125]\n",
      "12934 [D loss: (0.629)(R 0.633, F 0.626)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.837] [G acc: 0.438]\n",
      "12935 [D loss: (0.694)(R 0.664, F 0.724)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.626] [G acc: 0.562]\n",
      "12936 [D loss: (0.825)(R 0.717, F 0.933)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.794] [G acc: 0.438]\n",
      "12937 [D loss: (0.628)(R 0.625, F 0.630)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.934] [G acc: 0.188]\n",
      "12938 [D loss: (0.562)(R 0.618, F 0.506)] [D acc: (0.875)(0.812, 0.938)] [G loss: 0.795] [G acc: 0.312]\n",
      "12939 [D loss: (0.584)(R 0.548, F 0.620)] [D acc: (0.781)(0.938, 0.625)] [G loss: 0.783] [G acc: 0.438]\n",
      "12940 [D loss: (0.617)(R 0.599, F 0.635)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.867] [G acc: 0.250]\n",
      "12941 [D loss: (0.610)(R 0.592, F 0.628)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.717] [G acc: 0.625]\n",
      "12942 [D loss: (0.656)(R 0.637, F 0.675)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.721] [G acc: 0.438]\n",
      "12943 [D loss: (0.680)(R 0.614, F 0.746)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.829] [G acc: 0.375]\n",
      "12944 [D loss: (0.655)(R 0.631, F 0.679)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.827] [G acc: 0.500]\n",
      "12945 [D loss: (0.631)(R 0.629, F 0.634)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.757] [G acc: 0.500]\n",
      "12946 [D loss: (0.638)(R 0.663, F 0.614)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.746] [G acc: 0.500]\n",
      "12947 [D loss: (0.618)(R 0.584, F 0.651)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.847] [G acc: 0.438]\n",
      "12948 [D loss: (0.675)(R 0.648, F 0.702)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.742] [G acc: 0.438]\n",
      "12949 [D loss: (0.672)(R 0.657, F 0.687)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.772] [G acc: 0.562]\n",
      "12950 [D loss: (0.628)(R 0.579, F 0.677)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.834] [G acc: 0.312]\n",
      "12951 [D loss: (0.661)(R 0.600, F 0.721)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.793] [G acc: 0.438]\n",
      "12952 [D loss: (0.690)(R 0.629, F 0.750)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.734] [G acc: 0.438]\n",
      "12953 [D loss: (0.630)(R 0.570, F 0.689)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.793] [G acc: 0.312]\n",
      "12954 [D loss: (0.600)(R 0.487, F 0.713)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.853] [G acc: 0.375]\n",
      "12955 [D loss: (0.634)(R 0.589, F 0.680)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.806] [G acc: 0.250]\n",
      "12956 [D loss: (0.662)(R 0.601, F 0.723)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.821] [G acc: 0.312]\n",
      "12957 [D loss: (0.648)(R 0.548, F 0.747)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.726] [G acc: 0.375]\n",
      "12958 [D loss: (0.608)(R 0.562, F 0.655)] [D acc: (0.781)(0.938, 0.625)] [G loss: 0.700] [G acc: 0.625]\n",
      "12959 [D loss: (0.693)(R 0.652, F 0.734)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.863] [G acc: 0.375]\n",
      "12960 [D loss: (0.552)(R 0.642, F 0.463)] [D acc: (0.750)(0.750, 0.750)] [G loss: 2.353] [G acc: 0.250]\n",
      "12961 [D loss: (0.538)(R 0.589, F 0.487)] [D acc: (0.812)(0.875, 0.750)] [G loss: 5.388] [G acc: 0.312]\n",
      "12962 [D loss: (0.485)(R 0.584, F 0.387)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.533] [G acc: 0.188]\n",
      "12963 [D loss: (0.676)(R 0.694, F 0.658)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.814] [G acc: 0.438]\n",
      "12964 [D loss: (0.721)(R 0.680, F 0.763)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.845] [G acc: 0.250]\n",
      "12965 [D loss: (0.614)(R 0.600, F 0.628)] [D acc: (0.750)(0.938, 0.562)] [G loss: 0.840] [G acc: 0.125]\n",
      "12966 [D loss: (0.640)(R 0.627, F 0.654)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.864] [G acc: 0.250]\n",
      "12967 [D loss: (0.647)(R 0.657, F 0.636)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.789] [G acc: 0.438]\n",
      "12968 [D loss: (0.607)(R 0.596, F 0.619)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.762] [G acc: 0.375]\n",
      "12969 [D loss: (0.654)(R 0.613, F 0.695)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.754] [G acc: 0.562]\n",
      "12970 [D loss: (0.582)(R 0.548, F 0.616)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.938] [G acc: 0.312]\n",
      "12971 [D loss: (0.643)(R 0.650, F 0.636)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.880] [G acc: 0.312]\n",
      "12972 [D loss: (0.596)(R 0.592, F 0.600)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.766] [G acc: 0.438]\n",
      "12973 [D loss: (0.661)(R 0.587, F 0.736)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.826] [G acc: 0.375]\n",
      "12974 [D loss: (0.690)(R 0.709, F 0.672)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.890] [G acc: 0.250]\n",
      "12975 [D loss: (0.616)(R 0.616, F 0.616)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.841] [G acc: 0.250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12976 [D loss: (0.587)(R 0.592, F 0.583)] [D acc: (0.844)(0.938, 0.750)] [G loss: 0.910] [G acc: 0.312]\n",
      "12977 [D loss: (0.584)(R 0.633, F 0.535)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.873] [G acc: 0.250]\n",
      "12978 [D loss: (0.609)(R 0.632, F 0.586)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.845] [G acc: 0.250]\n",
      "12979 [D loss: (0.615)(R 0.652, F 0.578)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.792] [G acc: 0.312]\n",
      "12980 [D loss: (0.658)(R 0.610, F 0.706)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.886] [G acc: 0.250]\n",
      "12981 [D loss: (0.647)(R 0.601, F 0.692)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.833] [G acc: 0.500]\n",
      "12982 [D loss: (0.554)(R 0.550, F 0.558)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.818] [G acc: 0.375]\n",
      "12983 [D loss: (0.596)(R 0.643, F 0.550)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.776] [G acc: 0.375]\n",
      "12984 [D loss: (0.596)(R 0.632, F 0.560)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.782] [G acc: 0.562]\n",
      "12985 [D loss: (0.547)(R 0.473, F 0.621)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.921] [G acc: 0.250]\n",
      "12986 [D loss: (0.630)(R 0.663, F 0.597)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.804] [G acc: 0.375]\n",
      "12987 [D loss: (0.647)(R 0.697, F 0.597)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.802] [G acc: 0.438]\n",
      "12988 [D loss: (0.575)(R 0.514, F 0.636)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.918] [G acc: 0.250]\n",
      "12989 [D loss: (0.669)(R 0.633, F 0.706)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.761] [G acc: 0.500]\n",
      "12990 [D loss: (0.746)(R 0.721, F 0.770)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.988] [G acc: 0.250]\n",
      "12991 [D loss: (0.589)(R 0.555, F 0.622)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.899] [G acc: 0.250]\n",
      "12992 [D loss: (0.761)(R 0.694, F 0.827)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.844] [G acc: 0.250]\n",
      "12993 [D loss: (0.665)(R 0.606, F 0.725)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.772] [G acc: 0.375]\n",
      "12994 [D loss: (0.589)(R 0.557, F 0.620)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.804] [G acc: 0.312]\n",
      "12995 [D loss: (0.664)(R 0.664, F 0.665)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.852] [G acc: 0.438]\n",
      "12996 [D loss: (0.616)(R 0.571, F 0.661)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.750] [G acc: 0.500]\n",
      "12997 [D loss: (0.693)(R 0.673, F 0.713)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.769] [G acc: 0.500]\n",
      "12998 [D loss: (0.648)(R 0.550, F 0.745)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.777] [G acc: 0.438]\n",
      "12999 [D loss: (0.619)(R 0.571, F 0.666)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.819] [G acc: 0.188]\n",
      "13000 [D loss: (0.717)(R 0.699, F 0.735)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.738] [G acc: 0.375]\n",
      "13001 [D loss: (0.667)(R 0.639, F 0.695)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.873] [G acc: 0.188]\n",
      "13002 [D loss: (0.716)(R 0.770, F 0.661)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.791] [G acc: 0.312]\n",
      "13003 [D loss: (0.676)(R 0.667, F 0.686)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.892] [G acc: 0.312]\n",
      "13004 [D loss: (0.702)(R 0.707, F 0.697)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.714] [G acc: 0.562]\n",
      "13005 [D loss: (0.703)(R 0.737, F 0.670)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.810] [G acc: 0.188]\n",
      "13006 [D loss: (0.693)(R 0.587, F 0.800)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.786] [G acc: 0.375]\n",
      "13007 [D loss: (0.689)(R 0.704, F 0.673)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.842] [G acc: 0.188]\n",
      "13008 [D loss: (0.653)(R 0.659, F 0.648)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.859] [G acc: 0.312]\n",
      "13009 [D loss: (0.698)(R 0.739, F 0.656)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.802] [G acc: 0.250]\n",
      "13010 [D loss: (0.719)(R 0.752, F 0.686)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.745] [G acc: 0.375]\n",
      "13011 [D loss: (0.661)(R 0.667, F 0.655)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.866] [G acc: 0.062]\n",
      "13012 [D loss: (0.680)(R 0.714, F 0.645)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.880] [G acc: 0.062]\n",
      "13013 [D loss: (0.512)(R 0.723, F 0.301)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.826] [G acc: 0.062]\n",
      "13014 [D loss: (0.572)(R 0.647, F 0.498)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.299] [G acc: 0.188]\n",
      "13015 [D loss: (0.695)(R 0.701, F 0.688)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.727] [G acc: 0.500]\n",
      "13016 [D loss: (0.669)(R 0.722, F 0.616)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.840] [G acc: 0.188]\n",
      "13017 [D loss: (0.584)(R 0.565, F 0.603)] [D acc: (0.875)(0.875, 0.875)] [G loss: 0.744] [G acc: 0.438]\n",
      "13018 [D loss: (0.640)(R 0.557, F 0.723)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.873] [G acc: 0.125]\n",
      "13019 [D loss: (0.646)(R 0.677, F 0.614)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.784] [G acc: 0.250]\n",
      "13020 [D loss: (0.720)(R 0.686, F 0.753)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.799] [G acc: 0.250]\n",
      "13021 [D loss: (0.609)(R 0.599, F 0.618)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.873] [G acc: 0.188]\n",
      "13022 [D loss: (0.625)(R 0.593, F 0.657)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.845] [G acc: 0.250]\n",
      "13023 [D loss: (0.593)(R 0.628, F 0.557)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.846] [G acc: 0.250]\n",
      "13024 [D loss: (0.603)(R 0.560, F 0.646)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.814] [G acc: 0.312]\n",
      "13025 [D loss: (0.623)(R 0.572, F 0.675)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.889] [G acc: 0.250]\n",
      "13026 [D loss: (0.611)(R 0.596, F 0.626)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.954] [G acc: 0.125]\n",
      "13027 [D loss: (0.712)(R 0.734, F 0.690)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.807] [G acc: 0.312]\n",
      "13028 [D loss: (0.688)(R 0.734, F 0.643)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.854] [G acc: 0.062]\n",
      "13029 [D loss: (0.621)(R 0.655, F 0.587)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.825] [G acc: 0.188]\n",
      "13030 [D loss: (0.679)(R 0.789, F 0.569)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.874] [G acc: 0.062]\n",
      "13031 [D loss: (0.652)(R 0.696, F 0.607)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.826] [G acc: 0.125]\n",
      "13032 [D loss: (0.674)(R 0.728, F 0.620)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.720] [G acc: 0.500]\n",
      "13033 [D loss: (0.671)(R 0.706, F 0.636)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.850] [G acc: 0.250]\n",
      "13034 [D loss: (0.660)(R 0.679, F 0.641)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.852] [G acc: 0.250]\n",
      "13035 [D loss: (0.630)(R 0.632, F 0.628)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.878] [G acc: 0.250]\n",
      "13036 [D loss: (0.908)(R 1.102, F 0.714)] [D acc: (0.312)(0.250, 0.375)] [G loss: 0.811] [G acc: 0.312]\n",
      "13037 [D loss: (0.590)(R 0.590, F 0.590)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.805] [G acc: 0.188]\n",
      "13038 [D loss: (0.682)(R 0.707, F 0.656)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.776] [G acc: 0.438]\n",
      "13039 [D loss: (0.588)(R 0.579, F 0.597)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.790] [G acc: 0.312]\n",
      "13040 [D loss: (0.696)(R 0.690, F 0.702)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.760] [G acc: 0.312]\n",
      "13041 [D loss: (0.617)(R 0.631, F 0.602)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.793] [G acc: 0.375]\n",
      "13042 [D loss: (0.814)(R 0.743, F 0.886)] [D acc: (0.375)(0.500, 0.250)] [G loss: 0.833] [G acc: 0.188]\n",
      "13043 [D loss: (0.680)(R 0.680, F 0.680)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.729] [G acc: 0.500]\n",
      "13044 [D loss: (0.744)(R 0.679, F 0.808)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.722] [G acc: 0.438]\n",
      "13045 [D loss: (0.723)(R 0.703, F 0.743)] [D acc: (0.375)(0.375, 0.375)] [G loss: 0.736] [G acc: 0.438]\n",
      "13046 [D loss: (0.641)(R 0.599, F 0.682)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.867] [G acc: 0.312]\n",
      "13047 [D loss: (0.693)(R 0.705, F 0.681)] [D acc: (0.406)(0.500, 0.312)] [G loss: 0.750] [G acc: 0.375]\n",
      "13048 [D loss: (0.737)(R 0.689, F 0.784)] [D acc: (0.406)(0.500, 0.312)] [G loss: 0.767] [G acc: 0.438]\n",
      "13049 [D loss: (0.652)(R 0.573, F 0.731)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.716] [G acc: 0.312]\n",
      "13050 [D loss: (0.756)(R 0.772, F 0.740)] [D acc: (0.344)(0.312, 0.375)] [G loss: 0.704] [G acc: 0.562]\n",
      "13051 [D loss: (0.674)(R 0.678, F 0.670)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.749] [G acc: 0.438]\n",
      "13052 [D loss: (0.741)(R 0.815, F 0.668)] [D acc: (0.406)(0.312, 0.500)] [G loss: 0.710] [G acc: 0.312]\n",
      "13053 [D loss: (0.763)(R 0.791, F 0.736)] [D acc: (0.375)(0.312, 0.438)] [G loss: 0.684] [G acc: 0.438]\n",
      "13054 [D loss: (0.720)(R 0.654, F 0.787)] [D acc: (0.438)(0.688, 0.188)] [G loss: 0.671] [G acc: 0.500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13055 [D loss: (0.873)(R 0.656, F 1.089)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.676] [G acc: 0.500]\n",
      "13056 [D loss: (0.724)(R 0.655, F 0.792)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.674] [G acc: 0.688]\n",
      "13057 [D loss: (0.746)(R 0.705, F 0.786)] [D acc: (0.375)(0.375, 0.375)] [G loss: 0.692] [G acc: 0.562]\n",
      "13058 [D loss: (0.687)(R 0.632, F 0.742)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.621] [G acc: 0.812]\n",
      "13059 [D loss: (0.705)(R 0.628, F 0.783)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.629] [G acc: 0.625]\n",
      "13060 [D loss: (0.793)(R 0.670, F 0.917)] [D acc: (0.406)(0.625, 0.188)] [G loss: 0.666] [G acc: 0.500]\n",
      "13061 [D loss: (0.690)(R 0.620, F 0.760)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.839] [G acc: 0.312]\n",
      "13062 [D loss: (0.789)(R 0.791, F 0.787)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.599] [G acc: 0.688]\n",
      "13063 [D loss: (1.007)(R 0.853, F 1.161)] [D acc: (0.219)(0.375, 0.062)] [G loss: 0.679] [G acc: 0.625]\n",
      "13064 [D loss: (0.721)(R 0.637, F 0.805)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.649] [G acc: 0.562]\n",
      "13065 [D loss: (0.745)(R 0.686, F 0.803)] [D acc: (0.438)(0.562, 0.312)] [G loss: 1.529] [G acc: 0.312]\n",
      "13066 [D loss: (0.698)(R 0.734, F 0.662)] [D acc: (0.625)(0.438, 0.812)] [G loss: 3.794] [G acc: 0.312]\n",
      "13067 [D loss: (0.876)(R 0.780, F 0.972)] [D acc: (0.531)(0.438, 0.625)] [G loss: 1.340] [G acc: 0.562]\n",
      "13068 [D loss: (0.786)(R 0.773, F 0.800)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.704] [G acc: 0.438]\n",
      "13069 [D loss: (0.858)(R 0.705, F 1.012)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.873] [G acc: 0.438]\n",
      "13070 [D loss: (0.807)(R 0.710, F 0.903)] [D acc: (0.375)(0.438, 0.312)] [G loss: 0.669] [G acc: 0.625]\n",
      "13071 [D loss: (0.866)(R 0.692, F 1.040)] [D acc: (0.219)(0.250, 0.188)] [G loss: 0.576] [G acc: 0.750]\n",
      "13072 [D loss: (0.702)(R 0.676, F 0.727)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.724] [G acc: 0.500]\n",
      "13073 [D loss: (0.790)(R 0.624, F 0.956)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.617] [G acc: 0.500]\n",
      "13074 [D loss: (0.727)(R 0.638, F 0.815)] [D acc: (0.406)(0.625, 0.188)] [G loss: 0.663] [G acc: 0.562]\n",
      "13075 [D loss: (0.838)(R 0.757, F 0.918)] [D acc: (0.375)(0.562, 0.188)] [G loss: 0.647] [G acc: 0.562]\n",
      "13076 [D loss: (0.763)(R 0.654, F 0.872)] [D acc: (0.312)(0.375, 0.250)] [G loss: 0.710] [G acc: 0.562]\n",
      "13077 [D loss: (0.658)(R 0.636, F 0.681)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.553] [G acc: 0.688]\n",
      "13078 [D loss: (0.716)(R 0.661, F 0.771)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.657] [G acc: 0.688]\n",
      "13079 [D loss: (0.678)(R 0.741, F 0.615)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.743] [G acc: 0.562]\n",
      "13080 [D loss: (0.799)(R 0.855, F 0.744)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.686] [G acc: 0.625]\n",
      "13081 [D loss: (0.605)(R 0.545, F 0.664)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.789] [G acc: 0.375]\n",
      "13082 [D loss: (0.848)(R 0.860, F 0.836)] [D acc: (0.344)(0.562, 0.125)] [G loss: 0.715] [G acc: 0.500]\n",
      "13083 [D loss: (0.684)(R 0.628, F 0.740)] [D acc: (0.406)(0.500, 0.312)] [G loss: 0.663] [G acc: 0.688]\n",
      "13084 [D loss: (0.693)(R 0.654, F 0.733)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.750] [G acc: 0.375]\n",
      "13085 [D loss: (0.674)(R 0.645, F 0.702)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.708] [G acc: 0.562]\n",
      "13086 [D loss: (0.679)(R 0.612, F 0.746)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.720] [G acc: 0.375]\n",
      "13087 [D loss: (0.680)(R 0.695, F 0.666)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.603] [G acc: 0.750]\n",
      "13088 [D loss: (0.651)(R 0.566, F 0.736)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.723] [G acc: 0.625]\n",
      "13089 [D loss: (0.643)(R 0.637, F 0.649)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.555] [G acc: 0.625]\n",
      "13090 [D loss: (0.729)(R 0.743, F 0.715)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.728] [G acc: 0.562]\n",
      "13091 [D loss: (0.660)(R 0.627, F 0.693)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.775] [G acc: 0.312]\n",
      "13092 [D loss: (0.705)(R 0.722, F 0.688)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.790] [G acc: 0.250]\n",
      "13093 [D loss: (0.807)(R 0.707, F 0.908)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.740] [G acc: 0.438]\n",
      "13094 [D loss: (0.657)(R 0.579, F 0.736)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.712] [G acc: 0.438]\n",
      "13095 [D loss: (0.668)(R 0.622, F 0.713)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.792] [G acc: 0.312]\n",
      "13096 [D loss: (0.676)(R 0.639, F 0.712)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.720] [G acc: 0.438]\n",
      "13097 [D loss: (0.698)(R 0.690, F 0.707)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.726] [G acc: 0.562]\n",
      "13098 [D loss: (0.703)(R 0.699, F 0.707)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.807] [G acc: 0.438]\n",
      "13099 [D loss: (0.655)(R 0.727, F 0.584)] [D acc: (0.594)(0.500, 0.688)] [G loss: 2.152] [G acc: 0.188]\n",
      "13100 [D loss: (0.428)(R 0.656, F 0.200)] [D acc: (0.812)(0.688, 0.938)] [G loss: 2.590] [G acc: 0.188]\n",
      "13101 [D loss: (0.657)(R 0.661, F 0.653)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.909] [G acc: 0.188]\n",
      "13102 [D loss: (0.666)(R 0.695, F 0.636)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.811] [G acc: 0.312]\n",
      "13103 [D loss: (0.584)(R 0.642, F 0.526)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.861] [G acc: 0.188]\n",
      "13104 [D loss: (0.720)(R 0.848, F 0.593)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.831] [G acc: 0.312]\n",
      "13105 [D loss: (0.615)(R 0.538, F 0.691)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.838] [G acc: 0.188]\n",
      "13106 [D loss: (0.677)(R 0.739, F 0.616)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.816] [G acc: 0.250]\n",
      "13107 [D loss: (0.679)(R 0.649, F 0.710)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.697] [G acc: 0.438]\n",
      "13108 [D loss: (0.647)(R 0.647, F 0.647)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.845] [G acc: 0.188]\n",
      "13109 [D loss: (0.650)(R 0.628, F 0.673)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.831] [G acc: 0.188]\n",
      "13110 [D loss: (0.727)(R 0.790, F 0.664)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.824] [G acc: 0.188]\n",
      "13111 [D loss: (0.685)(R 0.716, F 0.654)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.814] [G acc: 0.250]\n",
      "13112 [D loss: (0.660)(R 0.676, F 0.644)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.752] [G acc: 0.500]\n",
      "13113 [D loss: (0.628)(R 0.664, F 0.592)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.899] [G acc: 0.188]\n",
      "13114 [D loss: (0.715)(R 0.802, F 0.629)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.960] [G acc: 0.125]\n",
      "13115 [D loss: (0.645)(R 0.725, F 0.564)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.938] [G acc: 0.125]\n",
      "13116 [D loss: (0.660)(R 0.668, F 0.652)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.855] [G acc: 0.438]\n",
      "13117 [D loss: (0.662)(R 0.705, F 0.620)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.864] [G acc: 0.312]\n",
      "13118 [D loss: (0.634)(R 0.696, F 0.572)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.945] [G acc: 0.188]\n",
      "13119 [D loss: (0.680)(R 0.691, F 0.669)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.816] [G acc: 0.188]\n",
      "13120 [D loss: (0.681)(R 0.697, F 0.665)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.797] [G acc: 0.250]\n",
      "13121 [D loss: (0.649)(R 0.733, F 0.564)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.794] [G acc: 0.375]\n",
      "13122 [D loss: (0.682)(R 0.674, F 0.689)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.758] [G acc: 0.250]\n",
      "13123 [D loss: (0.657)(R 0.670, F 0.645)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.785] [G acc: 0.312]\n",
      "13124 [D loss: (0.649)(R 0.621, F 0.677)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.884] [G acc: 0.250]\n",
      "13125 [D loss: (0.729)(R 0.772, F 0.685)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.754] [G acc: 0.375]\n",
      "13126 [D loss: (0.647)(R 0.623, F 0.670)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.719] [G acc: 0.375]\n",
      "13127 [D loss: (0.665)(R 0.677, F 0.654)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.685] [G acc: 0.562]\n",
      "13128 [D loss: (0.735)(R 0.766, F 0.704)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.854] [G acc: 0.250]\n",
      "13129 [D loss: (0.694)(R 0.694, F 0.693)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.770] [G acc: 0.250]\n",
      "13130 [D loss: (0.691)(R 0.673, F 0.709)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.803] [G acc: 0.312]\n",
      "13131 [D loss: (0.598)(R 0.574, F 0.622)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.862] [G acc: 0.062]\n",
      "13132 [D loss: (0.662)(R 0.685, F 0.640)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.773] [G acc: 0.250]\n",
      "13133 [D loss: (0.666)(R 0.723, F 0.609)] [D acc: (0.562)(0.500, 0.625)] [G loss: 1.047] [G acc: 0.000]\n",
      "13134 [D loss: (0.641)(R 0.723, F 0.559)] [D acc: (0.719)(0.500, 0.938)] [G loss: 0.826] [G acc: 0.250]\n",
      "13135 [D loss: (0.695)(R 0.769, F 0.620)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.859] [G acc: 0.188]\n",
      "13136 [D loss: (0.630)(R 0.642, F 0.617)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.863] [G acc: 0.062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13137 [D loss: (0.685)(R 0.731, F 0.639)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.877] [G acc: 0.250]\n",
      "13138 [D loss: (0.668)(R 0.690, F 0.645)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.848] [G acc: 0.375]\n",
      "13139 [D loss: (0.628)(R 0.648, F 0.608)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.804] [G acc: 0.125]\n",
      "13140 [D loss: (0.656)(R 0.663, F 0.650)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.874] [G acc: 0.062]\n",
      "13141 [D loss: (0.699)(R 0.702, F 0.697)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.821] [G acc: 0.250]\n",
      "13142 [D loss: (0.659)(R 0.693, F 0.625)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.760] [G acc: 0.250]\n",
      "13143 [D loss: (0.706)(R 0.755, F 0.657)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.772] [G acc: 0.312]\n",
      "13144 [D loss: (0.744)(R 0.694, F 0.795)] [D acc: (0.344)(0.375, 0.312)] [G loss: 0.741] [G acc: 0.375]\n",
      "13145 [D loss: (0.687)(R 0.679, F 0.696)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.736] [G acc: 0.438]\n",
      "13146 [D loss: (0.710)(R 0.664, F 0.756)] [D acc: (0.344)(0.438, 0.250)] [G loss: 0.786] [G acc: 0.312]\n",
      "13147 [D loss: (0.657)(R 0.668, F 0.647)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.669] [G acc: 0.562]\n",
      "13148 [D loss: (0.718)(R 0.713, F 0.722)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.744] [G acc: 0.375]\n",
      "13149 [D loss: (0.759)(R 0.767, F 0.751)] [D acc: (0.312)(0.250, 0.375)] [G loss: 0.705] [G acc: 0.625]\n",
      "13150 [D loss: (0.755)(R 0.731, F 0.779)] [D acc: (0.344)(0.375, 0.312)] [G loss: 0.819] [G acc: 0.562]\n",
      "13151 [D loss: (0.749)(R 0.722, F 0.776)] [D acc: (0.156)(0.125, 0.188)] [G loss: 0.750] [G acc: 0.500]\n",
      "13152 [D loss: (0.693)(R 0.783, F 0.604)] [D acc: (0.594)(0.312, 0.875)] [G loss: 0.696] [G acc: 0.625]\n",
      "13153 [D loss: (0.712)(R 0.736, F 0.688)] [D acc: (0.344)(0.188, 0.500)] [G loss: 0.718] [G acc: 0.562]\n",
      "13154 [D loss: (0.736)(R 0.757, F 0.716)] [D acc: (0.312)(0.250, 0.375)] [G loss: 0.702] [G acc: 0.625]\n",
      "13155 [D loss: (0.737)(R 0.730, F 0.744)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.682] [G acc: 0.625]\n",
      "13156 [D loss: (0.766)(R 0.756, F 0.776)] [D acc: (0.281)(0.250, 0.312)] [G loss: 0.718] [G acc: 0.375]\n",
      "13157 [D loss: (0.791)(R 0.782, F 0.800)] [D acc: (0.344)(0.500, 0.188)] [G loss: 0.628] [G acc: 0.875]\n",
      "13158 [D loss: (0.717)(R 0.695, F 0.739)] [D acc: (0.375)(0.312, 0.438)] [G loss: 0.775] [G acc: 0.438]\n",
      "13159 [D loss: (0.720)(R 0.739, F 0.701)] [D acc: (0.406)(0.375, 0.438)] [G loss: 0.725] [G acc: 0.500]\n",
      "13160 [D loss: (0.718)(R 0.682, F 0.755)] [D acc: (0.312)(0.375, 0.250)] [G loss: 0.689] [G acc: 0.500]\n",
      "13161 [D loss: (0.767)(R 0.796, F 0.739)] [D acc: (0.312)(0.250, 0.375)] [G loss: 0.665] [G acc: 0.562]\n",
      "13162 [D loss: (0.645)(R 0.538, F 0.752)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.640] [G acc: 0.688]\n",
      "13163 [D loss: (0.696)(R 0.635, F 0.757)] [D acc: (0.312)(0.438, 0.188)] [G loss: 0.673] [G acc: 0.500]\n",
      "13164 [D loss: (0.774)(R 0.766, F 0.782)] [D acc: (0.250)(0.250, 0.250)] [G loss: 0.625] [G acc: 0.812]\n",
      "13165 [D loss: (0.690)(R 0.683, F 0.697)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.740] [G acc: 0.375]\n",
      "13166 [D loss: (0.736)(R 0.743, F 0.729)] [D acc: (0.375)(0.375, 0.375)] [G loss: 0.730] [G acc: 0.250]\n",
      "13167 [D loss: (0.792)(R 0.843, F 0.741)] [D acc: (0.312)(0.188, 0.438)] [G loss: 0.682] [G acc: 0.625]\n",
      "13168 [D loss: (0.647)(R 0.553, F 0.741)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.659] [G acc: 0.625]\n",
      "13169 [D loss: (0.723)(R 0.698, F 0.747)] [D acc: (0.344)(0.438, 0.250)] [G loss: 0.789] [G acc: 0.375]\n",
      "13170 [D loss: (0.737)(R 0.702, F 0.773)] [D acc: (0.281)(0.375, 0.188)] [G loss: 0.733] [G acc: 0.312]\n",
      "13171 [D loss: (0.678)(R 0.639, F 0.717)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.747] [G acc: 0.500]\n",
      "13172 [D loss: (0.705)(R 0.693, F 0.716)] [D acc: (0.344)(0.438, 0.250)] [G loss: 0.881] [G acc: 0.250]\n",
      "13173 [D loss: (0.652)(R 0.750, F 0.553)] [D acc: (0.406)(0.125, 0.688)] [G loss: 1.665] [G acc: 0.062]\n",
      "13174 [D loss: (0.568)(R 0.684, F 0.451)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.859] [G acc: 0.375]\n",
      "13175 [D loss: (0.649)(R 0.594, F 0.703)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.715] [G acc: 0.562]\n",
      "13176 [D loss: (0.652)(R 0.564, F 0.741)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.709] [G acc: 0.562]\n",
      "13177 [D loss: (0.717)(R 0.736, F 0.698)] [D acc: (0.375)(0.312, 0.438)] [G loss: 0.770] [G acc: 0.375]\n",
      "13178 [D loss: (0.722)(R 0.755, F 0.689)] [D acc: (0.375)(0.312, 0.438)] [G loss: 0.795] [G acc: 0.125]\n",
      "13179 [D loss: (0.697)(R 0.698, F 0.696)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.778] [G acc: 0.312]\n",
      "13180 [D loss: (0.675)(R 0.630, F 0.720)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.684] [G acc: 0.625]\n",
      "13181 [D loss: (0.722)(R 0.733, F 0.712)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.733] [G acc: 0.312]\n",
      "13182 [D loss: (0.688)(R 0.662, F 0.713)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.721] [G acc: 0.438]\n",
      "13183 [D loss: (0.690)(R 0.687, F 0.694)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.734] [G acc: 0.375]\n",
      "13184 [D loss: (0.668)(R 0.672, F 0.664)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.707] [G acc: 0.438]\n",
      "13185 [D loss: (0.666)(R 0.636, F 0.696)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.675] [G acc: 0.750]\n",
      "13186 [D loss: (0.666)(R 0.628, F 0.704)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.742] [G acc: 0.438]\n",
      "13187 [D loss: (0.694)(R 0.732, F 0.656)] [D acc: (0.438)(0.312, 0.562)] [G loss: 0.743] [G acc: 0.188]\n",
      "13188 [D loss: (0.699)(R 0.734, F 0.663)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.694] [G acc: 0.500]\n",
      "13189 [D loss: (0.752)(R 0.702, F 0.801)] [D acc: (0.344)(0.438, 0.250)] [G loss: 0.681] [G acc: 0.625]\n",
      "13190 [D loss: (0.720)(R 0.698, F 0.741)] [D acc: (0.344)(0.438, 0.250)] [G loss: 0.654] [G acc: 0.812]\n",
      "13191 [D loss: (0.674)(R 0.619, F 0.730)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.698] [G acc: 0.375]\n",
      "13192 [D loss: (0.669)(R 0.643, F 0.696)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.695] [G acc: 0.562]\n",
      "13193 [D loss: (0.671)(R 0.626, F 0.715)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.724] [G acc: 0.438]\n",
      "13194 [D loss: (0.707)(R 0.691, F 0.723)] [D acc: (0.344)(0.438, 0.250)] [G loss: 0.701] [G acc: 0.375]\n",
      "13195 [D loss: (0.712)(R 0.623, F 0.800)] [D acc: (0.344)(0.438, 0.250)] [G loss: 0.724] [G acc: 0.375]\n",
      "13196 [D loss: (0.667)(R 0.611, F 0.722)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.697] [G acc: 0.375]\n",
      "13197 [D loss: (0.691)(R 0.667, F 0.716)] [D acc: (0.344)(0.312, 0.375)] [G loss: 0.776] [G acc: 0.125]\n",
      "13198 [D loss: (0.665)(R 0.672, F 0.658)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.744] [G acc: 0.188]\n",
      "13199 [D loss: (0.687)(R 0.695, F 0.679)] [D acc: (0.344)(0.250, 0.438)] [G loss: 0.710] [G acc: 0.500]\n",
      "13200 [D loss: (0.686)(R 0.624, F 0.749)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.685] [G acc: 0.688]\n",
      "13201 [D loss: (0.703)(R 0.697, F 0.710)] [D acc: (0.312)(0.312, 0.312)] [G loss: 0.713] [G acc: 0.438]\n",
      "13202 [D loss: (0.701)(R 0.708, F 0.693)] [D acc: (0.281)(0.125, 0.438)] [G loss: 0.731] [G acc: 0.312]\n",
      "13203 [D loss: (0.737)(R 0.682, F 0.793)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.714] [G acc: 0.250]\n",
      "13204 [D loss: (0.665)(R 0.645, F 0.685)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.659] [G acc: 0.625]\n",
      "13205 [D loss: (0.701)(R 0.649, F 0.754)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.716] [G acc: 0.375]\n",
      "13206 [D loss: (0.700)(R 0.699, F 0.702)] [D acc: (0.406)(0.312, 0.500)] [G loss: 0.672] [G acc: 0.375]\n",
      "13207 [D loss: (0.668)(R 0.623, F 0.712)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.645] [G acc: 0.625]\n",
      "13208 [D loss: (0.652)(R 0.624, F 0.680)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.739] [G acc: 0.375]\n",
      "13209 [D loss: (0.655)(R 0.635, F 0.675)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.682] [G acc: 0.500]\n",
      "13210 [D loss: (0.704)(R 0.610, F 0.798)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.739] [G acc: 0.312]\n",
      "13211 [D loss: (0.629)(R 0.566, F 0.692)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.766] [G acc: 0.188]\n",
      "13212 [D loss: (0.647)(R 0.611, F 0.682)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.738] [G acc: 0.250]\n",
      "13213 [D loss: (0.613)(R 0.550, F 0.675)] [D acc: (0.438)(0.312, 0.562)] [G loss: 0.720] [G acc: 0.312]\n",
      "13214 [D loss: (0.666)(R 0.642, F 0.690)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.754] [G acc: 0.312]\n",
      "13215 [D loss: (0.769)(R 0.678, F 0.860)] [D acc: (0.438)(0.188, 0.688)] [G loss: 0.731] [G acc: 0.250]\n",
      "13216 [D loss: (0.666)(R 0.629, F 0.702)] [D acc: (0.406)(0.250, 0.562)] [G loss: 0.740] [G acc: 0.250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13217 [D loss: (0.665)(R 0.696, F 0.634)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.781] [G acc: 0.250]\n",
      "13218 [D loss: (0.663)(R 0.664, F 0.662)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.745] [G acc: 0.250]\n",
      "13219 [D loss: (0.634)(R 0.622, F 0.646)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.733] [G acc: 0.375]\n",
      "13220 [D loss: (0.665)(R 0.666, F 0.665)] [D acc: (0.531)(0.250, 0.812)] [G loss: 0.747] [G acc: 0.312]\n",
      "13221 [D loss: (0.707)(R 0.724, F 0.690)] [D acc: (0.438)(0.188, 0.688)] [G loss: 0.752] [G acc: 0.312]\n",
      "13222 [D loss: (0.667)(R 0.675, F 0.660)] [D acc: (0.500)(0.312, 0.688)] [G loss: 0.696] [G acc: 0.312]\n",
      "13223 [D loss: (0.750)(R 0.728, F 0.772)] [D acc: (0.438)(0.250, 0.625)] [G loss: 0.721] [G acc: 0.188]\n",
      "13224 [D loss: (0.680)(R 0.694, F 0.667)] [D acc: (0.406)(0.250, 0.562)] [G loss: 0.734] [G acc: 0.312]\n",
      "13225 [D loss: (0.716)(R 0.758, F 0.673)] [D acc: (0.375)(0.125, 0.625)] [G loss: 0.749] [G acc: 0.250]\n",
      "13226 [D loss: (0.659)(R 0.684, F 0.634)] [D acc: (0.594)(0.312, 0.875)] [G loss: 0.767] [G acc: 0.000]\n",
      "13227 [D loss: (0.636)(R 0.640, F 0.632)] [D acc: (0.656)(0.375, 0.938)] [G loss: 0.751] [G acc: 0.125]\n",
      "13228 [D loss: (0.682)(R 0.737, F 0.628)] [D acc: (0.438)(0.125, 0.750)] [G loss: 0.764] [G acc: 0.188]\n",
      "13229 [D loss: (0.615)(R 0.601, F 0.629)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.753] [G acc: 0.125]\n",
      "13230 [D loss: (0.660)(R 0.687, F 0.632)] [D acc: (0.562)(0.250, 0.875)] [G loss: 0.694] [G acc: 0.312]\n",
      "13231 [D loss: (0.665)(R 0.711, F 0.619)] [D acc: (0.594)(0.250, 0.938)] [G loss: 0.733] [G acc: 0.188]\n",
      "13232 [D loss: (0.892)(R 0.764, F 1.019)] [D acc: (0.406)(0.125, 0.688)] [G loss: 0.778] [G acc: 0.125]\n",
      "13233 [D loss: (0.665)(R 0.654, F 0.675)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.695] [G acc: 0.312]\n",
      "13234 [D loss: (0.647)(R 0.683, F 0.612)] [D acc: (0.625)(0.250, 1.000)] [G loss: 0.756] [G acc: 0.062]\n",
      "13235 [D loss: (0.891)(R 0.677, F 1.105)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.756] [G acc: 0.062]\n",
      "13236 [D loss: (0.662)(R 0.687, F 0.637)] [D acc: (0.562)(0.250, 0.875)] [G loss: 0.744] [G acc: 0.125]\n",
      "13237 [D loss: (0.724)(R 0.726, F 0.722)] [D acc: (0.406)(0.188, 0.625)] [G loss: 0.763] [G acc: 0.062]\n",
      "13238 [D loss: (0.703)(R 0.765, F 0.641)] [D acc: (0.438)(0.062, 0.812)] [G loss: 0.770] [G acc: 0.062]\n",
      "13239 [D loss: (0.662)(R 0.680, F 0.644)] [D acc: (0.531)(0.188, 0.875)] [G loss: 0.772] [G acc: 0.000]\n",
      "13240 [D loss: (0.678)(R 0.739, F 0.616)] [D acc: (0.625)(0.250, 1.000)] [G loss: 0.742] [G acc: 0.250]\n",
      "13241 [D loss: (0.634)(R 0.647, F 0.621)] [D acc: (0.562)(0.188, 0.938)] [G loss: 0.745] [G acc: 0.188]\n",
      "13242 [D loss: (0.683)(R 0.745, F 0.621)] [D acc: (0.562)(0.188, 0.938)] [G loss: 0.681] [G acc: 0.375]\n",
      "13243 [D loss: (0.549)(R 0.610, F 0.487)] [D acc: (0.594)(0.250, 0.938)] [G loss: 1.299] [G acc: 0.375]\n",
      "13244 [D loss: (0.541)(R 0.743, F 0.339)] [D acc: (0.531)(0.188, 0.875)] [G loss: 2.184] [G acc: 0.000]\n",
      "13245 [D loss: (0.713)(R 0.752, F 0.674)] [D acc: (0.531)(0.188, 0.875)] [G loss: 0.709] [G acc: 0.188]\n",
      "13246 [D loss: (0.599)(R 0.584, F 0.615)] [D acc: (0.625)(0.312, 0.938)] [G loss: 0.802] [G acc: 0.062]\n",
      "13247 [D loss: (0.667)(R 0.551, F 0.782)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.689] [G acc: 0.312]\n",
      "13248 [D loss: (0.539)(R 0.469, F 0.609)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.742] [G acc: 0.250]\n",
      "13249 [D loss: (0.821)(R 0.763, F 0.880)] [D acc: (0.500)(0.312, 0.688)] [G loss: 0.756] [G acc: 0.188]\n",
      "13250 [D loss: (0.645)(R 0.677, F 0.613)] [D acc: (0.594)(0.250, 0.938)] [G loss: 0.755] [G acc: 0.125]\n",
      "13251 [D loss: (0.743)(R 0.769, F 0.717)] [D acc: (0.469)(0.188, 0.750)] [G loss: 0.754] [G acc: 0.250]\n",
      "13252 [D loss: (0.690)(R 0.754, F 0.625)] [D acc: (0.562)(0.125, 1.000)] [G loss: 0.778] [G acc: 0.000]\n",
      "13253 [D loss: (0.679)(R 0.720, F 0.639)] [D acc: (0.500)(0.125, 0.875)] [G loss: 0.786] [G acc: 0.188]\n",
      "13254 [D loss: (0.701)(R 0.702, F 0.699)] [D acc: (0.531)(0.250, 0.812)] [G loss: 0.788] [G acc: 0.125]\n",
      "13255 [D loss: (0.663)(R 0.711, F 0.615)] [D acc: (0.469)(0.125, 0.812)] [G loss: 0.709] [G acc: 0.250]\n",
      "13256 [D loss: (0.658)(R 0.722, F 0.594)] [D acc: (0.531)(0.188, 0.875)] [G loss: 0.817] [G acc: 0.062]\n",
      "13257 [D loss: (0.878)(R 0.690, F 1.067)] [D acc: (0.531)(0.188, 0.875)] [G loss: 0.809] [G acc: 0.000]\n",
      "13258 [D loss: (0.995)(R 0.742, F 1.249)] [D acc: (0.500)(0.188, 0.812)] [G loss: 0.831] [G acc: 0.062]\n",
      "13259 [D loss: (0.695)(R 0.803, F 0.587)] [D acc: (0.562)(0.125, 1.000)] [G loss: 0.716] [G acc: 0.375]\n",
      "13260 [D loss: (0.614)(R 0.614, F 0.613)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.795] [G acc: 0.125]\n",
      "13261 [D loss: (0.705)(R 0.787, F 0.624)] [D acc: (0.531)(0.125, 0.938)] [G loss: 0.796] [G acc: 0.062]\n",
      "13262 [D loss: (0.832)(R 0.640, F 1.024)] [D acc: (0.469)(0.188, 0.750)] [G loss: 0.832] [G acc: 0.000]\n",
      "13263 [D loss: (0.704)(R 0.782, F 0.627)] [D acc: (0.406)(0.000, 0.812)] [G loss: 0.781] [G acc: 0.125]\n",
      "13264 [D loss: (0.634)(R 0.678, F 0.590)] [D acc: (0.594)(0.188, 1.000)] [G loss: 0.832] [G acc: 0.062]\n",
      "13265 [D loss: (0.637)(R 0.671, F 0.603)] [D acc: (0.594)(0.312, 0.875)] [G loss: 0.765] [G acc: 0.125]\n",
      "13266 [D loss: (0.652)(R 0.741, F 0.563)] [D acc: (0.562)(0.188, 0.938)] [G loss: 0.864] [G acc: 0.000]\n",
      "13267 [D loss: (0.698)(R 0.782, F 0.614)] [D acc: (0.594)(0.188, 1.000)] [G loss: 0.820] [G acc: 0.062]\n",
      "13268 [D loss: (0.751)(R 0.710, F 0.791)] [D acc: (0.594)(0.312, 0.875)] [G loss: 0.886] [G acc: 0.000]\n",
      "13269 [D loss: (0.682)(R 0.782, F 0.582)] [D acc: (0.500)(0.062, 0.938)] [G loss: 0.819] [G acc: 0.062]\n",
      "13270 [D loss: (0.688)(R 0.786, F 0.591)] [D acc: (0.500)(0.062, 0.938)] [G loss: 0.765] [G acc: 0.188]\n",
      "13271 [D loss: (0.674)(R 0.725, F 0.623)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.851] [G acc: 0.000]\n",
      "13272 [D loss: (0.680)(R 0.805, F 0.554)] [D acc: (0.469)(0.000, 0.938)] [G loss: 0.794] [G acc: 0.062]\n",
      "13273 [D loss: (0.596)(R 0.606, F 0.586)] [D acc: (0.656)(0.375, 0.938)] [G loss: 0.817] [G acc: 0.062]\n",
      "13274 [D loss: (0.635)(R 0.660, F 0.610)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.884] [G acc: 0.000]\n",
      "13275 [D loss: (0.669)(R 0.771, F 0.567)] [D acc: (0.562)(0.188, 0.938)] [G loss: 0.804] [G acc: 0.125]\n",
      "13276 [D loss: (0.880)(R 0.728, F 1.032)] [D acc: (0.469)(0.188, 0.750)] [G loss: 0.794] [G acc: 0.125]\n",
      "13277 [D loss: (0.722)(R 0.789, F 0.656)] [D acc: (0.438)(0.062, 0.812)] [G loss: 0.900] [G acc: 0.000]\n",
      "13278 [D loss: (0.686)(R 0.783, F 0.590)] [D acc: (0.594)(0.188, 1.000)] [G loss: 0.852] [G acc: 0.125]\n",
      "13279 [D loss: (0.589)(R 0.604, F 0.574)] [D acc: (0.656)(0.312, 1.000)] [G loss: 0.878] [G acc: 0.062]\n",
      "13280 [D loss: (0.683)(R 0.808, F 0.557)] [D acc: (0.531)(0.062, 1.000)] [G loss: 0.829] [G acc: 0.000]\n",
      "13281 [D loss: (0.769)(R 0.902, F 0.637)] [D acc: (0.562)(0.188, 0.938)] [G loss: 0.808] [G acc: 0.062]\n",
      "13282 [D loss: (0.613)(R 0.635, F 0.591)] [D acc: (0.656)(0.375, 0.938)] [G loss: 0.788] [G acc: 0.125]\n",
      "13283 [D loss: (0.607)(R 0.620, F 0.593)] [D acc: (0.500)(0.312, 0.688)] [G loss: 0.976] [G acc: 0.125]\n",
      "13284 [D loss: (0.576)(R 0.696, F 0.455)] [D acc: (0.594)(0.250, 0.938)] [G loss: 0.896] [G acc: 0.000]\n",
      "13285 [D loss: (0.666)(R 0.703, F 0.630)] [D acc: (0.406)(0.188, 0.625)] [G loss: 0.825] [G acc: 0.125]\n",
      "13286 [D loss: (0.683)(R 0.767, F 0.599)] [D acc: (0.469)(0.188, 0.750)] [G loss: 0.878] [G acc: 0.125]\n",
      "13287 [D loss: (0.678)(R 0.737, F 0.619)] [D acc: (0.531)(0.188, 0.875)] [G loss: 0.822] [G acc: 0.062]\n",
      "13288 [D loss: (0.625)(R 0.623, F 0.627)] [D acc: (0.562)(0.312, 0.812)] [G loss: 1.196] [G acc: 0.000]\n",
      "13289 [D loss: (0.641)(R 0.719, F 0.563)] [D acc: (0.500)(0.062, 0.938)] [G loss: 0.849] [G acc: 0.062]\n",
      "13290 [D loss: (0.679)(R 0.767, F 0.591)] [D acc: (0.562)(0.250, 0.875)] [G loss: 0.799] [G acc: 0.062]\n",
      "13291 [D loss: (0.646)(R 0.684, F 0.607)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.825] [G acc: 0.000]\n",
      "13292 [D loss: (0.657)(R 0.680, F 0.634)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.856] [G acc: 0.125]\n",
      "13293 [D loss: (0.635)(R 0.698, F 0.572)] [D acc: (0.594)(0.250, 0.938)] [G loss: 0.844] [G acc: 0.188]\n",
      "13294 [D loss: (0.702)(R 0.794, F 0.610)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.786] [G acc: 0.125]\n",
      "13295 [D loss: (0.677)(R 0.705, F 0.649)] [D acc: (0.562)(0.250, 0.875)] [G loss: 0.766] [G acc: 0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13296 [D loss: (0.648)(R 0.713, F 0.583)] [D acc: (0.531)(0.188, 0.875)] [G loss: 0.828] [G acc: 0.062]\n",
      "13297 [D loss: (0.676)(R 0.689, F 0.663)] [D acc: (0.531)(0.250, 0.812)] [G loss: 0.863] [G acc: 0.000]\n",
      "13298 [D loss: (0.814)(R 0.655, F 0.973)] [D acc: (0.562)(0.312, 0.812)] [G loss: 0.935] [G acc: 0.000]\n",
      "13299 [D loss: (0.694)(R 0.715, F 0.673)] [D acc: (0.469)(0.188, 0.750)] [G loss: 0.829] [G acc: 0.062]\n",
      "13300 [D loss: (0.629)(R 0.645, F 0.612)] [D acc: (0.656)(0.375, 0.938)] [G loss: 0.835] [G acc: 0.062]\n",
      "13301 [D loss: (0.686)(R 0.751, F 0.620)] [D acc: (0.500)(0.188, 0.812)] [G loss: 0.799] [G acc: 0.000]\n",
      "13302 [D loss: (0.633)(R 0.669, F 0.597)] [D acc: (0.688)(0.438, 0.938)] [G loss: 0.884] [G acc: 0.000]\n",
      "13303 [D loss: (0.629)(R 0.682, F 0.577)] [D acc: (0.531)(0.125, 0.938)] [G loss: 0.842] [G acc: 0.062]\n",
      "13304 [D loss: (0.685)(R 0.754, F 0.616)] [D acc: (0.531)(0.125, 0.938)] [G loss: 0.748] [G acc: 0.188]\n",
      "13305 [D loss: (0.723)(R 0.687, F 0.758)] [D acc: (0.406)(0.250, 0.562)] [G loss: 1.031] [G acc: 0.062]\n",
      "13306 [D loss: (0.672)(R 0.725, F 0.619)] [D acc: (0.562)(0.188, 0.938)] [G loss: 1.119] [G acc: 0.000]\n",
      "13307 [D loss: (0.672)(R 0.759, F 0.585)] [D acc: (0.594)(0.188, 1.000)] [G loss: 0.813] [G acc: 0.062]\n",
      "13308 [D loss: (0.644)(R 0.688, F 0.600)] [D acc: (0.656)(0.375, 0.938)] [G loss: 0.840] [G acc: 0.000]\n",
      "13309 [D loss: (0.550)(R 0.523, F 0.578)] [D acc: (0.844)(0.688, 1.000)] [G loss: 0.863] [G acc: 0.000]\n",
      "13310 [D loss: (0.688)(R 0.764, F 0.613)] [D acc: (0.531)(0.188, 0.875)] [G loss: 0.896] [G acc: 0.062]\n",
      "13311 [D loss: (0.661)(R 0.711, F 0.610)] [D acc: (0.500)(0.188, 0.812)] [G loss: 0.800] [G acc: 0.062]\n",
      "13312 [D loss: (0.655)(R 0.701, F 0.609)] [D acc: (0.562)(0.188, 0.938)] [G loss: 0.812] [G acc: 0.188]\n",
      "13313 [D loss: (0.702)(R 0.788, F 0.616)] [D acc: (0.594)(0.250, 0.938)] [G loss: 0.823] [G acc: 0.000]\n",
      "13314 [D loss: (0.702)(R 0.692, F 0.713)] [D acc: (0.562)(0.375, 0.750)] [G loss: 4.594] [G acc: 0.000]\n",
      "13315 [D loss: (0.456)(R 0.570, F 0.342)] [D acc: (0.750)(0.625, 0.875)] [G loss: 2.939] [G acc: 0.062]\n",
      "13316 [D loss: (0.690)(R 0.759, F 0.622)] [D acc: (0.469)(0.188, 0.750)] [G loss: 0.841] [G acc: 0.062]\n",
      "13317 [D loss: (0.683)(R 0.715, F 0.650)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.838] [G acc: 0.062]\n",
      "13318 [D loss: (0.673)(R 0.740, F 0.606)] [D acc: (0.500)(0.188, 0.812)] [G loss: 0.812] [G acc: 0.250]\n",
      "13319 [D loss: (0.553)(R 0.578, F 0.528)] [D acc: (0.688)(0.438, 0.938)] [G loss: 0.827] [G acc: 0.000]\n",
      "13320 [D loss: (0.650)(R 0.701, F 0.598)] [D acc: (0.594)(0.312, 0.875)] [G loss: 0.831] [G acc: 0.062]\n",
      "13321 [D loss: (0.588)(R 0.587, F 0.589)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.810] [G acc: 0.125]\n",
      "13322 [D loss: (0.646)(R 0.740, F 0.553)] [D acc: (0.625)(0.250, 1.000)] [G loss: 0.849] [G acc: 0.125]\n",
      "13323 [D loss: (0.649)(R 0.694, F 0.604)] [D acc: (0.594)(0.312, 0.875)] [G loss: 0.824] [G acc: 0.125]\n",
      "13324 [D loss: (0.628)(R 0.707, F 0.549)] [D acc: (0.656)(0.375, 0.938)] [G loss: 0.887] [G acc: 0.000]\n",
      "13325 [D loss: (0.658)(R 0.740, F 0.575)] [D acc: (0.594)(0.250, 0.938)] [G loss: 0.849] [G acc: 0.062]\n",
      "13326 [D loss: (0.647)(R 0.716, F 0.578)] [D acc: (0.656)(0.375, 0.938)] [G loss: 0.878] [G acc: 0.062]\n",
      "13327 [D loss: (0.631)(R 0.602, F 0.660)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.866] [G acc: 0.125]\n",
      "13328 [D loss: (0.647)(R 0.720, F 0.575)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.828] [G acc: 0.125]\n",
      "13329 [D loss: (0.671)(R 0.770, F 0.572)] [D acc: (0.625)(0.312, 0.938)] [G loss: 0.944] [G acc: 0.125]\n",
      "13330 [D loss: (0.666)(R 0.720, F 0.611)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.802] [G acc: 0.250]\n",
      "13331 [D loss: (0.602)(R 0.643, F 0.561)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.887] [G acc: 0.125]\n",
      "13332 [D loss: (0.645)(R 0.677, F 0.613)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.800] [G acc: 0.125]\n",
      "13333 [D loss: (0.547)(R 0.552, F 0.542)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.922] [G acc: 0.125]\n",
      "13334 [D loss: (0.642)(R 0.681, F 0.602)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.818] [G acc: 0.062]\n",
      "13335 [D loss: (0.626)(R 0.697, F 0.556)] [D acc: (0.688)(0.438, 0.938)] [G loss: 0.796] [G acc: 0.125]\n",
      "13336 [D loss: (0.651)(R 0.700, F 0.602)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.940] [G acc: 0.125]\n",
      "13337 [D loss: (0.593)(R 0.581, F 0.604)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.852] [G acc: 0.062]\n",
      "13338 [D loss: (0.671)(R 0.735, F 0.608)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.761] [G acc: 0.250]\n",
      "13339 [D loss: (0.650)(R 0.656, F 0.645)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.838] [G acc: 0.250]\n",
      "13340 [D loss: (0.588)(R 0.608, F 0.568)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.959] [G acc: 0.062]\n",
      "13341 [D loss: (0.645)(R 0.698, F 0.593)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.855] [G acc: 0.062]\n",
      "13342 [D loss: (0.609)(R 0.626, F 0.592)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.902] [G acc: 0.000]\n",
      "13343 [D loss: (0.553)(R 0.558, F 0.549)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.826] [G acc: 0.188]\n",
      "13344 [D loss: (0.645)(R 0.760, F 0.530)] [D acc: (0.688)(0.500, 0.875)] [G loss: 1.071] [G acc: 0.062]\n",
      "13345 [D loss: (0.545)(R 0.577, F 0.512)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.040] [G acc: 0.062]\n",
      "13346 [D loss: (0.794)(R 0.943, F 0.646)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.818] [G acc: 0.188]\n",
      "13347 [D loss: (0.619)(R 0.589, F 0.648)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.954] [G acc: 0.062]\n",
      "13348 [D loss: (0.570)(R 0.582, F 0.558)] [D acc: (0.875)(0.812, 0.938)] [G loss: 0.894] [G acc: 0.188]\n",
      "13349 [D loss: (0.610)(R 0.666, F 0.553)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.833] [G acc: 0.438]\n",
      "13350 [D loss: (0.659)(R 0.666, F 0.652)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.893] [G acc: 0.062]\n",
      "13351 [D loss: (0.676)(R 0.710, F 0.643)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.945] [G acc: 0.062]\n",
      "13352 [D loss: (0.692)(R 0.723, F 0.660)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.873] [G acc: 0.125]\n",
      "13353 [D loss: (0.589)(R 0.590, F 0.587)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.890] [G acc: 0.062]\n",
      "13354 [D loss: (0.569)(R 0.612, F 0.526)] [D acc: (0.656)(0.375, 0.938)] [G loss: 1.060] [G acc: 0.188]\n",
      "13355 [D loss: (0.674)(R 0.717, F 0.632)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.980] [G acc: 0.125]\n",
      "13356 [D loss: (0.632)(R 0.650, F 0.613)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.776] [G acc: 0.438]\n",
      "13357 [D loss: (0.710)(R 0.651, F 0.769)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.881] [G acc: 0.188]\n",
      "13358 [D loss: (0.629)(R 0.600, F 0.657)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.797] [G acc: 0.312]\n",
      "13359 [D loss: (0.677)(R 0.761, F 0.592)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.779] [G acc: 0.250]\n",
      "13360 [D loss: (0.677)(R 0.670, F 0.684)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.846] [G acc: 0.188]\n",
      "13361 [D loss: (0.712)(R 0.820, F 0.604)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.915] [G acc: 0.188]\n",
      "13362 [D loss: (0.706)(R 0.737, F 0.675)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.796] [G acc: 0.312]\n",
      "13363 [D loss: (0.684)(R 0.730, F 0.637)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.807] [G acc: 0.312]\n",
      "13364 [D loss: (0.631)(R 0.595, F 0.667)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.753] [G acc: 0.312]\n",
      "13365 [D loss: (0.635)(R 0.648, F 0.622)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.745] [G acc: 0.312]\n",
      "13366 [D loss: (0.643)(R 0.629, F 0.657)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.800] [G acc: 0.312]\n",
      "13367 [D loss: (0.623)(R 0.583, F 0.663)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.836] [G acc: 0.312]\n",
      "13368 [D loss: (0.611)(R 0.514, F 0.709)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.769] [G acc: 0.312]\n",
      "13369 [D loss: (0.753)(R 0.678, F 0.828)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.748] [G acc: 0.188]\n",
      "13370 [D loss: (0.673)(R 0.629, F 0.718)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.695] [G acc: 0.438]\n",
      "13371 [D loss: (0.690)(R 0.676, F 0.705)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.788] [G acc: 0.438]\n",
      "13372 [D loss: (0.604)(R 0.562, F 0.647)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.729] [G acc: 0.500]\n",
      "13373 [D loss: (0.654)(R 0.588, F 0.720)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.665] [G acc: 0.688]\n",
      "13374 [D loss: (0.724)(R 0.715, F 0.732)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.715] [G acc: 0.500]\n",
      "13375 [D loss: (0.605)(R 0.540, F 0.669)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.728] [G acc: 0.500]\n",
      "13376 [D loss: (0.753)(R 0.784, F 0.723)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.749] [G acc: 0.375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13377 [D loss: (0.757)(R 0.742, F 0.771)] [D acc: (0.344)(0.438, 0.250)] [G loss: 0.731] [G acc: 0.500]\n",
      "13378 [D loss: (0.683)(R 0.643, F 0.723)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.686] [G acc: 0.438]\n",
      "13379 [D loss: (0.701)(R 0.682, F 0.720)] [D acc: (0.375)(0.312, 0.438)] [G loss: 0.768] [G acc: 0.375]\n",
      "13380 [D loss: (0.411)(R 0.498, F 0.323)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.262] [G acc: 0.312]\n",
      "13381 [D loss: (0.627)(R 0.658, F 0.596)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.764] [G acc: 0.500]\n",
      "13382 [D loss: (0.658)(R 0.611, F 0.706)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.788] [G acc: 0.375]\n",
      "13383 [D loss: (0.733)(R 0.723, F 0.743)] [D acc: (0.375)(0.500, 0.250)] [G loss: 0.782] [G acc: 0.250]\n",
      "13384 [D loss: (0.665)(R 0.611, F 0.719)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.791] [G acc: 0.250]\n",
      "13385 [D loss: (0.705)(R 0.732, F 0.678)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.804] [G acc: 0.188]\n",
      "13386 [D loss: (0.632)(R 0.565, F 0.699)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.752] [G acc: 0.438]\n",
      "13387 [D loss: (0.600)(R 0.564, F 0.637)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.747] [G acc: 0.500]\n",
      "13388 [D loss: (0.641)(R 0.606, F 0.676)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.710] [G acc: 0.438]\n",
      "13389 [D loss: (0.666)(R 0.621, F 0.711)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.802] [G acc: 0.250]\n",
      "13390 [D loss: (0.623)(R 0.563, F 0.684)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.820] [G acc: 0.188]\n",
      "13391 [D loss: (0.564)(R 0.453, F 0.676)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.744] [G acc: 0.312]\n",
      "13392 [D loss: (0.702)(R 0.602, F 0.801)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.828] [G acc: 0.125]\n",
      "13393 [D loss: (0.720)(R 0.805, F 0.635)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.823] [G acc: 0.312]\n",
      "13394 [D loss: (0.645)(R 0.670, F 0.620)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.826] [G acc: 0.062]\n",
      "13395 [D loss: (0.697)(R 0.723, F 0.670)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.843] [G acc: 0.062]\n",
      "13396 [D loss: (0.609)(R 0.589, F 0.629)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.778] [G acc: 0.312]\n",
      "13397 [D loss: (0.687)(R 0.713, F 0.660)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.798] [G acc: 0.250]\n",
      "13398 [D loss: (0.669)(R 0.718, F 0.621)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.746] [G acc: 0.375]\n",
      "13399 [D loss: (0.702)(R 0.679, F 0.724)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.883] [G acc: 0.062]\n",
      "13400 [D loss: (0.651)(R 0.642, F 0.660)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.814] [G acc: 0.188]\n",
      "13401 [D loss: (0.693)(R 0.796, F 0.590)] [D acc: (0.656)(0.375, 0.938)] [G loss: 0.838] [G acc: 0.125]\n",
      "13402 [D loss: (0.635)(R 0.645, F 0.625)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.834] [G acc: 0.000]\n",
      "13403 [D loss: (0.715)(R 0.775, F 0.655)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.843] [G acc: 0.000]\n",
      "13404 [D loss: (0.623)(R 0.626, F 0.619)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.881] [G acc: 0.000]\n",
      "13405 [D loss: (0.568)(R 0.539, F 0.598)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.895] [G acc: 0.062]\n",
      "13406 [D loss: (0.565)(R 0.564, F 0.566)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.834] [G acc: 0.188]\n",
      "13407 [D loss: (0.623)(R 0.647, F 0.599)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.897] [G acc: 0.062]\n",
      "13408 [D loss: (0.661)(R 0.685, F 0.637)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.863] [G acc: 0.062]\n",
      "13409 [D loss: (0.610)(R 0.649, F 0.570)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.886] [G acc: 0.188]\n",
      "13410 [D loss: (0.536)(R 0.529, F 0.542)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.391] [G acc: 0.000]\n",
      "13411 [D loss: (0.579)(R 0.618, F 0.539)] [D acc: (0.781)(0.562, 1.000)] [G loss: 1.816] [G acc: 0.000]\n",
      "13412 [D loss: (0.594)(R 0.616, F 0.571)] [D acc: (0.719)(0.500, 0.938)] [G loss: 1.008] [G acc: 0.000]\n",
      "13413 [D loss: (0.614)(R 0.662, F 0.567)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.978] [G acc: 0.188]\n",
      "13414 [D loss: (0.619)(R 0.714, F 0.524)] [D acc: (0.688)(0.375, 1.000)] [G loss: 0.968] [G acc: 0.062]\n",
      "13415 [D loss: (0.626)(R 0.654, F 0.599)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.977] [G acc: 0.125]\n",
      "13416 [D loss: (0.554)(R 0.563, F 0.546)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.917] [G acc: 0.000]\n",
      "13417 [D loss: (0.620)(R 0.726, F 0.514)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.927] [G acc: 0.000]\n",
      "13418 [D loss: (0.567)(R 0.607, F 0.528)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.948] [G acc: 0.188]\n",
      "13419 [D loss: (0.577)(R 0.615, F 0.539)] [D acc: (0.719)(0.500, 0.938)] [G loss: 0.992] [G acc: 0.000]\n",
      "13420 [D loss: (0.564)(R 0.618, F 0.511)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.961] [G acc: 0.125]\n",
      "13421 [D loss: (0.574)(R 0.591, F 0.558)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.124] [G acc: 0.000]\n",
      "13422 [D loss: (0.515)(R 0.499, F 0.530)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.988] [G acc: 0.000]\n",
      "13423 [D loss: (0.662)(R 0.708, F 0.617)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.018] [G acc: 0.062]\n",
      "13424 [D loss: (0.593)(R 0.576, F 0.610)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.038] [G acc: 0.000]\n",
      "13425 [D loss: (0.624)(R 0.763, F 0.484)] [D acc: (0.688)(0.375, 1.000)] [G loss: 1.022] [G acc: 0.062]\n",
      "13426 [D loss: (0.532)(R 0.563, F 0.501)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.946] [G acc: 0.125]\n",
      "13427 [D loss: (0.676)(R 0.779, F 0.572)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.038] [G acc: 0.000]\n",
      "13428 [D loss: (0.614)(R 0.630, F 0.597)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.975] [G acc: 0.250]\n",
      "13429 [D loss: (0.580)(R 0.555, F 0.606)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.926] [G acc: 0.125]\n",
      "13430 [D loss: (0.651)(R 0.572, F 0.730)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.999] [G acc: 0.062]\n",
      "13431 [D loss: (0.532)(R 0.554, F 0.509)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.856] [G acc: 0.375]\n",
      "13432 [D loss: (0.594)(R 0.594, F 0.595)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.038] [G acc: 0.062]\n",
      "13433 [D loss: (0.613)(R 0.693, F 0.532)] [D acc: (0.688)(0.500, 0.875)] [G loss: 1.036] [G acc: 0.125]\n",
      "13434 [D loss: (0.536)(R 0.511, F 0.561)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.857] [G acc: 0.250]\n",
      "13435 [D loss: (0.576)(R 0.620, F 0.532)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.893] [G acc: 0.188]\n",
      "13436 [D loss: (0.562)(R 0.557, F 0.568)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.902] [G acc: 0.188]\n",
      "13437 [D loss: (0.453)(R 0.342, F 0.565)] [D acc: (0.844)(0.938, 0.750)] [G loss: 0.920] [G acc: 0.125]\n",
      "13438 [D loss: (0.598)(R 0.671, F 0.526)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.997] [G acc: 0.125]\n",
      "13439 [D loss: (0.463)(R 0.502, F 0.424)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.053] [G acc: 0.188]\n",
      "13440 [D loss: (0.555)(R 0.508, F 0.603)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.069] [G acc: 0.062]\n",
      "13441 [D loss: (0.490)(R 0.546, F 0.434)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.132] [G acc: 0.000]\n",
      "13442 [D loss: (0.469)(R 0.518, F 0.420)] [D acc: (0.906)(0.875, 0.938)] [G loss: 1.162] [G acc: 0.000]\n",
      "13443 [D loss: (0.553)(R 0.584, F 0.521)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.109] [G acc: 0.000]\n",
      "13444 [D loss: (0.561)(R 0.594, F 0.528)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.989] [G acc: 0.188]\n",
      "13445 [D loss: (0.544)(R 0.458, F 0.631)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.002] [G acc: 0.188]\n",
      "13446 [D loss: (0.483)(R 0.504, F 0.463)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.116] [G acc: 0.125]\n",
      "13447 [D loss: (0.557)(R 0.605, F 0.508)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.070] [G acc: 0.125]\n",
      "13448 [D loss: (0.494)(R 0.574, F 0.413)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.096] [G acc: 0.062]\n",
      "13449 [D loss: (0.614)(R 0.686, F 0.542)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.037] [G acc: 0.188]\n",
      "13450 [D loss: (0.519)(R 0.545, F 0.493)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.080] [G acc: 0.062]\n",
      "13451 [D loss: (0.529)(R 0.627, F 0.431)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.121] [G acc: 0.000]\n",
      "13452 [D loss: (0.511)(R 0.510, F 0.512)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.006] [G acc: 0.312]\n",
      "13453 [D loss: (0.501)(R 0.518, F 0.484)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.014] [G acc: 0.188]\n",
      "13454 [D loss: (0.596)(R 0.631, F 0.561)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.047] [G acc: 0.062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13455 [D loss: (0.615)(R 0.658, F 0.572)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.086] [G acc: 0.062]\n",
      "13456 [D loss: (0.541)(R 0.543, F 0.540)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.991] [G acc: 0.188]\n",
      "13457 [D loss: (0.581)(R 0.702, F 0.460)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.270] [G acc: 0.188]\n",
      "13458 [D loss: (0.530)(R 0.594, F 0.466)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.131] [G acc: 0.125]\n",
      "13459 [D loss: (0.474)(R 0.488, F 0.460)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.197] [G acc: 0.062]\n",
      "13460 [D loss: (0.609)(R 0.722, F 0.497)] [D acc: (0.719)(0.500, 0.938)] [G loss: 1.051] [G acc: 0.125]\n",
      "13461 [D loss: (0.765)(R 0.575, F 0.955)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.029] [G acc: 0.188]\n",
      "13462 [D loss: (0.560)(R 0.551, F 0.568)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.930] [G acc: 0.375]\n",
      "13463 [D loss: (0.643)(R 0.740, F 0.547)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.831] [G acc: 0.438]\n",
      "13464 [D loss: (0.519)(R 0.532, F 0.506)] [D acc: (0.875)(0.750, 1.000)] [G loss: 1.095] [G acc: 0.125]\n",
      "13465 [D loss: (0.577)(R 0.642, F 0.512)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.110] [G acc: 0.125]\n",
      "13466 [D loss: (0.726)(R 0.698, F 0.754)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.765] [G acc: 0.375]\n",
      "13467 [D loss: (0.735)(R 0.614, F 0.855)] [D acc: (0.438)(0.688, 0.188)] [G loss: 0.908] [G acc: 0.312]\n",
      "13468 [D loss: (0.628)(R 0.623, F 0.634)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.781] [G acc: 0.375]\n",
      "13469 [D loss: (0.833)(R 0.754, F 0.912)] [D acc: (0.375)(0.500, 0.250)] [G loss: 0.817] [G acc: 0.312]\n",
      "13470 [D loss: (0.665)(R 0.696, F 0.633)] [D acc: (0.594)(0.500, 0.688)] [G loss: 1.121] [G acc: 0.375]\n",
      "13471 [D loss: (0.791)(R 0.622, F 0.960)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.772] [G acc: 0.438]\n",
      "13472 [D loss: (0.689)(R 0.634, F 0.744)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.815] [G acc: 0.375]\n",
      "13473 [D loss: (0.623)(R 0.653, F 0.594)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.916] [G acc: 0.250]\n",
      "13474 [D loss: (0.800)(R 0.680, F 0.920)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.654] [G acc: 0.625]\n",
      "13475 [D loss: (0.762)(R 0.691, F 0.834)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.769] [G acc: 0.500]\n",
      "13476 [D loss: (0.708)(R 0.619, F 0.797)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.818] [G acc: 0.312]\n",
      "13477 [D loss: (0.682)(R 0.637, F 0.727)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.705] [G acc: 0.688]\n",
      "13478 [D loss: (0.686)(R 0.558, F 0.814)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.619] [G acc: 0.688]\n",
      "13479 [D loss: (0.702)(R 0.694, F 0.710)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.853] [G acc: 0.250]\n",
      "13480 [D loss: (0.694)(R 0.594, F 0.794)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.786] [G acc: 0.438]\n",
      "13481 [D loss: (0.621)(R 0.571, F 0.670)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.750] [G acc: 0.500]\n",
      "13482 [D loss: (0.768)(R 0.686, F 0.851)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.719] [G acc: 0.438]\n",
      "13483 [D loss: (0.912)(R 0.655, F 1.168)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.779] [G acc: 0.375]\n",
      "13484 [D loss: (0.678)(R 0.530, F 0.827)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.744] [G acc: 0.375]\n",
      "13485 [D loss: (0.808)(R 0.629, F 0.987)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.559] [G acc: 0.312]\n",
      "13486 [D loss: (0.470)(R 0.699, F 0.241)] [D acc: (0.781)(0.625, 0.938)] [G loss: 2.619] [G acc: 0.188]\n",
      "13487 [D loss: (0.544)(R 0.557, F 0.532)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.857] [G acc: 0.188]\n",
      "13488 [D loss: (0.960)(R 0.712, F 1.209)] [D acc: (0.406)(0.500, 0.312)] [G loss: 1.134] [G acc: 0.250]\n",
      "13489 [D loss: (0.656)(R 0.762, F 0.550)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.893] [G acc: 0.312]\n",
      "13490 [D loss: (0.819)(R 0.709, F 0.930)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.666] [G acc: 0.500]\n",
      "13491 [D loss: (1.132)(R 0.726, F 1.537)] [D acc: (0.406)(0.625, 0.188)] [G loss: 0.901] [G acc: 0.438]\n",
      "13492 [D loss: (0.917)(R 0.974, F 0.859)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.692] [G acc: 0.312]\n",
      "13493 [D loss: (0.738)(R 0.811, F 0.664)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.828] [G acc: 0.250]\n",
      "13494 [D loss: (0.747)(R 0.778, F 0.715)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.801] [G acc: 0.312]\n",
      "13495 [D loss: (0.603)(R 0.565, F 0.641)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.724] [G acc: 0.438]\n",
      "13496 [D loss: (0.693)(R 0.807, F 0.578)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.678] [G acc: 0.375]\n",
      "13497 [D loss: (0.915)(R 0.665, F 1.165)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.645] [G acc: 0.500]\n",
      "13498 [D loss: (0.688)(R 0.709, F 0.667)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.750] [G acc: 0.312]\n",
      "13499 [D loss: (1.027)(R 0.787, F 1.268)] [D acc: (0.406)(0.375, 0.438)] [G loss: 0.932] [G acc: 0.125]\n",
      "13500 [D loss: (1.102)(R 0.599, F 1.605)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.754] [G acc: 0.438]\n",
      "13501 [D loss: (0.828)(R 0.754, F 0.902)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.798] [G acc: 0.188]\n",
      "13502 [D loss: (0.636)(R 0.636, F 0.636)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.639] [G acc: 0.438]\n",
      "13503 [D loss: (0.692)(R 0.638, F 0.746)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.560] [G acc: 0.500]\n",
      "13504 [D loss: (1.106)(R 0.810, F 1.403)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.799] [G acc: 0.250]\n",
      "13505 [D loss: (0.775)(R 0.800, F 0.750)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.782] [G acc: 0.312]\n",
      "13506 [D loss: (0.681)(R 0.678, F 0.685)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.948] [G acc: 0.188]\n",
      "13507 [D loss: (0.767)(R 0.789, F 0.745)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.864] [G acc: 0.125]\n",
      "13508 [D loss: (0.664)(R 0.769, F 0.558)] [D acc: (0.656)(0.375, 0.938)] [G loss: 0.808] [G acc: 0.312]\n",
      "13509 [D loss: (0.563)(R 0.550, F 0.576)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.770] [G acc: 0.312]\n",
      "13510 [D loss: (0.682)(R 0.772, F 0.591)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.911] [G acc: 0.125]\n",
      "13511 [D loss: (0.635)(R 0.664, F 0.606)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.817] [G acc: 0.250]\n",
      "13512 [D loss: (0.613)(R 0.618, F 0.608)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.893] [G acc: 0.188]\n",
      "13513 [D loss: (0.755)(R 0.893, F 0.616)] [D acc: (0.531)(0.250, 0.812)] [G loss: 0.697] [G acc: 0.312]\n",
      "13514 [D loss: (0.542)(R 0.468, F 0.617)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.867] [G acc: 0.062]\n",
      "13515 [D loss: (0.614)(R 0.650, F 0.577)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.900] [G acc: 0.062]\n",
      "13516 [D loss: (0.690)(R 0.674, F 0.706)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.804] [G acc: 0.312]\n",
      "13517 [D loss: (0.723)(R 0.742, F 0.704)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.864] [G acc: 0.250]\n",
      "13518 [D loss: (0.738)(R 0.713, F 0.762)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.800] [G acc: 0.250]\n",
      "13519 [D loss: (0.706)(R 0.729, F 0.683)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.820] [G acc: 0.250]\n",
      "13520 [D loss: (0.732)(R 0.598, F 0.867)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.759] [G acc: 0.375]\n",
      "13521 [D loss: (0.892)(R 0.644, F 1.141)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.834] [G acc: 0.250]\n",
      "13522 [D loss: (0.660)(R 0.643, F 0.678)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.470] [G acc: 0.562]\n",
      "13523 [D loss: (0.877)(R 0.717, F 1.038)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.768] [G acc: 0.250]\n",
      "13524 [D loss: (0.914)(R 0.724, F 1.105)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.523] [G acc: 0.625]\n",
      "13525 [D loss: (1.146)(R 0.764, F 1.528)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.484] [G acc: 0.688]\n",
      "13526 [D loss: (0.865)(R 0.573, F 1.156)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.800] [G acc: 0.312]\n",
      "13527 [D loss: (0.818)(R 0.672, F 0.965)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.732] [G acc: 0.438]\n",
      "13528 [D loss: (0.642)(R 0.600, F 0.684)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.704] [G acc: 0.562]\n",
      "13529 [D loss: (0.842)(R 0.738, F 0.945)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.862] [G acc: 0.250]\n",
      "13530 [D loss: (0.568)(R 0.566, F 0.571)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.739] [G acc: 0.438]\n",
      "13531 [D loss: (0.756)(R 0.730, F 0.782)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.866] [G acc: 0.188]\n",
      "13532 [D loss: (0.677)(R 0.686, F 0.667)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.695] [G acc: 0.562]\n",
      "13533 [D loss: (0.691)(R 0.639, F 0.742)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.646] [G acc: 0.500]\n",
      "13534 [D loss: (0.874)(R 0.790, F 0.959)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.707] [G acc: 0.375]\n",
      "13535 [D loss: (0.741)(R 0.774, F 0.708)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.799] [G acc: 0.250]\n",
      "13536 [D loss: (0.724)(R 0.749, F 0.700)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.765] [G acc: 0.375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13537 [D loss: (0.645)(R 0.726, F 0.564)] [D acc: (0.562)(0.312, 0.812)] [G loss: 0.659] [G acc: 0.500]\n",
      "13538 [D loss: (0.897)(R 0.774, F 1.020)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.652] [G acc: 0.562]\n",
      "13539 [D loss: (0.902)(R 0.743, F 1.060)] [D acc: (0.406)(0.375, 0.438)] [G loss: 0.449] [G acc: 0.750]\n",
      "13540 [D loss: (1.351)(R 0.701, F 2.001)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.622] [G acc: 0.562]\n",
      "13541 [D loss: (1.276)(R 0.560, F 1.993)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.771] [G acc: 0.438]\n",
      "13542 [D loss: (1.032)(R 0.729, F 1.335)] [D acc: (0.406)(0.375, 0.438)] [G loss: 0.837] [G acc: 0.250]\n",
      "13543 [D loss: (0.767)(R 0.752, F 0.782)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.818] [G acc: 0.375]\n",
      "13544 [D loss: (0.577)(R 0.676, F 0.477)] [D acc: (0.531)(0.375, 0.688)] [G loss: 4.774] [G acc: 0.000]\n",
      "13545 [D loss: (0.561)(R 0.698, F 0.425)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.279] [G acc: 0.375]\n",
      "13546 [D loss: (1.004)(R 0.899, F 1.109)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.756] [G acc: 0.312]\n",
      "13547 [D loss: (0.724)(R 0.717, F 0.732)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.867] [G acc: 0.188]\n",
      "13548 [D loss: (0.744)(R 0.800, F 0.687)] [D acc: (0.438)(0.188, 0.688)] [G loss: 0.644] [G acc: 0.688]\n",
      "13549 [D loss: (0.703)(R 0.781, F 0.626)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.811] [G acc: 0.188]\n",
      "13550 [D loss: (0.662)(R 0.644, F 0.680)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.812] [G acc: 0.562]\n",
      "13551 [D loss: (0.691)(R 0.663, F 0.719)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.463] [G acc: 0.562]\n",
      "13552 [D loss: (0.735)(R 0.584, F 0.886)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.737] [G acc: 0.312]\n",
      "13553 [D loss: (0.634)(R 0.621, F 0.648)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.856] [G acc: 0.188]\n",
      "13554 [D loss: (0.640)(R 0.619, F 0.661)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.791] [G acc: 0.312]\n",
      "13555 [D loss: (0.695)(R 0.741, F 0.648)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.835] [G acc: 0.250]\n",
      "13556 [D loss: (0.641)(R 0.599, F 0.682)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.742] [G acc: 0.500]\n",
      "13557 [D loss: (0.675)(R 0.671, F 0.678)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.847] [G acc: 0.375]\n",
      "13558 [D loss: (0.760)(R 0.850, F 0.669)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.825] [G acc: 0.312]\n",
      "13559 [D loss: (0.675)(R 0.540, F 0.810)] [D acc: (0.781)(0.938, 0.625)] [G loss: 0.923] [G acc: 0.375]\n",
      "13560 [D loss: (0.653)(R 0.696, F 0.609)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.955] [G acc: 0.375]\n",
      "13561 [D loss: (0.634)(R 0.609, F 0.660)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.750] [G acc: 0.438]\n",
      "13562 [D loss: (0.624)(R 0.581, F 0.667)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.775] [G acc: 0.312]\n",
      "13563 [D loss: (0.662)(R 0.630, F 0.694)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.796] [G acc: 0.375]\n",
      "13564 [D loss: (0.674)(R 0.651, F 0.698)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.868] [G acc: 0.250]\n",
      "13565 [D loss: (0.628)(R 0.534, F 0.721)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.815] [G acc: 0.500]\n",
      "13566 [D loss: (0.688)(R 0.770, F 0.606)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.376] [G acc: 0.875]\n",
      "13567 [D loss: (0.662)(R 0.617, F 0.708)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.733] [G acc: 0.438]\n",
      "13568 [D loss: (0.655)(R 0.584, F 0.726)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.787] [G acc: 0.375]\n",
      "13569 [D loss: (0.641)(R 0.602, F 0.679)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.786] [G acc: 0.438]\n",
      "13570 [D loss: (0.677)(R 0.589, F 0.764)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.746] [G acc: 0.438]\n",
      "13571 [D loss: (0.559)(R 0.504, F 0.615)] [D acc: (0.812)(0.938, 0.688)] [G loss: 0.783] [G acc: 0.438]\n",
      "13572 [D loss: (0.654)(R 0.563, F 0.746)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.882] [G acc: 0.375]\n",
      "13573 [D loss: (0.535)(R 0.521, F 0.548)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.788] [G acc: 0.500]\n",
      "13574 [D loss: (0.523)(R 0.521, F 0.525)] [D acc: (0.875)(0.938, 0.812)] [G loss: 0.908] [G acc: 0.312]\n",
      "13575 [D loss: (0.609)(R 0.545, F 0.674)] [D acc: (0.688)(0.812, 0.562)] [G loss: 1.005] [G acc: 0.375]\n",
      "13576 [D loss: (0.570)(R 0.573, F 0.567)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.898] [G acc: 0.125]\n",
      "13577 [D loss: (0.628)(R 0.602, F 0.654)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.838] [G acc: 0.312]\n",
      "13578 [D loss: (0.607)(R 0.554, F 0.660)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.908] [G acc: 0.188]\n",
      "13579 [D loss: (0.560)(R 0.561, F 0.559)] [D acc: (0.844)(0.938, 0.750)] [G loss: 1.095] [G acc: 0.312]\n",
      "13580 [D loss: (0.532)(R 0.576, F 0.488)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.942] [G acc: 0.312]\n",
      "13581 [D loss: (0.548)(R 0.491, F 0.605)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.717] [G acc: 0.562]\n",
      "13582 [D loss: (0.592)(R 0.570, F 0.615)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.943] [G acc: 0.312]\n",
      "13583 [D loss: (0.607)(R 0.504, F 0.710)] [D acc: (0.688)(0.875, 0.500)] [G loss: 1.226] [G acc: 0.125]\n",
      "13584 [D loss: (0.618)(R 0.566, F 0.670)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.138] [G acc: 0.312]\n",
      "13585 [D loss: (0.595)(R 0.586, F 0.603)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.874] [G acc: 0.250]\n",
      "13586 [D loss: (0.623)(R 0.556, F 0.689)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.848] [G acc: 0.250]\n",
      "13587 [D loss: (0.550)(R 0.569, F 0.530)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.330] [G acc: 0.250]\n",
      "13588 [D loss: (0.572)(R 0.528, F 0.616)] [D acc: (0.844)(0.875, 0.812)] [G loss: 0.948] [G acc: 0.250]\n",
      "13589 [D loss: (0.652)(R 0.519, F 0.784)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.938] [G acc: 0.375]\n",
      "13590 [D loss: (0.612)(R 0.604, F 0.619)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.047] [G acc: 0.312]\n",
      "13591 [D loss: (0.582)(R 0.503, F 0.662)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.925] [G acc: 0.250]\n",
      "13592 [D loss: (0.657)(R 0.672, F 0.642)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.738] [G acc: 0.438]\n",
      "13593 [D loss: (0.619)(R 0.541, F 0.696)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.866] [G acc: 0.250]\n",
      "13594 [D loss: (0.725)(R 0.701, F 0.748)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.853] [G acc: 0.312]\n",
      "13595 [D loss: (0.629)(R 0.569, F 0.690)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.771] [G acc: 0.500]\n",
      "13596 [D loss: (0.670)(R 0.773, F 0.566)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.768] [G acc: 0.375]\n",
      "13597 [D loss: (0.764)(R 0.820, F 0.708)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.797] [G acc: 0.375]\n",
      "13598 [D loss: (0.655)(R 0.652, F 0.658)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.909] [G acc: 0.125]\n",
      "13599 [D loss: (0.769)(R 0.776, F 0.762)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.782] [G acc: 0.250]\n",
      "13600 [D loss: (0.709)(R 0.707, F 0.712)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.918] [G acc: 0.188]\n",
      "13601 [D loss: (0.752)(R 0.658, F 0.847)] [D acc: (0.438)(0.688, 0.188)] [G loss: 0.849] [G acc: 0.250]\n",
      "13602 [D loss: (0.676)(R 0.628, F 0.724)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.704] [G acc: 0.438]\n",
      "13603 [D loss: (0.767)(R 0.809, F 0.726)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.858] [G acc: 0.312]\n",
      "13604 [D loss: (0.724)(R 0.665, F 0.784)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.782] [G acc: 0.375]\n",
      "13605 [D loss: (0.703)(R 0.616, F 0.790)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.748] [G acc: 0.438]\n",
      "13606 [D loss: (0.677)(R 0.640, F 0.715)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.759] [G acc: 0.375]\n",
      "13607 [D loss: (0.629)(R 0.637, F 0.621)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.760] [G acc: 0.438]\n",
      "13608 [D loss: (0.643)(R 0.654, F 0.632)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.776] [G acc: 0.438]\n",
      "13609 [D loss: (0.716)(R 0.631, F 0.801)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.781] [G acc: 0.438]\n",
      "13610 [D loss: (0.621)(R 0.534, F 0.709)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.783] [G acc: 0.375]\n",
      "13611 [D loss: (0.577)(R 0.598, F 0.555)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.455] [G acc: 0.438]\n",
      "13612 [D loss: (0.478)(R 0.650, F 0.306)] [D acc: (0.750)(0.688, 0.812)] [G loss: 5.312] [G acc: 0.188]\n",
      "13613 [D loss: (0.660)(R 0.614, F 0.707)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.739] [G acc: 0.375]\n",
      "13614 [D loss: (0.657)(R 0.594, F 0.721)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.696] [G acc: 0.375]\n",
      "13615 [D loss: (0.630)(R 0.604, F 0.657)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.712] [G acc: 0.438]\n",
      "13616 [D loss: (0.769)(R 0.853, F 0.686)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.770] [G acc: 0.375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13617 [D loss: (0.646)(R 0.634, F 0.657)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.797] [G acc: 0.500]\n",
      "13618 [D loss: (0.755)(R 0.754, F 0.756)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.766] [G acc: 0.312]\n",
      "13619 [D loss: (0.686)(R 0.715, F 0.656)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.887] [G acc: 0.125]\n",
      "13620 [D loss: (0.668)(R 0.639, F 0.698)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.829] [G acc: 0.250]\n",
      "13621 [D loss: (0.721)(R 0.774, F 0.668)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.722] [G acc: 0.438]\n",
      "13622 [D loss: (0.713)(R 0.753, F 0.673)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.780] [G acc: 0.312]\n",
      "13623 [D loss: (0.700)(R 0.687, F 0.712)] [D acc: (0.531)(0.562, 0.500)] [G loss: 1.004] [G acc: 0.188]\n",
      "13624 [D loss: (0.671)(R 0.706, F 0.635)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.854] [G acc: 0.188]\n",
      "13625 [D loss: (0.640)(R 0.572, F 0.708)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.709] [G acc: 0.500]\n",
      "13626 [D loss: (0.668)(R 0.731, F 0.604)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.784] [G acc: 0.312]\n",
      "13627 [D loss: (0.731)(R 0.741, F 0.721)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.745] [G acc: 0.438]\n",
      "13628 [D loss: (0.626)(R 0.621, F 0.631)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.824] [G acc: 0.250]\n",
      "13629 [D loss: (0.785)(R 0.868, F 0.701)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.801] [G acc: 0.250]\n",
      "13630 [D loss: (0.654)(R 0.648, F 0.660)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.784] [G acc: 0.312]\n",
      "13631 [D loss: (0.762)(R 0.824, F 0.700)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.794] [G acc: 0.250]\n",
      "13632 [D loss: (0.622)(R 0.590, F 0.653)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.901] [G acc: 0.188]\n",
      "13633 [D loss: (0.659)(R 0.561, F 0.757)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.853] [G acc: 0.250]\n",
      "13634 [D loss: (0.664)(R 0.563, F 0.764)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.724] [G acc: 0.500]\n",
      "13635 [D loss: (0.681)(R 0.709, F 0.654)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.750] [G acc: 0.312]\n",
      "13636 [D loss: (0.695)(R 0.689, F 0.701)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.725] [G acc: 0.375]\n",
      "13637 [D loss: (0.696)(R 0.625, F 0.767)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.791] [G acc: 0.312]\n",
      "13638 [D loss: (0.718)(R 0.647, F 0.789)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.723] [G acc: 0.500]\n",
      "13639 [D loss: (0.717)(R 0.694, F 0.741)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.813] [G acc: 0.375]\n",
      "13640 [D loss: (0.663)(R 0.681, F 0.645)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.892] [G acc: 0.188]\n",
      "13641 [D loss: (0.657)(R 0.639, F 0.676)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.828] [G acc: 0.250]\n",
      "13642 [D loss: (0.667)(R 0.642, F 0.693)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.823] [G acc: 0.250]\n",
      "13643 [D loss: (0.645)(R 0.558, F 0.731)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.834] [G acc: 0.250]\n",
      "13644 [D loss: (0.599)(R 0.628, F 0.569)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.806] [G acc: 0.188]\n",
      "13645 [D loss: (0.596)(R 0.497, F 0.696)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.785] [G acc: 0.375]\n",
      "13646 [D loss: (0.711)(R 0.725, F 0.697)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.839] [G acc: 0.250]\n",
      "13647 [D loss: (0.709)(R 0.695, F 0.723)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.645] [G acc: 0.625]\n",
      "13648 [D loss: (0.676)(R 0.630, F 0.723)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.769] [G acc: 0.250]\n",
      "13649 [D loss: (0.747)(R 0.757, F 0.737)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.989] [G acc: 0.062]\n",
      "13650 [D loss: (0.659)(R 0.768, F 0.550)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.838] [G acc: 0.250]\n",
      "13651 [D loss: (0.681)(R 0.695, F 0.667)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.750] [G acc: 0.500]\n",
      "13652 [D loss: (0.635)(R 0.712, F 0.559)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.812] [G acc: 0.312]\n",
      "13653 [D loss: (0.796)(R 0.896, F 0.695)] [D acc: (0.406)(0.188, 0.625)] [G loss: 0.703] [G acc: 0.562]\n",
      "13654 [D loss: (0.822)(R 0.832, F 0.812)] [D acc: (0.281)(0.250, 0.312)] [G loss: 0.747] [G acc: 0.438]\n",
      "13655 [D loss: (0.763)(R 0.763, F 0.763)] [D acc: (0.375)(0.312, 0.438)] [G loss: 0.811] [G acc: 0.250]\n",
      "13656 [D loss: (0.707)(R 0.588, F 0.825)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.857] [G acc: 0.312]\n",
      "13657 [D loss: (0.773)(R 0.754, F 0.793)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.749] [G acc: 0.438]\n",
      "13658 [D loss: (0.777)(R 0.831, F 0.723)] [D acc: (0.438)(0.312, 0.562)] [G loss: 0.644] [G acc: 0.500]\n",
      "13659 [D loss: (0.721)(R 0.623, F 0.818)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.578] [G acc: 0.750]\n",
      "13660 [D loss: (0.813)(R 0.840, F 0.786)] [D acc: (0.281)(0.250, 0.312)] [G loss: 0.649] [G acc: 0.562]\n",
      "13661 [D loss: (0.794)(R 0.679, F 0.908)] [D acc: (0.375)(0.562, 0.188)] [G loss: 0.608] [G acc: 0.688]\n",
      "13662 [D loss: (0.566)(R 0.711, F 0.421)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.835] [G acc: 0.312]\n",
      "13663 [D loss: (0.707)(R 0.549, F 0.866)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.687] [G acc: 0.500]\n",
      "13664 [D loss: (0.686)(R 0.653, F 0.720)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.621] [G acc: 0.688]\n",
      "13665 [D loss: (0.696)(R 0.748, F 0.644)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.630] [G acc: 0.688]\n",
      "13666 [D loss: (0.736)(R 0.727, F 0.744)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.662] [G acc: 0.625]\n",
      "13667 [D loss: (0.782)(R 0.748, F 0.816)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.666] [G acc: 0.562]\n",
      "13668 [D loss: (0.809)(R 0.727, F 0.891)] [D acc: (0.344)(0.500, 0.188)] [G loss: 0.591] [G acc: 0.750]\n",
      "13669 [D loss: (0.745)(R 0.716, F 0.773)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.619] [G acc: 0.688]\n",
      "13670 [D loss: (0.797)(R 0.738, F 0.856)] [D acc: (0.344)(0.438, 0.250)] [G loss: 0.626] [G acc: 0.688]\n",
      "13671 [D loss: (0.808)(R 0.777, F 0.838)] [D acc: (0.250)(0.188, 0.312)] [G loss: 0.647] [G acc: 0.562]\n",
      "13672 [D loss: (0.743)(R 0.659, F 0.828)] [D acc: (0.375)(0.500, 0.250)] [G loss: 0.683] [G acc: 0.500]\n",
      "13673 [D loss: (0.792)(R 0.758, F 0.826)] [D acc: (0.312)(0.375, 0.250)] [G loss: 0.694] [G acc: 0.500]\n",
      "13674 [D loss: (0.856)(R 0.787, F 0.925)] [D acc: (0.219)(0.250, 0.188)] [G loss: 0.692] [G acc: 0.500]\n",
      "13675 [D loss: (0.716)(R 0.651, F 0.781)] [D acc: (0.344)(0.375, 0.312)] [G loss: 0.610] [G acc: 0.562]\n",
      "13676 [D loss: (0.763)(R 0.717, F 0.810)] [D acc: (0.375)(0.438, 0.312)] [G loss: 0.664] [G acc: 0.500]\n",
      "13677 [D loss: (0.688)(R 0.639, F 0.736)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.707] [G acc: 0.438]\n",
      "13678 [D loss: (0.712)(R 0.650, F 0.775)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.624] [G acc: 0.625]\n",
      "13679 [D loss: (0.755)(R 0.696, F 0.814)] [D acc: (0.406)(0.500, 0.312)] [G loss: 0.718] [G acc: 0.375]\n",
      "13680 [D loss: (0.728)(R 0.771, F 0.685)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.694] [G acc: 0.562]\n",
      "13681 [D loss: (0.669)(R 0.649, F 0.690)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.676] [G acc: 0.562]\n",
      "13682 [D loss: (0.707)(R 0.630, F 0.783)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.600] [G acc: 0.688]\n",
      "13683 [D loss: (0.715)(R 0.601, F 0.828)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.658] [G acc: 0.562]\n",
      "13684 [D loss: (0.721)(R 0.667, F 0.775)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.680] [G acc: 0.625]\n",
      "13685 [D loss: (0.753)(R 0.710, F 0.797)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.621] [G acc: 0.688]\n",
      "13686 [D loss: (0.724)(R 0.653, F 0.795)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.721] [G acc: 0.375]\n",
      "13687 [D loss: (0.739)(R 0.678, F 0.799)] [D acc: (0.312)(0.312, 0.312)] [G loss: 0.623] [G acc: 0.750]\n",
      "13688 [D loss: (0.715)(R 0.604, F 0.826)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.649] [G acc: 0.500]\n",
      "13689 [D loss: (0.760)(R 0.686, F 0.834)] [D acc: (0.312)(0.375, 0.250)] [G loss: 0.631] [G acc: 0.688]\n",
      "13690 [D loss: (0.697)(R 0.646, F 0.749)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.629] [G acc: 0.750]\n",
      "13691 [D loss: (0.740)(R 0.692, F 0.787)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.693] [G acc: 0.375]\n",
      "13692 [D loss: (0.684)(R 0.581, F 0.787)] [D acc: (0.438)(0.688, 0.188)] [G loss: 0.618] [G acc: 0.625]\n",
      "13693 [D loss: (0.694)(R 0.637, F 0.751)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.711] [G acc: 0.438]\n",
      "13694 [D loss: (0.723)(R 0.663, F 0.783)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.636] [G acc: 0.688]\n",
      "13695 [D loss: (0.721)(R 0.692, F 0.751)] [D acc: (0.406)(0.312, 0.500)] [G loss: 0.687] [G acc: 0.500]\n",
      "13696 [D loss: (0.607)(R 0.695, F 0.519)] [D acc: (0.594)(0.438, 0.750)] [G loss: 1.072] [G acc: 0.250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13697 [D loss: (0.585)(R 0.689, F 0.480)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.886] [G acc: 0.250]\n",
      "13698 [D loss: (0.695)(R 0.689, F 0.701)] [D acc: (0.406)(0.312, 0.500)] [G loss: 0.743] [G acc: 0.250]\n",
      "13699 [D loss: (0.693)(R 0.682, F 0.704)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.797] [G acc: 0.250]\n",
      "13700 [D loss: (0.705)(R 0.693, F 0.718)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.650] [G acc: 0.562]\n",
      "13701 [D loss: (0.660)(R 0.613, F 0.707)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.744] [G acc: 0.312]\n",
      "13702 [D loss: (0.716)(R 0.728, F 0.704)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.741] [G acc: 0.312]\n",
      "13703 [D loss: (0.703)(R 0.736, F 0.669)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.670] [G acc: 0.562]\n",
      "13704 [D loss: (0.679)(R 0.601, F 0.756)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.719] [G acc: 0.312]\n",
      "13705 [D loss: (0.709)(R 0.698, F 0.720)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.789] [G acc: 0.250]\n",
      "13706 [D loss: (0.696)(R 0.717, F 0.675)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.722] [G acc: 0.375]\n",
      "13707 [D loss: (0.683)(R 0.631, F 0.736)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.661] [G acc: 0.500]\n",
      "13708 [D loss: (0.674)(R 0.675, F 0.674)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.695] [G acc: 0.500]\n",
      "13709 [D loss: (0.699)(R 0.678, F 0.720)] [D acc: (0.406)(0.375, 0.438)] [G loss: 0.748] [G acc: 0.188]\n",
      "13710 [D loss: (0.688)(R 0.650, F 0.726)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.683] [G acc: 0.312]\n",
      "13711 [D loss: (0.656)(R 0.632, F 0.680)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.759] [G acc: 0.125]\n",
      "13712 [D loss: (0.720)(R 0.743, F 0.696)] [D acc: (0.438)(0.188, 0.688)] [G loss: 0.710] [G acc: 0.375]\n",
      "13713 [D loss: (0.684)(R 0.643, F 0.725)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.719] [G acc: 0.438]\n",
      "13714 [D loss: (0.840)(R 0.923, F 0.758)] [D acc: (0.281)(0.250, 0.312)] [G loss: 0.700] [G acc: 0.562]\n",
      "13715 [D loss: (0.675)(R 0.657, F 0.694)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.691] [G acc: 0.500]\n",
      "13716 [D loss: (0.685)(R 0.599, F 0.772)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.660] [G acc: 0.500]\n",
      "13717 [D loss: (0.671)(R 0.640, F 0.703)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.700] [G acc: 0.312]\n",
      "13718 [D loss: (0.702)(R 0.746, F 0.659)] [D acc: (0.562)(0.250, 0.875)] [G loss: 0.699] [G acc: 0.500]\n",
      "13719 [D loss: (0.638)(R 0.600, F 0.675)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.755] [G acc: 0.125]\n",
      "13720 [D loss: (0.657)(R 0.578, F 0.735)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.707] [G acc: 0.438]\n",
      "13721 [D loss: (0.672)(R 0.630, F 0.714)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.735] [G acc: 0.312]\n",
      "13722 [D loss: (0.691)(R 0.665, F 0.717)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.748] [G acc: 0.250]\n",
      "13723 [D loss: (0.715)(R 0.624, F 0.807)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.714] [G acc: 0.312]\n",
      "13724 [D loss: (0.674)(R 0.632, F 0.716)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.756] [G acc: 0.188]\n",
      "13725 [D loss: (0.683)(R 0.663, F 0.703)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.680] [G acc: 0.500]\n",
      "13726 [D loss: (0.733)(R 0.713, F 0.753)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.689] [G acc: 0.438]\n",
      "13727 [D loss: (0.706)(R 0.665, F 0.746)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.738] [G acc: 0.312]\n",
      "13728 [D loss: (0.695)(R 0.700, F 0.691)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.714] [G acc: 0.500]\n",
      "13729 [D loss: (0.678)(R 0.678, F 0.678)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.694] [G acc: 0.500]\n",
      "13730 [D loss: (0.679)(R 0.609, F 0.749)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.682] [G acc: 0.562]\n",
      "13731 [D loss: (0.646)(R 0.618, F 0.673)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.701] [G acc: 0.375]\n",
      "13732 [D loss: (0.715)(R 0.708, F 0.722)] [D acc: (0.406)(0.250, 0.562)] [G loss: 0.733] [G acc: 0.188]\n",
      "13733 [D loss: (0.697)(R 0.681, F 0.712)] [D acc: (0.406)(0.250, 0.562)] [G loss: 0.733] [G acc: 0.312]\n",
      "13734 [D loss: (0.655)(R 0.623, F 0.686)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.742] [G acc: 0.188]\n",
      "13735 [D loss: (0.648)(R 0.649, F 0.647)] [D acc: (0.562)(0.312, 0.812)] [G loss: 0.704] [G acc: 0.375]\n",
      "13736 [D loss: (0.695)(R 0.703, F 0.688)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.741] [G acc: 0.250]\n",
      "13737 [D loss: (0.653)(R 0.625, F 0.681)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.736] [G acc: 0.250]\n",
      "13738 [D loss: (0.695)(R 0.692, F 0.697)] [D acc: (0.438)(0.312, 0.562)] [G loss: 0.744] [G acc: 0.125]\n",
      "13739 [D loss: (0.687)(R 0.700, F 0.673)] [D acc: (0.438)(0.312, 0.562)] [G loss: 0.723] [G acc: 0.250]\n",
      "13740 [D loss: (0.675)(R 0.649, F 0.702)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.741] [G acc: 0.125]\n",
      "13741 [D loss: (0.662)(R 0.626, F 0.699)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.664] [G acc: 0.438]\n",
      "13742 [D loss: (0.653)(R 0.611, F 0.695)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.741] [G acc: 0.312]\n",
      "13743 [D loss: (0.594)(R 0.609, F 0.579)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.843] [G acc: 0.062]\n",
      "13744 [D loss: (0.672)(R 0.607, F 0.737)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.763] [G acc: 0.188]\n",
      "13745 [D loss: (0.658)(R 0.622, F 0.694)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.745] [G acc: 0.312]\n",
      "13746 [D loss: (0.701)(R 0.659, F 0.742)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.756] [G acc: 0.188]\n",
      "13747 [D loss: (0.662)(R 0.689, F 0.635)] [D acc: (0.625)(0.312, 0.938)] [G loss: 0.761] [G acc: 0.250]\n",
      "13748 [D loss: (0.963)(R 0.643, F 1.283)] [D acc: (0.469)(0.375, 0.562)] [G loss: 1.588] [G acc: 0.312]\n",
      "13749 [D loss: (0.586)(R 0.625, F 0.547)] [D acc: (0.438)(0.375, 0.500)] [G loss: 2.991] [G acc: 0.062]\n",
      "13750 [D loss: (0.608)(R 0.549, F 0.667)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.681] [G acc: 0.312]\n",
      "13751 [D loss: (0.691)(R 0.745, F 0.636)] [D acc: (0.562)(0.312, 0.812)] [G loss: 0.750] [G acc: 0.375]\n",
      "13752 [D loss: (0.651)(R 0.601, F 0.701)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.704] [G acc: 0.375]\n",
      "13753 [D loss: (0.655)(R 0.599, F 0.711)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.765] [G acc: 0.125]\n",
      "13754 [D loss: (0.648)(R 0.637, F 0.658)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.717] [G acc: 0.125]\n",
      "13755 [D loss: (0.660)(R 0.657, F 0.664)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.760] [G acc: 0.188]\n",
      "13756 [D loss: (0.665)(R 0.663, F 0.668)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.759] [G acc: 0.188]\n",
      "13757 [D loss: (0.636)(R 0.643, F 0.628)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.734] [G acc: 0.312]\n",
      "13758 [D loss: (0.590)(R 0.558, F 0.622)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.786] [G acc: 0.062]\n",
      "13759 [D loss: (0.708)(R 0.747, F 0.669)] [D acc: (0.531)(0.250, 0.812)] [G loss: 0.790] [G acc: 0.062]\n",
      "13760 [D loss: (0.613)(R 0.588, F 0.637)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.758] [G acc: 0.125]\n",
      "13761 [D loss: (0.701)(R 0.711, F 0.690)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.737] [G acc: 0.250]\n",
      "13762 [D loss: (0.627)(R 0.608, F 0.646)] [D acc: (0.500)(0.312, 0.688)] [G loss: 0.762] [G acc: 0.125]\n",
      "13763 [D loss: (0.666)(R 0.702, F 0.630)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.760] [G acc: 0.188]\n",
      "13764 [D loss: (0.727)(R 0.775, F 0.680)] [D acc: (0.469)(0.188, 0.750)] [G loss: 0.773] [G acc: 0.062]\n",
      "13765 [D loss: (0.659)(R 0.686, F 0.631)] [D acc: (0.562)(0.312, 0.812)] [G loss: 0.742] [G acc: 0.250]\n",
      "13766 [D loss: (0.701)(R 0.760, F 0.641)] [D acc: (0.469)(0.188, 0.750)] [G loss: 0.755] [G acc: 0.188]\n",
      "13767 [D loss: (0.599)(R 0.587, F 0.612)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.755] [G acc: 0.312]\n",
      "13768 [D loss: (0.695)(R 0.694, F 0.696)] [D acc: (0.469)(0.250, 0.688)] [G loss: 0.698] [G acc: 0.312]\n",
      "13769 [D loss: (0.706)(R 0.731, F 0.681)] [D acc: (0.562)(0.312, 0.812)] [G loss: 0.772] [G acc: 0.062]\n",
      "13770 [D loss: (0.667)(R 0.667, F 0.668)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.776] [G acc: 0.125]\n",
      "13771 [D loss: (0.645)(R 0.622, F 0.668)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.749] [G acc: 0.250]\n",
      "13772 [D loss: (0.694)(R 0.700, F 0.687)] [D acc: (0.438)(0.312, 0.562)] [G loss: 0.750] [G acc: 0.125]\n",
      "13773 [D loss: (0.679)(R 0.654, F 0.704)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.726] [G acc: 0.438]\n",
      "13774 [D loss: (0.662)(R 0.663, F 0.661)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.743] [G acc: 0.312]\n",
      "13775 [D loss: (0.679)(R 0.709, F 0.648)] [D acc: (0.562)(0.250, 0.875)] [G loss: 0.737] [G acc: 0.375]\n",
      "13776 [D loss: (0.673)(R 0.605, F 0.741)] [D acc: (0.625)(0.312, 0.938)] [G loss: 0.769] [G acc: 0.188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13777 [D loss: (0.638)(R 0.650, F 0.625)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.744] [G acc: 0.312]\n",
      "13778 [D loss: (0.683)(R 0.680, F 0.686)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.769] [G acc: 0.188]\n",
      "13779 [D loss: (0.673)(R 0.698, F 0.647)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.725] [G acc: 0.375]\n",
      "13780 [D loss: (0.697)(R 0.701, F 0.693)] [D acc: (0.406)(0.188, 0.625)] [G loss: 0.769] [G acc: 0.250]\n",
      "13781 [D loss: (0.666)(R 0.668, F 0.663)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.707] [G acc: 0.438]\n",
      "13782 [D loss: (0.704)(R 0.685, F 0.724)] [D acc: (0.406)(0.312, 0.500)] [G loss: 0.738] [G acc: 0.250]\n",
      "13783 [D loss: (0.704)(R 0.736, F 0.672)] [D acc: (0.500)(0.312, 0.688)] [G loss: 0.727] [G acc: 0.312]\n",
      "13784 [D loss: (0.653)(R 0.649, F 0.658)] [D acc: (0.531)(0.250, 0.812)] [G loss: 0.668] [G acc: 0.438]\n",
      "13785 [D loss: (0.640)(R 0.579, F 0.701)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.722] [G acc: 0.375]\n",
      "13786 [D loss: (0.699)(R 0.726, F 0.672)] [D acc: (0.469)(0.250, 0.688)] [G loss: 0.779] [G acc: 0.188]\n",
      "13787 [D loss: (0.685)(R 0.701, F 0.669)] [D acc: (0.438)(0.250, 0.625)] [G loss: 0.712] [G acc: 0.312]\n",
      "13788 [D loss: (0.691)(R 0.693, F 0.688)] [D acc: (0.500)(0.312, 0.688)] [G loss: 0.725] [G acc: 0.312]\n",
      "13789 [D loss: (0.711)(R 0.728, F 0.694)] [D acc: (0.375)(0.250, 0.500)] [G loss: 0.747] [G acc: 0.125]\n",
      "13790 [D loss: (0.659)(R 0.639, F 0.679)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.755] [G acc: 0.250]\n",
      "13791 [D loss: (0.679)(R 0.666, F 0.693)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.734] [G acc: 0.250]\n",
      "13792 [D loss: (0.647)(R 0.584, F 0.711)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.671] [G acc: 0.375]\n",
      "13793 [D loss: (0.669)(R 0.636, F 0.701)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.736] [G acc: 0.312]\n",
      "13794 [D loss: (0.672)(R 0.708, F 0.636)] [D acc: (0.562)(0.250, 0.875)] [G loss: 0.709] [G acc: 0.312]\n",
      "13795 [D loss: (0.713)(R 0.652, F 0.774)] [D acc: (0.406)(0.375, 0.438)] [G loss: 0.731] [G acc: 0.375]\n",
      "13796 [D loss: (0.713)(R 0.730, F 0.697)] [D acc: (0.375)(0.250, 0.500)] [G loss: 0.715] [G acc: 0.250]\n",
      "13797 [D loss: (0.734)(R 0.670, F 0.798)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.598] [G acc: 0.500]\n",
      "13798 [D loss: (0.736)(R 0.752, F 0.721)] [D acc: (0.469)(0.312, 0.625)] [G loss: 1.390] [G acc: 0.312]\n",
      "13799 [D loss: (0.631)(R 0.688, F 0.574)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.756] [G acc: 0.188]\n",
      "13800 [D loss: (0.682)(R 0.641, F 0.723)] [D acc: (0.500)(0.312, 0.688)] [G loss: 0.862] [G acc: 0.375]\n",
      "13801 [D loss: (0.659)(R 0.571, F 0.747)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.768] [G acc: 0.250]\n",
      "13802 [D loss: (0.632)(R 0.600, F 0.664)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.716] [G acc: 0.312]\n",
      "13803 [D loss: (0.665)(R 0.700, F 0.631)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.753] [G acc: 0.250]\n",
      "13804 [D loss: (0.774)(R 0.655, F 0.893)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.740] [G acc: 0.250]\n",
      "13805 [D loss: (0.684)(R 0.717, F 0.651)] [D acc: (0.469)(0.125, 0.812)] [G loss: 0.782] [G acc: 0.062]\n",
      "13806 [D loss: (0.637)(R 0.648, F 0.626)] [D acc: (0.625)(0.312, 0.938)] [G loss: 0.780] [G acc: 0.125]\n",
      "13807 [D loss: (0.667)(R 0.689, F 0.645)] [D acc: (0.500)(0.250, 0.750)] [G loss: 0.711] [G acc: 0.375]\n",
      "13808 [D loss: (0.606)(R 0.579, F 0.634)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.761] [G acc: 0.125]\n",
      "13809 [D loss: (0.655)(R 0.646, F 0.664)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.734] [G acc: 0.312]\n",
      "13810 [D loss: (0.696)(R 0.677, F 0.716)] [D acc: (0.594)(0.312, 0.875)] [G loss: 0.742] [G acc: 0.188]\n",
      "13811 [D loss: (0.681)(R 0.708, F 0.655)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.720] [G acc: 0.188]\n",
      "13812 [D loss: (0.696)(R 0.709, F 0.682)] [D acc: (0.500)(0.250, 0.750)] [G loss: 0.552] [G acc: 0.562]\n",
      "13813 [D loss: (0.679)(R 0.704, F 0.654)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.721] [G acc: 0.375]\n",
      "13814 [D loss: (0.719)(R 0.582, F 0.856)] [D acc: (0.344)(0.375, 0.312)] [G loss: 0.727] [G acc: 0.125]\n",
      "13815 [D loss: (0.832)(R 0.679, F 0.986)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.760] [G acc: 0.188]\n",
      "13816 [D loss: (0.681)(R 0.708, F 0.655)] [D acc: (0.656)(0.375, 0.938)] [G loss: 0.781] [G acc: 0.125]\n",
      "13817 [D loss: (0.680)(R 0.728, F 0.633)] [D acc: (0.469)(0.188, 0.750)] [G loss: 0.747] [G acc: 0.125]\n",
      "13818 [D loss: (0.706)(R 0.722, F 0.689)] [D acc: (0.406)(0.125, 0.688)] [G loss: 0.766] [G acc: 0.000]\n",
      "13819 [D loss: (0.648)(R 0.637, F 0.658)] [D acc: (0.625)(0.438, 0.812)] [G loss: 1.205] [G acc: 0.438]\n",
      "13820 [D loss: (0.725)(R 0.722, F 0.728)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.804] [G acc: 0.125]\n",
      "13821 [D loss: (0.757)(R 0.736, F 0.779)] [D acc: (0.406)(0.250, 0.562)] [G loss: 0.697] [G acc: 0.375]\n",
      "13822 [D loss: (0.690)(R 0.694, F 0.686)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.773] [G acc: 0.188]\n",
      "13823 [D loss: (0.670)(R 0.657, F 0.683)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.778] [G acc: 0.188]\n",
      "13824 [D loss: (0.595)(R 0.584, F 0.606)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.776] [G acc: 0.250]\n",
      "13825 [D loss: (0.687)(R 0.692, F 0.682)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.699] [G acc: 0.375]\n",
      "13826 [D loss: (0.685)(R 0.663, F 0.708)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.754] [G acc: 0.250]\n",
      "13827 [D loss: (0.663)(R 0.681, F 0.645)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.743] [G acc: 0.188]\n",
      "13828 [D loss: (0.617)(R 0.566, F 0.669)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.687] [G acc: 0.250]\n",
      "13829 [D loss: (0.652)(R 0.695, F 0.609)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.754] [G acc: 0.438]\n",
      "13830 [D loss: (0.679)(R 0.645, F 0.713)] [D acc: (0.438)(0.312, 0.562)] [G loss: 0.738] [G acc: 0.312]\n",
      "13831 [D loss: (0.649)(R 0.652, F 0.646)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.698] [G acc: 0.312]\n",
      "13832 [D loss: (0.667)(R 0.581, F 0.753)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.694] [G acc: 0.500]\n",
      "13833 [D loss: (0.641)(R 0.634, F 0.648)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.699] [G acc: 0.438]\n",
      "13834 [D loss: (0.656)(R 0.639, F 0.673)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.722] [G acc: 0.312]\n",
      "13835 [D loss: (0.677)(R 0.604, F 0.750)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.669] [G acc: 0.375]\n",
      "13836 [D loss: (0.636)(R 0.658, F 0.614)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.769] [G acc: 0.188]\n",
      "13837 [D loss: (0.622)(R 0.611, F 0.634)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.777] [G acc: 0.250]\n",
      "13838 [D loss: (0.808)(R 0.630, F 0.987)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.748] [G acc: 0.250]\n",
      "13839 [D loss: (0.645)(R 0.661, F 0.629)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.729] [G acc: 0.375]\n",
      "13840 [D loss: (0.646)(R 0.656, F 0.637)] [D acc: (0.656)(0.438, 0.875)] [G loss: 1.030] [G acc: 0.438]\n",
      "13841 [D loss: (0.584)(R 0.611, F 0.557)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.497] [G acc: 0.000]\n",
      "13842 [D loss: (0.601)(R 0.621, F 0.581)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.831] [G acc: 0.125]\n",
      "13843 [D loss: (0.583)(R 0.611, F 0.556)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.759] [G acc: 0.250]\n",
      "13844 [D loss: (0.638)(R 0.738, F 0.538)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.798] [G acc: 0.250]\n",
      "13845 [D loss: (0.603)(R 0.576, F 0.630)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.267] [G acc: 0.250]\n",
      "13846 [D loss: (0.650)(R 0.653, F 0.646)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.749] [G acc: 0.312]\n",
      "13847 [D loss: (0.617)(R 0.589, F 0.645)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.753] [G acc: 0.438]\n",
      "13848 [D loss: (0.664)(R 0.598, F 0.731)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.769] [G acc: 0.250]\n",
      "13849 [D loss: (0.633)(R 0.584, F 0.682)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.787] [G acc: 0.312]\n",
      "13850 [D loss: (0.640)(R 0.592, F 0.687)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.613] [G acc: 0.375]\n",
      "13851 [D loss: (0.528)(R 0.549, F 0.507)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.093] [G acc: 0.250]\n",
      "13852 [D loss: (0.645)(R 0.619, F 0.670)] [D acc: (0.562)(0.562, 0.562)] [G loss: 1.017] [G acc: 0.188]\n",
      "13853 [D loss: (0.613)(R 0.592, F 0.634)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.757] [G acc: 0.312]\n",
      "13854 [D loss: (0.700)(R 0.685, F 0.714)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.764] [G acc: 0.188]\n",
      "13855 [D loss: (0.615)(R 0.591, F 0.638)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.848] [G acc: 0.312]\n",
      "13856 [D loss: (0.571)(R 0.499, F 0.644)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.716] [G acc: 0.375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13857 [D loss: (0.623)(R 0.576, F 0.671)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.866] [G acc: 0.125]\n",
      "13858 [D loss: (0.623)(R 0.601, F 0.646)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.030] [G acc: 0.188]\n",
      "13859 [D loss: (0.553)(R 0.519, F 0.587)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.036] [G acc: 0.188]\n",
      "13860 [D loss: (0.599)(R 0.618, F 0.580)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.766] [G acc: 0.312]\n",
      "13861 [D loss: (0.626)(R 0.640, F 0.613)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.839] [G acc: 0.188]\n",
      "13862 [D loss: (0.587)(R 0.533, F 0.640)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.772] [G acc: 0.312]\n",
      "13863 [D loss: (0.657)(R 0.708, F 0.607)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.746] [G acc: 0.438]\n",
      "13864 [D loss: (0.570)(R 0.576, F 0.564)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.831] [G acc: 0.312]\n",
      "13865 [D loss: (0.666)(R 0.601, F 0.731)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.829] [G acc: 0.125]\n",
      "13866 [D loss: (0.684)(R 0.639, F 0.728)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.863] [G acc: 0.188]\n",
      "13867 [D loss: (0.634)(R 0.628, F 0.640)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.686] [G acc: 0.500]\n",
      "13868 [D loss: (0.608)(R 0.445, F 0.770)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.842] [G acc: 0.375]\n",
      "13869 [D loss: (0.628)(R 0.613, F 0.643)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.679] [G acc: 0.625]\n",
      "13870 [D loss: (0.672)(R 0.681, F 0.662)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.735] [G acc: 0.500]\n",
      "13871 [D loss: (0.660)(R 0.616, F 0.704)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.882] [G acc: 0.250]\n",
      "13872 [D loss: (0.661)(R 0.626, F 0.695)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.746] [G acc: 0.500]\n",
      "13873 [D loss: (0.688)(R 0.701, F 0.675)] [D acc: (0.531)(0.438, 0.625)] [G loss: 1.006] [G acc: 0.312]\n",
      "13874 [D loss: (0.607)(R 0.536, F 0.678)] [D acc: (0.781)(0.938, 0.625)] [G loss: 0.922] [G acc: 0.312]\n",
      "13875 [D loss: (0.632)(R 0.594, F 0.669)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.864] [G acc: 0.312]\n",
      "13876 [D loss: (0.674)(R 0.637, F 0.711)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.091] [G acc: 0.250]\n",
      "13877 [D loss: (0.621)(R 0.611, F 0.631)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.887] [G acc: 0.250]\n",
      "13878 [D loss: (0.642)(R 0.583, F 0.702)] [D acc: (0.562)(0.688, 0.438)] [G loss: 1.010] [G acc: 0.438]\n",
      "13879 [D loss: (0.699)(R 0.708, F 0.690)] [D acc: (0.469)(0.500, 0.438)] [G loss: 1.575] [G acc: 0.250]\n",
      "13880 [D loss: (0.532)(R 0.589, F 0.475)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.221] [G acc: 0.375]\n",
      "13881 [D loss: (0.583)(R 0.517, F 0.649)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.926] [G acc: 0.312]\n",
      "13882 [D loss: (0.688)(R 0.683, F 0.692)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.802] [G acc: 0.312]\n",
      "13883 [D loss: (0.694)(R 0.597, F 0.791)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.872] [G acc: 0.312]\n",
      "13884 [D loss: (0.651)(R 0.708, F 0.595)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.697] [G acc: 0.562]\n",
      "13885 [D loss: (0.705)(R 0.642, F 0.767)] [D acc: (0.469)(0.562, 0.375)] [G loss: 1.159] [G acc: 0.312]\n",
      "13886 [D loss: (0.730)(R 0.771, F 0.688)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.942] [G acc: 0.312]\n",
      "13887 [D loss: (0.668)(R 0.576, F 0.759)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.707] [G acc: 0.625]\n",
      "13888 [D loss: (0.696)(R 0.644, F 0.748)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.811] [G acc: 0.438]\n",
      "13889 [D loss: (0.632)(R 0.607, F 0.656)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.798] [G acc: 0.438]\n",
      "13890 [D loss: (0.764)(R 0.796, F 0.731)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.755] [G acc: 0.438]\n",
      "13891 [D loss: (0.721)(R 0.715, F 0.728)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.743] [G acc: 0.500]\n",
      "13892 [D loss: (0.706)(R 0.700, F 0.712)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.775] [G acc: 0.375]\n",
      "13893 [D loss: (0.741)(R 0.786, F 0.696)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.871] [G acc: 0.375]\n",
      "13894 [D loss: (0.686)(R 0.627, F 0.745)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.804] [G acc: 0.312]\n",
      "13895 [D loss: (0.738)(R 0.720, F 0.756)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.630] [G acc: 0.562]\n",
      "13896 [D loss: (0.716)(R 0.751, F 0.681)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.761] [G acc: 0.562]\n",
      "13897 [D loss: (0.712)(R 0.673, F 0.751)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.721] [G acc: 0.438]\n",
      "13898 [D loss: (0.670)(R 0.598, F 0.742)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.718] [G acc: 0.438]\n",
      "13899 [D loss: (0.621)(R 0.541, F 0.700)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.749] [G acc: 0.438]\n",
      "13900 [D loss: (0.669)(R 0.632, F 0.706)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.737] [G acc: 0.500]\n",
      "13901 [D loss: (0.742)(R 0.698, F 0.785)] [D acc: (0.406)(0.500, 0.312)] [G loss: 0.731] [G acc: 0.500]\n",
      "13902 [D loss: (0.719)(R 0.665, F 0.772)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.665] [G acc: 0.688]\n",
      "13903 [D loss: (0.760)(R 0.717, F 0.802)] [D acc: (0.250)(0.312, 0.188)] [G loss: 0.741] [G acc: 0.375]\n",
      "13904 [D loss: (0.679)(R 0.712, F 0.645)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.692] [G acc: 0.500]\n",
      "13905 [D loss: (0.704)(R 0.630, F 0.778)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.672] [G acc: 0.500]\n",
      "13906 [D loss: (0.725)(R 0.719, F 0.730)] [D acc: (0.406)(0.375, 0.438)] [G loss: 0.657] [G acc: 0.625]\n",
      "13907 [D loss: (0.704)(R 0.702, F 0.705)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.655] [G acc: 0.688]\n",
      "13908 [D loss: (0.743)(R 0.748, F 0.739)] [D acc: (0.406)(0.375, 0.438)] [G loss: 0.769] [G acc: 0.438]\n",
      "13909 [D loss: (0.730)(R 0.698, F 0.763)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.747] [G acc: 0.375]\n",
      "13910 [D loss: (0.740)(R 0.743, F 0.738)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.788] [G acc: 0.375]\n",
      "13911 [D loss: (0.705)(R 0.663, F 0.747)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.729] [G acc: 0.500]\n",
      "13912 [D loss: (0.706)(R 0.718, F 0.695)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.695] [G acc: 0.625]\n",
      "13913 [D loss: (0.662)(R 0.684, F 0.640)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.644] [G acc: 0.625]\n",
      "13914 [D loss: (0.715)(R 0.642, F 0.788)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.714] [G acc: 0.500]\n",
      "13915 [D loss: (0.697)(R 0.702, F 0.691)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.629] [G acc: 0.562]\n",
      "13916 [D loss: (0.702)(R 0.737, F 0.667)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.729] [G acc: 0.438]\n",
      "13917 [D loss: (0.776)(R 0.804, F 0.749)] [D acc: (0.281)(0.188, 0.375)] [G loss: 0.769] [G acc: 0.312]\n",
      "13918 [D loss: (0.471)(R 0.639, F 0.303)] [D acc: (0.688)(0.625, 0.750)] [G loss: 2.211] [G acc: 0.250]\n",
      "13919 [D loss: (0.527)(R 0.609, F 0.444)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.167] [G acc: 0.500]\n",
      "13920 [D loss: (0.711)(R 0.679, F 0.743)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.704] [G acc: 0.438]\n",
      "13921 [D loss: (0.697)(R 0.640, F 0.754)] [D acc: (0.406)(0.500, 0.312)] [G loss: 0.732] [G acc: 0.438]\n",
      "13922 [D loss: (0.740)(R 0.721, F 0.759)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.631] [G acc: 0.688]\n",
      "13923 [D loss: (0.689)(R 0.653, F 0.724)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.692] [G acc: 0.500]\n",
      "13924 [D loss: (0.662)(R 0.613, F 0.712)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.705] [G acc: 0.438]\n",
      "13925 [D loss: (0.686)(R 0.618, F 0.754)] [D acc: (0.531)(0.688, 0.375)] [G loss: 1.149] [G acc: 0.375]\n",
      "13926 [D loss: (0.662)(R 0.628, F 0.697)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.765] [G acc: 0.312]\n",
      "13927 [D loss: (0.705)(R 0.703, F 0.706)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.786] [G acc: 0.375]\n",
      "13928 [D loss: (0.700)(R 0.675, F 0.725)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.758] [G acc: 0.312]\n",
      "13929 [D loss: (0.635)(R 0.644, F 0.627)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.796] [G acc: 0.188]\n",
      "13930 [D loss: (0.583)(R 0.566, F 0.600)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.804] [G acc: 0.188]\n",
      "13931 [D loss: (0.655)(R 0.636, F 0.673)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.822] [G acc: 0.188]\n",
      "13932 [D loss: (0.619)(R 0.595, F 0.643)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.770] [G acc: 0.312]\n",
      "13933 [D loss: (0.655)(R 0.550, F 0.760)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.839] [G acc: 0.188]\n",
      "13934 [D loss: (0.602)(R 0.566, F 0.638)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.732] [G acc: 0.438]\n",
      "13935 [D loss: (0.642)(R 0.614, F 0.670)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.759] [G acc: 0.438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13936 [D loss: (0.666)(R 0.667, F 0.665)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.784] [G acc: 0.312]\n",
      "13937 [D loss: (0.653)(R 0.656, F 0.651)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.808] [G acc: 0.312]\n",
      "13938 [D loss: (0.620)(R 0.579, F 0.661)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.849] [G acc: 0.062]\n",
      "13939 [D loss: (0.637)(R 0.587, F 0.686)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.791] [G acc: 0.312]\n",
      "13940 [D loss: (0.637)(R 0.636, F 0.639)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.851] [G acc: 0.312]\n",
      "13941 [D loss: (0.648)(R 0.585, F 0.711)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.765] [G acc: 0.250]\n",
      "13942 [D loss: (0.668)(R 0.647, F 0.688)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.846] [G acc: 0.250]\n",
      "13943 [D loss: (0.686)(R 0.692, F 0.681)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.865] [G acc: 0.188]\n",
      "13944 [D loss: (0.718)(R 0.696, F 0.740)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.842] [G acc: 0.188]\n",
      "13945 [D loss: (0.641)(R 0.673, F 0.610)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.811] [G acc: 0.188]\n",
      "13946 [D loss: (0.651)(R 0.665, F 0.638)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.781] [G acc: 0.375]\n",
      "13947 [D loss: (0.646)(R 0.667, F 0.625)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.853] [G acc: 0.125]\n",
      "13948 [D loss: (0.635)(R 0.618, F 0.652)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.807] [G acc: 0.312]\n",
      "13949 [D loss: (0.607)(R 0.576, F 0.638)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.815] [G acc: 0.062]\n",
      "13950 [D loss: (0.647)(R 0.660, F 0.634)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.776] [G acc: 0.375]\n",
      "13951 [D loss: (0.672)(R 0.736, F 0.609)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.798] [G acc: 0.438]\n",
      "13952 [D loss: (0.659)(R 0.634, F 0.684)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.832] [G acc: 0.188]\n",
      "13953 [D loss: (0.569)(R 0.474, F 0.664)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.839] [G acc: 0.250]\n",
      "13954 [D loss: (0.710)(R 0.816, F 0.604)] [D acc: (0.469)(0.125, 0.812)] [G loss: 0.759] [G acc: 0.438]\n",
      "13955 [D loss: (0.635)(R 0.664, F 0.607)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.824] [G acc: 0.250]\n",
      "13956 [D loss: (0.714)(R 0.800, F 0.628)] [D acc: (0.531)(0.250, 0.812)] [G loss: 0.762] [G acc: 0.188]\n",
      "13957 [D loss: (0.667)(R 0.698, F 0.637)] [D acc: (0.438)(0.312, 0.562)] [G loss: 0.786] [G acc: 0.312]\n",
      "13958 [D loss: (0.675)(R 0.679, F 0.671)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.766] [G acc: 0.188]\n",
      "13959 [D loss: (0.597)(R 0.539, F 0.655)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.768] [G acc: 0.250]\n",
      "13960 [D loss: (0.646)(R 0.660, F 0.632)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.786] [G acc: 0.250]\n",
      "13961 [D loss: (0.640)(R 0.616, F 0.664)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.776] [G acc: 0.312]\n",
      "13962 [D loss: (0.678)(R 0.631, F 0.725)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.803] [G acc: 0.125]\n",
      "13963 [D loss: (0.639)(R 0.627, F 0.651)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.750] [G acc: 0.312]\n",
      "13964 [D loss: (0.575)(R 0.409, F 0.741)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.708] [G acc: 0.438]\n",
      "13965 [D loss: (0.685)(R 0.611, F 0.760)] [D acc: (0.406)(0.500, 0.312)] [G loss: 0.780] [G acc: 0.125]\n",
      "13966 [D loss: (0.846)(R 0.581, F 1.111)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.686] [G acc: 0.375]\n",
      "13967 [D loss: (0.596)(R 0.570, F 0.622)] [D acc: (0.688)(0.438, 0.938)] [G loss: 0.734] [G acc: 0.250]\n",
      "13968 [D loss: (0.649)(R 0.526, F 0.772)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.711] [G acc: 0.250]\n",
      "13969 [D loss: (0.594)(R 0.525, F 0.664)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.771] [G acc: 0.250]\n",
      "13970 [D loss: (0.697)(R 0.545, F 0.849)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.850] [G acc: 0.062]\n",
      "13971 [D loss: (0.772)(R 0.803, F 0.741)] [D acc: (0.312)(0.188, 0.438)] [G loss: 0.774] [G acc: 0.188]\n",
      "13972 [D loss: (0.608)(R 0.530, F 0.685)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.664] [G acc: 0.438]\n",
      "13973 [D loss: (0.649)(R 0.505, F 0.793)] [D acc: (0.375)(0.438, 0.312)] [G loss: 0.637] [G acc: 0.500]\n",
      "13974 [D loss: (0.927)(R 0.646, F 1.208)] [D acc: (0.375)(0.312, 0.438)] [G loss: 0.587] [G acc: 0.750]\n",
      "13975 [D loss: (0.932)(R 0.685, F 1.179)] [D acc: (0.406)(0.312, 0.500)] [G loss: 0.637] [G acc: 0.500]\n",
      "13976 [D loss: (0.767)(R 0.651, F 0.884)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.687] [G acc: 0.375]\n",
      "13977 [D loss: (0.793)(R 0.686, F 0.900)] [D acc: (0.406)(0.375, 0.438)] [G loss: 0.675] [G acc: 0.438]\n",
      "13978 [D loss: (0.610)(R 0.499, F 0.720)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.593] [G acc: 0.500]\n",
      "13979 [D loss: (1.162)(R 0.620, F 1.704)] [D acc: (0.406)(0.500, 0.312)] [G loss: 0.637] [G acc: 0.500]\n",
      "13980 [D loss: (0.802)(R 0.726, F 0.878)] [D acc: (0.406)(0.188, 0.625)] [G loss: 0.556] [G acc: 0.750]\n",
      "13981 [D loss: (0.864)(R 0.581, F 1.147)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.551] [G acc: 0.500]\n",
      "13982 [D loss: (1.055)(R 0.697, F 1.412)] [D acc: (0.438)(0.312, 0.562)] [G loss: 0.472] [G acc: 0.625]\n",
      "13983 [D loss: (0.932)(R 0.727, F 1.137)] [D acc: (0.375)(0.188, 0.562)] [G loss: 0.476] [G acc: 0.688]\n",
      "13984 [D loss: (1.496)(R 0.643, F 2.349)] [D acc: (0.406)(0.312, 0.500)] [G loss: 0.385] [G acc: 0.812]\n",
      "13985 [D loss: (1.079)(R 0.838, F 1.321)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.630] [G acc: 0.375]\n",
      "13986 [D loss: (1.089)(R 0.612, F 1.566)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.615] [G acc: 0.438]\n",
      "13987 [D loss: (1.174)(R 0.612, F 1.736)] [D acc: (0.344)(0.375, 0.312)] [G loss: 0.557] [G acc: 0.500]\n",
      "13988 [D loss: (1.216)(R 0.631, F 1.801)] [D acc: (0.281)(0.250, 0.312)] [G loss: 0.613] [G acc: 0.500]\n",
      "13989 [D loss: (1.005)(R 0.702, F 1.308)] [D acc: (0.406)(0.312, 0.500)] [G loss: 0.466] [G acc: 0.562]\n",
      "13990 [D loss: (0.917)(R 0.647, F 1.188)] [D acc: (0.406)(0.312, 0.500)] [G loss: 0.591] [G acc: 0.375]\n",
      "13991 [D loss: (1.393)(R 0.718, F 2.068)] [D acc: (0.281)(0.250, 0.312)] [G loss: 0.584] [G acc: 0.562]\n",
      "13992 [D loss: (1.002)(R 0.575, F 1.429)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.684] [G acc: 0.438]\n",
      "13993 [D loss: (0.770)(R 0.707, F 0.834)] [D acc: (0.562)(0.438, 0.688)] [G loss: 2.707] [G acc: 0.375]\n",
      "13994 [D loss: (0.788)(R 0.628, F 0.949)] [D acc: (0.562)(0.562, 0.562)] [G loss: 1.307] [G acc: 0.438]\n",
      "13995 [D loss: (0.808)(R 0.725, F 0.891)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.542] [G acc: 0.500]\n",
      "13996 [D loss: (0.813)(R 0.590, F 1.036)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.632] [G acc: 0.625]\n",
      "13997 [D loss: (0.918)(R 0.674, F 1.161)] [D acc: (0.406)(0.500, 0.312)] [G loss: 0.652] [G acc: 0.562]\n",
      "13998 [D loss: (0.970)(R 0.735, F 1.204)] [D acc: (0.281)(0.188, 0.375)] [G loss: 0.659] [G acc: 0.438]\n",
      "13999 [D loss: (0.767)(R 0.693, F 0.841)] [D acc: (0.406)(0.312, 0.500)] [G loss: 0.422] [G acc: 0.688]\n",
      "14000 [D loss: (0.678)(R 0.508, F 0.849)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.697] [G acc: 0.500]\n",
      "14001 [D loss: (1.197)(R 0.724, F 1.671)] [D acc: (0.312)(0.375, 0.250)] [G loss: 0.705] [G acc: 0.375]\n",
      "14002 [D loss: (0.678)(R 0.661, F 0.695)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.511] [G acc: 0.750]\n",
      "14003 [D loss: (0.798)(R 0.590, F 1.006)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.392] [G acc: 0.812]\n",
      "14004 [D loss: (0.695)(R 0.563, F 0.826)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.571] [G acc: 0.500]\n",
      "14005 [D loss: (0.722)(R 0.670, F 0.775)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.505] [G acc: 0.500]\n",
      "14006 [D loss: (0.946)(R 0.546, F 1.346)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.694] [G acc: 0.312]\n",
      "14007 [D loss: (0.721)(R 0.709, F 0.732)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.690] [G acc: 0.500]\n",
      "14008 [D loss: (0.692)(R 0.661, F 0.724)] [D acc: (0.375)(0.500, 0.250)] [G loss: 1.444] [G acc: 0.562]\n",
      "14009 [D loss: (0.708)(R 0.579, F 0.837)] [D acc: (0.469)(0.500, 0.438)] [G loss: 1.128] [G acc: 0.312]\n",
      "14010 [D loss: (0.746)(R 0.686, F 0.806)] [D acc: (0.438)(0.562, 0.312)] [G loss: 1.036] [G acc: 0.562]\n",
      "14011 [D loss: (0.710)(R 0.673, F 0.746)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.625] [G acc: 0.500]\n",
      "14012 [D loss: (0.669)(R 0.662, F 0.675)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.672] [G acc: 0.562]\n",
      "14013 [D loss: (0.653)(R 0.584, F 0.723)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.693] [G acc: 0.438]\n",
      "14014 [D loss: (0.693)(R 0.608, F 0.778)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.852] [G acc: 0.312]\n",
      "14015 [D loss: (0.690)(R 0.672, F 0.708)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.642] [G acc: 0.562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14016 [D loss: (0.687)(R 0.642, F 0.732)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.711] [G acc: 0.250]\n",
      "14017 [D loss: (0.616)(R 0.550, F 0.683)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.698] [G acc: 0.438]\n",
      "14018 [D loss: (0.621)(R 0.550, F 0.691)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.711] [G acc: 0.188]\n",
      "14019 [D loss: (0.647)(R 0.637, F 0.657)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.688] [G acc: 0.500]\n",
      "14020 [D loss: (0.685)(R 0.660, F 0.711)] [D acc: (0.406)(0.625, 0.188)] [G loss: 0.701] [G acc: 0.500]\n",
      "14021 [D loss: (0.673)(R 0.651, F 0.694)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.728] [G acc: 0.312]\n",
      "14022 [D loss: (0.679)(R 0.662, F 0.697)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.723] [G acc: 0.312]\n",
      "14023 [D loss: (0.651)(R 0.616, F 0.686)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.714] [G acc: 0.438]\n",
      "14024 [D loss: (0.560)(R 0.457, F 0.663)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.697] [G acc: 0.312]\n",
      "14025 [D loss: (0.654)(R 0.613, F 0.694)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.617] [G acc: 0.562]\n",
      "14026 [D loss: (0.698)(R 0.634, F 0.762)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.734] [G acc: 0.312]\n",
      "14027 [D loss: (0.658)(R 0.654, F 0.662)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.700] [G acc: 0.500]\n",
      "14028 [D loss: (0.637)(R 0.591, F 0.683)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.738] [G acc: 0.312]\n",
      "14029 [D loss: (0.621)(R 0.575, F 0.667)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.751] [G acc: 0.125]\n",
      "14030 [D loss: (0.571)(R 0.476, F 0.667)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.744] [G acc: 0.312]\n",
      "14031 [D loss: (0.676)(R 0.686, F 0.666)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.753] [G acc: 0.375]\n",
      "14032 [D loss: (0.589)(R 0.559, F 0.619)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.627] [G acc: 0.688]\n",
      "14033 [D loss: (0.594)(R 0.556, F 0.632)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.734] [G acc: 0.500]\n",
      "14034 [D loss: (0.575)(R 0.582, F 0.567)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.718] [G acc: 0.312]\n",
      "14035 [D loss: (0.615)(R 0.528, F 0.702)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.794] [G acc: 0.125]\n",
      "14036 [D loss: (0.533)(R 0.480, F 0.586)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.862] [G acc: 0.500]\n",
      "14037 [D loss: (0.512)(R 0.572, F 0.452)] [D acc: (0.781)(0.812, 0.750)] [G loss: 2.772] [G acc: 0.188]\n",
      "14038 [D loss: (0.458)(R 0.714, F 0.202)] [D acc: (0.781)(0.625, 0.938)] [G loss: 4.239] [G acc: 0.250]\n",
      "14039 [D loss: (0.590)(R 0.617, F 0.563)] [D acc: (0.844)(0.875, 0.812)] [G loss: 0.898] [G acc: 0.188]\n",
      "14040 [D loss: (0.612)(R 0.575, F 0.649)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.806] [G acc: 0.312]\n",
      "14041 [D loss: (0.543)(R 0.475, F 0.611)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.813] [G acc: 0.312]\n",
      "14042 [D loss: (0.579)(R 0.497, F 0.661)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.834] [G acc: 0.125]\n",
      "14043 [D loss: (0.528)(R 0.487, F 0.569)] [D acc: (0.844)(0.750, 0.938)] [G loss: 0.813] [G acc: 0.188]\n",
      "14044 [D loss: (0.596)(R 0.596, F 0.596)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.924] [G acc: 0.188]\n",
      "14045 [D loss: (0.580)(R 0.566, F 0.593)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.872] [G acc: 0.188]\n",
      "14046 [D loss: (0.490)(R 0.377, F 0.603)] [D acc: (0.844)(0.938, 0.750)] [G loss: 0.971] [G acc: 0.188]\n",
      "14047 [D loss: (0.491)(R 0.377, F 0.605)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.925] [G acc: 0.125]\n",
      "14048 [D loss: (0.532)(R 0.502, F 0.563)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.792] [G acc: 0.688]\n",
      "14049 [D loss: (0.568)(R 0.596, F 0.540)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.189] [G acc: 0.188]\n",
      "14050 [D loss: (0.520)(R 0.492, F 0.547)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.951] [G acc: 0.188]\n",
      "14051 [D loss: (0.540)(R 0.582, F 0.497)] [D acc: (0.875)(0.938, 0.812)] [G loss: 0.995] [G acc: 0.250]\n",
      "14052 [D loss: (0.666)(R 0.776, F 0.556)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.880] [G acc: 0.375]\n",
      "14053 [D loss: (0.472)(R 0.467, F 0.477)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.741] [G acc: 0.125]\n",
      "14054 [D loss: (0.448)(R 0.536, F 0.360)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.035] [G acc: 0.312]\n",
      "14055 [D loss: (0.422)(R 0.484, F 0.361)] [D acc: (0.906)(0.875, 0.938)] [G loss: 1.110] [G acc: 0.188]\n",
      "14056 [D loss: (0.412)(R 0.396, F 0.427)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.563] [G acc: 0.062]\n",
      "14057 [D loss: (0.444)(R 0.474, F 0.414)] [D acc: (0.781)(0.688, 0.875)] [G loss: 2.113] [G acc: 0.125]\n",
      "14058 [D loss: (0.561)(R 0.646, F 0.476)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.040] [G acc: 0.375]\n",
      "14059 [D loss: (0.435)(R 0.318, F 0.552)] [D acc: (0.844)(0.938, 0.750)] [G loss: 1.183] [G acc: 0.188]\n",
      "14060 [D loss: (0.483)(R 0.514, F 0.452)] [D acc: (0.938)(0.938, 0.938)] [G loss: 1.192] [G acc: 0.125]\n",
      "14061 [D loss: (0.520)(R 0.457, F 0.583)] [D acc: (0.906)(1.000, 0.812)] [G loss: 1.594] [G acc: 0.188]\n",
      "14062 [D loss: (0.436)(R 0.514, F 0.358)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.998] [G acc: 0.438]\n",
      "14063 [D loss: (0.459)(R 0.571, F 0.346)] [D acc: (0.875)(0.750, 1.000)] [G loss: 1.392] [G acc: 0.188]\n",
      "14064 [D loss: (0.768)(R 0.557, F 0.979)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.292] [G acc: 0.312]\n",
      "14065 [D loss: (0.414)(R 0.406, F 0.422)] [D acc: (0.906)(1.000, 0.812)] [G loss: 1.354] [G acc: 0.250]\n",
      "14066 [D loss: (0.600)(R 0.779, F 0.421)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.577] [G acc: 0.188]\n",
      "14067 [D loss: (0.761)(R 0.497, F 1.026)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.364] [G acc: 0.312]\n",
      "14068 [D loss: (0.445)(R 0.472, F 0.417)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.958] [G acc: 0.375]\n",
      "14069 [D loss: (0.502)(R 0.405, F 0.598)] [D acc: (0.812)(0.938, 0.688)] [G loss: 1.256] [G acc: 0.188]\n",
      "14070 [D loss: (0.370)(R 0.438, F 0.302)] [D acc: (0.844)(0.875, 0.812)] [G loss: 2.043] [G acc: 0.250]\n",
      "14071 [D loss: (0.401)(R 0.372, F 0.429)] [D acc: (0.844)(1.000, 0.688)] [G loss: 1.539] [G acc: 0.438]\n",
      "14072 [D loss: (0.514)(R 0.559, F 0.469)] [D acc: (0.625)(0.750, 0.500)] [G loss: 2.504] [G acc: 0.312]\n",
      "14073 [D loss: (0.413)(R 0.494, F 0.332)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.152] [G acc: 0.375]\n",
      "14074 [D loss: (0.415)(R 0.504, F 0.326)] [D acc: (0.906)(0.938, 0.875)] [G loss: 1.529] [G acc: 0.188]\n",
      "14075 [D loss: (0.419)(R 0.479, F 0.360)] [D acc: (0.844)(0.938, 0.750)] [G loss: 1.546] [G acc: 0.188]\n",
      "14076 [D loss: (0.323)(R 0.430, F 0.217)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.777] [G acc: 0.500]\n",
      "14077 [D loss: (0.305)(R 0.292, F 0.317)] [D acc: (0.875)(1.000, 0.750)] [G loss: 2.442] [G acc: 0.250]\n",
      "14078 [D loss: (0.386)(R 0.412, F 0.360)] [D acc: (0.844)(0.938, 0.750)] [G loss: 1.969] [G acc: 0.188]\n",
      "14079 [D loss: (0.435)(R 0.518, F 0.351)] [D acc: (0.875)(0.938, 0.812)] [G loss: 1.483] [G acc: 0.312]\n",
      "14080 [D loss: (0.382)(R 0.402, F 0.362)] [D acc: (0.906)(1.000, 0.812)] [G loss: 1.860] [G acc: 0.188]\n",
      "14081 [D loss: (0.410)(R 0.392, F 0.428)] [D acc: (0.812)(0.938, 0.688)] [G loss: 1.777] [G acc: 0.188]\n",
      "14082 [D loss: (0.813)(R 0.478, F 1.148)] [D acc: (0.812)(0.938, 0.688)] [G loss: 1.238] [G acc: 0.312]\n",
      "14083 [D loss: (0.492)(R 0.601, F 0.382)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.748] [G acc: 0.125]\n",
      "14084 [D loss: (0.619)(R 0.829, F 0.408)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.881] [G acc: 0.375]\n",
      "14085 [D loss: (0.397)(R 0.670, F 0.124)] [D acc: (0.719)(0.562, 0.875)] [G loss: 4.383] [G acc: 0.375]\n",
      "14086 [D loss: (0.599)(R 0.654, F 0.544)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.295] [G acc: 0.250]\n",
      "14087 [D loss: (0.450)(R 0.458, F 0.441)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.632] [G acc: 0.188]\n",
      "14088 [D loss: (0.483)(R 0.365, F 0.600)] [D acc: (0.719)(0.875, 0.562)] [G loss: 1.237] [G acc: 0.250]\n",
      "14089 [D loss: (0.654)(R 0.597, F 0.711)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.203] [G acc: 0.312]\n",
      "14090 [D loss: (0.728)(R 0.926, F 0.529)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.934] [G acc: 0.500]\n",
      "14091 [D loss: (0.403)(R 0.370, F 0.435)] [D acc: (0.844)(0.938, 0.750)] [G loss: 1.352] [G acc: 0.250]\n",
      "14092 [D loss: (0.630)(R 0.551, F 0.709)] [D acc: (0.719)(0.875, 0.562)] [G loss: 1.834] [G acc: 0.312]\n",
      "14093 [D loss: (0.675)(R 0.918, F 0.432)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.773] [G acc: 0.500]\n",
      "14094 [D loss: (0.534)(R 0.533, F 0.534)] [D acc: (0.781)(0.938, 0.625)] [G loss: 1.428] [G acc: 0.312]\n",
      "14095 [D loss: (0.446)(R 0.446, F 0.446)] [D acc: (0.812)(0.938, 0.688)] [G loss: 1.247] [G acc: 0.312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14096 [D loss: (0.638)(R 0.472, F 0.804)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.841] [G acc: 0.562]\n",
      "14097 [D loss: (0.479)(R 0.490, F 0.467)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.060] [G acc: 0.688]\n",
      "14098 [D loss: (0.554)(R 0.489, F 0.618)] [D acc: (0.594)(0.750, 0.438)] [G loss: 1.773] [G acc: 0.250]\n",
      "14099 [D loss: (0.531)(R 0.407, F 0.654)] [D acc: (0.719)(1.000, 0.438)] [G loss: 1.049] [G acc: 0.375]\n",
      "14100 [D loss: (0.712)(R 0.819, F 0.605)] [D acc: (0.719)(0.875, 0.562)] [G loss: 1.090] [G acc: 0.312]\n",
      "14101 [D loss: (0.944)(R 0.907, F 0.982)] [D acc: (0.625)(0.875, 0.375)] [G loss: 1.010] [G acc: 0.188]\n",
      "14102 [D loss: (0.415)(R 0.306, F 0.525)] [D acc: (0.844)(1.000, 0.688)] [G loss: 0.959] [G acc: 0.500]\n",
      "14103 [D loss: (0.568)(R 0.541, F 0.595)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.957] [G acc: 0.438]\n",
      "14104 [D loss: (0.622)(R 0.640, F 0.604)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.783] [G acc: 0.688]\n",
      "14105 [D loss: (0.501)(R 0.419, F 0.583)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.874] [G acc: 0.438]\n",
      "14106 [D loss: (0.584)(R 0.567, F 0.602)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.250] [G acc: 0.500]\n",
      "14107 [D loss: (0.744)(R 0.718, F 0.769)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.805] [G acc: 0.438]\n",
      "14108 [D loss: (0.688)(R 0.686, F 0.689)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.981] [G acc: 0.312]\n",
      "14109 [D loss: (0.593)(R 0.596, F 0.591)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.927] [G acc: 0.438]\n",
      "14110 [D loss: (0.716)(R 0.552, F 0.880)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.697] [G acc: 0.625]\n",
      "14111 [D loss: (0.799)(R 0.541, F 1.057)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.850] [G acc: 0.562]\n",
      "14112 [D loss: (0.624)(R 0.682, F 0.566)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.773] [G acc: 0.500]\n",
      "14113 [D loss: (0.669)(R 0.680, F 0.659)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.726] [G acc: 0.625]\n",
      "14114 [D loss: (0.743)(R 0.679, F 0.807)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.859] [G acc: 0.625]\n",
      "14115 [D loss: (0.942)(R 0.486, F 1.399)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.744] [G acc: 0.438]\n",
      "14116 [D loss: (0.621)(R 0.422, F 0.820)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.694] [G acc: 0.562]\n",
      "14117 [D loss: (0.776)(R 0.590, F 0.961)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.694] [G acc: 0.625]\n",
      "14118 [D loss: (0.768)(R 0.705, F 0.830)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.907] [G acc: 0.312]\n",
      "14119 [D loss: (0.541)(R 0.451, F 0.632)] [D acc: (0.750)(0.812, 0.688)] [G loss: 4.202] [G acc: 0.500]\n",
      "14120 [D loss: (0.755)(R 0.735, F 0.775)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.624] [G acc: 0.562]\n",
      "14121 [D loss: (0.577)(R 0.401, F 0.752)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.658] [G acc: 0.625]\n",
      "14122 [D loss: (0.608)(R 0.489, F 0.726)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.955] [G acc: 0.562]\n",
      "14123 [D loss: (0.541)(R 0.404, F 0.678)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.706] [G acc: 0.688]\n",
      "14124 [D loss: (0.702)(R 0.694, F 0.710)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.659] [G acc: 0.500]\n",
      "14125 [D loss: (0.862)(R 0.901, F 0.823)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.785] [G acc: 0.500]\n",
      "14126 [D loss: (0.665)(R 0.516, F 0.814)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.779] [G acc: 0.500]\n",
      "14127 [D loss: (0.669)(R 0.564, F 0.773)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.663] [G acc: 0.562]\n",
      "14128 [D loss: (0.659)(R 0.620, F 0.699)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.731] [G acc: 0.625]\n",
      "14129 [D loss: (0.780)(R 0.624, F 0.935)] [D acc: (0.438)(0.812, 0.062)] [G loss: 0.722] [G acc: 0.562]\n",
      "14130 [D loss: (0.727)(R 0.617, F 0.836)] [D acc: (0.438)(0.688, 0.188)] [G loss: 0.667] [G acc: 0.688]\n",
      "14131 [D loss: (0.613)(R 0.437, F 0.789)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.642] [G acc: 0.750]\n",
      "14132 [D loss: (0.574)(R 0.416, F 0.732)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.715] [G acc: 0.562]\n",
      "14133 [D loss: (0.747)(R 0.581, F 0.913)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.714] [G acc: 0.500]\n",
      "14134 [D loss: (0.754)(R 0.623, F 0.885)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.727] [G acc: 0.500]\n",
      "14135 [D loss: (0.685)(R 0.618, F 0.752)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.714] [G acc: 0.562]\n",
      "14136 [D loss: (0.615)(R 0.490, F 0.739)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.685] [G acc: 0.625]\n",
      "14137 [D loss: (0.679)(R 0.524, F 0.834)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.671] [G acc: 0.688]\n",
      "14138 [D loss: (0.668)(R 0.611, F 0.725)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.812] [G acc: 0.312]\n",
      "14139 [D loss: (0.572)(R 0.494, F 0.650)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.888] [G acc: 0.500]\n",
      "14140 [D loss: (0.646)(R 0.625, F 0.668)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.730] [G acc: 0.438]\n",
      "14141 [D loss: (0.619)(R 0.603, F 0.636)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.794] [G acc: 0.375]\n",
      "14142 [D loss: (0.616)(R 0.556, F 0.675)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.755] [G acc: 0.500]\n",
      "14143 [D loss: (0.637)(R 0.594, F 0.679)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.622] [G acc: 0.625]\n",
      "14144 [D loss: (0.689)(R 0.557, F 0.822)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.768] [G acc: 0.438]\n",
      "14145 [D loss: (0.670)(R 0.515, F 0.826)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.656] [G acc: 0.625]\n",
      "14146 [D loss: (0.652)(R 0.694, F 0.611)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.712] [G acc: 0.500]\n",
      "14147 [D loss: (0.783)(R 0.583, F 0.983)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.677] [G acc: 0.500]\n",
      "14148 [D loss: (0.756)(R 0.611, F 0.901)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.666] [G acc: 0.688]\n",
      "14149 [D loss: (1.179)(R 0.586, F 1.773)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.639] [G acc: 0.625]\n",
      "14150 [D loss: (0.953)(R 0.640, F 1.267)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.624] [G acc: 0.562]\n",
      "14151 [D loss: (1.006)(R 0.653, F 1.360)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.534] [G acc: 0.750]\n",
      "14152 [D loss: (0.806)(R 0.603, F 1.009)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.537] [G acc: 0.625]\n",
      "14153 [D loss: (1.001)(R 0.646, F 1.357)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.504] [G acc: 0.812]\n",
      "14154 [D loss: (0.792)(R 0.636, F 0.948)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.723] [G acc: 0.375]\n",
      "14155 [D loss: (0.816)(R 0.601, F 1.030)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.564] [G acc: 0.688]\n",
      "14156 [D loss: (0.937)(R 0.657, F 1.217)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.700] [G acc: 0.562]\n",
      "14157 [D loss: (0.761)(R 0.631, F 0.890)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.654] [G acc: 0.562]\n",
      "14158 [D loss: (0.919)(R 0.570, F 1.269)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.672] [G acc: 0.562]\n",
      "14159 [D loss: (1.005)(R 0.643, F 1.367)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.661] [G acc: 0.625]\n",
      "14160 [D loss: (0.844)(R 0.618, F 1.070)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.988] [G acc: 0.625]\n",
      "14161 [D loss: (0.729)(R 0.626, F 0.833)] [D acc: (0.688)(0.875, 0.500)] [G loss: 3.809] [G acc: 0.375]\n",
      "14162 [D loss: (0.752)(R 0.656, F 0.849)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.737] [G acc: 0.438]\n",
      "14163 [D loss: (0.738)(R 0.611, F 0.865)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.569] [G acc: 0.812]\n",
      "14164 [D loss: (0.842)(R 0.589, F 1.096)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.620] [G acc: 0.812]\n",
      "14165 [D loss: (0.682)(R 0.606, F 0.759)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.638] [G acc: 0.812]\n",
      "14166 [D loss: (1.113)(R 0.569, F 1.658)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.761] [G acc: 0.438]\n",
      "14167 [D loss: (0.719)(R 0.615, F 0.822)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.701] [G acc: 0.375]\n",
      "14168 [D loss: (0.882)(R 0.670, F 1.093)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.842] [G acc: 0.312]\n",
      "14169 [D loss: (0.826)(R 0.649, F 1.003)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.812] [G acc: 0.188]\n",
      "14170 [D loss: (0.639)(R 0.554, F 0.723)] [D acc: (0.750)(0.938, 0.562)] [G loss: 0.634] [G acc: 0.625]\n",
      "14171 [D loss: (1.019)(R 0.739, F 1.299)] [D acc: (0.406)(0.500, 0.312)] [G loss: 0.706] [G acc: 0.500]\n",
      "14172 [D loss: (0.722)(R 0.724, F 0.719)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.663] [G acc: 0.625]\n",
      "14173 [D loss: (0.959)(R 0.681, F 1.236)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.809] [G acc: 0.375]\n",
      "14174 [D loss: (0.925)(R 1.123, F 0.726)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.669] [G acc: 0.562]\n",
      "14175 [D loss: (0.663)(R 0.613, F 0.713)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.771] [G acc: 0.250]\n",
      "14176 [D loss: (0.872)(R 0.634, F 1.110)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.514] [G acc: 0.688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14177 [D loss: (1.020)(R 0.667, F 1.372)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.637] [G acc: 0.562]\n",
      "14178 [D loss: (0.980)(R 0.587, F 1.373)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.775] [G acc: 0.562]\n",
      "14179 [D loss: (0.852)(R 0.656, F 1.048)] [D acc: (0.688)(0.875, 0.500)] [G loss: 1.022] [G acc: 0.250]\n",
      "14180 [D loss: (0.593)(R 0.677, F 0.510)] [D acc: (0.625)(0.688, 0.562)] [G loss: 3.693] [G acc: 0.438]\n",
      "14181 [D loss: (0.488)(R 0.515, F 0.461)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.506] [G acc: 0.438]\n",
      "14182 [D loss: (1.106)(R 0.740, F 1.473)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.543] [G acc: 0.750]\n",
      "14183 [D loss: (0.973)(R 0.608, F 1.339)] [D acc: (0.719)(1.000, 0.438)] [G loss: 0.792] [G acc: 0.438]\n",
      "14184 [D loss: (0.926)(R 0.683, F 1.169)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.690] [G acc: 0.438]\n",
      "14185 [D loss: (0.773)(R 0.642, F 0.904)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.880] [G acc: 0.250]\n",
      "14186 [D loss: (1.128)(R 0.573, F 1.684)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.763] [G acc: 0.438]\n",
      "14187 [D loss: (0.635)(R 0.534, F 0.737)] [D acc: (0.688)(0.875, 0.500)] [G loss: 1.031] [G acc: 0.188]\n",
      "14188 [D loss: (0.727)(R 0.628, F 0.827)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.806] [G acc: 0.312]\n",
      "14189 [D loss: (0.659)(R 0.672, F 0.647)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.813] [G acc: 0.438]\n",
      "14190 [D loss: (0.728)(R 0.639, F 0.817)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.630] [G acc: 0.688]\n",
      "14191 [D loss: (0.765)(R 0.905, F 0.626)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.714] [G acc: 0.562]\n",
      "14192 [D loss: (0.681)(R 0.706, F 0.655)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.786] [G acc: 0.500]\n",
      "14193 [D loss: (0.644)(R 0.658, F 0.630)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.708] [G acc: 0.500]\n",
      "14194 [D loss: (0.694)(R 0.753, F 0.636)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.778] [G acc: 0.438]\n",
      "14195 [D loss: (0.651)(R 0.633, F 0.669)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.770] [G acc: 0.625]\n",
      "14196 [D loss: (0.660)(R 0.646, F 0.673)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.651] [G acc: 0.688]\n",
      "14197 [D loss: (0.713)(R 0.657, F 0.769)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.868] [G acc: 0.375]\n",
      "14198 [D loss: (0.663)(R 0.638, F 0.689)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.642] [G acc: 0.625]\n",
      "14199 [D loss: (0.603)(R 0.579, F 0.627)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.636] [G acc: 0.625]\n",
      "14200 [D loss: (0.892)(R 0.643, F 1.141)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.845] [G acc: 0.375]\n",
      "14201 [D loss: (0.672)(R 0.625, F 0.719)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.805] [G acc: 0.438]\n",
      "14202 [D loss: (0.645)(R 0.639, F 0.650)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.510] [G acc: 0.750]\n",
      "14203 [D loss: (0.903)(R 0.607, F 1.199)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.474] [G acc: 0.875]\n",
      "14204 [D loss: (0.614)(R 0.632, F 0.595)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.502] [G acc: 0.688]\n",
      "14205 [D loss: (0.562)(R 0.514, F 0.610)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.807] [G acc: 0.438]\n",
      "14206 [D loss: (0.927)(R 0.647, F 1.206)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.860] [G acc: 0.500]\n",
      "14207 [D loss: (0.797)(R 0.626, F 0.968)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.922] [G acc: 0.375]\n",
      "14208 [D loss: (0.611)(R 0.670, F 0.552)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.810] [G acc: 0.438]\n",
      "14209 [D loss: (0.965)(R 0.655, F 1.276)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.834] [G acc: 0.438]\n",
      "14210 [D loss: (0.627)(R 0.671, F 0.582)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.794] [G acc: 0.562]\n",
      "14211 [D loss: (0.582)(R 0.579, F 0.585)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.928] [G acc: 0.188]\n",
      "14212 [D loss: (0.648)(R 0.612, F 0.684)] [D acc: (0.781)(1.000, 0.562)] [G loss: 0.663] [G acc: 0.500]\n",
      "14213 [D loss: (0.793)(R 0.656, F 0.931)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.961] [G acc: 0.375]\n",
      "14214 [D loss: (0.700)(R 0.641, F 0.760)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.793] [G acc: 0.562]\n",
      "14215 [D loss: (0.606)(R 0.655, F 0.557)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.956] [G acc: 0.312]\n",
      "14216 [D loss: (0.667)(R 0.701, F 0.632)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.925] [G acc: 0.500]\n",
      "14217 [D loss: (0.579)(R 0.570, F 0.589)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.797] [G acc: 0.375]\n",
      "14218 [D loss: (0.563)(R 0.574, F 0.551)] [D acc: (0.750)(0.938, 0.562)] [G loss: 0.895] [G acc: 0.250]\n",
      "14219 [D loss: (0.550)(R 0.589, F 0.511)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.897] [G acc: 0.312]\n",
      "14220 [D loss: (0.631)(R 0.635, F 0.627)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.925] [G acc: 0.250]\n",
      "14221 [D loss: (0.595)(R 0.675, F 0.515)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.145] [G acc: 0.188]\n",
      "14222 [D loss: (0.559)(R 0.637, F 0.481)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.919] [G acc: 0.438]\n",
      "14223 [D loss: (0.529)(R 0.617, F 0.442)] [D acc: (0.875)(0.875, 0.875)] [G loss: 0.978] [G acc: 0.438]\n",
      "14224 [D loss: (0.611)(R 0.681, F 0.540)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.043] [G acc: 0.312]\n",
      "14225 [D loss: (0.608)(R 0.650, F 0.567)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.962] [G acc: 0.188]\n",
      "14226 [D loss: (0.657)(R 0.665, F 0.649)] [D acc: (0.562)(0.688, 0.438)] [G loss: 2.486] [G acc: 0.500]\n",
      "14227 [D loss: (0.598)(R 0.669, F 0.527)] [D acc: (0.625)(0.750, 0.500)] [G loss: 1.339] [G acc: 0.250]\n",
      "14228 [D loss: (0.530)(R 0.613, F 0.446)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.940] [G acc: 0.250]\n",
      "14229 [D loss: (0.661)(R 0.718, F 0.605)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.904] [G acc: 0.375]\n",
      "14230 [D loss: (0.578)(R 0.595, F 0.562)] [D acc: (0.781)(0.938, 0.625)] [G loss: 1.106] [G acc: 0.438]\n",
      "14231 [D loss: (0.603)(R 0.600, F 0.605)] [D acc: (0.625)(0.875, 0.375)] [G loss: 1.007] [G acc: 0.438]\n",
      "14232 [D loss: (0.574)(R 0.616, F 0.532)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.194] [G acc: 0.125]\n",
      "14233 [D loss: (0.579)(R 0.569, F 0.590)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.890] [G acc: 0.375]\n",
      "14234 [D loss: (0.561)(R 0.644, F 0.479)] [D acc: (0.656)(0.562, 0.750)] [G loss: 2.042] [G acc: 0.188]\n",
      "14235 [D loss: (0.571)(R 0.611, F 0.532)] [D acc: (0.781)(0.938, 0.625)] [G loss: 1.128] [G acc: 0.375]\n",
      "14236 [D loss: (0.603)(R 0.643, F 0.563)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.927] [G acc: 0.375]\n",
      "14237 [D loss: (0.529)(R 0.611, F 0.448)] [D acc: (0.750)(0.875, 0.625)] [G loss: 1.292] [G acc: 0.250]\n",
      "14238 [D loss: (0.581)(R 0.612, F 0.550)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.427] [G acc: 0.312]\n",
      "14239 [D loss: (0.581)(R 0.691, F 0.470)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.214] [G acc: 0.375]\n",
      "14240 [D loss: (0.587)(R 0.612, F 0.562)] [D acc: (0.656)(0.875, 0.438)] [G loss: 1.596] [G acc: 0.312]\n",
      "14241 [D loss: (0.586)(R 0.623, F 0.550)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.125] [G acc: 0.312]\n",
      "14242 [D loss: (0.657)(R 0.705, F 0.610)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.643] [G acc: 0.812]\n",
      "14243 [D loss: (0.584)(R 0.702, F 0.466)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.685] [G acc: 0.375]\n",
      "14244 [D loss: (0.568)(R 0.610, F 0.526)] [D acc: (0.688)(0.812, 0.562)] [G loss: 1.367] [G acc: 0.438]\n",
      "14245 [D loss: (0.572)(R 0.646, F 0.498)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.771] [G acc: 0.312]\n",
      "14246 [D loss: (0.734)(R 0.790, F 0.678)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.826] [G acc: 0.438]\n",
      "14247 [D loss: (0.670)(R 0.627, F 0.714)] [D acc: (0.625)(0.938, 0.312)] [G loss: 1.197] [G acc: 0.250]\n",
      "14248 [D loss: (0.711)(R 0.841, F 0.581)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.724] [G acc: 0.500]\n",
      "14249 [D loss: (0.602)(R 0.580, F 0.624)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.739] [G acc: 0.500]\n",
      "14250 [D loss: (0.615)(R 0.705, F 0.525)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.089] [G acc: 0.375]\n",
      "14251 [D loss: (0.628)(R 0.666, F 0.590)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.896] [G acc: 0.500]\n",
      "14252 [D loss: (0.617)(R 0.703, F 0.531)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.077] [G acc: 0.312]\n",
      "14253 [D loss: (0.677)(R 0.668, F 0.687)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.750] [G acc: 0.562]\n",
      "14254 [D loss: (0.629)(R 0.641, F 0.616)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.831] [G acc: 0.312]\n",
      "14255 [D loss: (0.752)(R 0.789, F 0.715)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.889] [G acc: 0.375]\n",
      "14256 [D loss: (0.607)(R 0.597, F 0.617)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.696] [G acc: 0.625]\n",
      "14257 [D loss: (0.648)(R 0.647, F 0.648)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.859] [G acc: 0.438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14258 [D loss: (0.658)(R 0.672, F 0.644)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.808] [G acc: 0.438]\n",
      "14259 [D loss: (0.747)(R 0.808, F 0.686)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.830] [G acc: 0.312]\n",
      "14260 [D loss: (0.675)(R 0.607, F 0.743)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.686] [G acc: 0.688]\n",
      "14261 [D loss: (0.743)(R 0.794, F 0.691)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.785] [G acc: 0.500]\n",
      "14262 [D loss: (0.750)(R 0.714, F 0.787)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.859] [G acc: 0.438]\n",
      "14263 [D loss: (0.749)(R 0.757, F 0.741)] [D acc: (0.406)(0.625, 0.188)] [G loss: 0.714] [G acc: 0.625]\n",
      "14264 [D loss: (0.707)(R 0.725, F 0.689)] [D acc: (0.469)(0.562, 0.375)] [G loss: 2.102] [G acc: 0.188]\n",
      "14265 [D loss: (0.651)(R 0.852, F 0.450)] [D acc: (0.688)(0.625, 0.750)] [G loss: 6.123] [G acc: 0.375]\n",
      "14266 [D loss: (0.602)(R 0.551, F 0.654)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.805] [G acc: 0.312]\n",
      "14267 [D loss: (0.681)(R 0.701, F 0.660)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.780] [G acc: 0.312]\n",
      "14268 [D loss: (0.685)(R 0.735, F 0.636)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.855] [G acc: 0.250]\n",
      "14269 [D loss: (0.718)(R 0.779, F 0.657)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.781] [G acc: 0.375]\n",
      "14270 [D loss: (0.763)(R 0.835, F 0.691)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.873] [G acc: 0.312]\n",
      "14271 [D loss: (0.623)(R 0.625, F 0.622)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.814] [G acc: 0.250]\n",
      "14272 [D loss: (0.710)(R 0.793, F 0.627)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.812] [G acc: 0.312]\n",
      "14273 [D loss: (0.661)(R 0.696, F 0.627)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.815] [G acc: 0.312]\n",
      "14274 [D loss: (0.682)(R 0.713, F 0.650)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.872] [G acc: 0.312]\n",
      "14275 [D loss: (0.708)(R 0.721, F 0.695)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.751] [G acc: 0.562]\n",
      "14276 [D loss: (1.029)(R 1.455, F 0.602)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.887] [G acc: 0.125]\n",
      "14277 [D loss: (0.661)(R 0.736, F 0.586)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.744] [G acc: 0.500]\n",
      "14278 [D loss: (0.665)(R 0.690, F 0.640)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.750] [G acc: 0.438]\n",
      "14279 [D loss: (0.695)(R 0.767, F 0.624)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.842] [G acc: 0.188]\n",
      "14280 [D loss: (0.654)(R 0.682, F 0.627)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.827] [G acc: 0.312]\n",
      "14281 [D loss: (0.682)(R 0.678, F 0.686)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.773] [G acc: 0.438]\n",
      "14282 [D loss: (0.728)(R 0.876, F 0.579)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.827] [G acc: 0.375]\n",
      "14283 [D loss: (0.742)(R 0.752, F 0.733)] [D acc: (0.406)(0.500, 0.312)] [G loss: 0.833] [G acc: 0.312]\n",
      "14284 [D loss: (0.658)(R 0.674, F 0.641)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.924] [G acc: 0.250]\n",
      "14285 [D loss: (0.646)(R 0.673, F 0.619)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.862] [G acc: 0.312]\n",
      "14286 [D loss: (0.657)(R 0.711, F 0.602)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.942] [G acc: 0.062]\n",
      "14287 [D loss: (0.741)(R 0.886, F 0.595)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.732] [G acc: 0.625]\n",
      "14288 [D loss: (0.635)(R 0.649, F 0.620)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.870] [G acc: 0.250]\n",
      "14289 [D loss: (0.662)(R 0.672, F 0.651)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.021] [G acc: 0.312]\n",
      "14290 [D loss: (0.696)(R 0.743, F 0.650)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.943] [G acc: 0.312]\n",
      "14291 [D loss: (0.687)(R 0.748, F 0.627)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.725] [G acc: 0.500]\n",
      "14292 [D loss: (0.679)(R 0.708, F 0.650)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.962] [G acc: 0.375]\n",
      "14293 [D loss: (0.711)(R 0.791, F 0.631)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.785] [G acc: 0.438]\n",
      "14294 [D loss: (0.695)(R 0.725, F 0.665)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.936] [G acc: 0.375]\n",
      "14295 [D loss: (0.705)(R 0.820, F 0.590)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.932] [G acc: 0.250]\n",
      "14296 [D loss: (0.714)(R 0.768, F 0.660)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.785] [G acc: 0.375]\n",
      "14297 [D loss: (0.655)(R 0.641, F 0.669)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.880] [G acc: 0.438]\n",
      "14298 [D loss: (0.722)(R 0.786, F 0.658)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.862] [G acc: 0.312]\n",
      "14299 [D loss: (0.718)(R 0.802, F 0.634)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.800] [G acc: 0.438]\n",
      "14300 [D loss: (0.700)(R 0.676, F 0.723)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.766] [G acc: 0.438]\n",
      "14301 [D loss: (0.735)(R 0.848, F 0.622)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.826] [G acc: 0.312]\n",
      "14302 [D loss: (0.638)(R 0.632, F 0.643)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.771] [G acc: 0.375]\n",
      "14303 [D loss: (0.654)(R 0.684, F 0.624)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.948] [G acc: 0.188]\n",
      "14304 [D loss: (0.709)(R 0.698, F 0.720)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.994] [G acc: 0.250]\n",
      "14305 [D loss: (0.687)(R 0.778, F 0.597)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.807] [G acc: 0.250]\n",
      "14306 [D loss: (0.717)(R 0.821, F 0.613)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.776] [G acc: 0.375]\n",
      "14307 [D loss: (0.846)(R 1.052, F 0.640)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.748] [G acc: 0.562]\n",
      "14308 [D loss: (0.617)(R 0.564, F 0.669)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.826] [G acc: 0.250]\n",
      "14309 [D loss: (0.710)(R 0.750, F 0.670)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.758] [G acc: 0.562]\n",
      "14310 [D loss: (0.678)(R 0.671, F 0.685)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.661] [G acc: 0.812]\n",
      "14311 [D loss: (0.802)(R 0.868, F 0.735)] [D acc: (0.344)(0.375, 0.312)] [G loss: 0.734] [G acc: 0.625]\n",
      "14312 [D loss: (0.694)(R 0.671, F 0.717)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.640] [G acc: 0.812]\n",
      "14313 [D loss: (0.714)(R 0.648, F 0.779)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.766] [G acc: 0.500]\n",
      "14314 [D loss: (0.607)(R 0.550, F 0.664)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.801] [G acc: 0.438]\n",
      "14315 [D loss: (0.760)(R 0.783, F 0.737)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.730] [G acc: 0.562]\n",
      "14316 [D loss: (0.668)(R 0.565, F 0.771)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.700] [G acc: 0.688]\n",
      "14317 [D loss: (0.765)(R 0.714, F 0.815)] [D acc: (0.281)(0.562, 0.000)] [G loss: 0.809] [G acc: 0.500]\n",
      "14318 [D loss: (0.665)(R 0.602, F 0.729)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.689] [G acc: 0.688]\n",
      "14319 [D loss: (0.695)(R 0.711, F 0.679)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.645] [G acc: 0.812]\n",
      "14320 [D loss: (0.723)(R 0.630, F 0.817)] [D acc: (0.438)(0.688, 0.188)] [G loss: 0.715] [G acc: 0.688]\n",
      "14321 [D loss: (0.744)(R 0.656, F 0.832)] [D acc: (0.375)(0.750, 0.000)] [G loss: 0.712] [G acc: 0.688]\n",
      "14322 [D loss: (0.666)(R 0.589, F 0.743)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.726] [G acc: 0.562]\n",
      "14323 [D loss: (0.704)(R 0.666, F 0.742)] [D acc: (0.406)(0.625, 0.188)] [G loss: 0.705] [G acc: 0.812]\n",
      "14324 [D loss: (0.646)(R 0.591, F 0.701)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.614] [G acc: 0.938]\n",
      "14325 [D loss: (0.696)(R 0.704, F 0.688)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.774] [G acc: 0.562]\n",
      "14326 [D loss: (0.636)(R 0.620, F 0.651)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.702] [G acc: 0.688]\n",
      "14327 [D loss: (0.712)(R 0.640, F 0.783)] [D acc: (0.406)(0.750, 0.062)] [G loss: 0.669] [G acc: 0.688]\n",
      "14328 [D loss: (0.575)(R 0.542, F 0.607)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.638] [G acc: 0.812]\n",
      "14329 [D loss: (0.641)(R 0.825, F 0.458)] [D acc: (0.469)(0.438, 0.500)] [G loss: 6.782] [G acc: 0.250]\n",
      "14330 [D loss: (0.567)(R 0.658, F 0.477)] [D acc: (0.656)(0.750, 0.562)] [G loss: 2.372] [G acc: 0.375]\n",
      "14331 [D loss: (0.646)(R 0.550, F 0.741)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.736] [G acc: 0.562]\n",
      "14332 [D loss: (0.688)(R 0.685, F 0.692)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.739] [G acc: 0.438]\n",
      "14333 [D loss: (0.595)(R 0.547, F 0.643)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.695] [G acc: 0.500]\n",
      "14334 [D loss: (0.795)(R 0.900, F 0.690)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.791] [G acc: 0.438]\n",
      "14335 [D loss: (0.687)(R 0.636, F 0.738)] [D acc: (0.438)(0.688, 0.188)] [G loss: 0.762] [G acc: 0.375]\n",
      "14336 [D loss: (0.710)(R 0.694, F 0.726)] [D acc: (0.500)(0.625, 0.375)] [G loss: 1.049] [G acc: 0.250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14337 [D loss: (0.653)(R 0.573, F 0.732)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.824] [G acc: 0.188]\n",
      "14338 [D loss: (0.685)(R 0.684, F 0.687)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.680] [G acc: 0.750]\n",
      "14339 [D loss: (0.676)(R 0.624, F 0.728)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.711] [G acc: 0.625]\n",
      "14340 [D loss: (0.690)(R 0.646, F 0.734)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.725] [G acc: 0.438]\n",
      "14341 [D loss: (0.671)(R 0.633, F 0.708)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.716] [G acc: 0.500]\n",
      "14342 [D loss: (0.667)(R 0.606, F 0.729)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.735] [G acc: 0.562]\n",
      "14343 [D loss: (0.703)(R 0.722, F 0.685)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.859] [G acc: 0.125]\n",
      "14344 [D loss: (0.608)(R 0.533, F 0.682)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.827] [G acc: 0.312]\n",
      "14345 [D loss: (0.721)(R 0.778, F 0.664)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.830] [G acc: 0.500]\n",
      "14346 [D loss: (0.680)(R 0.671, F 0.689)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.817] [G acc: 0.438]\n",
      "14347 [D loss: (0.716)(R 0.690, F 0.742)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.757] [G acc: 0.312]\n",
      "14348 [D loss: (0.647)(R 0.605, F 0.688)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.790] [G acc: 0.438]\n",
      "14349 [D loss: (0.654)(R 0.698, F 0.611)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.762] [G acc: 0.250]\n",
      "14350 [D loss: (0.761)(R 0.717, F 0.804)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.790] [G acc: 0.438]\n",
      "14351 [D loss: (0.676)(R 0.619, F 0.734)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.792] [G acc: 0.312]\n",
      "14352 [D loss: (0.604)(R 0.584, F 0.624)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.846] [G acc: 0.125]\n",
      "14353 [D loss: (0.704)(R 0.760, F 0.647)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.776] [G acc: 0.500]\n",
      "14354 [D loss: (0.597)(R 0.520, F 0.674)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.814] [G acc: 0.250]\n",
      "14355 [D loss: (0.647)(R 0.634, F 0.661)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.826] [G acc: 0.312]\n",
      "14356 [D loss: (0.629)(R 0.699, F 0.559)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.810] [G acc: 0.312]\n",
      "14357 [D loss: (0.696)(R 0.768, F 0.623)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.801] [G acc: 0.188]\n",
      "14358 [D loss: (0.656)(R 0.686, F 0.625)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.825] [G acc: 0.312]\n",
      "14359 [D loss: (0.649)(R 0.631, F 0.666)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.781] [G acc: 0.438]\n",
      "14360 [D loss: (0.674)(R 0.635, F 0.714)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.793] [G acc: 0.375]\n",
      "14361 [D loss: (0.678)(R 0.721, F 0.636)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.876] [G acc: 0.312]\n",
      "14362 [D loss: (0.704)(R 0.700, F 0.708)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.823] [G acc: 0.375]\n",
      "14363 [D loss: (0.702)(R 0.749, F 0.656)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.733] [G acc: 0.500]\n",
      "14364 [D loss: (0.792)(R 0.585, F 1.000)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.730] [G acc: 0.500]\n",
      "14365 [D loss: (0.655)(R 0.639, F 0.671)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.685] [G acc: 0.562]\n",
      "14366 [D loss: (0.624)(R 0.632, F 0.617)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.810] [G acc: 0.188]\n",
      "14367 [D loss: (0.652)(R 0.652, F 0.652)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.832] [G acc: 0.312]\n",
      "14368 [D loss: (0.680)(R 0.549, F 0.812)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.852] [G acc: 0.375]\n",
      "14369 [D loss: (0.710)(R 0.648, F 0.772)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.696] [G acc: 0.438]\n",
      "14370 [D loss: (0.907)(R 0.684, F 1.130)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.819] [G acc: 0.312]\n",
      "14371 [D loss: (0.833)(R 0.806, F 0.860)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.766] [G acc: 0.500]\n",
      "14372 [D loss: (0.656)(R 0.674, F 0.639)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.680] [G acc: 0.500]\n",
      "14373 [D loss: (0.735)(R 0.658, F 0.812)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.668] [G acc: 0.625]\n",
      "14374 [D loss: (0.763)(R 0.707, F 0.819)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.565] [G acc: 0.750]\n",
      "14375 [D loss: (0.769)(R 0.564, F 0.974)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.845] [G acc: 0.375]\n",
      "14376 [D loss: (0.888)(R 0.724, F 1.053)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.772] [G acc: 0.438]\n",
      "14377 [D loss: (0.830)(R 0.715, F 0.946)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.696] [G acc: 0.625]\n",
      "14378 [D loss: (0.752)(R 0.667, F 0.837)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.695] [G acc: 0.625]\n",
      "14379 [D loss: (0.943)(R 0.635, F 1.252)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.864] [G acc: 0.438]\n",
      "14380 [D loss: (0.540)(R 0.713, F 0.368)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.501] [G acc: 0.188]\n",
      "14381 [D loss: (0.514)(R 0.646, F 0.381)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.350] [G acc: 0.250]\n",
      "14382 [D loss: (0.731)(R 0.743, F 0.720)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.680] [G acc: 0.688]\n",
      "14383 [D loss: (0.684)(R 0.670, F 0.697)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.706] [G acc: 0.500]\n",
      "14384 [D loss: (0.571)(R 0.518, F 0.624)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.786] [G acc: 0.375]\n",
      "14385 [D loss: (0.724)(R 0.663, F 0.785)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.830] [G acc: 0.375]\n",
      "14386 [D loss: (0.696)(R 0.735, F 0.657)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.727] [G acc: 0.375]\n",
      "14387 [D loss: (0.786)(R 0.898, F 0.673)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.765] [G acc: 0.188]\n",
      "14388 [D loss: (0.580)(R 0.525, F 0.635)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.763] [G acc: 0.312]\n",
      "14389 [D loss: (0.679)(R 0.710, F 0.648)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.845] [G acc: 0.125]\n",
      "14390 [D loss: (0.673)(R 0.717, F 0.628)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.780] [G acc: 0.375]\n",
      "14391 [D loss: (0.832)(R 0.698, F 0.967)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.741] [G acc: 0.562]\n",
      "14392 [D loss: (0.691)(R 0.736, F 0.646)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.781] [G acc: 0.375]\n",
      "14393 [D loss: (0.669)(R 0.728, F 0.611)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.814] [G acc: 0.312]\n",
      "14394 [D loss: (0.662)(R 0.639, F 0.686)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.773] [G acc: 0.500]\n",
      "14395 [D loss: (0.648)(R 0.680, F 0.616)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.833] [G acc: 0.250]\n",
      "14396 [D loss: (0.706)(R 0.720, F 0.693)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.810] [G acc: 0.250]\n",
      "14397 [D loss: (0.697)(R 0.727, F 0.667)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.922] [G acc: 0.250]\n",
      "14398 [D loss: (0.720)(R 0.797, F 0.643)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.738] [G acc: 0.625]\n",
      "14399 [D loss: (0.664)(R 0.713, F 0.615)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.762] [G acc: 0.438]\n",
      "14400 [D loss: (0.696)(R 0.736, F 0.657)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.817] [G acc: 0.312]\n",
      "14401 [D loss: (0.685)(R 0.748, F 0.622)] [D acc: (0.594)(0.438, 0.750)] [G loss: 1.167] [G acc: 0.125]\n",
      "14402 [D loss: (0.680)(R 0.864, F 0.496)] [D acc: (0.469)(0.125, 0.812)] [G loss: 1.954] [G acc: 0.125]\n",
      "14403 [D loss: (0.751)(R 1.224, F 0.278)] [D acc: (0.688)(0.438, 0.938)] [G loss: 5.860] [G acc: 0.250]\n",
      "14404 [D loss: (0.686)(R 0.739, F 0.634)] [D acc: (0.406)(0.375, 0.438)] [G loss: 0.723] [G acc: 0.500]\n",
      "14405 [D loss: (0.632)(R 0.655, F 0.609)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.770] [G acc: 0.375]\n",
      "14406 [D loss: (0.612)(R 0.650, F 0.573)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.804] [G acc: 0.375]\n",
      "14407 [D loss: (0.570)(R 0.534, F 0.607)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.810] [G acc: 0.250]\n",
      "14408 [D loss: (0.620)(R 0.713, F 0.526)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.934] [G acc: 0.250]\n",
      "14409 [D loss: (0.570)(R 0.641, F 0.499)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.056] [G acc: 0.062]\n",
      "14410 [D loss: (0.774)(R 0.924, F 0.623)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.960] [G acc: 0.250]\n",
      "14411 [D loss: (0.572)(R 0.641, F 0.502)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.029] [G acc: 0.188]\n",
      "14412 [D loss: (0.652)(R 0.807, F 0.498)] [D acc: (0.656)(0.375, 0.938)] [G loss: 0.926] [G acc: 0.312]\n",
      "14413 [D loss: (0.636)(R 0.686, F 0.585)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.905] [G acc: 0.375]\n",
      "14414 [D loss: (0.627)(R 0.689, F 0.566)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.016] [G acc: 0.375]\n",
      "14415 [D loss: (0.654)(R 0.806, F 0.501)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.946] [G acc: 0.250]\n",
      "14416 [D loss: (0.726)(R 0.837, F 0.615)] [D acc: (0.594)(0.438, 0.750)] [G loss: 1.116] [G acc: 0.188]\n",
      "14417 [D loss: (0.637)(R 0.700, F 0.574)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.976] [G acc: 0.188]\n",
      "14418 [D loss: (0.589)(R 0.615, F 0.563)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.117] [G acc: 0.250]\n",
      "14419 [D loss: (0.593)(R 0.692, F 0.494)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.981] [G acc: 0.312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14420 [D loss: (0.694)(R 0.734, F 0.653)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.865] [G acc: 0.375]\n",
      "14421 [D loss: (0.628)(R 0.627, F 0.630)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.239] [G acc: 0.250]\n",
      "14422 [D loss: (0.597)(R 0.621, F 0.572)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.946] [G acc: 0.250]\n",
      "14423 [D loss: (0.554)(R 0.587, F 0.520)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.144] [G acc: 0.125]\n",
      "14424 [D loss: (0.644)(R 0.731, F 0.558)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.779] [G acc: 0.375]\n",
      "14425 [D loss: (0.611)(R 0.670, F 0.552)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.025] [G acc: 0.312]\n",
      "14426 [D loss: (0.612)(R 0.690, F 0.535)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.083] [G acc: 0.188]\n",
      "14427 [D loss: (0.650)(R 0.807, F 0.493)] [D acc: (0.594)(0.375, 0.812)] [G loss: 1.013] [G acc: 0.250]\n",
      "14428 [D loss: (0.595)(R 0.696, F 0.494)] [D acc: (0.812)(0.750, 0.875)] [G loss: 3.107] [G acc: 0.250]\n",
      "14429 [D loss: (0.566)(R 0.644, F 0.488)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.397] [G acc: 0.250]\n",
      "14430 [D loss: (0.561)(R 0.662, F 0.459)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.075] [G acc: 0.250]\n",
      "14431 [D loss: (0.565)(R 0.705, F 0.424)] [D acc: (0.844)(0.750, 0.938)] [G loss: 0.929] [G acc: 0.125]\n",
      "14432 [D loss: (0.648)(R 0.705, F 0.591)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.936] [G acc: 0.188]\n",
      "14433 [D loss: (0.554)(R 0.559, F 0.548)] [D acc: (0.875)(1.000, 0.750)] [G loss: 1.049] [G acc: 0.188]\n",
      "14434 [D loss: (0.623)(R 0.671, F 0.575)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.345] [G acc: 0.375]\n",
      "14435 [D loss: (0.641)(R 0.704, F 0.578)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.161] [G acc: 0.125]\n",
      "14436 [D loss: (0.649)(R 0.704, F 0.593)] [D acc: (0.625)(0.750, 0.500)] [G loss: 1.039] [G acc: 0.062]\n",
      "14437 [D loss: (0.754)(R 0.887, F 0.621)] [D acc: (0.562)(0.500, 0.625)] [G loss: 1.003] [G acc: 0.125]\n",
      "14438 [D loss: (0.626)(R 0.643, F 0.609)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.981] [G acc: 0.250]\n",
      "14439 [D loss: (0.791)(R 0.944, F 0.639)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.961] [G acc: 0.188]\n",
      "14440 [D loss: (0.592)(R 0.633, F 0.551)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.073] [G acc: 0.125]\n",
      "14441 [D loss: (0.521)(R 0.448, F 0.593)] [D acc: (0.781)(0.938, 0.625)] [G loss: 1.028] [G acc: 0.375]\n",
      "14442 [D loss: (0.659)(R 0.849, F 0.468)] [D acc: (0.688)(0.500, 0.875)] [G loss: 1.059] [G acc: 0.250]\n",
      "14443 [D loss: (0.640)(R 0.699, F 0.582)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.954] [G acc: 0.312]\n",
      "14444 [D loss: (0.684)(R 0.758, F 0.611)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.710] [G acc: 0.625]\n",
      "14445 [D loss: (0.674)(R 0.830, F 0.518)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.956] [G acc: 0.250]\n",
      "14446 [D loss: (0.638)(R 0.677, F 0.600)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.130] [G acc: 0.250]\n",
      "14447 [D loss: (0.588)(R 0.645, F 0.531)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.812] [G acc: 0.375]\n",
      "14448 [D loss: (0.737)(R 0.894, F 0.580)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.715] [G acc: 0.500]\n",
      "14449 [D loss: (0.634)(R 0.722, F 0.546)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.270] [G acc: 0.250]\n",
      "14450 [D loss: (0.602)(R 0.579, F 0.625)] [D acc: (0.781)(0.938, 0.625)] [G loss: 0.863] [G acc: 0.250]\n",
      "14451 [D loss: (0.609)(R 0.676, F 0.542)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.984] [G acc: 0.312]\n",
      "14452 [D loss: (0.675)(R 0.702, F 0.648)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.868] [G acc: 0.250]\n",
      "14453 [D loss: (0.682)(R 0.705, F 0.659)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.732] [G acc: 0.500]\n",
      "14454 [D loss: (0.679)(R 0.753, F 0.604)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.855] [G acc: 0.438]\n",
      "14455 [D loss: (0.562)(R 0.562, F 0.562)] [D acc: (0.844)(0.875, 0.812)] [G loss: 0.857] [G acc: 0.312]\n",
      "14456 [D loss: (0.678)(R 0.723, F 0.632)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.822] [G acc: 0.438]\n",
      "14457 [D loss: (0.621)(R 0.694, F 0.548)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.790] [G acc: 0.312]\n",
      "14458 [D loss: (0.714)(R 0.780, F 0.649)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.854] [G acc: 0.375]\n",
      "14459 [D loss: (0.714)(R 0.788, F 0.639)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.827] [G acc: 0.375]\n",
      "14460 [D loss: (0.671)(R 0.715, F 0.627)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.889] [G acc: 0.250]\n",
      "14461 [D loss: (0.648)(R 0.659, F 0.638)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.925] [G acc: 0.062]\n",
      "14462 [D loss: (0.605)(R 0.649, F 0.562)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.791] [G acc: 0.500]\n",
      "14463 [D loss: (0.643)(R 0.621, F 0.665)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.782] [G acc: 0.500]\n",
      "14464 [D loss: (0.691)(R 0.737, F 0.644)] [D acc: (0.562)(0.500, 0.625)] [G loss: 1.094] [G acc: 0.125]\n",
      "14465 [D loss: (0.632)(R 0.747, F 0.517)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.527] [G acc: 0.250]\n",
      "14466 [D loss: (0.481)(R 0.752, F 0.211)] [D acc: (0.656)(0.438, 0.875)] [G loss: 5.462] [G acc: 0.188]\n",
      "14467 [D loss: (0.676)(R 0.683, F 0.670)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.347] [G acc: 0.188]\n",
      "14468 [D loss: (0.629)(R 0.645, F 0.613)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.841] [G acc: 0.312]\n",
      "14469 [D loss: (0.549)(R 0.584, F 0.513)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.873] [G acc: 0.188]\n",
      "14470 [D loss: (0.702)(R 0.708, F 0.695)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.921] [G acc: 0.188]\n",
      "14471 [D loss: (0.623)(R 0.624, F 0.621)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.660] [G acc: 0.688]\n",
      "14472 [D loss: (0.742)(R 0.802, F 0.682)] [D acc: (0.406)(0.312, 0.500)] [G loss: 0.850] [G acc: 0.375]\n",
      "14473 [D loss: (0.648)(R 0.637, F 0.658)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.816] [G acc: 0.375]\n",
      "14474 [D loss: (0.857)(R 1.044, F 0.669)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.766] [G acc: 0.500]\n",
      "14475 [D loss: (0.705)(R 0.729, F 0.682)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.864] [G acc: 0.250]\n",
      "14476 [D loss: (0.699)(R 0.726, F 0.673)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.802] [G acc: 0.312]\n",
      "14477 [D loss: (0.655)(R 0.702, F 0.609)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.838] [G acc: 0.250]\n",
      "14478 [D loss: (0.767)(R 0.819, F 0.714)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.967] [G acc: 0.250]\n",
      "14479 [D loss: (0.578)(R 0.710, F 0.446)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.040] [G acc: 0.250]\n",
      "14480 [D loss: (0.525)(R 0.593, F 0.457)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.958] [G acc: 0.250]\n",
      "14481 [D loss: (0.666)(R 0.814, F 0.518)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.763] [G acc: 0.562]\n",
      "14482 [D loss: (0.774)(R 0.786, F 0.762)] [D acc: (0.375)(0.500, 0.250)] [G loss: 0.643] [G acc: 0.812]\n",
      "14483 [D loss: (0.604)(R 0.549, F 0.659)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.714] [G acc: 0.562]\n",
      "14484 [D loss: (0.689)(R 0.624, F 0.753)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.811] [G acc: 0.312]\n",
      "14485 [D loss: (0.658)(R 0.607, F 0.709)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.761] [G acc: 0.375]\n",
      "14486 [D loss: (0.745)(R 0.844, F 0.646)] [D acc: (0.406)(0.312, 0.500)] [G loss: 0.712] [G acc: 0.625]\n",
      "14487 [D loss: (0.766)(R 0.850, F 0.681)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.659] [G acc: 0.812]\n",
      "14488 [D loss: (0.639)(R 0.603, F 0.675)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.808] [G acc: 0.250]\n",
      "14489 [D loss: (0.622)(R 0.580, F 0.664)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.660] [G acc: 0.688]\n",
      "14490 [D loss: (0.695)(R 0.653, F 0.737)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.634] [G acc: 0.812]\n",
      "14491 [D loss: (0.793)(R 0.778, F 0.809)] [D acc: (0.375)(0.625, 0.125)] [G loss: 0.730] [G acc: 0.562]\n",
      "14492 [D loss: (0.695)(R 0.593, F 0.798)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.804] [G acc: 0.438]\n",
      "14493 [D loss: (0.629)(R 0.581, F 0.677)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.724] [G acc: 0.562]\n",
      "14494 [D loss: (0.650)(R 0.583, F 0.717)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.657] [G acc: 0.688]\n",
      "14495 [D loss: (0.755)(R 0.740, F 0.770)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.747] [G acc: 0.500]\n",
      "14496 [D loss: (0.655)(R 0.590, F 0.720)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.696] [G acc: 0.562]\n",
      "14497 [D loss: (0.627)(R 0.526, F 0.728)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.713] [G acc: 0.562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14498 [D loss: (0.707)(R 0.682, F 0.733)] [D acc: (0.375)(0.500, 0.250)] [G loss: 0.756] [G acc: 0.500]\n",
      "14499 [D loss: (0.646)(R 0.527, F 0.766)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.717] [G acc: 0.500]\n",
      "14500 [D loss: (0.693)(R 0.607, F 0.779)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.663] [G acc: 0.750]\n",
      "14501 [D loss: (0.610)(R 0.489, F 0.731)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.675] [G acc: 0.688]\n",
      "14502 [D loss: (0.599)(R 0.485, F 0.712)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.751] [G acc: 0.562]\n",
      "14503 [D loss: (0.610)(R 0.497, F 0.723)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.706] [G acc: 0.750]\n",
      "14504 [D loss: (0.605)(R 0.488, F 0.722)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.609] [G acc: 0.562]\n",
      "14505 [D loss: (0.738)(R 0.661, F 0.816)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.683] [G acc: 0.688]\n",
      "14506 [D loss: (0.600)(R 0.492, F 0.708)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.639] [G acc: 0.750]\n",
      "14507 [D loss: (0.695)(R 0.602, F 0.788)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.643] [G acc: 0.625]\n",
      "14508 [D loss: (0.670)(R 0.583, F 0.757)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.677] [G acc: 0.750]\n",
      "14509 [D loss: (0.723)(R 0.656, F 0.790)] [D acc: (0.375)(0.625, 0.125)] [G loss: 0.670] [G acc: 0.812]\n",
      "14510 [D loss: (0.568)(R 0.458, F 0.678)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.676] [G acc: 0.812]\n",
      "14511 [D loss: (0.725)(R 0.568, F 0.883)] [D acc: (0.375)(0.562, 0.188)] [G loss: 0.642] [G acc: 0.750]\n",
      "14512 [D loss: (0.754)(R 0.614, F 0.894)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.684] [G acc: 0.500]\n",
      "14513 [D loss: (0.654)(R 0.580, F 0.729)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.748] [G acc: 0.562]\n",
      "14514 [D loss: (0.649)(R 0.581, F 0.716)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.700] [G acc: 0.562]\n",
      "14515 [D loss: (0.651)(R 0.613, F 0.689)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.745] [G acc: 0.438]\n",
      "14516 [D loss: (0.615)(R 0.726, F 0.504)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.092] [G acc: 0.250]\n",
      "14517 [D loss: (0.582)(R 0.549, F 0.616)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.752] [G acc: 0.312]\n",
      "14518 [D loss: (0.644)(R 0.593, F 0.695)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.804] [G acc: 0.250]\n",
      "14519 [D loss: (0.664)(R 0.615, F 0.713)] [D acc: (0.406)(0.625, 0.188)] [G loss: 0.800] [G acc: 0.125]\n",
      "14520 [D loss: (0.606)(R 0.529, F 0.682)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.851] [G acc: 0.250]\n",
      "14521 [D loss: (0.687)(R 0.671, F 0.704)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.737] [G acc: 0.438]\n",
      "14522 [D loss: (0.618)(R 0.542, F 0.695)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.704] [G acc: 0.438]\n",
      "14523 [D loss: (0.708)(R 0.702, F 0.713)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.692] [G acc: 0.562]\n",
      "14524 [D loss: (0.651)(R 0.606, F 0.695)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.729] [G acc: 0.188]\n",
      "14525 [D loss: (0.640)(R 0.612, F 0.669)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.713] [G acc: 0.562]\n",
      "14526 [D loss: (0.574)(R 0.514, F 0.633)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.726] [G acc: 0.375]\n",
      "14527 [D loss: (0.594)(R 0.506, F 0.683)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.759] [G acc: 0.375]\n",
      "14528 [D loss: (0.714)(R 0.649, F 0.778)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.699] [G acc: 0.312]\n",
      "14529 [D loss: (0.652)(R 0.614, F 0.690)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.723] [G acc: 0.625]\n",
      "14530 [D loss: (0.767)(R 0.605, F 0.929)] [D acc: (0.375)(0.562, 0.188)] [G loss: 0.769] [G acc: 0.125]\n",
      "14531 [D loss: (0.531)(R 0.389, F 0.672)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.725] [G acc: 0.375]\n",
      "14532 [D loss: (0.560)(R 0.470, F 0.649)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.770] [G acc: 0.125]\n",
      "14533 [D loss: (0.608)(R 0.539, F 0.677)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.760] [G acc: 0.312]\n",
      "14534 [D loss: (0.587)(R 0.516, F 0.658)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.744] [G acc: 0.438]\n",
      "14535 [D loss: (0.668)(R 0.661, F 0.674)] [D acc: (0.406)(0.375, 0.438)] [G loss: 0.685] [G acc: 0.375]\n",
      "14536 [D loss: (0.760)(R 0.839, F 0.680)] [D acc: (0.375)(0.188, 0.562)] [G loss: 0.755] [G acc: 0.000]\n",
      "14537 [D loss: (0.610)(R 0.527, F 0.693)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.779] [G acc: 0.312]\n",
      "14538 [D loss: (0.992)(R 0.645, F 1.339)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.757] [G acc: 0.125]\n",
      "14539 [D loss: (0.839)(R 0.506, F 1.173)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.670] [G acc: 0.500]\n",
      "14540 [D loss: (0.607)(R 0.574, F 0.640)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.764] [G acc: 0.250]\n",
      "14541 [D loss: (0.641)(R 0.600, F 0.682)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.698] [G acc: 0.250]\n",
      "14542 [D loss: (0.690)(R 0.700, F 0.681)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.724] [G acc: 0.312]\n",
      "14543 [D loss: (0.610)(R 0.563, F 0.658)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.741] [G acc: 0.250]\n",
      "14544 [D loss: (0.614)(R 0.567, F 0.661)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.797] [G acc: 0.125]\n",
      "14545 [D loss: (0.657)(R 0.644, F 0.671)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.727] [G acc: 0.375]\n",
      "14546 [D loss: (0.595)(R 0.514, F 0.676)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.673] [G acc: 0.250]\n",
      "14547 [D loss: (0.652)(R 0.613, F 0.691)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.712] [G acc: 0.438]\n",
      "14548 [D loss: (0.755)(R 0.609, F 0.901)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.682] [G acc: 0.312]\n",
      "14549 [D loss: (0.659)(R 0.618, F 0.700)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.720] [G acc: 0.375]\n",
      "14550 [D loss: (0.739)(R 0.628, F 0.851)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.744] [G acc: 0.188]\n",
      "14551 [D loss: (0.663)(R 0.597, F 0.728)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.711] [G acc: 0.312]\n",
      "14552 [D loss: (0.663)(R 0.684, F 0.642)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.752] [G acc: 0.188]\n",
      "14553 [D loss: (0.674)(R 0.666, F 0.683)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.696] [G acc: 0.312]\n",
      "14554 [D loss: (0.705)(R 0.620, F 0.791)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.747] [G acc: 0.188]\n",
      "14555 [D loss: (0.684)(R 0.740, F 0.628)] [D acc: (0.656)(0.375, 0.938)] [G loss: 0.695] [G acc: 0.312]\n",
      "14556 [D loss: (0.632)(R 0.583, F 0.681)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.755] [G acc: 0.125]\n",
      "14557 [D loss: (0.896)(R 0.630, F 1.162)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.730] [G acc: 0.125]\n",
      "14558 [D loss: (0.666)(R 0.663, F 0.670)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.785] [G acc: 0.188]\n",
      "14559 [D loss: (0.672)(R 0.553, F 0.792)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.725] [G acc: 0.250]\n",
      "14560 [D loss: (0.606)(R 0.541, F 0.671)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.709] [G acc: 0.438]\n",
      "14561 [D loss: (0.607)(R 0.576, F 0.638)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.742] [G acc: 0.250]\n",
      "14562 [D loss: (0.677)(R 0.661, F 0.693)] [D acc: (0.438)(0.250, 0.625)] [G loss: 0.721] [G acc: 0.375]\n",
      "14563 [D loss: (0.401)(R 0.572, F 0.229)] [D acc: (0.688)(0.438, 0.938)] [G loss: 8.040] [G acc: 0.188]\n",
      "14564 [D loss: (0.513)(R 0.573, F 0.453)] [D acc: (0.594)(0.312, 0.875)] [G loss: 6.002] [G acc: 0.062]\n",
      "14565 [D loss: (0.915)(R 0.648, F 1.182)] [D acc: (0.406)(0.375, 0.438)] [G loss: 2.794] [G acc: 0.250]\n",
      "14566 [D loss: (0.465)(R 0.584, F 0.346)] [D acc: (0.625)(0.438, 0.812)] [G loss: 1.751] [G acc: 0.125]\n",
      "14567 [D loss: (0.462)(R 0.566, F 0.358)] [D acc: (0.688)(0.438, 0.938)] [G loss: 0.858] [G acc: 0.250]\n",
      "14568 [D loss: (0.548)(R 0.637, F 0.459)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.795] [G acc: 0.312]\n",
      "14569 [D loss: (0.720)(R 0.616, F 0.824)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.815] [G acc: 0.062]\n",
      "14570 [D loss: (0.800)(R 0.957, F 0.644)] [D acc: (0.562)(0.312, 0.812)] [G loss: 0.813] [G acc: 0.125]\n",
      "14571 [D loss: (0.665)(R 0.700, F 0.629)] [D acc: (0.625)(0.312, 0.938)] [G loss: 0.738] [G acc: 0.312]\n",
      "14572 [D loss: (0.800)(R 0.671, F 0.928)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.850] [G acc: 0.375]\n",
      "14573 [D loss: (0.599)(R 0.562, F 0.636)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.751] [G acc: 0.125]\n",
      "14574 [D loss: (0.706)(R 0.733, F 0.679)] [D acc: (0.438)(0.250, 0.625)] [G loss: 0.723] [G acc: 0.375]\n",
      "14575 [D loss: (0.637)(R 0.585, F 0.689)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.800] [G acc: 0.188]\n",
      "14576 [D loss: (0.625)(R 0.572, F 0.678)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.888] [G acc: 0.125]\n",
      "14577 [D loss: (0.662)(R 0.686, F 0.638)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.769] [G acc: 0.125]\n",
      "14578 [D loss: (0.766)(R 0.815, F 0.717)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.718] [G acc: 0.375]\n",
      "14579 [D loss: (0.908)(R 0.762, F 1.055)] [D acc: (0.438)(0.312, 0.562)] [G loss: 0.743] [G acc: 0.375]\n",
      "14580 [D loss: (0.638)(R 0.602, F 0.675)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.754] [G acc: 0.188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14581 [D loss: (0.668)(R 0.671, F 0.664)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.699] [G acc: 0.562]\n",
      "14582 [D loss: (0.604)(R 0.553, F 0.655)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.774] [G acc: 0.062]\n",
      "14583 [D loss: (0.650)(R 0.620, F 0.679)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.780] [G acc: 0.000]\n",
      "14584 [D loss: (0.665)(R 0.669, F 0.662)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.688] [G acc: 0.312]\n",
      "14585 [D loss: (0.637)(R 0.565, F 0.709)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.728] [G acc: 0.312]\n",
      "14586 [D loss: (0.603)(R 0.534, F 0.672)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.746] [G acc: 0.125]\n",
      "14587 [D loss: (0.627)(R 0.616, F 0.639)] [D acc: (0.500)(0.312, 0.688)] [G loss: 0.750] [G acc: 0.312]\n",
      "14588 [D loss: (0.620)(R 0.576, F 0.664)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.721] [G acc: 0.312]\n",
      "14589 [D loss: (0.774)(R 0.649, F 0.899)] [D acc: (0.500)(0.312, 0.688)] [G loss: 0.743] [G acc: 0.188]\n",
      "14590 [D loss: (0.893)(R 0.599, F 1.187)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.710] [G acc: 0.188]\n",
      "14591 [D loss: (0.699)(R 0.645, F 0.753)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.706] [G acc: 0.188]\n",
      "14592 [D loss: (0.678)(R 0.707, F 0.649)] [D acc: (0.594)(0.312, 0.875)] [G loss: 0.716] [G acc: 0.312]\n",
      "14593 [D loss: (0.681)(R 0.680, F 0.683)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.744] [G acc: 0.250]\n",
      "14594 [D loss: (0.635)(R 0.632, F 0.638)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.744] [G acc: 0.188]\n",
      "14595 [D loss: (0.637)(R 0.643, F 0.632)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.686] [G acc: 0.312]\n",
      "14596 [D loss: (0.614)(R 0.556, F 0.672)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.725] [G acc: 0.312]\n",
      "14597 [D loss: (0.620)(R 0.569, F 0.670)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.772] [G acc: 0.188]\n",
      "14598 [D loss: (0.654)(R 0.661, F 0.648)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.676] [G acc: 0.312]\n",
      "14599 [D loss: (0.639)(R 0.611, F 0.667)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.697] [G acc: 0.562]\n",
      "14600 [D loss: (0.629)(R 0.610, F 0.647)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.760] [G acc: 0.125]\n",
      "14601 [D loss: (0.646)(R 0.468, F 0.824)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.703] [G acc: 0.250]\n",
      "14602 [D loss: (0.716)(R 0.544, F 0.887)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.679] [G acc: 0.500]\n",
      "14603 [D loss: (0.667)(R 0.668, F 0.666)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.656] [G acc: 0.312]\n",
      "14604 [D loss: (0.968)(R 0.656, F 1.280)] [D acc: (0.406)(0.312, 0.500)] [G loss: 0.652] [G acc: 0.375]\n",
      "14605 [D loss: (0.686)(R 0.701, F 0.672)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.692] [G acc: 0.500]\n",
      "14606 [D loss: (0.801)(R 0.626, F 0.976)] [D acc: (0.344)(0.375, 0.312)] [G loss: 0.653] [G acc: 0.312]\n",
      "14607 [D loss: (1.028)(R 0.743, F 1.313)] [D acc: (0.250)(0.188, 0.312)] [G loss: 0.696] [G acc: 0.250]\n",
      "14608 [D loss: (0.872)(R 0.723, F 1.021)] [D acc: (0.312)(0.375, 0.250)] [G loss: 0.650] [G acc: 0.500]\n",
      "14609 [D loss: (0.796)(R 0.636, F 0.957)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.673] [G acc: 0.312]\n",
      "14610 [D loss: (1.385)(R 0.741, F 2.028)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.596] [G acc: 0.500]\n",
      "14611 [D loss: (1.154)(R 0.585, F 1.723)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.767] [G acc: 0.188]\n",
      "14612 [D loss: (0.821)(R 0.749, F 0.892)] [D acc: (0.375)(0.188, 0.562)] [G loss: 1.060] [G acc: 0.562]\n",
      "14613 [D loss: (0.974)(R 0.757, F 1.191)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.622] [G acc: 0.438]\n",
      "14614 [D loss: (1.425)(R 0.690, F 2.161)] [D acc: (0.281)(0.312, 0.250)] [G loss: 0.367] [G acc: 0.625]\n",
      "14615 [D loss: (0.669)(R 0.592, F 0.745)] [D acc: (0.500)(0.312, 0.688)] [G loss: 0.689] [G acc: 0.375]\n",
      "14616 [D loss: (1.657)(R 0.693, F 2.621)] [D acc: (0.344)(0.250, 0.438)] [G loss: 0.507] [G acc: 0.625]\n",
      "14617 [D loss: (0.840)(R 0.628, F 1.053)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.689] [G acc: 0.500]\n",
      "14618 [D loss: (0.944)(R 0.736, F 1.152)] [D acc: (0.312)(0.250, 0.375)] [G loss: 0.447] [G acc: 0.688]\n",
      "14619 [D loss: (1.220)(R 0.620, F 1.819)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.667] [G acc: 0.375]\n",
      "14620 [D loss: (1.000)(R 0.819, F 1.180)] [D acc: (0.281)(0.125, 0.438)] [G loss: 0.769] [G acc: 0.438]\n",
      "14621 [D loss: (0.733)(R 0.705, F 0.760)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.712] [G acc: 0.375]\n",
      "14622 [D loss: (1.134)(R 0.756, F 1.512)] [D acc: (0.375)(0.250, 0.500)] [G loss: 0.697] [G acc: 0.438]\n",
      "14623 [D loss: (0.673)(R 0.563, F 0.783)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.629] [G acc: 0.625]\n",
      "14624 [D loss: (0.624)(R 0.579, F 0.669)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.681] [G acc: 0.375]\n",
      "14625 [D loss: (0.696)(R 0.686, F 0.706)] [D acc: (0.375)(0.188, 0.562)] [G loss: 0.687] [G acc: 0.438]\n",
      "14626 [D loss: (0.873)(R 0.814, F 0.931)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.752] [G acc: 0.188]\n",
      "14627 [D loss: (0.812)(R 0.742, F 0.882)] [D acc: (0.438)(0.312, 0.562)] [G loss: 0.692] [G acc: 0.250]\n",
      "14628 [D loss: (0.868)(R 0.747, F 0.989)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.746] [G acc: 0.062]\n",
      "14629 [D loss: (0.672)(R 0.686, F 0.659)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.642] [G acc: 0.625]\n",
      "14630 [D loss: (0.805)(R 0.688, F 0.922)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.463] [G acc: 0.688]\n",
      "14631 [D loss: (0.963)(R 0.682, F 1.244)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.724] [G acc: 0.188]\n",
      "14632 [D loss: (0.697)(R 0.717, F 0.677)] [D acc: (0.406)(0.312, 0.500)] [G loss: 0.605] [G acc: 0.625]\n",
      "14633 [D loss: (0.877)(R 0.702, F 1.053)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.700] [G acc: 0.250]\n",
      "14634 [D loss: (0.934)(R 0.727, F 1.142)] [D acc: (0.406)(0.312, 0.500)] [G loss: 0.742] [G acc: 0.438]\n",
      "14635 [D loss: (0.672)(R 0.672, F 0.672)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.757] [G acc: 0.375]\n",
      "14636 [D loss: (0.816)(R 0.692, F 0.939)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.721] [G acc: 0.500]\n",
      "14637 [D loss: (0.649)(R 0.642, F 0.657)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.539] [G acc: 0.625]\n",
      "14638 [D loss: (0.712)(R 0.745, F 0.679)] [D acc: (0.344)(0.312, 0.375)] [G loss: 0.697] [G acc: 0.500]\n",
      "14639 [D loss: (0.720)(R 0.731, F 0.709)] [D acc: (0.344)(0.375, 0.312)] [G loss: 0.696] [G acc: 0.562]\n",
      "14640 [D loss: (0.673)(R 0.648, F 0.698)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.708] [G acc: 0.312]\n",
      "14641 [D loss: (0.683)(R 0.684, F 0.682)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.698] [G acc: 0.375]\n",
      "14642 [D loss: (0.700)(R 0.725, F 0.674)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.686] [G acc: 0.562]\n",
      "14643 [D loss: (0.667)(R 0.678, F 0.655)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.755] [G acc: 0.312]\n",
      "14644 [D loss: (0.685)(R 0.698, F 0.671)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.758] [G acc: 0.375]\n",
      "14645 [D loss: (0.687)(R 0.677, F 0.696)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.724] [G acc: 0.500]\n",
      "14646 [D loss: (0.681)(R 0.640, F 0.722)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.520] [G acc: 0.500]\n",
      "14647 [D loss: (0.688)(R 0.691, F 0.684)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.715] [G acc: 0.562]\n",
      "14648 [D loss: (0.672)(R 0.696, F 0.648)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.808] [G acc: 0.625]\n",
      "14649 [D loss: (0.731)(R 0.794, F 0.669)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.767] [G acc: 0.375]\n",
      "14650 [D loss: (0.626)(R 0.611, F 0.642)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.714] [G acc: 0.312]\n",
      "14651 [D loss: (0.688)(R 0.677, F 0.699)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.519] [G acc: 0.688]\n",
      "14652 [D loss: (0.771)(R 0.691, F 0.851)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.648] [G acc: 0.562]\n",
      "14653 [D loss: (0.699)(R 0.662, F 0.736)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.531] [G acc: 0.688]\n",
      "14654 [D loss: (0.660)(R 0.688, F 0.631)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.821] [G acc: 0.250]\n",
      "14655 [D loss: (0.903)(R 0.746, F 1.060)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.732] [G acc: 0.438]\n",
      "14656 [D loss: (0.710)(R 0.694, F 0.726)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.771] [G acc: 0.375]\n",
      "14657 [D loss: (0.688)(R 0.743, F 0.633)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.847] [G acc: 0.312]\n",
      "14658 [D loss: (0.680)(R 0.664, F 0.696)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.760] [G acc: 0.500]\n",
      "14659 [D loss: (0.614)(R 0.658, F 0.569)] [D acc: (0.750)(0.875, 0.625)] [G loss: 1.003] [G acc: 0.312]\n",
      "14660 [D loss: (0.577)(R 0.695, F 0.458)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.492] [G acc: 0.312]\n",
      "14661 [D loss: (0.654)(R 0.690, F 0.618)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.868] [G acc: 0.375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14662 [D loss: (0.688)(R 0.812, F 0.564)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.857] [G acc: 0.188]\n",
      "14663 [D loss: (0.621)(R 0.642, F 0.601)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.793] [G acc: 0.500]\n",
      "14664 [D loss: (0.608)(R 0.620, F 0.597)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.842] [G acc: 0.188]\n",
      "14665 [D loss: (0.654)(R 0.636, F 0.673)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.874] [G acc: 0.312]\n",
      "14666 [D loss: (0.683)(R 0.714, F 0.653)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.887] [G acc: 0.312]\n",
      "14667 [D loss: (0.569)(R 0.659, F 0.478)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.836] [G acc: 0.312]\n",
      "14668 [D loss: (0.648)(R 0.839, F 0.457)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.921] [G acc: 0.312]\n",
      "14669 [D loss: (0.657)(R 0.695, F 0.618)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.828] [G acc: 0.375]\n",
      "14670 [D loss: (0.608)(R 0.642, F 0.575)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.824] [G acc: 0.312]\n",
      "14671 [D loss: (0.631)(R 0.678, F 0.584)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.772] [G acc: 0.562]\n",
      "14672 [D loss: (0.622)(R 0.653, F 0.591)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.826] [G acc: 0.375]\n",
      "14673 [D loss: (0.628)(R 0.651, F 0.606)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.755] [G acc: 0.438]\n",
      "14674 [D loss: (0.613)(R 0.618, F 0.608)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.883] [G acc: 0.375]\n",
      "14675 [D loss: (0.515)(R 0.572, F 0.458)] [D acc: (0.844)(0.875, 0.812)] [G loss: 0.865] [G acc: 0.312]\n",
      "14676 [D loss: (0.564)(R 0.647, F 0.482)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.903] [G acc: 0.188]\n",
      "14677 [D loss: (0.642)(R 0.756, F 0.527)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.953] [G acc: 0.312]\n",
      "14678 [D loss: (0.685)(R 0.631, F 0.738)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.978] [G acc: 0.250]\n",
      "14679 [D loss: (0.567)(R 0.657, F 0.478)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.950] [G acc: 0.688]\n",
      "14680 [D loss: (0.633)(R 0.733, F 0.533)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.923] [G acc: 0.375]\n",
      "14681 [D loss: (0.627)(R 0.722, F 0.532)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.059] [G acc: 0.438]\n",
      "14682 [D loss: (0.686)(R 0.618, F 0.753)] [D acc: (0.594)(0.812, 0.375)] [G loss: 1.006] [G acc: 0.250]\n",
      "14683 [D loss: (0.619)(R 0.648, F 0.590)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.755] [G acc: 0.625]\n",
      "14684 [D loss: (0.646)(R 0.730, F 0.563)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.987] [G acc: 0.375]\n",
      "14685 [D loss: (0.630)(R 0.658, F 0.601)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.032] [G acc: 0.375]\n",
      "14686 [D loss: (0.586)(R 0.633, F 0.539)] [D acc: (0.844)(0.875, 0.812)] [G loss: 0.993] [G acc: 0.312]\n",
      "14687 [D loss: (0.456)(R 0.628, F 0.285)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.921] [G acc: 0.312]\n",
      "14688 [D loss: (0.587)(R 0.629, F 0.546)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.260] [G acc: 0.375]\n",
      "14689 [D loss: (0.625)(R 0.643, F 0.606)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.811] [G acc: 0.500]\n",
      "14690 [D loss: (0.625)(R 0.687, F 0.563)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.814] [G acc: 0.312]\n",
      "14691 [D loss: (0.664)(R 0.700, F 0.628)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.724] [G acc: 0.750]\n",
      "14692 [D loss: (0.721)(R 0.854, F 0.588)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.111] [G acc: 0.250]\n",
      "14693 [D loss: (0.636)(R 0.652, F 0.619)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.706] [G acc: 0.625]\n",
      "14694 [D loss: (0.625)(R 0.611, F 0.638)] [D acc: (0.781)(0.938, 0.625)] [G loss: 0.979] [G acc: 0.438]\n",
      "14695 [D loss: (0.662)(R 0.684, F 0.640)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.002] [G acc: 0.250]\n",
      "14696 [D loss: (0.597)(R 0.590, F 0.604)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.894] [G acc: 0.312]\n",
      "14697 [D loss: (0.663)(R 0.656, F 0.671)] [D acc: (0.656)(0.812, 0.500)] [G loss: 1.007] [G acc: 0.312]\n",
      "14698 [D loss: (0.688)(R 0.655, F 0.722)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.827] [G acc: 0.438]\n",
      "14699 [D loss: (0.641)(R 0.608, F 0.674)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.719] [G acc: 0.625]\n",
      "14700 [D loss: (0.720)(R 0.707, F 0.732)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.904] [G acc: 0.438]\n",
      "14701 [D loss: (0.718)(R 0.761, F 0.675)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.956] [G acc: 0.438]\n",
      "14702 [D loss: (0.660)(R 0.718, F 0.602)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.936] [G acc: 0.312]\n",
      "14703 [D loss: (0.728)(R 0.735, F 0.720)] [D acc: (0.406)(0.500, 0.312)] [G loss: 0.895] [G acc: 0.250]\n",
      "14704 [D loss: (0.724)(R 0.772, F 0.676)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.833] [G acc: 0.625]\n",
      "14705 [D loss: (0.696)(R 0.727, F 0.665)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.943] [G acc: 0.312]\n",
      "14706 [D loss: (0.701)(R 0.719, F 0.683)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.897] [G acc: 0.438]\n",
      "14707 [D loss: (0.569)(R 0.579, F 0.560)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.895] [G acc: 0.125]\n",
      "14708 [D loss: (0.632)(R 0.636, F 0.628)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.783] [G acc: 0.312]\n",
      "14709 [D loss: (0.647)(R 0.652, F 0.641)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.811] [G acc: 0.375]\n",
      "14710 [D loss: (0.635)(R 0.618, F 0.652)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.818] [G acc: 0.375]\n",
      "14711 [D loss: (0.684)(R 0.707, F 0.660)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.921] [G acc: 0.500]\n",
      "14712 [D loss: (0.652)(R 0.653, F 0.652)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.970] [G acc: 0.375]\n",
      "14713 [D loss: (0.693)(R 0.797, F 0.589)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.835] [G acc: 0.500]\n",
      "14714 [D loss: (0.674)(R 0.751, F 0.597)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.768] [G acc: 0.250]\n",
      "14715 [D loss: (0.655)(R 0.622, F 0.688)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.799] [G acc: 0.375]\n",
      "14716 [D loss: (0.584)(R 0.563, F 0.605)] [D acc: (0.812)(0.938, 0.688)] [G loss: 0.930] [G acc: 0.312]\n",
      "14717 [D loss: (0.634)(R 0.584, F 0.684)] [D acc: (0.688)(0.875, 0.500)] [G loss: 1.353] [G acc: 0.375]\n",
      "14718 [D loss: (0.571)(R 0.644, F 0.497)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.085] [G acc: 0.312]\n",
      "14719 [D loss: (0.845)(R 1.020, F 0.670)] [D acc: (0.344)(0.250, 0.438)] [G loss: 0.702] [G acc: 0.500]\n",
      "14720 [D loss: (0.658)(R 0.601, F 0.715)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.893] [G acc: 0.375]\n",
      "14721 [D loss: (0.637)(R 0.596, F 0.677)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.776] [G acc: 0.500]\n",
      "14722 [D loss: (0.764)(R 0.747, F 0.781)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.759] [G acc: 0.562]\n",
      "14723 [D loss: (0.690)(R 0.636, F 0.743)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.678] [G acc: 0.812]\n",
      "14724 [D loss: (0.685)(R 0.680, F 0.691)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.874] [G acc: 0.500]\n",
      "14725 [D loss: (0.770)(R 0.795, F 0.745)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.667] [G acc: 0.750]\n",
      "14726 [D loss: (0.720)(R 0.629, F 0.811)] [D acc: (0.375)(0.688, 0.062)] [G loss: 0.843] [G acc: 0.625]\n",
      "14727 [D loss: (0.488)(R 0.672, F 0.305)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.961] [G acc: 0.188]\n",
      "14728 [D loss: (0.746)(R 0.821, F 0.671)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.667] [G acc: 0.625]\n",
      "14729 [D loss: (0.672)(R 0.605, F 0.739)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.719] [G acc: 0.688]\n",
      "14730 [D loss: (0.682)(R 0.638, F 0.725)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.730] [G acc: 0.625]\n",
      "14731 [D loss: (0.727)(R 0.693, F 0.761)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.657] [G acc: 0.812]\n",
      "14732 [D loss: (0.726)(R 0.601, F 0.850)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.620] [G acc: 0.812]\n",
      "14733 [D loss: (0.773)(R 0.737, F 0.809)] [D acc: (0.312)(0.625, 0.000)] [G loss: 0.634] [G acc: 0.812]\n",
      "14734 [D loss: (0.674)(R 0.596, F 0.753)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.667] [G acc: 0.625]\n",
      "14735 [D loss: (0.674)(R 0.637, F 0.711)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.615] [G acc: 0.812]\n",
      "14736 [D loss: (0.676)(R 0.631, F 0.722)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.644] [G acc: 0.750]\n",
      "14737 [D loss: (0.693)(R 0.659, F 0.728)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.644] [G acc: 0.875]\n",
      "14738 [D loss: (0.681)(R 0.625, F 0.736)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.616] [G acc: 0.875]\n",
      "14739 [D loss: (0.691)(R 0.601, F 0.782)] [D acc: (0.500)(0.938, 0.062)] [G loss: 0.632] [G acc: 0.812]\n",
      "14740 [D loss: (0.777)(R 0.752, F 0.801)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.654] [G acc: 0.688]\n",
      "14741 [D loss: (0.707)(R 0.647, F 0.767)] [D acc: (0.438)(0.688, 0.188)] [G loss: 0.598] [G acc: 1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14742 [D loss: (0.692)(R 0.621, F 0.762)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.690] [G acc: 0.688]\n",
      "14743 [D loss: (0.735)(R 0.677, F 0.794)] [D acc: (0.438)(0.812, 0.062)] [G loss: 0.639] [G acc: 0.750]\n",
      "14744 [D loss: (0.680)(R 0.601, F 0.760)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.752] [G acc: 0.750]\n",
      "14745 [D loss: (0.703)(R 0.615, F 0.791)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.674] [G acc: 0.750]\n",
      "14746 [D loss: (0.731)(R 0.685, F 0.777)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.659] [G acc: 0.750]\n",
      "14747 [D loss: (0.692)(R 0.651, F 0.733)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.672] [G acc: 0.688]\n",
      "14748 [D loss: (0.679)(R 0.580, F 0.778)] [D acc: (0.438)(0.688, 0.188)] [G loss: 0.619] [G acc: 0.938]\n",
      "14749 [D loss: (0.707)(R 0.615, F 0.800)] [D acc: (0.500)(0.938, 0.062)] [G loss: 0.753] [G acc: 0.562]\n",
      "14750 [D loss: (0.715)(R 0.635, F 0.796)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.792] [G acc: 0.500]\n",
      "14751 [D loss: (0.740)(R 0.681, F 0.800)] [D acc: (0.312)(0.625, 0.000)] [G loss: 0.613] [G acc: 0.875]\n",
      "14752 [D loss: (0.681)(R 0.598, F 0.764)] [D acc: (0.625)(1.000, 0.250)] [G loss: 0.639] [G acc: 0.812]\n",
      "14753 [D loss: (0.706)(R 0.618, F 0.795)] [D acc: (0.438)(0.812, 0.062)] [G loss: 0.667] [G acc: 0.625]\n",
      "14754 [D loss: (0.700)(R 0.638, F 0.762)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.637] [G acc: 0.750]\n",
      "14755 [D loss: (0.709)(R 0.639, F 0.780)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.637] [G acc: 0.750]\n",
      "14756 [D loss: (0.697)(R 0.617, F 0.776)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.644] [G acc: 0.750]\n",
      "14757 [D loss: (0.712)(R 0.639, F 0.784)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.676] [G acc: 0.562]\n",
      "14758 [D loss: (0.696)(R 0.627, F 0.766)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.626] [G acc: 0.875]\n",
      "14759 [D loss: (0.607)(R 0.480, F 0.735)] [D acc: (0.656)(1.000, 0.312)] [G loss: 0.641] [G acc: 0.750]\n",
      "14760 [D loss: (0.691)(R 0.611, F 0.771)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.626] [G acc: 0.812]\n",
      "14761 [D loss: (0.722)(R 0.668, F 0.776)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.638] [G acc: 0.688]\n",
      "14762 [D loss: (0.691)(R 0.632, F 0.751)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.650] [G acc: 0.688]\n",
      "14763 [D loss: (0.680)(R 0.611, F 0.750)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.639] [G acc: 0.875]\n",
      "14764 [D loss: (0.821)(R 0.883, F 0.758)] [D acc: (0.438)(0.688, 0.188)] [G loss: 0.686] [G acc: 0.688]\n",
      "14765 [D loss: (0.673)(R 0.575, F 0.771)] [D acc: (0.531)(0.938, 0.125)] [G loss: 0.635] [G acc: 0.812]\n",
      "14766 [D loss: (0.675)(R 0.582, F 0.768)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.639] [G acc: 0.875]\n",
      "14767 [D loss: (0.683)(R 0.617, F 0.749)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.678] [G acc: 0.562]\n",
      "14768 [D loss: (0.675)(R 0.621, F 0.728)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.641] [G acc: 0.875]\n",
      "14769 [D loss: (0.690)(R 0.628, F 0.753)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.651] [G acc: 0.875]\n",
      "14770 [D loss: (0.697)(R 0.622, F 0.772)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.652] [G acc: 0.750]\n",
      "14771 [D loss: (0.740)(R 0.694, F 0.785)] [D acc: (0.406)(0.750, 0.062)] [G loss: 0.620] [G acc: 0.875]\n",
      "14772 [D loss: (0.704)(R 0.618, F 0.790)] [D acc: (0.469)(0.875, 0.062)] [G loss: 0.645] [G acc: 0.688]\n",
      "14773 [D loss: (0.656)(R 0.553, F 0.758)] [D acc: (0.500)(0.938, 0.062)] [G loss: 0.657] [G acc: 0.750]\n",
      "14774 [D loss: (0.649)(R 0.511, F 0.788)] [D acc: (0.500)(0.938, 0.062)] [G loss: 0.612] [G acc: 0.938]\n",
      "14775 [D loss: (0.689)(R 0.635, F 0.743)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.660] [G acc: 0.750]\n",
      "14776 [D loss: (0.669)(R 0.585, F 0.754)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.630] [G acc: 0.875]\n",
      "14777 [D loss: (0.702)(R 0.651, F 0.752)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.623] [G acc: 0.938]\n",
      "14778 [D loss: (0.678)(R 0.614, F 0.742)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.619] [G acc: 0.875]\n",
      "14779 [D loss: (0.656)(R 0.542, F 0.771)] [D acc: (0.562)(1.000, 0.125)] [G loss: 0.629] [G acc: 0.875]\n",
      "14780 [D loss: (0.639)(R 0.496, F 0.782)] [D acc: (0.500)(0.938, 0.062)] [G loss: 0.606] [G acc: 0.938]\n",
      "14781 [D loss: (0.688)(R 0.595, F 0.782)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.628] [G acc: 0.812]\n",
      "14782 [D loss: (0.697)(R 0.623, F 0.771)] [D acc: (0.562)(1.000, 0.125)] [G loss: 0.679] [G acc: 0.562]\n",
      "14783 [D loss: (0.736)(R 0.704, F 0.768)] [D acc: (0.375)(0.625, 0.125)] [G loss: 0.678] [G acc: 0.625]\n",
      "14784 [D loss: (0.632)(R 0.651, F 0.613)] [D acc: (0.562)(0.750, 0.375)] [G loss: 2.356] [G acc: 0.375]\n",
      "14785 [D loss: (0.496)(R 0.577, F 0.416)] [D acc: (0.844)(1.000, 0.688)] [G loss: 0.860] [G acc: 0.625]\n",
      "14786 [D loss: (0.677)(R 0.583, F 0.770)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.637] [G acc: 0.812]\n",
      "14787 [D loss: (0.669)(R 0.554, F 0.783)] [D acc: (0.562)(0.938, 0.188)] [G loss: 0.626] [G acc: 0.875]\n",
      "14788 [D loss: (0.691)(R 0.633, F 0.750)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.666] [G acc: 0.688]\n",
      "14789 [D loss: (0.702)(R 0.623, F 0.781)] [D acc: (0.438)(0.812, 0.062)] [G loss: 0.664] [G acc: 0.812]\n",
      "14790 [D loss: (0.690)(R 0.642, F 0.738)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.667] [G acc: 0.562]\n",
      "14791 [D loss: (0.676)(R 0.559, F 0.794)] [D acc: (0.469)(0.938, 0.000)] [G loss: 0.677] [G acc: 0.688]\n",
      "14792 [D loss: (0.646)(R 0.591, F 0.701)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.657] [G acc: 0.688]\n",
      "14793 [D loss: (0.708)(R 0.629, F 0.787)] [D acc: (0.375)(0.750, 0.000)] [G loss: 0.632] [G acc: 0.812]\n",
      "14794 [D loss: (0.673)(R 0.605, F 0.742)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.668] [G acc: 0.688]\n",
      "14795 [D loss: (0.638)(R 0.527, F 0.749)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.651] [G acc: 0.688]\n",
      "14796 [D loss: (0.665)(R 0.590, F 0.739)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.655] [G acc: 0.688]\n",
      "14797 [D loss: (0.636)(R 0.550, F 0.723)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.701] [G acc: 0.562]\n",
      "14798 [D loss: (0.645)(R 0.543, F 0.747)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.642] [G acc: 0.812]\n",
      "14799 [D loss: (0.661)(R 0.561, F 0.761)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.645] [G acc: 0.812]\n",
      "14800 [D loss: (0.656)(R 0.584, F 0.727)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.659] [G acc: 0.688]\n",
      "14801 [D loss: (0.694)(R 0.637, F 0.751)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.643] [G acc: 0.812]\n",
      "14802 [D loss: (0.638)(R 0.547, F 0.728)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.687] [G acc: 0.625]\n",
      "14803 [D loss: (0.640)(R 0.614, F 0.665)] [D acc: (0.781)(0.938, 0.625)] [G loss: 0.667] [G acc: 0.688]\n",
      "14804 [D loss: (0.638)(R 0.564, F 0.712)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.692] [G acc: 0.625]\n",
      "14805 [D loss: (0.699)(R 0.685, F 0.713)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.662] [G acc: 0.625]\n",
      "14806 [D loss: (0.664)(R 0.628, F 0.700)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.770] [G acc: 0.312]\n",
      "14807 [D loss: (0.621)(R 0.536, F 0.706)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.697] [G acc: 0.688]\n",
      "14808 [D loss: (0.670)(R 0.640, F 0.701)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.679] [G acc: 0.625]\n",
      "14809 [D loss: (0.688)(R 0.623, F 0.754)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.668] [G acc: 0.688]\n",
      "14810 [D loss: (0.709)(R 0.715, F 0.703)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.707] [G acc: 0.562]\n",
      "14811 [D loss: (0.659)(R 0.578, F 0.740)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.654] [G acc: 0.688]\n",
      "14812 [D loss: (0.633)(R 0.559, F 0.707)] [D acc: (0.656)(0.938, 0.375)] [G loss: 0.672] [G acc: 0.625]\n",
      "14813 [D loss: (0.664)(R 0.595, F 0.733)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.709] [G acc: 0.500]\n",
      "14814 [D loss: (0.646)(R 0.583, F 0.709)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.643] [G acc: 0.625]\n",
      "14815 [D loss: (0.647)(R 0.601, F 0.692)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.721] [G acc: 0.438]\n",
      "14816 [D loss: (0.646)(R 0.589, F 0.704)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.688] [G acc: 0.562]\n",
      "14817 [D loss: (0.747)(R 0.737, F 0.756)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.651] [G acc: 0.750]\n",
      "14818 [D loss: (0.596)(R 0.495, F 0.697)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.707] [G acc: 0.625]\n",
      "14819 [D loss: (0.623)(R 0.517, F 0.729)] [D acc: (0.656)(0.938, 0.375)] [G loss: 0.783] [G acc: 0.438]\n",
      "14820 [D loss: (0.639)(R 0.652, F 0.627)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.665] [G acc: 0.688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14821 [D loss: (0.668)(R 0.638, F 0.699)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.727] [G acc: 0.312]\n",
      "14822 [D loss: (0.608)(R 0.559, F 0.658)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.703] [G acc: 0.438]\n",
      "14823 [D loss: (0.758)(R 0.539, F 0.976)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.719] [G acc: 0.562]\n",
      "14824 [D loss: (0.598)(R 0.548, F 0.647)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.756] [G acc: 0.500]\n",
      "14825 [D loss: (0.642)(R 0.606, F 0.678)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.711] [G acc: 0.625]\n",
      "14826 [D loss: (0.639)(R 0.616, F 0.661)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.719] [G acc: 0.375]\n",
      "14827 [D loss: (0.660)(R 0.577, F 0.742)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.750] [G acc: 0.375]\n",
      "14828 [D loss: (0.620)(R 0.572, F 0.668)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.741] [G acc: 0.375]\n",
      "14829 [D loss: (0.668)(R 0.362, F 0.975)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.730] [G acc: 0.500]\n",
      "14830 [D loss: (0.545)(R 0.424, F 0.666)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.727] [G acc: 0.312]\n",
      "14831 [D loss: (0.665)(R 0.643, F 0.687)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.745] [G acc: 0.250]\n",
      "14832 [D loss: (0.566)(R 0.480, F 0.652)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.675] [G acc: 0.438]\n",
      "14833 [D loss: (0.645)(R 0.617, F 0.673)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.697] [G acc: 0.562]\n",
      "14834 [D loss: (0.627)(R 0.567, F 0.687)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.745] [G acc: 0.250]\n",
      "14835 [D loss: (0.663)(R 0.645, F 0.680)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.759] [G acc: 0.438]\n",
      "14836 [D loss: (0.804)(R 0.531, F 1.077)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.642] [G acc: 0.562]\n",
      "14837 [D loss: (0.822)(R 0.646, F 0.999)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.748] [G acc: 0.500]\n",
      "14838 [D loss: (0.781)(R 0.645, F 0.917)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.555] [G acc: 0.500]\n",
      "14839 [D loss: (0.860)(R 0.648, F 1.072)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.667] [G acc: 0.562]\n",
      "14840 [D loss: (0.737)(R 0.548, F 0.927)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.600] [G acc: 0.688]\n",
      "14841 [D loss: (1.068)(R 0.648, F 1.488)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.894] [G acc: 0.500]\n",
      "14842 [D loss: (0.405)(R 0.510, F 0.301)] [D acc: (0.906)(0.812, 1.000)] [G loss: 6.703] [G acc: 0.312]\n",
      "14843 [D loss: (0.497)(R 0.572, F 0.421)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.707] [G acc: 0.438]\n",
      "14844 [D loss: (0.604)(R 0.635, F 0.572)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.746] [G acc: 0.375]\n",
      "14845 [D loss: (0.534)(R 0.534, F 0.534)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.819] [G acc: 0.562]\n",
      "14846 [D loss: (0.672)(R 0.651, F 0.694)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.740] [G acc: 0.438]\n",
      "14847 [D loss: (0.662)(R 0.633, F 0.691)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.764] [G acc: 0.562]\n",
      "14848 [D loss: (0.673)(R 0.533, F 0.813)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.554] [G acc: 0.750]\n",
      "14849 [D loss: (1.025)(R 0.440, F 1.611)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.574] [G acc: 0.625]\n",
      "14850 [D loss: (0.870)(R 0.645, F 1.095)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.776] [G acc: 0.375]\n",
      "14851 [D loss: (0.584)(R 0.634, F 0.533)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.812] [G acc: 0.438]\n",
      "14852 [D loss: (0.737)(R 0.659, F 0.816)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.755] [G acc: 0.375]\n",
      "14853 [D loss: (0.681)(R 0.699, F 0.663)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.739] [G acc: 0.375]\n",
      "14854 [D loss: (0.661)(R 0.633, F 0.690)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.789] [G acc: 0.125]\n",
      "14855 [D loss: (0.647)(R 0.615, F 0.678)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.775] [G acc: 0.250]\n",
      "14856 [D loss: (0.570)(R 0.600, F 0.539)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.343] [G acc: 0.250]\n",
      "14857 [D loss: (0.497)(R 0.615, F 0.378)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.587] [G acc: 0.125]\n",
      "14858 [D loss: (0.577)(R 0.601, F 0.552)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.432] [G acc: 0.375]\n",
      "14859 [D loss: (0.652)(R 0.627, F 0.677)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.796] [G acc: 0.125]\n",
      "14860 [D loss: (0.628)(R 0.597, F 0.660)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.767] [G acc: 0.312]\n",
      "14861 [D loss: (0.631)(R 0.604, F 0.658)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.828] [G acc: 0.188]\n",
      "14862 [D loss: (0.608)(R 0.600, F 0.615)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.097] [G acc: 0.188]\n",
      "14863 [D loss: (0.674)(R 0.705, F 0.642)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.763] [G acc: 0.250]\n",
      "14864 [D loss: (0.659)(R 0.592, F 0.727)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.732] [G acc: 0.500]\n",
      "14865 [D loss: (0.622)(R 0.604, F 0.639)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.741] [G acc: 0.438]\n",
      "14866 [D loss: (0.718)(R 0.790, F 0.645)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.728] [G acc: 0.500]\n",
      "14867 [D loss: (0.682)(R 0.660, F 0.703)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.701] [G acc: 0.562]\n",
      "14868 [D loss: (0.624)(R 0.584, F 0.664)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.637] [G acc: 0.562]\n",
      "14869 [D loss: (0.677)(R 0.677, F 0.676)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.814] [G acc: 0.062]\n",
      "14870 [D loss: (0.643)(R 0.615, F 0.671)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.754] [G acc: 0.312]\n",
      "14871 [D loss: (0.651)(R 0.601, F 0.700)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.769] [G acc: 0.188]\n",
      "14872 [D loss: (0.682)(R 0.756, F 0.608)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.729] [G acc: 0.312]\n",
      "14873 [D loss: (0.573)(R 0.488, F 0.657)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.778] [G acc: 0.250]\n",
      "14874 [D loss: (0.639)(R 0.601, F 0.677)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.706] [G acc: 0.312]\n",
      "14875 [D loss: (0.830)(R 0.679, F 0.981)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.778] [G acc: 0.375]\n",
      "14876 [D loss: (0.670)(R 0.698, F 0.642)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.779] [G acc: 0.312]\n",
      "14877 [D loss: (0.700)(R 0.695, F 0.705)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.758] [G acc: 0.375]\n",
      "14878 [D loss: (0.641)(R 0.656, F 0.626)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.819] [G acc: 0.062]\n",
      "14879 [D loss: (0.666)(R 0.716, F 0.615)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.782] [G acc: 0.250]\n",
      "14880 [D loss: (0.610)(R 0.519, F 0.700)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.743] [G acc: 0.438]\n",
      "14881 [D loss: (0.659)(R 0.636, F 0.683)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.717] [G acc: 0.312]\n",
      "14882 [D loss: (0.747)(R 0.687, F 0.808)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.787] [G acc: 0.312]\n",
      "14883 [D loss: (0.634)(R 0.610, F 0.658)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.755] [G acc: 0.250]\n",
      "14884 [D loss: (0.654)(R 0.665, F 0.642)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.733] [G acc: 0.375]\n",
      "14885 [D loss: (0.596)(R 0.527, F 0.665)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.841] [G acc: 0.250]\n",
      "14886 [D loss: (0.660)(R 0.694, F 0.625)] [D acc: (0.656)(0.375, 0.938)] [G loss: 0.762] [G acc: 0.125]\n",
      "14887 [D loss: (0.644)(R 0.586, F 0.703)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.734] [G acc: 0.188]\n",
      "14888 [D loss: (0.688)(R 0.740, F 0.637)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.744] [G acc: 0.250]\n",
      "14889 [D loss: (0.646)(R 0.652, F 0.640)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.820] [G acc: 0.188]\n",
      "14890 [D loss: (0.662)(R 0.650, F 0.675)] [D acc: (0.344)(0.250, 0.438)] [G loss: 0.655] [G acc: 0.500]\n",
      "14891 [D loss: (0.628)(R 0.609, F 0.647)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.782] [G acc: 0.188]\n",
      "14892 [D loss: (0.603)(R 0.536, F 0.670)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.774] [G acc: 0.188]\n",
      "14893 [D loss: (0.653)(R 0.610, F 0.696)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.745] [G acc: 0.312]\n",
      "14894 [D loss: (0.569)(R 0.498, F 0.640)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.700] [G acc: 0.375]\n",
      "14895 [D loss: (0.737)(R 0.623, F 0.851)] [D acc: (0.500)(0.250, 0.750)] [G loss: 0.620] [G acc: 0.438]\n",
      "14896 [D loss: (0.763)(R 0.595, F 0.931)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.626] [G acc: 0.438]\n",
      "14897 [D loss: (0.587)(R 0.576, F 0.599)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.695] [G acc: 0.188]\n",
      "14898 [D loss: (0.662)(R 0.566, F 0.758)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.988] [G acc: 0.000]\n",
      "14899 [D loss: (0.612)(R 0.622, F 0.602)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.816] [G acc: 0.188]\n",
      "14900 [D loss: (0.688)(R 0.752, F 0.624)] [D acc: (0.469)(0.125, 0.812)] [G loss: 0.801] [G acc: 0.125]\n",
      "14901 [D loss: (0.646)(R 0.656, F 0.635)] [D acc: (0.594)(0.375, 0.812)] [G loss: 1.281] [G acc: 0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14902 [D loss: (0.487)(R 0.656, F 0.318)] [D acc: (0.562)(0.250, 0.875)] [G loss: 4.554] [G acc: 0.125]\n",
      "14903 [D loss: (0.610)(R 0.597, F 0.623)] [D acc: (0.594)(0.312, 0.875)] [G loss: 0.827] [G acc: 0.188]\n",
      "14904 [D loss: (0.641)(R 0.652, F 0.630)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.771] [G acc: 0.062]\n",
      "14905 [D loss: (0.641)(R 0.666, F 0.615)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.655] [G acc: 0.250]\n",
      "14906 [D loss: (0.642)(R 0.642, F 0.642)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.798] [G acc: 0.188]\n",
      "14907 [D loss: (0.656)(R 0.693, F 0.618)] [D acc: (0.625)(0.312, 0.938)] [G loss: 0.801] [G acc: 0.000]\n",
      "14908 [D loss: (0.886)(R 0.571, F 1.200)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.778] [G acc: 0.062]\n",
      "14909 [D loss: (0.619)(R 0.634, F 0.605)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.733] [G acc: 0.188]\n",
      "14910 [D loss: (0.524)(R 0.454, F 0.595)] [D acc: (0.781)(0.562, 1.000)] [G loss: 0.746] [G acc: 0.188]\n",
      "14911 [D loss: (0.646)(R 0.668, F 0.623)] [D acc: (0.594)(0.250, 0.938)] [G loss: 0.857] [G acc: 0.188]\n",
      "14912 [D loss: (0.596)(R 0.594, F 0.598)] [D acc: (0.656)(0.375, 0.938)] [G loss: 0.812] [G acc: 0.062]\n",
      "14913 [D loss: (0.616)(R 0.660, F 0.572)] [D acc: (0.656)(0.312, 1.000)] [G loss: 0.781] [G acc: 0.062]\n",
      "14914 [D loss: (0.656)(R 0.700, F 0.612)] [D acc: (0.594)(0.312, 0.875)] [G loss: 0.809] [G acc: 0.062]\n",
      "14915 [D loss: (0.845)(R 0.628, F 1.063)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.737] [G acc: 0.125]\n",
      "14916 [D loss: (0.660)(R 0.695, F 0.625)] [D acc: (0.469)(0.188, 0.750)] [G loss: 0.783] [G acc: 0.188]\n",
      "14917 [D loss: (0.848)(R 0.657, F 1.038)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.754] [G acc: 0.062]\n",
      "14918 [D loss: (0.631)(R 0.609, F 0.653)] [D acc: (0.594)(0.312, 0.875)] [G loss: 0.794] [G acc: 0.125]\n",
      "14919 [D loss: (0.631)(R 0.596, F 0.666)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.775] [G acc: 0.062]\n",
      "14920 [D loss: (0.613)(R 0.607, F 0.619)] [D acc: (0.719)(0.500, 0.938)] [G loss: 0.763] [G acc: 0.125]\n",
      "14921 [D loss: (0.608)(R 0.627, F 0.589)] [D acc: (0.594)(0.312, 0.875)] [G loss: 0.754] [G acc: 0.312]\n",
      "14922 [D loss: (0.689)(R 0.700, F 0.678)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.774] [G acc: 0.062]\n",
      "14923 [D loss: (0.686)(R 0.588, F 0.783)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.804] [G acc: 0.000]\n",
      "14924 [D loss: (0.657)(R 0.687, F 0.627)] [D acc: (0.594)(0.250, 0.938)] [G loss: 0.809] [G acc: 0.062]\n",
      "14925 [D loss: (0.664)(R 0.659, F 0.668)] [D acc: (0.656)(0.375, 0.938)] [G loss: 0.776] [G acc: 0.125]\n",
      "14926 [D loss: (0.643)(R 0.698, F 0.588)] [D acc: (0.656)(0.312, 1.000)] [G loss: 0.825] [G acc: 0.062]\n",
      "14927 [D loss: (0.622)(R 0.599, F 0.646)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.757] [G acc: 0.062]\n",
      "14928 [D loss: (0.671)(R 0.720, F 0.622)] [D acc: (0.625)(0.250, 1.000)] [G loss: 0.734] [G acc: 0.125]\n",
      "14929 [D loss: (0.587)(R 0.573, F 0.600)] [D acc: (0.625)(0.312, 0.938)] [G loss: 0.757] [G acc: 0.188]\n",
      "14930 [D loss: (0.627)(R 0.649, F 0.605)] [D acc: (0.562)(0.250, 0.875)] [G loss: 0.781] [G acc: 0.125]\n",
      "14931 [D loss: (0.591)(R 0.532, F 0.649)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.715] [G acc: 0.250]\n",
      "14932 [D loss: (0.668)(R 0.713, F 0.623)] [D acc: (0.656)(0.375, 0.938)] [G loss: 0.765] [G acc: 0.062]\n",
      "14933 [D loss: (0.800)(R 0.685, F 0.915)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.759] [G acc: 0.125]\n",
      "14934 [D loss: (0.688)(R 0.497, F 0.879)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.793] [G acc: 0.000]\n",
      "14935 [D loss: (0.942)(R 0.670, F 1.214)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.747] [G acc: 0.125]\n",
      "14936 [D loss: (0.600)(R 0.600, F 0.600)] [D acc: (0.656)(0.375, 0.938)] [G loss: 0.796] [G acc: 0.000]\n",
      "14937 [D loss: (0.624)(R 0.630, F 0.617)] [D acc: (0.656)(0.375, 0.938)] [G loss: 0.814] [G acc: 0.000]\n",
      "14938 [D loss: (0.684)(R 0.613, F 0.755)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.763] [G acc: 0.125]\n",
      "14939 [D loss: (0.637)(R 0.630, F 0.645)] [D acc: (0.562)(0.250, 0.875)] [G loss: 0.835] [G acc: 0.062]\n",
      "14940 [D loss: (0.622)(R 0.590, F 0.654)] [D acc: (0.625)(0.312, 0.938)] [G loss: 0.767] [G acc: 0.188]\n",
      "14941 [D loss: (0.630)(R 0.604, F 0.657)] [D acc: (0.719)(0.500, 0.938)] [G loss: 0.783] [G acc: 0.125]\n",
      "14942 [D loss: (0.595)(R 0.607, F 0.582)] [D acc: (0.656)(0.375, 0.938)] [G loss: 0.800] [G acc: 0.062]\n",
      "14943 [D loss: (0.678)(R 0.697, F 0.658)] [D acc: (0.500)(0.188, 0.812)] [G loss: 0.808] [G acc: 0.062]\n",
      "14944 [D loss: (0.690)(R 0.651, F 0.728)] [D acc: (0.531)(0.250, 0.812)] [G loss: 0.821] [G acc: 0.125]\n",
      "14945 [D loss: (0.601)(R 0.612, F 0.590)] [D acc: (0.688)(0.375, 1.000)] [G loss: 0.785] [G acc: 0.125]\n",
      "14946 [D loss: (0.638)(R 0.585, F 0.691)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.771] [G acc: 0.125]\n",
      "14947 [D loss: (0.596)(R 0.596, F 0.596)] [D acc: (0.688)(0.438, 0.938)] [G loss: 0.831] [G acc: 0.062]\n",
      "14948 [D loss: (0.728)(R 0.725, F 0.731)] [D acc: (0.562)(0.188, 0.938)] [G loss: 0.926] [G acc: 0.000]\n",
      "14949 [D loss: (0.669)(R 0.662, F 0.677)] [D acc: (0.688)(0.438, 0.938)] [G loss: 0.769] [G acc: 0.125]\n",
      "14950 [D loss: (0.649)(R 0.729, F 0.568)] [D acc: (0.656)(0.312, 1.000)] [G loss: 0.736] [G acc: 0.125]\n",
      "14951 [D loss: (0.600)(R 0.604, F 0.597)] [D acc: (0.625)(0.312, 0.938)] [G loss: 0.689] [G acc: 0.312]\n",
      "14952 [D loss: (0.929)(R 0.697, F 1.162)] [D acc: (0.562)(0.312, 0.812)] [G loss: 0.804] [G acc: 0.000]\n",
      "14953 [D loss: (0.686)(R 0.769, F 0.603)] [D acc: (0.500)(0.062, 0.938)] [G loss: 0.776] [G acc: 0.312]\n",
      "14954 [D loss: (0.716)(R 0.721, F 0.712)] [D acc: (0.438)(0.188, 0.688)] [G loss: 0.647] [G acc: 0.312]\n",
      "14955 [D loss: (0.753)(R 0.709, F 0.797)] [D acc: (0.438)(0.250, 0.625)] [G loss: 0.661] [G acc: 0.375]\n",
      "14956 [D loss: (0.790)(R 0.822, F 0.757)] [D acc: (0.344)(0.062, 0.625)] [G loss: 0.910] [G acc: 0.250]\n",
      "14957 [D loss: (0.559)(R 0.651, F 0.467)] [D acc: (0.594)(0.250, 0.938)] [G loss: 1.994] [G acc: 0.312]\n",
      "14958 [D loss: (0.511)(R 0.737, F 0.285)] [D acc: (0.562)(0.188, 0.938)] [G loss: 1.146] [G acc: 0.062]\n",
      "14959 [D loss: (0.837)(R 0.735, F 0.939)] [D acc: (0.406)(0.188, 0.625)] [G loss: 0.781] [G acc: 0.188]\n",
      "14960 [D loss: (0.693)(R 0.736, F 0.649)] [D acc: (0.469)(0.188, 0.750)] [G loss: 0.716] [G acc: 0.250]\n",
      "14961 [D loss: (0.948)(R 0.687, F 1.209)] [D acc: (0.438)(0.250, 0.625)] [G loss: 0.701] [G acc: 0.188]\n",
      "14962 [D loss: (0.631)(R 0.634, F 0.627)] [D acc: (0.594)(0.250, 0.938)] [G loss: 0.725] [G acc: 0.188]\n",
      "14963 [D loss: (0.738)(R 0.762, F 0.714)] [D acc: (0.406)(0.062, 0.750)] [G loss: 0.715] [G acc: 0.250]\n",
      "14964 [D loss: (0.775)(R 0.711, F 0.838)] [D acc: (0.500)(0.125, 0.875)] [G loss: 0.849] [G acc: 0.125]\n",
      "14965 [D loss: (0.713)(R 0.802, F 0.623)] [D acc: (0.500)(0.250, 0.750)] [G loss: 0.791] [G acc: 0.188]\n",
      "14966 [D loss: (0.658)(R 0.695, F 0.622)] [D acc: (0.562)(0.250, 0.875)] [G loss: 0.770] [G acc: 0.125]\n",
      "14967 [D loss: (1.111)(R 0.816, F 1.406)] [D acc: (0.344)(0.000, 0.688)] [G loss: 0.764] [G acc: 0.062]\n",
      "14968 [D loss: (0.680)(R 0.754, F 0.606)] [D acc: (0.500)(0.250, 0.750)] [G loss: 0.715] [G acc: 0.188]\n",
      "14969 [D loss: (0.830)(R 0.787, F 0.873)] [D acc: (0.375)(0.125, 0.625)] [G loss: 0.799] [G acc: 0.062]\n",
      "14970 [D loss: (0.778)(R 0.781, F 0.775)] [D acc: (0.438)(0.312, 0.562)] [G loss: 0.737] [G acc: 0.250]\n",
      "14971 [D loss: (0.739)(R 0.703, F 0.776)] [D acc: (0.562)(0.312, 0.812)] [G loss: 0.754] [G acc: 0.000]\n",
      "14972 [D loss: (0.691)(R 0.734, F 0.649)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.773] [G acc: 0.125]\n",
      "14973 [D loss: (0.727)(R 0.792, F 0.662)] [D acc: (0.469)(0.125, 0.812)] [G loss: 0.756] [G acc: 0.000]\n",
      "14974 [D loss: (0.717)(R 0.694, F 0.740)] [D acc: (0.500)(0.250, 0.750)] [G loss: 0.672] [G acc: 0.125]\n",
      "14975 [D loss: (0.665)(R 0.705, F 0.624)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.700] [G acc: 0.188]\n",
      "14976 [D loss: (0.680)(R 0.709, F 0.652)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.730] [G acc: 0.062]\n",
      "14977 [D loss: (0.663)(R 0.732, F 0.595)] [D acc: (0.562)(0.188, 0.938)] [G loss: 0.729] [G acc: 0.125]\n",
      "14978 [D loss: (0.853)(R 0.986, F 0.720)] [D acc: (0.438)(0.188, 0.688)] [G loss: 0.753] [G acc: 0.188]\n",
      "14979 [D loss: (0.711)(R 0.749, F 0.673)] [D acc: (0.406)(0.000, 0.812)] [G loss: 0.786] [G acc: 0.188]\n",
      "14980 [D loss: (0.674)(R 0.676, F 0.673)] [D acc: (0.438)(0.250, 0.625)] [G loss: 0.700] [G acc: 0.250]\n",
      "14981 [D loss: (0.690)(R 0.738, F 0.641)] [D acc: (0.500)(0.125, 0.875)] [G loss: 0.692] [G acc: 0.250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14982 [D loss: (0.653)(R 0.629, F 0.676)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.724] [G acc: 0.125]\n",
      "14983 [D loss: (0.677)(R 0.697, F 0.658)] [D acc: (0.531)(0.125, 0.938)] [G loss: 0.680] [G acc: 0.312]\n",
      "14984 [D loss: (0.720)(R 0.756, F 0.684)] [D acc: (0.344)(0.125, 0.562)] [G loss: 0.732] [G acc: 0.312]\n",
      "14985 [D loss: (0.669)(R 0.671, F 0.667)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.743] [G acc: 0.125]\n",
      "14986 [D loss: (0.701)(R 0.731, F 0.670)] [D acc: (0.438)(0.250, 0.625)] [G loss: 0.679] [G acc: 0.312]\n",
      "14987 [D loss: (0.649)(R 0.635, F 0.664)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.731] [G acc: 0.125]\n",
      "14988 [D loss: (0.663)(R 0.671, F 0.655)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.726] [G acc: 0.188]\n",
      "14989 [D loss: (0.697)(R 0.723, F 0.672)] [D acc: (0.438)(0.188, 0.688)] [G loss: 0.748] [G acc: 0.125]\n",
      "14990 [D loss: (0.659)(R 0.655, F 0.663)] [D acc: (0.469)(0.250, 0.688)] [G loss: 0.757] [G acc: 0.062]\n",
      "14991 [D loss: (0.661)(R 0.674, F 0.648)] [D acc: (0.625)(0.312, 0.938)] [G loss: 0.743] [G acc: 0.062]\n",
      "14992 [D loss: (0.703)(R 0.717, F 0.689)] [D acc: (0.438)(0.250, 0.625)] [G loss: 0.748] [G acc: 0.062]\n",
      "14993 [D loss: (0.695)(R 0.719, F 0.671)] [D acc: (0.469)(0.188, 0.750)] [G loss: 0.732] [G acc: 0.062]\n",
      "14994 [D loss: (0.666)(R 0.665, F 0.666)] [D acc: (0.500)(0.312, 0.688)] [G loss: 0.736] [G acc: 0.188]\n",
      "14995 [D loss: (0.665)(R 0.661, F 0.669)] [D acc: (0.500)(0.250, 0.750)] [G loss: 0.694] [G acc: 0.125]\n",
      "14996 [D loss: (0.623)(R 0.589, F 0.656)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.682] [G acc: 0.312]\n",
      "14997 [D loss: (0.746)(R 0.728, F 0.763)] [D acc: (0.438)(0.062, 0.812)] [G loss: 0.706] [G acc: 0.312]\n",
      "14998 [D loss: (0.701)(R 0.712, F 0.690)] [D acc: (0.469)(0.250, 0.688)] [G loss: 0.742] [G acc: 0.062]\n",
      "14999 [D loss: (0.680)(R 0.730, F 0.631)] [D acc: (0.469)(0.188, 0.750)] [G loss: 0.703] [G acc: 0.250]\n",
      "15000 [D loss: (0.715)(R 0.705, F 0.724)] [D acc: (0.312)(0.188, 0.438)] [G loss: 0.682] [G acc: 0.312]\n",
      "15001 [D loss: (0.692)(R 0.707, F 0.677)] [D acc: (0.438)(0.125, 0.750)] [G loss: 0.736] [G acc: 0.188]\n",
      "15002 [D loss: (0.711)(R 0.651, F 0.771)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.725] [G acc: 0.375]\n",
      "15003 [D loss: (0.711)(R 0.685, F 0.737)] [D acc: (0.594)(0.312, 0.875)] [G loss: 0.746] [G acc: 0.125]\n",
      "15004 [D loss: (0.666)(R 0.661, F 0.671)] [D acc: (0.719)(0.500, 0.938)] [G loss: 0.724] [G acc: 0.312]\n",
      "15005 [D loss: (0.828)(R 0.664, F 0.993)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.709] [G acc: 0.250]\n",
      "15006 [D loss: (0.683)(R 0.662, F 0.704)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.721] [G acc: 0.188]\n",
      "15007 [D loss: (0.707)(R 0.732, F 0.681)] [D acc: (0.500)(0.188, 0.812)] [G loss: 0.739] [G acc: 0.250]\n",
      "15008 [D loss: (0.791)(R 0.657, F 0.926)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.734] [G acc: 0.188]\n",
      "15009 [D loss: (0.716)(R 0.621, F 0.811)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.683] [G acc: 0.312]\n",
      "15010 [D loss: (0.728)(R 0.724, F 0.732)] [D acc: (0.375)(0.188, 0.562)] [G loss: 0.785] [G acc: 0.312]\n",
      "15011 [D loss: (0.673)(R 0.722, F 0.623)] [D acc: (0.438)(0.125, 0.750)] [G loss: 6.272] [G acc: 0.062]\n",
      "15012 [D loss: (0.714)(R 0.712, F 0.717)] [D acc: (0.469)(0.438, 0.500)] [G loss: 1.537] [G acc: 0.312]\n",
      "15013 [D loss: (0.773)(R 0.663, F 0.884)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.693] [G acc: 0.438]\n",
      "15014 [D loss: (0.761)(R 0.659, F 0.863)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.673] [G acc: 0.250]\n",
      "15015 [D loss: (0.779)(R 0.717, F 0.841)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.690] [G acc: 0.438]\n",
      "15016 [D loss: (0.724)(R 0.726, F 0.722)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.760] [G acc: 0.250]\n",
      "15017 [D loss: (0.674)(R 0.671, F 0.677)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.773] [G acc: 0.188]\n",
      "15018 [D loss: (0.672)(R 0.664, F 0.681)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.722] [G acc: 0.250]\n",
      "15019 [D loss: (0.705)(R 0.723, F 0.687)] [D acc: (0.406)(0.312, 0.500)] [G loss: 0.767] [G acc: 0.500]\n",
      "15020 [D loss: (0.704)(R 0.708, F 0.700)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.787] [G acc: 0.312]\n",
      "15021 [D loss: (0.712)(R 0.720, F 0.704)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.684] [G acc: 0.625]\n",
      "15022 [D loss: (0.713)(R 0.661, F 0.765)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.790] [G acc: 0.312]\n",
      "15023 [D loss: (0.705)(R 0.723, F 0.688)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.743] [G acc: 0.188]\n",
      "15024 [D loss: (0.669)(R 0.711, F 0.628)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.707] [G acc: 0.375]\n",
      "15025 [D loss: (0.852)(R 0.702, F 1.003)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.730] [G acc: 0.562]\n",
      "15026 [D loss: (0.666)(R 0.692, F 0.640)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.737] [G acc: 0.625]\n",
      "15027 [D loss: (0.827)(R 0.708, F 0.945)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.706] [G acc: 0.375]\n",
      "15028 [D loss: (0.698)(R 0.730, F 0.666)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.730] [G acc: 0.312]\n",
      "15029 [D loss: (0.722)(R 0.787, F 0.658)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.698] [G acc: 0.625]\n",
      "15030 [D loss: (0.669)(R 0.681, F 0.656)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.742] [G acc: 0.375]\n",
      "15031 [D loss: (0.681)(R 0.692, F 0.671)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.706] [G acc: 0.438]\n",
      "15032 [D loss: (0.690)(R 0.706, F 0.675)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.038] [G acc: 0.500]\n",
      "15033 [D loss: (0.584)(R 0.687, F 0.482)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.588] [G acc: 0.188]\n",
      "15034 [D loss: (0.681)(R 0.715, F 0.648)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.768] [G acc: 0.438]\n",
      "15035 [D loss: (0.649)(R 0.674, F 0.624)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.770] [G acc: 0.125]\n",
      "15036 [D loss: (0.656)(R 0.687, F 0.626)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.778] [G acc: 0.250]\n",
      "15037 [D loss: (0.667)(R 0.682, F 0.653)] [D acc: (0.656)(0.688, 0.625)] [G loss: 2.386] [G acc: 0.312]\n",
      "15038 [D loss: (0.607)(R 0.697, F 0.517)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.992] [G acc: 0.312]\n",
      "15039 [D loss: (0.577)(R 0.665, F 0.490)] [D acc: (0.875)(0.875, 0.875)] [G loss: 0.853] [G acc: 0.312]\n",
      "15040 [D loss: (0.629)(R 0.672, F 0.586)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.803] [G acc: 0.375]\n",
      "15041 [D loss: (0.667)(R 0.718, F 0.615)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.772] [G acc: 0.312]\n",
      "15042 [D loss: (0.601)(R 0.647, F 0.555)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.129] [G acc: 0.312]\n",
      "15043 [D loss: (0.594)(R 0.645, F 0.543)] [D acc: (0.938)(0.938, 0.938)] [G loss: 1.138] [G acc: 0.438]\n",
      "15044 [D loss: (0.634)(R 0.680, F 0.589)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.843] [G acc: 0.312]\n",
      "15045 [D loss: (0.679)(R 0.717, F 0.641)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.818] [G acc: 0.188]\n",
      "15046 [D loss: (0.661)(R 0.698, F 0.625)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.804] [G acc: 0.250]\n",
      "15047 [D loss: (0.646)(R 0.661, F 0.631)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.798] [G acc: 0.250]\n",
      "15048 [D loss: (0.647)(R 0.688, F 0.606)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.875] [G acc: 0.438]\n",
      "15049 [D loss: (0.639)(R 0.704, F 0.574)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.808] [G acc: 0.250]\n",
      "15050 [D loss: (0.666)(R 0.710, F 0.621)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.817] [G acc: 0.250]\n",
      "15051 [D loss: (0.623)(R 0.615, F 0.631)] [D acc: (0.750)(0.938, 0.562)] [G loss: 0.819] [G acc: 0.250]\n",
      "15052 [D loss: (0.681)(R 0.783, F 0.578)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.819] [G acc: 0.312]\n",
      "15053 [D loss: (0.610)(R 0.660, F 0.560)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.922] [G acc: 0.250]\n",
      "15054 [D loss: (0.666)(R 0.691, F 0.641)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.746] [G acc: 0.250]\n",
      "15055 [D loss: (0.766)(R 0.903, F 0.629)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.139] [G acc: 0.188]\n",
      "15056 [D loss: (0.650)(R 0.661, F 0.640)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.830] [G acc: 0.125]\n",
      "15057 [D loss: (0.684)(R 0.686, F 0.681)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.749] [G acc: 0.250]\n",
      "15058 [D loss: (0.655)(R 0.686, F 0.624)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.796] [G acc: 0.188]\n",
      "15059 [D loss: (0.662)(R 0.701, F 0.623)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.784] [G acc: 0.375]\n",
      "15060 [D loss: (0.649)(R 0.668, F 0.629)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.843] [G acc: 0.312]\n",
      "15061 [D loss: (0.670)(R 0.783, F 0.556)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.894] [G acc: 0.125]\n",
      "15062 [D loss: (0.580)(R 0.626, F 0.534)] [D acc: (0.875)(0.875, 0.875)] [G loss: 0.902] [G acc: 0.250]\n",
      "15063 [D loss: (0.623)(R 0.661, F 0.585)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.962] [G acc: 0.188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15064 [D loss: (0.634)(R 0.678, F 0.591)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.949] [G acc: 0.125]\n",
      "15065 [D loss: (0.685)(R 0.768, F 0.602)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.861] [G acc: 0.250]\n",
      "15066 [D loss: (0.601)(R 0.672, F 0.530)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.026] [G acc: 0.125]\n",
      "15067 [D loss: (0.578)(R 0.641, F 0.515)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.194] [G acc: 0.125]\n",
      "15068 [D loss: (0.652)(R 0.668, F 0.637)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.006] [G acc: 0.188]\n",
      "15069 [D loss: (0.663)(R 0.720, F 0.607)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.054] [G acc: 0.312]\n",
      "15070 [D loss: (0.665)(R 0.695, F 0.635)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.767] [G acc: 0.438]\n",
      "15071 [D loss: (0.787)(R 0.965, F 0.610)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.760] [G acc: 0.312]\n",
      "15072 [D loss: (0.654)(R 0.699, F 0.609)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.827] [G acc: 0.312]\n",
      "15073 [D loss: (0.626)(R 0.594, F 0.658)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.772] [G acc: 0.312]\n",
      "15074 [D loss: (0.715)(R 0.783, F 0.647)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.868] [G acc: 0.375]\n",
      "15075 [D loss: (0.620)(R 0.687, F 0.553)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.973] [G acc: 0.188]\n",
      "15076 [D loss: (0.510)(R 0.681, F 0.340)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.337] [G acc: 0.125]\n",
      "15077 [D loss: (0.660)(R 0.732, F 0.588)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.854] [G acc: 0.188]\n",
      "15078 [D loss: (0.604)(R 0.671, F 0.537)] [D acc: (0.875)(0.750, 1.000)] [G loss: 0.912] [G acc: 0.125]\n",
      "15079 [D loss: (0.684)(R 0.783, F 0.584)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.851] [G acc: 0.125]\n",
      "15080 [D loss: (0.665)(R 0.742, F 0.587)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.815] [G acc: 0.312]\n",
      "15081 [D loss: (0.654)(R 0.725, F 0.584)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.778] [G acc: 0.250]\n",
      "15082 [D loss: (0.718)(R 0.837, F 0.600)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.881] [G acc: 0.125]\n",
      "15083 [D loss: (0.640)(R 0.679, F 0.601)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.087] [G acc: 0.125]\n",
      "15084 [D loss: (0.603)(R 0.636, F 0.569)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.054] [G acc: 0.062]\n",
      "15085 [D loss: (0.680)(R 0.779, F 0.581)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.792] [G acc: 0.312]\n",
      "15086 [D loss: (0.658)(R 0.716, F 0.599)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.791] [G acc: 0.312]\n",
      "15087 [D loss: (0.600)(R 0.627, F 0.573)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.058] [G acc: 0.188]\n",
      "15088 [D loss: (0.674)(R 0.754, F 0.595)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.842] [G acc: 0.062]\n",
      "15089 [D loss: (0.687)(R 0.785, F 0.589)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.772] [G acc: 0.438]\n",
      "15090 [D loss: (0.560)(R 0.551, F 0.568)] [D acc: (0.906)(0.875, 0.938)] [G loss: 0.843] [G acc: 0.125]\n",
      "15091 [D loss: (0.627)(R 0.661, F 0.594)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.869] [G acc: 0.188]\n",
      "15092 [D loss: (0.678)(R 0.768, F 0.588)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.837] [G acc: 0.250]\n",
      "15093 [D loss: (0.660)(R 0.699, F 0.621)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.810] [G acc: 0.312]\n",
      "15094 [D loss: (0.674)(R 0.748, F 0.599)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.874] [G acc: 0.188]\n",
      "15095 [D loss: (0.613)(R 0.670, F 0.556)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.818] [G acc: 0.312]\n",
      "15096 [D loss: (0.499)(R 0.659, F 0.339)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.045] [G acc: 0.062]\n",
      "15097 [D loss: (0.649)(R 0.748, F 0.549)] [D acc: (0.656)(0.375, 0.938)] [G loss: 0.798] [G acc: 0.250]\n",
      "15098 [D loss: (0.668)(R 0.711, F 0.624)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.842] [G acc: 0.250]\n",
      "15099 [D loss: (0.620)(R 0.637, F 0.602)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.873] [G acc: 0.125]\n",
      "15100 [D loss: (0.668)(R 0.680, F 0.657)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.782] [G acc: 0.375]\n",
      "15101 [D loss: (0.633)(R 0.705, F 0.561)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.785] [G acc: 0.188]\n",
      "15102 [D loss: (0.677)(R 0.721, F 0.632)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.851] [G acc: 0.188]\n",
      "15103 [D loss: (0.663)(R 0.690, F 0.636)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.882] [G acc: 0.125]\n",
      "15104 [D loss: (0.709)(R 0.773, F 0.644)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.742] [G acc: 0.250]\n",
      "15105 [D loss: (0.739)(R 0.811, F 0.667)] [D acc: (0.344)(0.188, 0.500)] [G loss: 0.834] [G acc: 0.250]\n",
      "15106 [D loss: (0.690)(R 0.705, F 0.675)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.723] [G acc: 0.562]\n",
      "15107 [D loss: (0.712)(R 0.753, F 0.672)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.793] [G acc: 0.375]\n",
      "15108 [D loss: (0.659)(R 0.713, F 0.606)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.729] [G acc: 0.562]\n",
      "15109 [D loss: (0.606)(R 0.556, F 0.655)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.730] [G acc: 0.562]\n",
      "15110 [D loss: (0.698)(R 0.709, F 0.686)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.724] [G acc: 0.375]\n",
      "15111 [D loss: (0.646)(R 0.670, F 0.622)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.683] [G acc: 0.625]\n",
      "15112 [D loss: (0.667)(R 0.610, F 0.725)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.807] [G acc: 0.375]\n",
      "15113 [D loss: (0.664)(R 0.693, F 0.636)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.819] [G acc: 0.500]\n",
      "15114 [D loss: (0.679)(R 0.662, F 0.696)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.724] [G acc: 0.500]\n",
      "15115 [D loss: (0.716)(R 0.747, F 0.686)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.760] [G acc: 0.188]\n",
      "15116 [D loss: (0.655)(R 0.641, F 0.668)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.692] [G acc: 0.625]\n",
      "15117 [D loss: (0.664)(R 0.662, F 0.665)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.821] [G acc: 0.500]\n",
      "15118 [D loss: (0.682)(R 0.685, F 0.679)] [D acc: (0.531)(0.562, 0.500)] [G loss: 1.363] [G acc: 0.062]\n",
      "15119 [D loss: (0.462)(R 0.573, F 0.351)] [D acc: (0.719)(0.750, 0.688)] [G loss: 3.680] [G acc: 0.250]\n",
      "15120 [D loss: (0.595)(R 0.501, F 0.688)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.670] [G acc: 0.688]\n",
      "15121 [D loss: (0.672)(R 0.665, F 0.679)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.727] [G acc: 0.562]\n",
      "15122 [D loss: (0.651)(R 0.637, F 0.665)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.767] [G acc: 0.375]\n",
      "15123 [D loss: (0.691)(R 0.681, F 0.701)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.757] [G acc: 0.500]\n",
      "15124 [D loss: (0.623)(R 0.589, F 0.657)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.689] [G acc: 0.625]\n",
      "15125 [D loss: (0.536)(R 0.412, F 0.660)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.746] [G acc: 0.375]\n",
      "15126 [D loss: (0.607)(R 0.552, F 0.663)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.804] [G acc: 0.312]\n",
      "15127 [D loss: (0.680)(R 0.691, F 0.669)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.713] [G acc: 0.438]\n",
      "15128 [D loss: (0.649)(R 0.511, F 0.786)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.700] [G acc: 0.500]\n",
      "15129 [D loss: (0.643)(R 0.589, F 0.696)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.717] [G acc: 0.562]\n",
      "15130 [D loss: (0.729)(R 0.646, F 0.812)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.807] [G acc: 0.375]\n",
      "15131 [D loss: (0.522)(R 0.496, F 0.548)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.622] [G acc: 0.625]\n",
      "15132 [D loss: (0.569)(R 0.457, F 0.681)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.692] [G acc: 0.375]\n",
      "15133 [D loss: (0.627)(R 0.601, F 0.653)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.700] [G acc: 0.375]\n",
      "15134 [D loss: (0.698)(R 0.621, F 0.774)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.627] [G acc: 0.625]\n",
      "15135 [D loss: (0.629)(R 0.555, F 0.704)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.832] [G acc: 0.188]\n",
      "15136 [D loss: (0.671)(R 0.567, F 0.776)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.765] [G acc: 0.375]\n",
      "15137 [D loss: (0.694)(R 0.706, F 0.682)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.744] [G acc: 0.250]\n",
      "15138 [D loss: (0.605)(R 0.546, F 0.664)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.757] [G acc: 0.312]\n",
      "15139 [D loss: (0.672)(R 0.678, F 0.667)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.675] [G acc: 0.438]\n",
      "15140 [D loss: (0.657)(R 0.609, F 0.706)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.831] [G acc: 0.250]\n",
      "15141 [D loss: (0.740)(R 0.572, F 0.907)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.713] [G acc: 0.500]\n",
      "15142 [D loss: (0.664)(R 0.763, F 0.565)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.772] [G acc: 0.438]\n",
      "15143 [D loss: (0.767)(R 0.676, F 0.857)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.962] [G acc: 0.250]\n",
      "15144 [D loss: (0.673)(R 0.794, F 0.552)] [D acc: (0.594)(0.312, 0.875)] [G loss: 0.889] [G acc: 0.312]\n",
      "15145 [D loss: (0.561)(R 0.593, F 0.530)] [D acc: (0.844)(0.750, 0.938)] [G loss: 0.751] [G acc: 0.438]\n",
      "15146 [D loss: (0.799)(R 0.748, F 0.851)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.787] [G acc: 0.312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15147 [D loss: (0.660)(R 0.706, F 0.615)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.841] [G acc: 0.375]\n",
      "15148 [D loss: (0.625)(R 0.718, F 0.531)] [D acc: (0.625)(0.438, 0.812)] [G loss: 2.273] [G acc: 0.188]\n",
      "15149 [D loss: (0.636)(R 0.729, F 0.543)] [D acc: (0.594)(0.500, 0.688)] [G loss: 1.428] [G acc: 0.188]\n",
      "15150 [D loss: (0.687)(R 0.706, F 0.669)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.886] [G acc: 0.312]\n",
      "15151 [D loss: (0.621)(R 0.687, F 0.555)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.862] [G acc: 0.125]\n",
      "15152 [D loss: (0.640)(R 0.608, F 0.673)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.828] [G acc: 0.125]\n",
      "15153 [D loss: (0.879)(R 0.971, F 0.787)] [D acc: (0.406)(0.250, 0.562)] [G loss: 0.875] [G acc: 0.188]\n",
      "15154 [D loss: (0.601)(R 0.634, F 0.569)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.847] [G acc: 0.188]\n",
      "15155 [D loss: (0.641)(R 0.589, F 0.693)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.832] [G acc: 0.312]\n",
      "15156 [D loss: (0.689)(R 0.635, F 0.743)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.869] [G acc: 0.250]\n",
      "15157 [D loss: (0.699)(R 0.668, F 0.730)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.895] [G acc: 0.125]\n",
      "15158 [D loss: (0.641)(R 0.695, F 0.588)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.848] [G acc: 0.375]\n",
      "15159 [D loss: (0.673)(R 0.704, F 0.643)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.844] [G acc: 0.188]\n",
      "15160 [D loss: (0.664)(R 0.727, F 0.601)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.947] [G acc: 0.250]\n",
      "15161 [D loss: (0.683)(R 0.676, F 0.690)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.083] [G acc: 0.188]\n",
      "15162 [D loss: (0.609)(R 0.703, F 0.516)] [D acc: (0.844)(0.688, 1.000)] [G loss: 0.970] [G acc: 0.188]\n",
      "15163 [D loss: (0.664)(R 0.790, F 0.537)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.862] [G acc: 0.062]\n",
      "15164 [D loss: (0.634)(R 0.708, F 0.559)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.970] [G acc: 0.250]\n",
      "15165 [D loss: (0.602)(R 0.665, F 0.539)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.948] [G acc: 0.125]\n",
      "15166 [D loss: (0.663)(R 0.771, F 0.555)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.984] [G acc: 0.188]\n",
      "15167 [D loss: (0.689)(R 0.809, F 0.569)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.799] [G acc: 0.375]\n",
      "15168 [D loss: (0.602)(R 0.648, F 0.556)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.946] [G acc: 0.250]\n",
      "15169 [D loss: (0.665)(R 0.668, F 0.663)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.969] [G acc: 0.188]\n",
      "15170 [D loss: (0.639)(R 0.756, F 0.523)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.783] [G acc: 0.312]\n",
      "15171 [D loss: (0.641)(R 0.618, F 0.664)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.849] [G acc: 0.188]\n",
      "15172 [D loss: (0.673)(R 0.749, F 0.597)] [D acc: (0.594)(0.500, 0.688)] [G loss: 1.178] [G acc: 0.250]\n",
      "15173 [D loss: (0.705)(R 0.773, F 0.636)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.844] [G acc: 0.188]\n",
      "15174 [D loss: (0.669)(R 0.694, F 0.644)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.830] [G acc: 0.312]\n",
      "15175 [D loss: (0.682)(R 0.715, F 0.650)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.856] [G acc: 0.188]\n",
      "15176 [D loss: (0.624)(R 0.666, F 0.583)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.842] [G acc: 0.312]\n",
      "15177 [D loss: (0.629)(R 0.705, F 0.553)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.855] [G acc: 0.312]\n",
      "15178 [D loss: (0.670)(R 0.692, F 0.648)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.754] [G acc: 0.188]\n",
      "15179 [D loss: (0.618)(R 0.606, F 0.631)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.830] [G acc: 0.250]\n",
      "15180 [D loss: (0.706)(R 0.719, F 0.693)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.892] [G acc: 0.188]\n",
      "15181 [D loss: (0.648)(R 0.698, F 0.598)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.839] [G acc: 0.250]\n",
      "15182 [D loss: (0.677)(R 0.656, F 0.698)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.883] [G acc: 0.125]\n",
      "15183 [D loss: (0.633)(R 0.687, F 0.579)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.852] [G acc: 0.062]\n",
      "15184 [D loss: (0.640)(R 0.657, F 0.622)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.851] [G acc: 0.188]\n",
      "15185 [D loss: (0.645)(R 0.639, F 0.650)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.721] [G acc: 0.375]\n",
      "15186 [D loss: (0.623)(R 0.589, F 0.656)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.842] [G acc: 0.125]\n",
      "15187 [D loss: (0.686)(R 0.667, F 0.705)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.907] [G acc: 0.375]\n",
      "15188 [D loss: (0.636)(R 0.617, F 0.654)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.792] [G acc: 0.312]\n",
      "15189 [D loss: (0.597)(R 0.530, F 0.664)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.762] [G acc: 0.375]\n",
      "15190 [D loss: (0.699)(R 0.596, F 0.801)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.820] [G acc: 0.438]\n",
      "15191 [D loss: (0.661)(R 0.657, F 0.664)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.697] [G acc: 0.562]\n",
      "15192 [D loss: (0.606)(R 0.555, F 0.656)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.704] [G acc: 0.438]\n",
      "15193 [D loss: (0.596)(R 0.509, F 0.684)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.850] [G acc: 0.438]\n",
      "15194 [D loss: (0.649)(R 0.567, F 0.731)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.593] [G acc: 0.250]\n",
      "15195 [D loss: (0.587)(R 0.755, F 0.418)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.886] [G acc: 0.125]\n",
      "15196 [D loss: (0.666)(R 0.694, F 0.638)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.807] [G acc: 0.375]\n",
      "15197 [D loss: (0.695)(R 0.720, F 0.671)] [D acc: (0.375)(0.375, 0.375)] [G loss: 0.812] [G acc: 0.188]\n",
      "15198 [D loss: (0.645)(R 0.625, F 0.665)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.846] [G acc: 0.062]\n",
      "15199 [D loss: (0.590)(R 0.590, F 0.590)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.749] [G acc: 0.500]\n",
      "15200 [D loss: (0.695)(R 0.731, F 0.658)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.781] [G acc: 0.375]\n",
      "15201 [D loss: (0.653)(R 0.618, F 0.687)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.705] [G acc: 0.562]\n",
      "15202 [D loss: (0.701)(R 0.778, F 0.623)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.724] [G acc: 0.562]\n",
      "15203 [D loss: (0.778)(R 0.581, F 0.974)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.770] [G acc: 0.375]\n",
      "15204 [D loss: (0.634)(R 0.603, F 0.664)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.817] [G acc: 0.188]\n",
      "15205 [D loss: (0.632)(R 0.528, F 0.736)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.777] [G acc: 0.375]\n",
      "15206 [D loss: (0.557)(R 0.478, F 0.635)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.803] [G acc: 0.188]\n",
      "15207 [D loss: (0.588)(R 0.520, F 0.656)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.785] [G acc: 0.312]\n",
      "15208 [D loss: (0.604)(R 0.593, F 0.615)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.724] [G acc: 0.250]\n",
      "15209 [D loss: (0.607)(R 0.516, F 0.698)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.740] [G acc: 0.438]\n",
      "15210 [D loss: (0.706)(R 0.659, F 0.754)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.717] [G acc: 0.312]\n",
      "15211 [D loss: (0.611)(R 0.598, F 0.624)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.725] [G acc: 0.312]\n",
      "15212 [D loss: (0.575)(R 0.557, F 0.593)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.748] [G acc: 0.312]\n",
      "15213 [D loss: (0.577)(R 0.535, F 0.618)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.817] [G acc: 0.250]\n",
      "15214 [D loss: (0.592)(R 0.544, F 0.639)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.730] [G acc: 0.250]\n",
      "15215 [D loss: (0.683)(R 0.689, F 0.677)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.851] [G acc: 0.000]\n",
      "15216 [D loss: (0.624)(R 0.591, F 0.657)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.714] [G acc: 0.375]\n",
      "15217 [D loss: (0.718)(R 0.747, F 0.689)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.772] [G acc: 0.188]\n",
      "15218 [D loss: (0.574)(R 0.539, F 0.610)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.813] [G acc: 0.062]\n",
      "15219 [D loss: (0.667)(R 0.641, F 0.693)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.694] [G acc: 0.188]\n",
      "15220 [D loss: (0.717)(R 0.611, F 0.823)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.729] [G acc: 0.312]\n",
      "15221 [D loss: (0.902)(R 0.648, F 1.156)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.803] [G acc: 0.125]\n",
      "15222 [D loss: (0.553)(R 0.601, F 0.504)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.814] [G acc: 0.188]\n",
      "15223 [D loss: (0.634)(R 0.589, F 0.678)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.673] [G acc: 0.500]\n",
      "15224 [D loss: (0.633)(R 0.402, F 0.865)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.768] [G acc: 0.250]\n",
      "15225 [D loss: (0.726)(R 0.678, F 0.773)] [D acc: (0.562)(0.438, 0.688)] [G loss: 1.448] [G acc: 0.188]\n",
      "15226 [D loss: (0.645)(R 0.689, F 0.600)] [D acc: (0.594)(0.250, 0.938)] [G loss: 1.121] [G acc: 0.125]\n",
      "15227 [D loss: (0.525)(R 0.606, F 0.445)] [D acc: (0.688)(0.375, 1.000)] [G loss: 0.831] [G acc: 0.062]\n",
      "15228 [D loss: (0.529)(R 0.607, F 0.452)] [D acc: (0.562)(0.312, 0.812)] [G loss: 3.012] [G acc: 0.062]\n",
      "15229 [D loss: (0.621)(R 0.666, F 0.576)] [D acc: (0.594)(0.375, 0.812)] [G loss: 1.854] [G acc: 0.062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15230 [D loss: (0.648)(R 0.652, F 0.644)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.827] [G acc: 0.062]\n",
      "15231 [D loss: (0.590)(R 0.597, F 0.583)] [D acc: (0.688)(0.438, 0.938)] [G loss: 0.869] [G acc: 0.125]\n",
      "15232 [D loss: (0.620)(R 0.552, F 0.688)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.800] [G acc: 0.312]\n",
      "15233 [D loss: (0.685)(R 0.740, F 0.630)] [D acc: (0.469)(0.188, 0.750)] [G loss: 0.843] [G acc: 0.125]\n",
      "15234 [D loss: (0.612)(R 0.624, F 0.600)] [D acc: (0.625)(0.438, 0.812)] [G loss: 1.009] [G acc: 0.000]\n",
      "15235 [D loss: (0.569)(R 0.541, F 0.597)] [D acc: (0.719)(0.500, 0.938)] [G loss: 0.829] [G acc: 0.062]\n",
      "15236 [D loss: (0.655)(R 0.717, F 0.592)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.857] [G acc: 0.062]\n",
      "15237 [D loss: (0.710)(R 0.638, F 0.783)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.808] [G acc: 0.188]\n",
      "15238 [D loss: (0.613)(R 0.628, F 0.597)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.786] [G acc: 0.188]\n",
      "15239 [D loss: (0.600)(R 0.571, F 0.630)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.815] [G acc: 0.188]\n",
      "15240 [D loss: (0.608)(R 0.631, F 0.585)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.858] [G acc: 0.062]\n",
      "15241 [D loss: (0.589)(R 0.562, F 0.617)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.803] [G acc: 0.188]\n",
      "15242 [D loss: (0.615)(R 0.663, F 0.566)] [D acc: (0.562)(0.312, 0.812)] [G loss: 0.899] [G acc: 0.062]\n",
      "15243 [D loss: (0.800)(R 0.610, F 0.990)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.805] [G acc: 0.188]\n",
      "15244 [D loss: (0.605)(R 0.525, F 0.685)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.834] [G acc: 0.062]\n",
      "15245 [D loss: (0.610)(R 0.617, F 0.602)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.859] [G acc: 0.062]\n",
      "15246 [D loss: (0.551)(R 0.564, F 0.538)] [D acc: (0.812)(0.625, 1.000)] [G loss: 0.834] [G acc: 0.125]\n",
      "15247 [D loss: (0.551)(R 0.517, F 0.584)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.855] [G acc: 0.188]\n",
      "15248 [D loss: (0.551)(R 0.502, F 0.600)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.834] [G acc: 0.125]\n",
      "15249 [D loss: (0.665)(R 0.713, F 0.616)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.858] [G acc: 0.125]\n",
      "15250 [D loss: (0.592)(R 0.593, F 0.591)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.832] [G acc: 0.188]\n",
      "15251 [D loss: (0.780)(R 0.628, F 0.933)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.846] [G acc: 0.188]\n",
      "15252 [D loss: (0.560)(R 0.494, F 0.626)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.856] [G acc: 0.062]\n",
      "15253 [D loss: (0.636)(R 0.710, F 0.563)] [D acc: (0.594)(0.312, 0.875)] [G loss: 0.867] [G acc: 0.062]\n",
      "15254 [D loss: (0.654)(R 0.571, F 0.736)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.773] [G acc: 0.188]\n",
      "15255 [D loss: (0.718)(R 0.682, F 0.755)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.854] [G acc: 0.188]\n",
      "15256 [D loss: (0.610)(R 0.658, F 0.562)] [D acc: (0.562)(0.312, 0.812)] [G loss: 0.832] [G acc: 0.250]\n",
      "15257 [D loss: (0.520)(R 0.479, F 0.560)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.834] [G acc: 0.188]\n",
      "15258 [D loss: (0.634)(R 0.721, F 0.548)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.852] [G acc: 0.062]\n",
      "15259 [D loss: (0.546)(R 0.504, F 0.588)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.810] [G acc: 0.250]\n",
      "15260 [D loss: (0.709)(R 0.786, F 0.633)] [D acc: (0.406)(0.250, 0.562)] [G loss: 0.914] [G acc: 0.000]\n",
      "15261 [D loss: (0.580)(R 0.607, F 0.553)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.860] [G acc: 0.062]\n",
      "15262 [D loss: (0.637)(R 0.725, F 0.550)] [D acc: (0.594)(0.312, 0.875)] [G loss: 0.714] [G acc: 0.438]\n",
      "15263 [D loss: (0.759)(R 0.657, F 0.860)] [D acc: (0.500)(0.312, 0.688)] [G loss: 0.824] [G acc: 0.125]\n",
      "15264 [D loss: (0.630)(R 0.649, F 0.612)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.806] [G acc: 0.188]\n",
      "15265 [D loss: (0.662)(R 0.746, F 0.578)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.787] [G acc: 0.250]\n",
      "15266 [D loss: (0.805)(R 0.713, F 0.897)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.824] [G acc: 0.188]\n",
      "15267 [D loss: (0.633)(R 0.631, F 0.635)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.810] [G acc: 0.250]\n",
      "15268 [D loss: (0.923)(R 0.696, F 1.151)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.692] [G acc: 0.438]\n",
      "15269 [D loss: (0.649)(R 0.665, F 0.633)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.805] [G acc: 0.312]\n",
      "15270 [D loss: (0.622)(R 0.606, F 0.638)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.806] [G acc: 0.062]\n",
      "15271 [D loss: (0.693)(R 0.711, F 0.674)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.748] [G acc: 0.250]\n",
      "15272 [D loss: (0.604)(R 0.574, F 0.633)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.806] [G acc: 0.250]\n",
      "15273 [D loss: (0.659)(R 0.698, F 0.620)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.787] [G acc: 0.250]\n",
      "15274 [D loss: (0.700)(R 0.629, F 0.772)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.766] [G acc: 0.250]\n",
      "15275 [D loss: (0.632)(R 0.618, F 0.645)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.753] [G acc: 0.250]\n",
      "15276 [D loss: (0.629)(R 0.624, F 0.635)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.620] [G acc: 0.562]\n",
      "15277 [D loss: (0.741)(R 0.637, F 0.844)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.749] [G acc: 0.312]\n",
      "15278 [D loss: (0.811)(R 0.690, F 0.932)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.615] [G acc: 0.625]\n",
      "15279 [D loss: (2.085)(R 0.467, F 3.703)] [D acc: (0.438)(0.500, 0.375)] [G loss: 1.193] [G acc: 0.438]\n",
      "15280 [D loss: (0.401)(R 0.662, F 0.141)] [D acc: (0.688)(0.375, 1.000)] [G loss: 7.371] [G acc: 0.312]\n",
      "15281 [D loss: (1.062)(R 0.608, F 1.515)] [D acc: (0.344)(0.438, 0.250)] [G loss: 0.719] [G acc: 0.375]\n",
      "15282 [D loss: (0.622)(R 0.422, F 0.823)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.607] [G acc: 0.750]\n",
      "15283 [D loss: (0.880)(R 0.705, F 1.055)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.842] [G acc: 0.125]\n",
      "15284 [D loss: (0.768)(R 0.655, F 0.882)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.705] [G acc: 0.500]\n",
      "15285 [D loss: (0.922)(R 0.676, F 1.168)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.825] [G acc: 0.312]\n",
      "15286 [D loss: (0.643)(R 0.625, F 0.662)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.652] [G acc: 0.562]\n",
      "15287 [D loss: (0.632)(R 0.584, F 0.680)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.553] [G acc: 0.688]\n",
      "15288 [D loss: (0.796)(R 0.707, F 0.884)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.729] [G acc: 0.500]\n",
      "15289 [D loss: (0.755)(R 0.681, F 0.829)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.805] [G acc: 0.188]\n",
      "15290 [D loss: (0.636)(R 0.593, F 0.678)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.756] [G acc: 0.438]\n",
      "15291 [D loss: (0.740)(R 0.702, F 0.779)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.673] [G acc: 0.500]\n",
      "15292 [D loss: (0.708)(R 0.594, F 0.821)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.844] [G acc: 0.375]\n",
      "15293 [D loss: (0.681)(R 0.678, F 0.684)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.922] [G acc: 0.188]\n",
      "15294 [D loss: (0.619)(R 0.687, F 0.552)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.919] [G acc: 0.375]\n",
      "15295 [D loss: (0.563)(R 0.698, F 0.427)] [D acc: (0.531)(0.438, 0.625)] [G loss: 1.497] [G acc: 0.250]\n",
      "15296 [D loss: (0.634)(R 0.611, F 0.657)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.759] [G acc: 0.250]\n",
      "15297 [D loss: (0.675)(R 0.698, F 0.653)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.764] [G acc: 0.250]\n",
      "15298 [D loss: (0.721)(R 0.744, F 0.698)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.718] [G acc: 0.562]\n",
      "15299 [D loss: (0.677)(R 0.608, F 0.745)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.772] [G acc: 0.438]\n",
      "15300 [D loss: (0.688)(R 0.695, F 0.681)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.673] [G acc: 0.688]\n",
      "15301 [D loss: (0.669)(R 0.677, F 0.662)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.706] [G acc: 0.500]\n",
      "15302 [D loss: (0.681)(R 0.639, F 0.723)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.753] [G acc: 0.438]\n",
      "15303 [D loss: (0.720)(R 0.741, F 0.699)] [D acc: (0.375)(0.375, 0.375)] [G loss: 0.736] [G acc: 0.375]\n",
      "15304 [D loss: (0.669)(R 0.670, F 0.667)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.724] [G acc: 0.625]\n",
      "15305 [D loss: (0.652)(R 0.652, F 0.651)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.778] [G acc: 0.375]\n",
      "15306 [D loss: (0.652)(R 0.615, F 0.690)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.701] [G acc: 0.562]\n",
      "15307 [D loss: (0.679)(R 0.683, F 0.675)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.758] [G acc: 0.312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15308 [D loss: (0.682)(R 0.680, F 0.683)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.727] [G acc: 0.500]\n",
      "15309 [D loss: (0.682)(R 0.661, F 0.702)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.703] [G acc: 0.625]\n",
      "15310 [D loss: (0.694)(R 0.702, F 0.687)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.713] [G acc: 0.438]\n",
      "15311 [D loss: (0.638)(R 0.591, F 0.685)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.675] [G acc: 0.688]\n",
      "15312 [D loss: (0.656)(R 0.624, F 0.689)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.733] [G acc: 0.312]\n",
      "15313 [D loss: (0.719)(R 0.656, F 0.783)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.745] [G acc: 0.250]\n",
      "15314 [D loss: (0.697)(R 0.674, F 0.720)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.712] [G acc: 0.562]\n",
      "15315 [D loss: (0.646)(R 0.631, F 0.660)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.673] [G acc: 0.625]\n",
      "15316 [D loss: (0.659)(R 0.644, F 0.675)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.726] [G acc: 0.438]\n",
      "15317 [D loss: (0.680)(R 0.702, F 0.657)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.697] [G acc: 0.438]\n",
      "15318 [D loss: (0.630)(R 0.585, F 0.675)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.716] [G acc: 0.562]\n",
      "15319 [D loss: (0.664)(R 0.637, F 0.692)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.694] [G acc: 0.562]\n",
      "15320 [D loss: (0.689)(R 0.642, F 0.737)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.708] [G acc: 0.562]\n",
      "15321 [D loss: (0.704)(R 0.689, F 0.720)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.721] [G acc: 0.438]\n",
      "15322 [D loss: (0.672)(R 0.675, F 0.669)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.691] [G acc: 0.750]\n",
      "15323 [D loss: (0.676)(R 0.667, F 0.685)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.699] [G acc: 0.562]\n",
      "15324 [D loss: (0.610)(R 0.559, F 0.661)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.604] [G acc: 0.688]\n",
      "15325 [D loss: (0.670)(R 0.635, F 0.705)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.709] [G acc: 0.562]\n",
      "15326 [D loss: (0.689)(R 0.706, F 0.672)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.687] [G acc: 0.625]\n",
      "15327 [D loss: (0.727)(R 0.741, F 0.712)] [D acc: (0.375)(0.438, 0.312)] [G loss: 0.669] [G acc: 0.438]\n",
      "15328 [D loss: (1.024)(R 0.638, F 1.410)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.741] [G acc: 0.312]\n",
      "15329 [D loss: (1.040)(R 0.597, F 1.483)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.569] [G acc: 0.688]\n",
      "15330 [D loss: (1.100)(R 0.684, F 1.516)] [D acc: (0.375)(0.500, 0.250)] [G loss: 0.753] [G acc: 0.375]\n",
      "15331 [D loss: (0.742)(R 0.709, F 0.774)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.773] [G acc: 0.312]\n",
      "15332 [D loss: (0.745)(R 0.679, F 0.812)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.672] [G acc: 0.625]\n",
      "15333 [D loss: (0.734)(R 0.695, F 0.773)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.695] [G acc: 0.500]\n",
      "15334 [D loss: (0.920)(R 0.716, F 1.123)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.490] [G acc: 0.875]\n",
      "15335 [D loss: (1.142)(R 0.684, F 1.601)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.547] [G acc: 0.688]\n",
      "15336 [D loss: (1.031)(R 0.674, F 1.389)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.685] [G acc: 0.625]\n",
      "15337 [D loss: (0.892)(R 0.651, F 1.134)] [D acc: (0.656)(0.938, 0.375)] [G loss: 0.544] [G acc: 0.750]\n",
      "15338 [D loss: (0.879)(R 0.567, F 1.192)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.672] [G acc: 0.500]\n",
      "15339 [D loss: (1.310)(R 0.685, F 1.936)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.561] [G acc: 0.688]\n",
      "15340 [D loss: (1.211)(R 0.666, F 1.757)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.659] [G acc: 0.562]\n",
      "15341 [D loss: (1.207)(R 0.716, F 1.699)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.740] [G acc: 0.375]\n",
      "15342 [D loss: (0.723)(R 0.671, F 0.776)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.545] [G acc: 0.688]\n",
      "15343 [D loss: (1.141)(R 0.614, F 1.668)] [D acc: (0.688)(1.000, 0.375)] [G loss: 0.798] [G acc: 0.375]\n",
      "15344 [D loss: (0.817)(R 0.728, F 0.907)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.612] [G acc: 0.812]\n",
      "15345 [D loss: (0.815)(R 0.667, F 0.963)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.568] [G acc: 0.625]\n",
      "15346 [D loss: (1.153)(R 0.653, F 1.652)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.490] [G acc: 0.812]\n",
      "15347 [D loss: (1.144)(R 0.673, F 1.615)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.569] [G acc: 0.812]\n",
      "15348 [D loss: (1.030)(R 0.654, F 1.405)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.785] [G acc: 0.562]\n",
      "15349 [D loss: (0.707)(R 0.670, F 0.744)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.409] [G acc: 0.750]\n",
      "15350 [D loss: (0.886)(R 0.628, F 1.145)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.457] [G acc: 0.688]\n",
      "15351 [D loss: (1.136)(R 0.669, F 1.603)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.769] [G acc: 0.375]\n",
      "15352 [D loss: (0.601)(R 0.641, F 0.561)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.805] [G acc: 0.375]\n",
      "15353 [D loss: (1.016)(R 0.688, F 1.343)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.735] [G acc: 0.438]\n",
      "15354 [D loss: (0.959)(R 0.675, F 1.243)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.701] [G acc: 0.812]\n",
      "15355 [D loss: (0.641)(R 0.649, F 0.632)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.621] [G acc: 0.688]\n",
      "15356 [D loss: (0.675)(R 0.640, F 0.711)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.608] [G acc: 0.562]\n",
      "15357 [D loss: (0.846)(R 0.640, F 1.052)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.680] [G acc: 0.625]\n",
      "15358 [D loss: (0.781)(R 0.640, F 0.922)] [D acc: (0.688)(0.875, 0.500)] [G loss: 1.458] [G acc: 0.188]\n",
      "15359 [D loss: (0.663)(R 0.630, F 0.696)] [D acc: (0.656)(0.812, 0.500)] [G loss: 4.618] [G acc: 0.500]\n",
      "15360 [D loss: (0.663)(R 0.666, F 0.661)] [D acc: (0.719)(0.875, 0.562)] [G loss: 1.266] [G acc: 0.438]\n",
      "15361 [D loss: (0.664)(R 0.624, F 0.704)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.774] [G acc: 0.312]\n",
      "15362 [D loss: (0.746)(R 0.842, F 0.651)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.734] [G acc: 0.312]\n",
      "15363 [D loss: (0.798)(R 0.905, F 0.692)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.767] [G acc: 0.625]\n",
      "15364 [D loss: (0.661)(R 0.663, F 0.659)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.705] [G acc: 0.562]\n",
      "15365 [D loss: (0.917)(R 1.082, F 0.752)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.682] [G acc: 0.562]\n",
      "15366 [D loss: (0.716)(R 0.629, F 0.804)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.692] [G acc: 0.500]\n",
      "15367 [D loss: (0.710)(R 0.670, F 0.751)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.782] [G acc: 0.250]\n",
      "15368 [D loss: (0.624)(R 0.651, F 0.596)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.703] [G acc: 0.625]\n",
      "15369 [D loss: (0.653)(R 0.652, F 0.653)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.945] [G acc: 0.312]\n",
      "15370 [D loss: (0.720)(R 0.633, F 0.808)] [D acc: (0.844)(0.938, 0.750)] [G loss: 0.796] [G acc: 0.250]\n",
      "15371 [D loss: (0.617)(R 0.641, F 0.592)] [D acc: (0.781)(0.938, 0.625)] [G loss: 0.887] [G acc: 0.375]\n",
      "15372 [D loss: (0.612)(R 0.661, F 0.564)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.779] [G acc: 0.438]\n",
      "15373 [D loss: (0.621)(R 0.711, F 0.530)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.817] [G acc: 0.312]\n",
      "15374 [D loss: (0.622)(R 0.695, F 0.548)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.777] [G acc: 0.375]\n",
      "15375 [D loss: (0.594)(R 0.652, F 0.535)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.140] [G acc: 0.188]\n",
      "15376 [D loss: (0.664)(R 0.675, F 0.653)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.004] [G acc: 0.250]\n",
      "15377 [D loss: (0.694)(R 0.817, F 0.572)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.847] [G acc: 0.250]\n",
      "15378 [D loss: (0.607)(R 0.643, F 0.571)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.031] [G acc: 0.188]\n",
      "15379 [D loss: (0.652)(R 0.721, F 0.583)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.834] [G acc: 0.312]\n",
      "15380 [D loss: (0.581)(R 0.680, F 0.482)] [D acc: (0.906)(0.875, 0.938)] [G loss: 0.760] [G acc: 0.562]\n",
      "15381 [D loss: (0.618)(R 0.652, F 0.583)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.047] [G acc: 0.562]\n",
      "15382 [D loss: (0.588)(R 0.694, F 0.481)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.853] [G acc: 0.500]\n",
      "15383 [D loss: (0.659)(R 0.700, F 0.618)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.828] [G acc: 0.562]\n",
      "15384 [D loss: (0.746)(R 0.660, F 0.832)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.108] [G acc: 0.438]\n",
      "15385 [D loss: (0.563)(R 0.638, F 0.487)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.987] [G acc: 0.250]\n",
      "15386 [D loss: (0.495)(R 0.658, F 0.333)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.908] [G acc: 0.188]\n",
      "15387 [D loss: (0.403)(R 0.641, F 0.164)] [D acc: (0.938)(0.938, 0.938)] [G loss: 3.401] [G acc: 0.375]\n",
      "15388 [D loss: (0.605)(R 0.688, F 0.522)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.975] [G acc: 0.438]\n",
      "15389 [D loss: (0.591)(R 0.662, F 0.520)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.970] [G acc: 0.250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15390 [D loss: (0.620)(R 0.780, F 0.459)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.976] [G acc: 0.125]\n",
      "15391 [D loss: (0.586)(R 0.619, F 0.552)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.000] [G acc: 0.062]\n",
      "15392 [D loss: (0.569)(R 0.624, F 0.513)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.062] [G acc: 0.250]\n",
      "15393 [D loss: (0.564)(R 0.660, F 0.468)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.118] [G acc: 0.125]\n",
      "15394 [D loss: (0.585)(R 0.679, F 0.492)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.048] [G acc: 0.188]\n",
      "15395 [D loss: (0.746)(R 1.034, F 0.458)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.075] [G acc: 0.188]\n",
      "15396 [D loss: (0.624)(R 0.717, F 0.531)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.036] [G acc: 0.250]\n",
      "15397 [D loss: (0.517)(R 0.611, F 0.424)] [D acc: (0.906)(0.875, 0.938)] [G loss: 1.064] [G acc: 0.125]\n",
      "15398 [D loss: (0.581)(R 0.627, F 0.535)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.201] [G acc: 0.188]\n",
      "15399 [D loss: (0.497)(R 0.607, F 0.387)] [D acc: (0.906)(0.938, 0.875)] [G loss: 1.065] [G acc: 0.125]\n",
      "15400 [D loss: (0.547)(R 0.673, F 0.420)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.095] [G acc: 0.062]\n",
      "15401 [D loss: (0.583)(R 0.691, F 0.475)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.084] [G acc: 0.188]\n",
      "15402 [D loss: (0.568)(R 0.656, F 0.480)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.269] [G acc: 0.375]\n",
      "15403 [D loss: (0.552)(R 0.672, F 0.431)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.870] [G acc: 0.312]\n",
      "15404 [D loss: (0.529)(R 0.702, F 0.356)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.250] [G acc: 0.312]\n",
      "15405 [D loss: (0.570)(R 0.722, F 0.418)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.045] [G acc: 0.312]\n",
      "15406 [D loss: (0.576)(R 0.661, F 0.491)] [D acc: (0.781)(0.938, 0.625)] [G loss: 1.338] [G acc: 0.438]\n",
      "15407 [D loss: (0.541)(R 0.667, F 0.416)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.536] [G acc: 0.188]\n",
      "15408 [D loss: (0.538)(R 0.610, F 0.465)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.745] [G acc: 0.250]\n",
      "15409 [D loss: (0.606)(R 0.790, F 0.421)] [D acc: (0.750)(0.750, 0.750)] [G loss: 2.186] [G acc: 0.312]\n",
      "15410 [D loss: (0.762)(R 1.198, F 0.327)] [D acc: (0.875)(0.750, 1.000)] [G loss: 1.386] [G acc: 0.250]\n",
      "15411 [D loss: (0.554)(R 0.702, F 0.406)] [D acc: (0.844)(0.938, 0.750)] [G loss: 1.137] [G acc: 0.125]\n",
      "15412 [D loss: (0.622)(R 0.804, F 0.441)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.412] [G acc: 0.125]\n",
      "15413 [D loss: (0.525)(R 0.607, F 0.442)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.024] [G acc: 0.188]\n",
      "15414 [D loss: (0.531)(R 0.644, F 0.417)] [D acc: (0.844)(0.938, 0.750)] [G loss: 1.115] [G acc: 0.375]\n",
      "15415 [D loss: (0.585)(R 0.683, F 0.487)] [D acc: (0.719)(0.750, 0.688)] [G loss: 2.015] [G acc: 0.438]\n",
      "15416 [D loss: (0.490)(R 0.534, F 0.446)] [D acc: (0.844)(1.000, 0.688)] [G loss: 1.422] [G acc: 0.188]\n",
      "15417 [D loss: (0.653)(R 0.829, F 0.478)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.628] [G acc: 0.250]\n",
      "15418 [D loss: (0.527)(R 0.641, F 0.412)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.436] [G acc: 0.188]\n",
      "15419 [D loss: (0.483)(R 0.611, F 0.356)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.212] [G acc: 0.250]\n",
      "15420 [D loss: (0.547)(R 0.585, F 0.508)] [D acc: (0.844)(0.938, 0.750)] [G loss: 1.147] [G acc: 0.312]\n",
      "15421 [D loss: (0.527)(R 0.580, F 0.474)] [D acc: (0.750)(0.875, 0.625)] [G loss: 1.678] [G acc: 0.125]\n",
      "15422 [D loss: (0.495)(R 0.681, F 0.310)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.227] [G acc: 0.125]\n",
      "15423 [D loss: (0.533)(R 0.650, F 0.416)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.276] [G acc: 0.188]\n",
      "15424 [D loss: (0.673)(R 0.892, F 0.453)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.337] [G acc: 0.188]\n",
      "15425 [D loss: (0.527)(R 0.619, F 0.436)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.456] [G acc: 0.312]\n",
      "15426 [D loss: (0.541)(R 0.696, F 0.386)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.101] [G acc: 0.375]\n",
      "15427 [D loss: (0.698)(R 0.956, F 0.440)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.598] [G acc: 0.375]\n",
      "15428 [D loss: (0.552)(R 0.599, F 0.504)] [D acc: (0.844)(0.938, 0.750)] [G loss: 1.314] [G acc: 0.375]\n",
      "15429 [D loss: (0.539)(R 0.632, F 0.446)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.218] [G acc: 0.188]\n",
      "15430 [D loss: (0.505)(R 0.531, F 0.480)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.411] [G acc: 0.188]\n",
      "15431 [D loss: (0.640)(R 0.871, F 0.408)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.238] [G acc: 0.250]\n",
      "15432 [D loss: (0.552)(R 0.571, F 0.534)] [D acc: (0.750)(0.875, 0.625)] [G loss: 1.495] [G acc: 0.250]\n",
      "15433 [D loss: (0.546)(R 0.660, F 0.433)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.355] [G acc: 0.250]\n",
      "15434 [D loss: (0.428)(R 0.466, F 0.390)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.395] [G acc: 0.188]\n",
      "15435 [D loss: (0.475)(R 0.584, F 0.365)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.959] [G acc: 0.188]\n",
      "15436 [D loss: (0.573)(R 0.561, F 0.586)] [D acc: (0.750)(0.875, 0.625)] [G loss: 1.611] [G acc: 0.250]\n",
      "15437 [D loss: (0.490)(R 0.462, F 0.519)] [D acc: (0.812)(1.000, 0.625)] [G loss: 0.991] [G acc: 0.188]\n",
      "15438 [D loss: (0.609)(R 0.773, F 0.446)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.291] [G acc: 0.312]\n",
      "15439 [D loss: (0.667)(R 0.766, F 0.568)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.142] [G acc: 0.312]\n",
      "15440 [D loss: (0.510)(R 0.528, F 0.493)] [D acc: (0.875)(0.938, 0.812)] [G loss: 0.929] [G acc: 0.375]\n",
      "15441 [D loss: (0.591)(R 0.499, F 0.683)] [D acc: (0.656)(1.000, 0.312)] [G loss: 1.065] [G acc: 0.312]\n",
      "15442 [D loss: (0.642)(R 0.635, F 0.648)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.865] [G acc: 0.375]\n",
      "15443 [D loss: (0.733)(R 0.812, F 0.653)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.895] [G acc: 0.312]\n",
      "15444 [D loss: (0.777)(R 0.687, F 0.866)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.701] [G acc: 0.625]\n",
      "15445 [D loss: (0.860)(R 0.771, F 0.949)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.826] [G acc: 0.562]\n",
      "15446 [D loss: (0.696)(R 0.748, F 0.644)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.878] [G acc: 0.438]\n",
      "15447 [D loss: (0.651)(R 0.591, F 0.712)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.990] [G acc: 0.500]\n",
      "15448 [D loss: (0.672)(R 0.570, F 0.774)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.766] [G acc: 0.625]\n",
      "15449 [D loss: (0.826)(R 0.518, F 1.134)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.578] [G acc: 0.875]\n",
      "15450 [D loss: (0.839)(R 0.953, F 0.724)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.849] [G acc: 0.562]\n",
      "15451 [D loss: (0.468)(R 0.515, F 0.421)] [D acc: (0.844)(0.938, 0.750)] [G loss: 1.546] [G acc: 0.250]\n",
      "15452 [D loss: (0.789)(R 0.792, F 0.786)] [D acc: (0.375)(0.562, 0.188)] [G loss: 0.696] [G acc: 0.688]\n",
      "15453 [D loss: (0.617)(R 0.615, F 0.619)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.823] [G acc: 0.562]\n",
      "15454 [D loss: (0.709)(R 0.652, F 0.767)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.703] [G acc: 0.562]\n",
      "15455 [D loss: (0.678)(R 0.595, F 0.762)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.759] [G acc: 0.688]\n",
      "15456 [D loss: (0.573)(R 0.494, F 0.651)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.706] [G acc: 0.500]\n",
      "15457 [D loss: (0.706)(R 0.737, F 0.675)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.667] [G acc: 0.625]\n",
      "15458 [D loss: (0.708)(R 0.661, F 0.754)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.640] [G acc: 0.750]\n",
      "15459 [D loss: (0.713)(R 0.649, F 0.776)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.875] [G acc: 0.562]\n",
      "15460 [D loss: (0.649)(R 0.593, F 0.704)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.582] [G acc: 0.938]\n",
      "15461 [D loss: (0.791)(R 0.700, F 0.882)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.724] [G acc: 0.812]\n",
      "15462 [D loss: (0.798)(R 0.713, F 0.883)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.648] [G acc: 0.875]\n",
      "15463 [D loss: (0.782)(R 0.787, F 0.777)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.933] [G acc: 0.625]\n",
      "15464 [D loss: (0.783)(R 0.718, F 0.848)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.765] [G acc: 0.500]\n",
      "15465 [D loss: (0.683)(R 0.681, F 0.685)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.660] [G acc: 0.688]\n",
      "15466 [D loss: (0.722)(R 0.665, F 0.779)] [D acc: (0.438)(0.750, 0.125)] [G loss: 1.053] [G acc: 0.500]\n",
      "15467 [D loss: (0.714)(R 0.610, F 0.818)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.685] [G acc: 0.688]\n",
      "15468 [D loss: (0.672)(R 0.591, F 0.753)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.658] [G acc: 0.750]\n",
      "15469 [D loss: (0.690)(R 0.584, F 0.796)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.571] [G acc: 0.938]\n",
      "15470 [D loss: (0.675)(R 0.572, F 0.778)] [D acc: (0.625)(1.000, 0.250)] [G loss: 0.593] [G acc: 0.875]\n",
      "15471 [D loss: (0.671)(R 0.576, F 0.765)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.709] [G acc: 0.688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15472 [D loss: (0.652)(R 0.604, F 0.700)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.823] [G acc: 0.562]\n",
      "15473 [D loss: (0.560)(R 0.613, F 0.507)] [D acc: (0.719)(0.938, 0.500)] [G loss: 1.451] [G acc: 0.250]\n",
      "15474 [D loss: (0.635)(R 0.567, F 0.703)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.726] [G acc: 0.562]\n",
      "15475 [D loss: (0.737)(R 0.703, F 0.771)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.658] [G acc: 0.688]\n",
      "15476 [D loss: (0.749)(R 0.718, F 0.781)] [D acc: (0.344)(0.625, 0.062)] [G loss: 0.652] [G acc: 0.688]\n",
      "15477 [D loss: (0.738)(R 0.669, F 0.807)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.630] [G acc: 0.812]\n",
      "15478 [D loss: (0.698)(R 0.573, F 0.823)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.666] [G acc: 0.750]\n",
      "15479 [D loss: (0.719)(R 0.621, F 0.817)] [D acc: (0.438)(0.875, 0.000)] [G loss: 0.653] [G acc: 0.625]\n",
      "15480 [D loss: (0.792)(R 0.846, F 0.738)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.673] [G acc: 0.688]\n",
      "15481 [D loss: (0.728)(R 0.628, F 0.827)] [D acc: (0.406)(0.688, 0.125)] [G loss: 0.713] [G acc: 0.625]\n",
      "15482 [D loss: (0.748)(R 0.744, F 0.753)] [D acc: (0.406)(0.688, 0.125)] [G loss: 0.584] [G acc: 1.000]\n",
      "15483 [D loss: (0.668)(R 0.517, F 0.819)] [D acc: (0.500)(0.938, 0.062)] [G loss: 0.677] [G acc: 0.688]\n",
      "15484 [D loss: (0.651)(R 0.506, F 0.797)] [D acc: (0.531)(0.938, 0.125)] [G loss: 0.652] [G acc: 0.688]\n",
      "15485 [D loss: (0.713)(R 0.621, F 0.804)] [D acc: (0.344)(0.688, 0.000)] [G loss: 0.611] [G acc: 0.875]\n",
      "15486 [D loss: (0.750)(R 0.616, F 0.885)] [D acc: (0.469)(0.875, 0.062)] [G loss: 0.612] [G acc: 0.875]\n",
      "15487 [D loss: (0.682)(R 0.577, F 0.786)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.658] [G acc: 0.688]\n",
      "15488 [D loss: (0.658)(R 0.558, F 0.758)] [D acc: (0.562)(0.938, 0.188)] [G loss: 0.654] [G acc: 0.812]\n",
      "15489 [D loss: (0.782)(R 0.616, F 0.948)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.625] [G acc: 0.875]\n",
      "15490 [D loss: (0.699)(R 0.627, F 0.772)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.681] [G acc: 0.812]\n",
      "15491 [D loss: (1.182)(R 1.614, F 0.750)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.627] [G acc: 0.812]\n",
      "15492 [D loss: (0.637)(R 0.497, F 0.776)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.577] [G acc: 0.938]\n",
      "15493 [D loss: (0.681)(R 0.584, F 0.778)] [D acc: (0.406)(0.750, 0.062)] [G loss: 0.624] [G acc: 0.812]\n",
      "15494 [D loss: (0.662)(R 0.556, F 0.767)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.605] [G acc: 0.938]\n",
      "15495 [D loss: (0.723)(R 0.589, F 0.857)] [D acc: (0.406)(0.750, 0.062)] [G loss: 0.609] [G acc: 0.938]\n",
      "15496 [D loss: (0.718)(R 0.642, F 0.793)] [D acc: (0.375)(0.688, 0.062)] [G loss: 0.616] [G acc: 0.938]\n",
      "15497 [D loss: (0.737)(R 0.727, F 0.747)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.609] [G acc: 0.875]\n",
      "15498 [D loss: (0.684)(R 0.572, F 0.795)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.617] [G acc: 0.875]\n",
      "15499 [D loss: (0.676)(R 0.595, F 0.757)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.634] [G acc: 0.875]\n",
      "15500 [D loss: (0.694)(R 0.613, F 0.775)] [D acc: (0.531)(0.938, 0.125)] [G loss: 0.620] [G acc: 0.875]\n",
      "15501 [D loss: (0.739)(R 0.611, F 0.867)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.598] [G acc: 1.000]\n",
      "15502 [D loss: (0.701)(R 0.588, F 0.813)] [D acc: (0.406)(0.812, 0.000)] [G loss: 0.613] [G acc: 0.875]\n",
      "15503 [D loss: (0.690)(R 0.576, F 0.805)] [D acc: (0.562)(0.938, 0.188)] [G loss: 0.840] [G acc: 0.688]\n",
      "15504 [D loss: (0.640)(R 0.620, F 0.660)] [D acc: (0.656)(0.812, 0.500)] [G loss: 2.585] [G acc: 0.375]\n",
      "15505 [D loss: (0.547)(R 0.562, F 0.531)] [D acc: (0.781)(1.000, 0.562)] [G loss: 0.945] [G acc: 0.500]\n",
      "15506 [D loss: (0.639)(R 0.610, F 0.669)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.694] [G acc: 0.625]\n",
      "15507 [D loss: (0.654)(R 0.629, F 0.680)] [D acc: (0.656)(0.938, 0.375)] [G loss: 0.638] [G acc: 0.875]\n",
      "15508 [D loss: (0.751)(R 0.745, F 0.758)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.645] [G acc: 0.750]\n",
      "15509 [D loss: (0.635)(R 0.579, F 0.692)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.685] [G acc: 0.625]\n",
      "15510 [D loss: (0.647)(R 0.580, F 0.714)] [D acc: (0.594)(0.875, 0.312)] [G loss: 1.153] [G acc: 0.562]\n",
      "15511 [D loss: (0.680)(R 0.602, F 0.758)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.805] [G acc: 0.500]\n",
      "15512 [D loss: (0.752)(R 0.769, F 0.735)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.689] [G acc: 0.812]\n",
      "15513 [D loss: (0.668)(R 0.643, F 0.693)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.700] [G acc: 0.625]\n",
      "15514 [D loss: (0.700)(R 0.673, F 0.727)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.744] [G acc: 0.562]\n",
      "15515 [D loss: (0.698)(R 0.634, F 0.763)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.754] [G acc: 0.375]\n",
      "15516 [D loss: (0.638)(R 0.514, F 0.762)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.680] [G acc: 0.562]\n",
      "15517 [D loss: (0.712)(R 0.647, F 0.777)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.672] [G acc: 0.688]\n",
      "15518 [D loss: (0.682)(R 0.586, F 0.778)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.714] [G acc: 0.688]\n",
      "15519 [D loss: (0.702)(R 0.656, F 0.748)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.713] [G acc: 0.562]\n",
      "15520 [D loss: (0.695)(R 0.649, F 0.742)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.696] [G acc: 0.625]\n",
      "15521 [D loss: (0.750)(R 0.729, F 0.772)] [D acc: (0.375)(0.688, 0.062)] [G loss: 1.738] [G acc: 0.562]\n",
      "15522 [D loss: (0.656)(R 0.615, F 0.696)] [D acc: (0.562)(0.812, 0.312)] [G loss: 1.111] [G acc: 0.562]\n",
      "15523 [D loss: (0.667)(R 0.645, F 0.689)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.750] [G acc: 0.500]\n",
      "15524 [D loss: (0.758)(R 0.783, F 0.733)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.661] [G acc: 0.750]\n",
      "15525 [D loss: (0.631)(R 0.587, F 0.675)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.681] [G acc: 0.688]\n",
      "15526 [D loss: (0.661)(R 0.671, F 0.650)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.689] [G acc: 0.500]\n",
      "15527 [D loss: (0.614)(R 0.588, F 0.640)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.718] [G acc: 0.688]\n",
      "15528 [D loss: (0.693)(R 0.647, F 0.739)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.799] [G acc: 0.562]\n",
      "15529 [D loss: (0.674)(R 0.659, F 0.690)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.705] [G acc: 0.688]\n",
      "15530 [D loss: (0.606)(R 0.517, F 0.696)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.706] [G acc: 0.625]\n",
      "15531 [D loss: (0.639)(R 0.591, F 0.687)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.710] [G acc: 0.562]\n",
      "15532 [D loss: (0.673)(R 0.670, F 0.676)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.761] [G acc: 0.562]\n",
      "15533 [D loss: (0.689)(R 0.660, F 0.718)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.686] [G acc: 0.562]\n",
      "15534 [D loss: (0.636)(R 0.582, F 0.690)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.733] [G acc: 0.625]\n",
      "15535 [D loss: (0.716)(R 0.725, F 0.707)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.678] [G acc: 0.625]\n",
      "15536 [D loss: (0.762)(R 0.791, F 0.733)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.666] [G acc: 0.750]\n",
      "15537 [D loss: (0.647)(R 0.537, F 0.758)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.743] [G acc: 0.438]\n",
      "15538 [D loss: (0.693)(R 0.633, F 0.753)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.714] [G acc: 0.375]\n",
      "15539 [D loss: (0.696)(R 0.687, F 0.705)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.712] [G acc: 0.688]\n",
      "15540 [D loss: (0.646)(R 0.595, F 0.698)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.728] [G acc: 0.625]\n",
      "15541 [D loss: (0.675)(R 0.610, F 0.739)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.739] [G acc: 0.562]\n",
      "15542 [D loss: (0.669)(R 0.586, F 0.752)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.693] [G acc: 0.688]\n",
      "15543 [D loss: (0.643)(R 0.555, F 0.731)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.725] [G acc: 0.562]\n",
      "15544 [D loss: (0.757)(R 0.580, F 0.934)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.701] [G acc: 0.500]\n",
      "15545 [D loss: (0.681)(R 0.553, F 0.809)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.788] [G acc: 0.438]\n",
      "15546 [D loss: (0.649)(R 0.624, F 0.675)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.751] [G acc: 0.562]\n",
      "15547 [D loss: (0.958)(R 1.127, F 0.789)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.702] [G acc: 0.625]\n",
      "15548 [D loss: (0.686)(R 0.582, F 0.789)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.656] [G acc: 0.750]\n",
      "15549 [D loss: (0.684)(R 0.579, F 0.788)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.718] [G acc: 0.625]\n",
      "15550 [D loss: (0.712)(R 0.646, F 0.778)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.711] [G acc: 0.625]\n",
      "15551 [D loss: (0.680)(R 0.631, F 0.730)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.696] [G acc: 0.750]\n",
      "15552 [D loss: (0.754)(R 0.674, F 0.834)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.828] [G acc: 0.562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15553 [D loss: (0.686)(R 0.635, F 0.738)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.707] [G acc: 0.438]\n",
      "15554 [D loss: (0.701)(R 0.647, F 0.755)] [D acc: (0.375)(0.562, 0.188)] [G loss: 0.695] [G acc: 0.625]\n",
      "15555 [D loss: (0.682)(R 0.612, F 0.752)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.630] [G acc: 0.938]\n",
      "15556 [D loss: (0.663)(R 0.586, F 0.740)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.679] [G acc: 0.688]\n",
      "15557 [D loss: (0.630)(R 0.550, F 0.711)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.646] [G acc: 0.875]\n",
      "15558 [D loss: (0.811)(R 0.737, F 0.885)] [D acc: (0.375)(0.688, 0.062)] [G loss: 0.665] [G acc: 0.562]\n",
      "15559 [D loss: (0.815)(R 0.531, F 1.100)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.591] [G acc: 0.875]\n",
      "15560 [D loss: (0.842)(R 0.632, F 1.051)] [D acc: (0.406)(0.688, 0.125)] [G loss: 0.602] [G acc: 0.875]\n",
      "15561 [D loss: (1.030)(R 0.636, F 1.424)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.609] [G acc: 0.812]\n",
      "15562 [D loss: (0.722)(R 0.630, F 0.815)] [D acc: (0.469)(0.875, 0.062)] [G loss: 0.649] [G acc: 0.812]\n",
      "15563 [D loss: (0.715)(R 0.663, F 0.766)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.640] [G acc: 0.812]\n",
      "15564 [D loss: (0.799)(R 0.634, F 0.964)] [D acc: (0.406)(0.688, 0.125)] [G loss: 0.590] [G acc: 0.750]\n",
      "15565 [D loss: (0.359)(R 0.580, F 0.137)] [D acc: (0.938)(1.000, 0.875)] [G loss: 0.963] [G acc: 0.312]\n",
      "15566 [D loss: (0.694)(R 0.611, F 0.777)] [D acc: (0.531)(0.938, 0.125)] [G loss: 0.607] [G acc: 0.750]\n",
      "15567 [D loss: (0.712)(R 0.642, F 0.781)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.662] [G acc: 0.812]\n",
      "15568 [D loss: (0.695)(R 0.657, F 0.733)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.667] [G acc: 0.812]\n",
      "15569 [D loss: (0.683)(R 0.643, F 0.722)] [D acc: (0.562)(0.625, 0.500)] [G loss: 2.364] [G acc: 0.625]\n",
      "15570 [D loss: (0.604)(R 0.675, F 0.533)] [D acc: (0.562)(0.688, 0.438)] [G loss: 2.030] [G acc: 0.312]\n",
      "15571 [D loss: (0.595)(R 0.676, F 0.513)] [D acc: (0.625)(0.625, 0.625)] [G loss: 4.544] [G acc: 0.375]\n",
      "15572 [D loss: (0.694)(R 0.659, F 0.728)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.681] [G acc: 0.562]\n",
      "15573 [D loss: (0.692)(R 0.659, F 0.726)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.678] [G acc: 0.750]\n",
      "15574 [D loss: (0.704)(R 0.686, F 0.722)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.655] [G acc: 0.688]\n",
      "15575 [D loss: (0.664)(R 0.624, F 0.704)] [D acc: (0.719)(1.000, 0.438)] [G loss: 0.690] [G acc: 0.625]\n",
      "15576 [D loss: (0.661)(R 0.594, F 0.727)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.653] [G acc: 0.750]\n",
      "15577 [D loss: (0.715)(R 0.685, F 0.746)] [D acc: (0.406)(0.625, 0.188)] [G loss: 0.668] [G acc: 0.625]\n",
      "15578 [D loss: (0.695)(R 0.666, F 0.724)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.716] [G acc: 0.625]\n",
      "15579 [D loss: (0.718)(R 0.705, F 0.730)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.746] [G acc: 0.500]\n",
      "15580 [D loss: (0.719)(R 0.691, F 0.748)] [D acc: (0.375)(0.562, 0.188)] [G loss: 0.673] [G acc: 0.688]\n",
      "15581 [D loss: (0.730)(R 0.703, F 0.756)] [D acc: (0.406)(0.625, 0.188)] [G loss: 0.658] [G acc: 0.812]\n",
      "15582 [D loss: (0.614)(R 0.506, F 0.722)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.657] [G acc: 0.875]\n",
      "15583 [D loss: (0.685)(R 0.616, F 0.755)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.642] [G acc: 0.750]\n",
      "15584 [D loss: (0.733)(R 0.703, F 0.764)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.707] [G acc: 0.500]\n",
      "15585 [D loss: (0.661)(R 0.579, F 0.743)] [D acc: (0.438)(0.812, 0.062)] [G loss: 0.672] [G acc: 0.750]\n",
      "15586 [D loss: (0.654)(R 0.579, F 0.729)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.641] [G acc: 0.812]\n",
      "15587 [D loss: (0.708)(R 0.667, F 0.749)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.659] [G acc: 0.750]\n",
      "15588 [D loss: (0.665)(R 0.604, F 0.726)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.660] [G acc: 0.812]\n",
      "15589 [D loss: (0.732)(R 0.651, F 0.814)] [D acc: (0.375)(0.625, 0.125)] [G loss: 0.665] [G acc: 0.688]\n",
      "15590 [D loss: (0.712)(R 0.615, F 0.810)] [D acc: (0.500)(0.938, 0.062)] [G loss: 0.650] [G acc: 0.750]\n",
      "15591 [D loss: (0.689)(R 0.618, F 0.761)] [D acc: (0.375)(0.625, 0.125)] [G loss: 0.657] [G acc: 0.750]\n",
      "15592 [D loss: (0.692)(R 0.635, F 0.749)] [D acc: (0.562)(0.938, 0.188)] [G loss: 0.717] [G acc: 0.500]\n",
      "15593 [D loss: (0.719)(R 0.660, F 0.778)] [D acc: (0.406)(0.750, 0.062)] [G loss: 0.649] [G acc: 0.750]\n",
      "15594 [D loss: (0.675)(R 0.619, F 0.731)] [D acc: (0.656)(1.000, 0.312)] [G loss: 0.673] [G acc: 0.625]\n",
      "15595 [D loss: (0.729)(R 0.673, F 0.785)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.640] [G acc: 0.875]\n",
      "15596 [D loss: (0.706)(R 0.664, F 0.748)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.655] [G acc: 0.750]\n",
      "15597 [D loss: (0.675)(R 0.590, F 0.759)] [D acc: (0.438)(0.812, 0.062)] [G loss: 0.603] [G acc: 0.938]\n",
      "15598 [D loss: (0.716)(R 0.669, F 0.762)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.640] [G acc: 0.938]\n",
      "15599 [D loss: (0.646)(R 0.526, F 0.766)] [D acc: (0.438)(0.875, 0.000)] [G loss: 0.641] [G acc: 0.938]\n",
      "15600 [D loss: (0.711)(R 0.668, F 0.755)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.643] [G acc: 0.938]\n",
      "15601 [D loss: (0.662)(R 0.580, F 0.743)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.636] [G acc: 1.000]\n",
      "15602 [D loss: (0.680)(R 0.601, F 0.759)] [D acc: (0.500)(0.938, 0.062)] [G loss: 0.624] [G acc: 1.000]\n",
      "15603 [D loss: (0.699)(R 0.644, F 0.755)] [D acc: (0.469)(0.875, 0.062)] [G loss: 0.648] [G acc: 0.875]\n",
      "15604 [D loss: (0.715)(R 0.645, F 0.784)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.656] [G acc: 0.812]\n",
      "15605 [D loss: (0.701)(R 0.624, F 0.777)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.691] [G acc: 0.562]\n",
      "15606 [D loss: (0.662)(R 0.606, F 0.719)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.757] [G acc: 0.688]\n",
      "15607 [D loss: (0.584)(R 0.630, F 0.539)] [D acc: (0.625)(0.812, 0.438)] [G loss: 3.607] [G acc: 0.312]\n",
      "15608 [D loss: (0.669)(R 0.662, F 0.676)] [D acc: (0.469)(0.812, 0.125)] [G loss: 2.218] [G acc: 0.562]\n",
      "15609 [D loss: (0.708)(R 0.687, F 0.728)] [D acc: (0.375)(0.625, 0.125)] [G loss: 0.675] [G acc: 0.812]\n",
      "15610 [D loss: (0.669)(R 0.626, F 0.712)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.646] [G acc: 1.000]\n",
      "15611 [D loss: (0.617)(R 0.537, F 0.698)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.671] [G acc: 0.812]\n",
      "15612 [D loss: (0.639)(R 0.575, F 0.704)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.697] [G acc: 0.562]\n",
      "15613 [D loss: (0.670)(R 0.678, F 0.663)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.754] [G acc: 0.562]\n",
      "15614 [D loss: (0.686)(R 0.650, F 0.722)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.733] [G acc: 0.500]\n",
      "15615 [D loss: (0.647)(R 0.609, F 0.685)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.034] [G acc: 0.688]\n",
      "15616 [D loss: (0.714)(R 0.717, F 0.711)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.682] [G acc: 0.688]\n",
      "15617 [D loss: (0.635)(R 0.585, F 0.685)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.704] [G acc: 0.375]\n",
      "15618 [D loss: (0.668)(R 0.646, F 0.689)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.747] [G acc: 0.375]\n",
      "15619 [D loss: (0.670)(R 0.641, F 0.699)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.706] [G acc: 0.625]\n",
      "15620 [D loss: (0.751)(R 0.593, F 0.909)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.732] [G acc: 0.250]\n",
      "15621 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.719] [G acc: 0.375]\n",
      "15622 [D loss: (0.790)(R 0.889, F 0.691)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.721] [G acc: 0.500]\n",
      "15623 [D loss: (0.638)(R 0.594, F 0.682)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.714] [G acc: 0.562]\n",
      "15624 [D loss: (0.646)(R 0.637, F 0.655)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.677] [G acc: 0.562]\n",
      "15625 [D loss: (0.734)(R 0.633, F 0.834)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.755] [G acc: 0.438]\n",
      "15626 [D loss: (0.663)(R 0.637, F 0.689)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.760] [G acc: 0.438]\n",
      "15627 [D loss: (0.674)(R 0.684, F 0.663)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.704] [G acc: 0.250]\n",
      "15628 [D loss: (0.691)(R 0.694, F 0.689)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.732] [G acc: 0.312]\n",
      "15629 [D loss: (0.675)(R 0.688, F 0.663)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.734] [G acc: 0.312]\n",
      "15630 [D loss: (0.641)(R 0.619, F 0.662)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.752] [G acc: 0.312]\n",
      "15631 [D loss: (0.646)(R 0.630, F 0.662)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.689] [G acc: 0.562]\n",
      "15632 [D loss: (0.631)(R 0.602, F 0.660)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.784] [G acc: 0.250]\n",
      "15633 [D loss: (0.666)(R 0.697, F 0.635)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.762] [G acc: 0.250]\n",
      "15634 [D loss: (0.635)(R 0.583, F 0.688)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.750] [G acc: 0.375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15635 [D loss: (0.711)(R 0.735, F 0.688)] [D acc: (0.406)(0.312, 0.500)] [G loss: 0.685] [G acc: 0.688]\n",
      "15636 [D loss: (0.626)(R 0.571, F 0.681)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.767] [G acc: 0.250]\n",
      "15637 [D loss: (0.685)(R 0.705, F 0.665)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.693] [G acc: 0.562]\n",
      "15638 [D loss: (0.657)(R 0.688, F 0.626)] [D acc: (0.719)(0.500, 0.938)] [G loss: 0.711] [G acc: 0.500]\n",
      "15639 [D loss: (0.686)(R 0.670, F 0.703)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.730] [G acc: 0.438]\n",
      "15640 [D loss: (0.658)(R 0.608, F 0.709)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.633] [G acc: 0.625]\n",
      "15641 [D loss: (0.666)(R 0.664, F 0.668)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.789] [G acc: 0.438]\n",
      "15642 [D loss: (0.707)(R 0.710, F 0.704)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.671] [G acc: 0.625]\n",
      "15643 [D loss: (0.750)(R 0.636, F 0.864)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.705] [G acc: 0.438]\n",
      "15644 [D loss: (0.679)(R 0.663, F 0.695)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.711] [G acc: 0.500]\n",
      "15645 [D loss: (0.666)(R 0.645, F 0.686)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.745] [G acc: 0.500]\n",
      "15646 [D loss: (0.692)(R 0.705, F 0.678)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.659] [G acc: 0.625]\n",
      "15647 [D loss: (0.780)(R 0.717, F 0.843)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.764] [G acc: 0.562]\n",
      "15648 [D loss: (0.645)(R 0.673, F 0.617)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.763] [G acc: 0.438]\n",
      "15649 [D loss: (0.653)(R 0.693, F 0.613)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.679] [G acc: 0.500]\n",
      "15650 [D loss: (0.643)(R 0.626, F 0.661)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.781] [G acc: 0.312]\n",
      "15651 [D loss: (0.674)(R 0.693, F 0.656)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.715] [G acc: 0.438]\n",
      "15652 [D loss: (0.657)(R 0.660, F 0.654)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.788] [G acc: 0.062]\n",
      "15653 [D loss: (0.641)(R 0.626, F 0.656)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.711] [G acc: 0.562]\n",
      "15654 [D loss: (0.651)(R 0.644, F 0.658)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.743] [G acc: 0.375]\n",
      "15655 [D loss: (0.693)(R 0.681, F 0.704)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.738] [G acc: 0.500]\n",
      "15656 [D loss: (0.702)(R 0.712, F 0.693)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.684] [G acc: 0.625]\n",
      "15657 [D loss: (0.719)(R 0.703, F 0.736)] [D acc: (0.312)(0.375, 0.250)] [G loss: 0.681] [G acc: 0.562]\n",
      "15658 [D loss: (0.711)(R 0.605, F 0.817)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.843] [G acc: 0.250]\n",
      "15659 [D loss: (0.662)(R 0.697, F 0.627)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.770] [G acc: 0.438]\n",
      "15660 [D loss: (0.685)(R 0.683, F 0.688)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.760] [G acc: 0.312]\n",
      "15661 [D loss: (0.758)(R 0.627, F 0.888)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.856] [G acc: 0.438]\n",
      "15662 [D loss: (0.517)(R 0.657, F 0.378)] [D acc: (0.750)(0.625, 0.875)] [G loss: 3.788] [G acc: 0.312]\n",
      "15663 [D loss: (0.555)(R 0.725, F 0.384)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.763] [G acc: 0.312]\n",
      "15664 [D loss: (0.535)(R 0.601, F 0.469)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.728] [G acc: 0.375]\n",
      "15665 [D loss: (0.593)(R 0.650, F 0.537)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.743] [G acc: 0.500]\n",
      "15666 [D loss: (0.693)(R 0.712, F 0.674)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.754] [G acc: 0.312]\n",
      "15667 [D loss: (0.675)(R 0.717, F 0.632)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.752] [G acc: 0.375]\n",
      "15668 [D loss: (0.618)(R 0.648, F 0.587)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.748] [G acc: 0.312]\n",
      "15669 [D loss: (0.676)(R 0.715, F 0.636)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.750] [G acc: 0.375]\n",
      "15670 [D loss: (0.645)(R 0.658, F 0.631)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.732] [G acc: 0.375]\n",
      "15671 [D loss: (0.660)(R 0.653, F 0.667)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.723] [G acc: 0.500]\n",
      "15672 [D loss: (0.615)(R 0.699, F 0.530)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.888] [G acc: 0.250]\n",
      "15673 [D loss: (0.667)(R 0.683, F 0.651)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.694] [G acc: 0.562]\n",
      "15674 [D loss: (0.624)(R 0.666, F 0.582)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.770] [G acc: 0.375]\n",
      "15675 [D loss: (0.691)(R 0.701, F 0.681)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.751] [G acc: 0.500]\n",
      "15676 [D loss: (0.666)(R 0.633, F 0.699)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.713] [G acc: 0.438]\n",
      "15677 [D loss: (0.873)(R 0.741, F 1.006)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.814] [G acc: 0.188]\n",
      "15678 [D loss: (0.674)(R 0.670, F 0.677)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.787] [G acc: 0.125]\n",
      "15679 [D loss: (0.686)(R 0.700, F 0.673)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.701] [G acc: 0.500]\n",
      "15680 [D loss: (0.656)(R 0.646, F 0.665)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.742] [G acc: 0.375]\n",
      "15681 [D loss: (0.706)(R 0.704, F 0.708)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.735] [G acc: 0.438]\n",
      "15682 [D loss: (0.626)(R 0.579, F 0.673)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.736] [G acc: 0.312]\n",
      "15683 [D loss: (0.711)(R 0.758, F 0.663)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.709] [G acc: 0.562]\n",
      "15684 [D loss: (0.603)(R 0.525, F 0.681)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.688] [G acc: 0.500]\n",
      "15685 [D loss: (0.690)(R 0.665, F 0.715)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.741] [G acc: 0.438]\n",
      "15686 [D loss: (0.656)(R 0.574, F 0.738)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.671] [G acc: 0.500]\n",
      "15687 [D loss: (0.678)(R 0.670, F 0.687)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.749] [G acc: 0.375]\n",
      "15688 [D loss: (0.643)(R 0.649, F 0.638)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.744] [G acc: 0.500]\n",
      "15689 [D loss: (0.671)(R 0.655, F 0.687)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.717] [G acc: 0.500]\n",
      "15690 [D loss: (0.679)(R 0.678, F 0.680)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.713] [G acc: 0.500]\n",
      "15691 [D loss: (0.660)(R 0.536, F 0.784)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.722] [G acc: 0.438]\n",
      "15692 [D loss: (0.621)(R 0.545, F 0.696)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.658] [G acc: 0.500]\n",
      "15693 [D loss: (0.708)(R 0.699, F 0.717)] [D acc: (0.406)(0.375, 0.438)] [G loss: 0.731] [G acc: 0.500]\n",
      "15694 [D loss: (0.697)(R 0.489, F 0.904)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.709] [G acc: 0.438]\n",
      "15695 [D loss: (0.849)(R 0.718, F 0.979)] [D acc: (0.344)(0.438, 0.250)] [G loss: 0.709] [G acc: 0.688]\n",
      "15696 [D loss: (0.669)(R 0.622, F 0.716)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.667] [G acc: 0.562]\n",
      "15697 [D loss: (0.753)(R 0.592, F 0.913)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.700] [G acc: 0.500]\n",
      "15698 [D loss: (0.645)(R 0.567, F 0.724)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.643] [G acc: 0.438]\n",
      "15699 [D loss: (0.660)(R 0.644, F 0.676)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.704] [G acc: 0.500]\n",
      "15700 [D loss: (0.700)(R 0.673, F 0.728)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.735] [G acc: 0.375]\n",
      "15701 [D loss: (0.727)(R 0.691, F 0.763)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.677] [G acc: 0.500]\n",
      "15702 [D loss: (0.646)(R 0.588, F 0.704)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.682] [G acc: 0.500]\n",
      "15703 [D loss: (0.650)(R 0.615, F 0.686)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.738] [G acc: 0.500]\n",
      "15704 [D loss: (0.931)(R 0.607, F 1.256)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.577] [G acc: 0.688]\n",
      "15705 [D loss: (0.635)(R 0.703, F 0.568)] [D acc: (0.406)(0.312, 0.500)] [G loss: 1.063] [G acc: 0.188]\n",
      "15706 [D loss: (0.641)(R 0.689, F 0.592)] [D acc: (0.688)(0.562, 0.812)] [G loss: 7.838] [G acc: 0.250]\n",
      "15707 [D loss: (0.678)(R 0.669, F 0.686)] [D acc: (0.469)(0.438, 0.500)] [G loss: 1.117] [G acc: 0.312]\n",
      "15708 [D loss: (0.685)(R 0.673, F 0.698)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.802] [G acc: 0.188]\n",
      "15709 [D loss: (0.689)(R 0.729, F 0.650)] [D acc: (0.500)(0.438, 0.562)] [G loss: 6.601] [G acc: 0.125]\n",
      "15710 [D loss: (0.637)(R 0.610, F 0.664)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.731] [G acc: 0.375]\n",
      "15711 [D loss: (0.716)(R 0.684, F 0.747)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.664] [G acc: 0.438]\n",
      "15712 [D loss: (0.693)(R 0.690, F 0.697)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.758] [G acc: 0.250]\n",
      "15713 [D loss: (0.714)(R 0.691, F 0.738)] [D acc: (0.375)(0.375, 0.375)] [G loss: 0.693] [G acc: 0.312]\n",
      "15714 [D loss: (0.699)(R 0.680, F 0.719)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.772] [G acc: 0.250]\n",
      "15715 [D loss: (0.636)(R 0.612, F 0.659)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.812] [G acc: 0.250]\n",
      "15716 [D loss: (0.635)(R 0.565, F 0.704)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.670] [G acc: 0.688]\n",
      "15717 [D loss: (0.705)(R 0.730, F 0.679)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.738] [G acc: 0.438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15718 [D loss: (0.621)(R 0.589, F 0.653)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.767] [G acc: 0.250]\n",
      "15719 [D loss: (0.658)(R 0.608, F 0.708)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.707] [G acc: 0.125]\n",
      "15720 [D loss: (0.667)(R 0.671, F 0.664)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.713] [G acc: 0.500]\n",
      "15721 [D loss: (0.632)(R 0.589, F 0.674)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.742] [G acc: 0.250]\n",
      "15722 [D loss: (0.663)(R 0.595, F 0.731)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.698] [G acc: 0.500]\n",
      "15723 [D loss: (0.656)(R 0.624, F 0.688)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.710] [G acc: 0.375]\n",
      "15724 [D loss: (0.682)(R 0.596, F 0.767)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.701] [G acc: 0.438]\n",
      "15725 [D loss: (0.732)(R 0.757, F 0.707)] [D acc: (0.375)(0.500, 0.250)] [G loss: 0.790] [G acc: 0.125]\n",
      "15726 [D loss: (0.716)(R 0.733, F 0.699)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.925] [G acc: 0.438]\n",
      "15727 [D loss: (0.642)(R 0.589, F 0.696)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.746] [G acc: 0.188]\n",
      "15728 [D loss: (0.639)(R 0.646, F 0.633)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.766] [G acc: 0.188]\n",
      "15729 [D loss: (0.746)(R 0.693, F 0.800)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.756] [G acc: 0.312]\n",
      "15730 [D loss: (0.673)(R 0.673, F 0.674)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.725] [G acc: 0.438]\n",
      "15731 [D loss: (0.642)(R 0.581, F 0.703)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.740] [G acc: 0.375]\n",
      "15732 [D loss: (0.617)(R 0.569, F 0.665)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.698] [G acc: 0.375]\n",
      "15733 [D loss: (0.675)(R 0.691, F 0.658)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.751] [G acc: 0.250]\n",
      "15734 [D loss: (0.672)(R 0.682, F 0.661)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.713] [G acc: 0.250]\n",
      "15735 [D loss: (0.684)(R 0.684, F 0.685)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.694] [G acc: 0.688]\n",
      "15736 [D loss: (0.665)(R 0.641, F 0.688)] [D acc: (0.375)(0.438, 0.312)] [G loss: 0.773] [G acc: 0.250]\n",
      "15737 [D loss: (0.608)(R 0.589, F 0.627)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.744] [G acc: 0.250]\n",
      "15738 [D loss: (0.659)(R 0.682, F 0.635)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.728] [G acc: 0.375]\n",
      "15739 [D loss: (0.592)(R 0.535, F 0.649)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.716] [G acc: 0.375]\n",
      "15740 [D loss: (0.646)(R 0.628, F 0.664)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.800] [G acc: 0.312]\n",
      "15741 [D loss: (0.628)(R 0.652, F 0.604)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.798] [G acc: 0.188]\n",
      "15742 [D loss: (0.618)(R 0.596, F 0.640)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.850] [G acc: 0.188]\n",
      "15743 [D loss: (0.597)(R 0.569, F 0.624)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.752] [G acc: 0.312]\n",
      "15744 [D loss: (0.628)(R 0.581, F 0.674)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.811] [G acc: 0.188]\n",
      "15745 [D loss: (0.654)(R 0.690, F 0.618)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.747] [G acc: 0.438]\n",
      "15746 [D loss: (0.591)(R 0.538, F 0.644)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.524] [G acc: 0.625]\n",
      "15747 [D loss: (0.689)(R 0.648, F 0.731)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.876] [G acc: 0.188]\n",
      "15748 [D loss: (0.505)(R 0.642, F 0.369)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.666] [G acc: 0.188]\n",
      "15749 [D loss: (0.572)(R 0.484, F 0.660)] [D acc: (0.688)(0.750, 0.625)] [G loss: 3.133] [G acc: 0.188]\n",
      "15750 [D loss: (0.464)(R 0.719, F 0.208)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.949] [G acc: 0.062]\n",
      "15751 [D loss: (0.468)(R 0.543, F 0.392)] [D acc: (0.844)(0.812, 0.875)] [G loss: 2.547] [G acc: 0.188]\n",
      "15752 [D loss: (0.648)(R 0.678, F 0.619)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.439] [G acc: 0.250]\n",
      "15753 [D loss: (0.651)(R 0.692, F 0.610)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.798] [G acc: 0.250]\n",
      "15754 [D loss: (0.609)(R 0.601, F 0.617)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.843] [G acc: 0.312]\n",
      "15755 [D loss: (0.738)(R 0.950, F 0.527)] [D acc: (0.625)(0.312, 0.938)] [G loss: 0.945] [G acc: 0.125]\n",
      "15756 [D loss: (0.603)(R 0.611, F 0.594)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.816] [G acc: 0.312]\n",
      "15757 [D loss: (0.695)(R 0.643, F 0.747)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.815] [G acc: 0.250]\n",
      "15758 [D loss: (0.609)(R 0.521, F 0.698)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.911] [G acc: 0.125]\n",
      "15759 [D loss: (0.655)(R 0.731, F 0.578)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.861] [G acc: 0.062]\n",
      "15760 [D loss: (0.624)(R 0.607, F 0.642)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.844] [G acc: 0.125]\n",
      "15761 [D loss: (0.676)(R 0.596, F 0.757)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.812] [G acc: 0.250]\n",
      "15762 [D loss: (0.564)(R 0.566, F 0.563)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.907] [G acc: 0.062]\n",
      "15763 [D loss: (0.603)(R 0.607, F 0.600)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.903] [G acc: 0.062]\n",
      "15764 [D loss: (0.624)(R 0.660, F 0.588)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.732] [G acc: 0.438]\n",
      "15765 [D loss: (0.670)(R 0.734, F 0.606)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.909] [G acc: 0.062]\n",
      "15766 [D loss: (0.620)(R 0.702, F 0.538)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.861] [G acc: 0.188]\n",
      "15767 [D loss: (0.659)(R 0.753, F 0.565)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.886] [G acc: 0.188]\n",
      "15768 [D loss: (0.614)(R 0.663, F 0.565)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.773] [G acc: 0.375]\n",
      "15769 [D loss: (0.565)(R 0.514, F 0.616)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.977] [G acc: 0.125]\n",
      "15770 [D loss: (0.604)(R 0.615, F 0.593)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.013] [G acc: 0.250]\n",
      "15771 [D loss: (0.703)(R 0.525, F 0.880)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.986] [G acc: 0.125]\n",
      "15772 [D loss: (0.777)(R 0.834, F 0.720)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.789] [G acc: 0.312]\n",
      "15773 [D loss: (0.534)(R 0.576, F 0.492)] [D acc: (0.875)(0.812, 0.938)] [G loss: 0.923] [G acc: 0.188]\n",
      "15774 [D loss: (0.483)(R 0.512, F 0.453)] [D acc: (0.844)(0.750, 0.938)] [G loss: 0.803] [G acc: 0.375]\n",
      "15775 [D loss: (0.834)(R 0.662, F 1.006)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.114] [G acc: 0.188]\n",
      "15776 [D loss: (0.627)(R 0.655, F 0.599)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.924] [G acc: 0.062]\n",
      "15777 [D loss: (0.622)(R 0.662, F 0.582)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.030] [G acc: 0.188]\n",
      "15778 [D loss: (0.586)(R 0.617, F 0.555)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.923] [G acc: 0.250]\n",
      "15779 [D loss: (0.634)(R 0.680, F 0.588)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.895] [G acc: 0.250]\n",
      "15780 [D loss: (0.630)(R 0.704, F 0.555)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.872] [G acc: 0.250]\n",
      "15781 [D loss: (0.547)(R 0.553, F 0.540)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.267] [G acc: 0.188]\n",
      "15782 [D loss: (0.581)(R 0.582, F 0.579)] [D acc: (0.750)(0.750, 0.750)] [G loss: 3.191] [G acc: 0.125]\n",
      "15783 [D loss: (0.395)(R 0.526, F 0.263)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.772] [G acc: 0.125]\n",
      "15784 [D loss: (0.609)(R 0.682, F 0.537)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.824] [G acc: 0.312]\n",
      "15785 [D loss: (0.513)(R 0.461, F 0.564)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.974] [G acc: 0.188]\n",
      "15786 [D loss: (0.526)(R 0.479, F 0.573)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.028] [G acc: 0.062]\n",
      "15787 [D loss: (0.520)(R 0.550, F 0.490)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.110] [G acc: 0.188]\n",
      "15788 [D loss: (0.501)(R 0.540, F 0.462)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.878] [G acc: 0.250]\n",
      "15789 [D loss: (0.644)(R 0.751, F 0.536)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.987] [G acc: 0.062]\n",
      "15790 [D loss: (0.667)(R 0.764, F 0.569)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.982] [G acc: 0.188]\n",
      "15791 [D loss: (0.589)(R 0.670, F 0.508)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.861] [G acc: 0.438]\n",
      "15792 [D loss: (0.728)(R 0.669, F 0.786)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.025] [G acc: 0.125]\n",
      "15793 [D loss: (0.563)(R 0.506, F 0.620)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.890] [G acc: 0.125]\n",
      "15794 [D loss: (0.534)(R 0.459, F 0.609)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.913] [G acc: 0.125]\n",
      "15795 [D loss: (0.760)(R 0.458, F 1.061)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.908] [G acc: 0.312]\n",
      "15796 [D loss: (0.534)(R 0.455, F 0.613)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.910] [G acc: 0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15797 [D loss: (0.542)(R 0.589, F 0.495)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.258] [G acc: 0.250]\n",
      "15798 [D loss: (0.657)(R 0.634, F 0.680)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.832] [G acc: 0.438]\n",
      "15799 [D loss: (0.485)(R 0.418, F 0.552)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.074] [G acc: 0.188]\n",
      "15800 [D loss: (0.573)(R 0.656, F 0.491)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.026] [G acc: 0.125]\n",
      "15801 [D loss: (0.553)(R 0.597, F 0.508)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.903] [G acc: 0.250]\n",
      "15802 [D loss: (0.524)(R 0.512, F 0.537)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.078] [G acc: 0.125]\n",
      "15803 [D loss: (0.683)(R 0.656, F 0.711)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.807] [G acc: 0.312]\n",
      "15804 [D loss: (0.547)(R 0.513, F 0.580)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.067] [G acc: 0.188]\n",
      "15805 [D loss: (0.646)(R 0.801, F 0.490)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.650] [G acc: 0.438]\n",
      "15806 [D loss: (0.769)(R 0.936, F 0.602)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.976] [G acc: 0.125]\n",
      "15807 [D loss: (0.618)(R 0.627, F 0.609)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.011] [G acc: 0.125]\n",
      "15808 [D loss: (0.608)(R 0.725, F 0.490)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.089] [G acc: 0.125]\n",
      "15809 [D loss: (0.579)(R 0.569, F 0.589)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.984] [G acc: 0.062]\n",
      "15810 [D loss: (0.635)(R 0.685, F 0.585)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.923] [G acc: 0.188]\n",
      "15811 [D loss: (0.598)(R 0.581, F 0.616)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.896] [G acc: 0.312]\n",
      "15812 [D loss: (0.666)(R 0.613, F 0.720)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.920] [G acc: 0.250]\n",
      "15813 [D loss: (0.697)(R 0.723, F 0.671)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.857] [G acc: 0.312]\n",
      "15814 [D loss: (0.566)(R 0.524, F 0.608)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.733] [G acc: 0.438]\n",
      "15815 [D loss: (0.632)(R 0.678, F 0.586)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.773] [G acc: 0.375]\n",
      "15816 [D loss: (0.645)(R 0.651, F 0.638)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.850] [G acc: 0.438]\n",
      "15817 [D loss: (0.604)(R 0.565, F 0.643)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.839] [G acc: 0.250]\n",
      "15818 [D loss: (0.686)(R 0.506, F 0.866)] [D acc: (0.562)(0.750, 0.375)] [G loss: 1.036] [G acc: 0.062]\n",
      "15819 [D loss: (0.565)(R 0.556, F 0.574)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.897] [G acc: 0.375]\n",
      "15820 [D loss: (0.799)(R 0.875, F 0.722)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.956] [G acc: 0.312]\n",
      "15821 [D loss: (0.715)(R 0.547, F 0.883)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.747] [G acc: 0.438]\n",
      "15822 [D loss: (0.698)(R 0.749, F 0.647)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.771] [G acc: 0.438]\n",
      "15823 [D loss: (0.678)(R 0.548, F 0.807)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.739] [G acc: 0.562]\n",
      "15824 [D loss: (0.681)(R 0.647, F 0.715)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.987] [G acc: 0.250]\n",
      "15825 [D loss: (0.734)(R 0.741, F 0.727)] [D acc: (0.406)(0.500, 0.312)] [G loss: 0.865] [G acc: 0.250]\n",
      "15826 [D loss: (0.921)(R 0.785, F 1.057)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.720] [G acc: 0.438]\n",
      "15827 [D loss: (0.696)(R 0.693, F 0.698)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.774] [G acc: 0.438]\n",
      "15828 [D loss: (0.613)(R 0.606, F 0.621)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.842] [G acc: 0.312]\n",
      "15829 [D loss: (0.759)(R 0.730, F 0.788)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.764] [G acc: 0.438]\n",
      "15830 [D loss: (0.762)(R 0.697, F 0.827)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.781] [G acc: 0.438]\n",
      "15831 [D loss: (0.821)(R 0.669, F 0.974)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.668] [G acc: 0.625]\n",
      "15832 [D loss: (0.634)(R 0.512, F 0.756)] [D acc: (0.594)(0.688, 0.500)] [G loss: 1.071] [G acc: 0.312]\n",
      "15833 [D loss: (0.440)(R 0.620, F 0.259)] [D acc: (0.781)(0.688, 0.875)] [G loss: 7.805] [G acc: 0.188]\n",
      "15834 [D loss: (0.708)(R 0.671, F 0.746)] [D acc: (0.438)(0.688, 0.188)] [G loss: 0.722] [G acc: 0.500]\n",
      "15835 [D loss: (0.716)(R 0.634, F 0.797)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.548] [G acc: 0.875]\n",
      "15836 [D loss: (0.667)(R 0.619, F 0.714)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.728] [G acc: 0.500]\n",
      "15837 [D loss: (0.787)(R 0.682, F 0.891)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.792] [G acc: 0.438]\n",
      "15838 [D loss: (0.664)(R 0.643, F 0.685)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.754] [G acc: 0.438]\n",
      "15839 [D loss: (0.629)(R 0.550, F 0.707)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.759] [G acc: 0.438]\n",
      "15840 [D loss: (0.748)(R 0.611, F 0.884)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.743] [G acc: 0.625]\n",
      "15841 [D loss: (0.681)(R 0.619, F 0.742)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.655] [G acc: 0.750]\n",
      "15842 [D loss: (0.701)(R 0.608, F 0.794)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.703] [G acc: 0.625]\n",
      "15843 [D loss: (0.655)(R 0.628, F 0.682)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.116] [G acc: 0.500]\n",
      "15844 [D loss: (0.630)(R 0.615, F 0.644)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.857] [G acc: 0.375]\n",
      "15845 [D loss: (0.620)(R 0.572, F 0.668)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.762] [G acc: 0.438]\n",
      "15846 [D loss: (0.737)(R 0.729, F 0.746)] [D acc: (0.375)(0.500, 0.250)] [G loss: 0.697] [G acc: 0.562]\n",
      "15847 [D loss: (0.647)(R 0.547, F 0.746)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.676] [G acc: 0.625]\n",
      "15848 [D loss: (0.640)(R 0.617, F 0.663)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.758] [G acc: 0.562]\n",
      "15849 [D loss: (0.668)(R 0.583, F 0.753)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.799] [G acc: 0.438]\n",
      "15850 [D loss: (0.657)(R 0.604, F 0.710)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.692] [G acc: 0.500]\n",
      "15851 [D loss: (0.666)(R 0.596, F 0.736)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.727] [G acc: 0.438]\n",
      "15852 [D loss: (0.604)(R 0.489, F 0.720)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.651] [G acc: 0.688]\n",
      "15853 [D loss: (0.628)(R 0.544, F 0.712)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.669] [G acc: 0.500]\n",
      "15854 [D loss: (0.697)(R 0.681, F 0.713)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.832] [G acc: 0.250]\n",
      "15855 [D loss: (0.610)(R 0.534, F 0.685)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.770] [G acc: 0.438]\n",
      "15856 [D loss: (0.588)(R 0.483, F 0.692)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.723] [G acc: 0.438]\n",
      "15857 [D loss: (0.540)(R 0.428, F 0.652)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.784] [G acc: 0.312]\n",
      "15858 [D loss: (0.657)(R 0.634, F 0.680)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.823] [G acc: 0.312]\n",
      "15859 [D loss: (0.696)(R 0.545, F 0.846)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.734] [G acc: 0.562]\n",
      "15860 [D loss: (0.595)(R 0.600, F 0.590)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.762] [G acc: 0.438]\n",
      "15861 [D loss: (0.622)(R 0.495, F 0.748)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.812] [G acc: 0.250]\n",
      "15862 [D loss: (0.559)(R 0.477, F 0.641)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.735] [G acc: 0.438]\n",
      "15863 [D loss: (0.586)(R 0.529, F 0.643)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.766] [G acc: 0.500]\n",
      "15864 [D loss: (0.685)(R 0.702, F 0.667)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.750] [G acc: 0.500]\n",
      "15865 [D loss: (0.543)(R 0.478, F 0.608)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.776] [G acc: 0.250]\n",
      "15866 [D loss: (0.610)(R 0.553, F 0.668)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.696] [G acc: 0.750]\n",
      "15867 [D loss: (0.572)(R 0.494, F 0.650)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.723] [G acc: 0.562]\n",
      "15868 [D loss: (0.666)(R 0.669, F 0.664)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.757] [G acc: 0.438]\n",
      "15869 [D loss: (0.635)(R 0.618, F 0.653)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.752] [G acc: 0.438]\n",
      "15870 [D loss: (0.496)(R 0.382, F 0.611)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.834] [G acc: 0.188]\n",
      "15871 [D loss: (0.565)(R 0.523, F 0.608)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.721] [G acc: 0.500]\n",
      "15872 [D loss: (0.726)(R 0.751, F 0.701)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.842] [G acc: 0.312]\n",
      "15873 [D loss: (0.698)(R 0.634, F 0.761)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.881] [G acc: 0.062]\n",
      "15874 [D loss: (0.687)(R 0.680, F 0.694)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.774] [G acc: 0.375]\n",
      "15875 [D loss: (0.639)(R 0.620, F 0.658)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.743] [G acc: 0.438]\n",
      "15876 [D loss: (0.632)(R 0.529, F 0.735)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.807] [G acc: 0.188]\n",
      "15877 [D loss: (0.613)(R 0.606, F 0.619)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.809] [G acc: 0.250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15878 [D loss: (0.903)(R 0.533, F 1.274)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.783] [G acc: 0.312]\n",
      "15879 [D loss: (0.710)(R 0.754, F 0.666)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.810] [G acc: 0.188]\n",
      "15880 [D loss: (0.659)(R 0.634, F 0.684)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.787] [G acc: 0.188]\n",
      "15881 [D loss: (0.609)(R 0.569, F 0.650)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.663] [G acc: 0.562]\n",
      "15882 [D loss: (0.800)(R 0.551, F 1.048)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.737] [G acc: 0.312]\n",
      "15883 [D loss: (0.778)(R 0.612, F 0.945)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.808] [G acc: 0.188]\n",
      "15884 [D loss: (0.612)(R 0.540, F 0.685)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.774] [G acc: 0.500]\n",
      "15885 [D loss: (0.652)(R 0.654, F 0.649)] [D acc: (0.531)(0.375, 0.688)] [G loss: 1.124] [G acc: 0.250]\n",
      "15886 [D loss: (0.456)(R 0.567, F 0.345)] [D acc: (0.750)(0.500, 1.000)] [G loss: 3.413] [G acc: 0.250]\n",
      "15887 [D loss: (0.653)(R 0.628, F 0.677)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.830] [G acc: 0.375]\n",
      "15888 [D loss: (0.662)(R 0.685, F 0.639)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.785] [G acc: 0.312]\n",
      "15889 [D loss: (0.638)(R 0.700, F 0.577)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.882] [G acc: 0.125]\n",
      "15890 [D loss: (0.685)(R 0.742, F 0.628)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.703] [G acc: 0.438]\n",
      "15891 [D loss: (0.575)(R 0.589, F 0.560)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.832] [G acc: 0.125]\n",
      "15892 [D loss: (0.646)(R 0.650, F 0.641)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.724] [G acc: 0.188]\n",
      "15893 [D loss: (0.689)(R 0.762, F 0.616)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.859] [G acc: 0.188]\n",
      "15894 [D loss: (0.755)(R 0.800, F 0.709)] [D acc: (0.438)(0.188, 0.688)] [G loss: 0.805] [G acc: 0.188]\n",
      "15895 [D loss: (0.657)(R 0.683, F 0.632)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.789] [G acc: 0.188]\n",
      "15896 [D loss: (0.693)(R 0.741, F 0.645)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.829] [G acc: 0.250]\n",
      "15897 [D loss: (0.605)(R 0.577, F 0.634)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.794] [G acc: 0.125]\n",
      "15898 [D loss: (0.687)(R 0.757, F 0.618)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.771] [G acc: 0.188]\n",
      "15899 [D loss: (0.813)(R 0.701, F 0.925)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.761] [G acc: 0.312]\n",
      "15900 [D loss: (0.615)(R 0.515, F 0.715)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.759] [G acc: 0.188]\n",
      "15901 [D loss: (0.684)(R 0.758, F 0.609)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.826] [G acc: 0.188]\n",
      "15902 [D loss: (0.693)(R 0.742, F 0.644)] [D acc: (0.500)(0.188, 0.812)] [G loss: 0.692] [G acc: 0.375]\n",
      "15903 [D loss: (0.549)(R 0.514, F 0.584)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.808] [G acc: 0.062]\n",
      "15904 [D loss: (0.692)(R 0.762, F 0.623)] [D acc: (0.531)(0.250, 0.812)] [G loss: 0.777] [G acc: 0.312]\n",
      "15905 [D loss: (0.812)(R 0.582, F 1.043)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.779] [G acc: 0.312]\n",
      "15906 [D loss: (0.740)(R 0.861, F 0.618)] [D acc: (0.562)(0.250, 0.875)] [G loss: 0.734] [G acc: 0.312]\n",
      "15907 [D loss: (0.695)(R 0.751, F 0.638)] [D acc: (0.438)(0.188, 0.688)] [G loss: 0.777] [G acc: 0.188]\n",
      "15908 [D loss: (0.717)(R 0.730, F 0.704)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.774] [G acc: 0.125]\n",
      "15909 [D loss: (0.677)(R 0.735, F 0.619)] [D acc: (0.562)(0.188, 0.938)] [G loss: 0.778] [G acc: 0.125]\n",
      "15910 [D loss: (0.626)(R 0.666, F 0.587)] [D acc: (0.531)(0.188, 0.875)] [G loss: 0.827] [G acc: 0.188]\n",
      "15911 [D loss: (0.598)(R 0.575, F 0.621)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.819] [G acc: 0.125]\n",
      "15912 [D loss: (0.644)(R 0.660, F 0.628)] [D acc: (0.688)(0.438, 0.938)] [G loss: 1.127] [G acc: 0.312]\n",
      "15913 [D loss: (0.643)(R 0.657, F 0.628)] [D acc: (0.531)(0.312, 0.750)] [G loss: 2.891] [G acc: 0.438]\n",
      "15914 [D loss: (0.609)(R 0.639, F 0.579)] [D acc: (0.594)(0.375, 0.812)] [G loss: 1.009] [G acc: 0.062]\n",
      "15915 [D loss: (0.621)(R 0.635, F 0.608)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.232] [G acc: 0.062]\n",
      "15916 [D loss: (0.616)(R 0.670, F 0.563)] [D acc: (0.719)(0.500, 0.938)] [G loss: 0.905] [G acc: 0.000]\n",
      "15917 [D loss: (0.645)(R 0.585, F 0.705)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.911] [G acc: 0.062]\n",
      "15918 [D loss: (0.654)(R 0.740, F 0.567)] [D acc: (0.656)(0.312, 1.000)] [G loss: 0.913] [G acc: 0.000]\n",
      "15919 [D loss: (0.655)(R 0.750, F 0.559)] [D acc: (0.594)(0.312, 0.875)] [G loss: 0.868] [G acc: 0.125]\n",
      "15920 [D loss: (0.598)(R 0.639, F 0.557)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.904] [G acc: 0.000]\n",
      "15921 [D loss: (0.856)(R 1.028, F 0.684)] [D acc: (0.562)(0.312, 0.812)] [G loss: 0.944] [G acc: 0.062]\n",
      "15922 [D loss: (0.690)(R 0.659, F 0.722)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.791] [G acc: 0.188]\n",
      "15923 [D loss: (0.670)(R 0.733, F 0.608)] [D acc: (0.562)(0.188, 0.938)] [G loss: 0.809] [G acc: 0.125]\n",
      "15924 [D loss: (0.746)(R 0.831, F 0.662)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.720] [G acc: 0.375]\n",
      "15925 [D loss: (0.614)(R 0.538, F 0.690)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.675] [G acc: 0.438]\n",
      "15926 [D loss: (0.704)(R 0.734, F 0.673)] [D acc: (0.438)(0.250, 0.625)] [G loss: 0.767] [G acc: 0.312]\n",
      "15927 [D loss: (0.686)(R 0.620, F 0.753)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.751] [G acc: 0.250]\n",
      "15928 [D loss: (0.672)(R 0.692, F 0.652)] [D acc: (0.500)(0.312, 0.688)] [G loss: 0.757] [G acc: 0.062]\n",
      "15929 [D loss: (0.646)(R 0.667, F 0.626)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.648] [G acc: 0.312]\n",
      "15930 [D loss: (0.713)(R 0.560, F 0.866)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.745] [G acc: 0.250]\n",
      "15931 [D loss: (0.769)(R 0.596, F 0.942)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.847] [G acc: 0.125]\n",
      "15932 [D loss: (0.727)(R 0.717, F 0.736)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.818] [G acc: 0.188]\n",
      "15933 [D loss: (0.682)(R 0.666, F 0.698)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.815] [G acc: 0.250]\n",
      "15934 [D loss: (0.693)(R 0.742, F 0.645)] [D acc: (0.625)(0.312, 0.938)] [G loss: 0.902] [G acc: 0.062]\n",
      "15935 [D loss: (0.679)(R 0.787, F 0.570)] [D acc: (0.594)(0.250, 0.938)] [G loss: 0.851] [G acc: 0.125]\n",
      "15936 [D loss: (0.662)(R 0.734, F 0.591)] [D acc: (0.562)(0.250, 0.875)] [G loss: 0.728] [G acc: 0.500]\n",
      "15937 [D loss: (0.677)(R 0.722, F 0.632)] [D acc: (0.500)(0.312, 0.688)] [G loss: 0.666] [G acc: 0.562]\n",
      "15938 [D loss: (0.758)(R 0.687, F 0.830)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.845] [G acc: 0.062]\n",
      "15939 [D loss: (0.660)(R 0.704, F 0.615)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.873] [G acc: 0.188]\n",
      "15940 [D loss: (0.667)(R 0.774, F 0.560)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.901] [G acc: 0.125]\n",
      "15941 [D loss: (0.657)(R 0.654, F 0.660)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.845] [G acc: 0.250]\n",
      "15942 [D loss: (0.633)(R 0.666, F 0.599)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.755] [G acc: 0.250]\n",
      "15943 [D loss: (0.637)(R 0.645, F 0.629)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.850] [G acc: 0.125]\n",
      "15944 [D loss: (0.695)(R 0.776, F 0.614)] [D acc: (0.500)(0.188, 0.812)] [G loss: 0.921] [G acc: 0.000]\n",
      "15945 [D loss: (0.653)(R 0.723, F 0.582)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.895] [G acc: 0.125]\n",
      "15946 [D loss: (0.651)(R 0.638, F 0.664)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.867] [G acc: 0.250]\n",
      "15947 [D loss: (0.592)(R 0.560, F 0.624)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.859] [G acc: 0.125]\n",
      "15948 [D loss: (0.650)(R 0.712, F 0.587)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.860] [G acc: 0.188]\n",
      "15949 [D loss: (0.667)(R 0.741, F 0.593)] [D acc: (0.688)(0.500, 0.875)] [G loss: 1.033] [G acc: 0.062]\n",
      "15950 [D loss: (0.676)(R 0.650, F 0.701)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.740] [G acc: 0.312]\n",
      "15951 [D loss: (0.631)(R 0.681, F 0.580)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.808] [G acc: 0.375]\n",
      "15952 [D loss: (0.641)(R 0.632, F 0.649)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.773] [G acc: 0.375]\n",
      "15953 [D loss: (0.740)(R 0.708, F 0.771)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.821] [G acc: 0.312]\n",
      "15954 [D loss: (0.662)(R 0.660, F 0.665)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.641] [G acc: 0.625]\n",
      "15955 [D loss: (0.627)(R 0.680, F 0.575)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.982] [G acc: 0.188]\n",
      "15956 [D loss: (0.658)(R 0.711, F 0.605)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.919] [G acc: 0.312]\n",
      "15957 [D loss: (0.780)(R 0.659, F 0.901)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.750] [G acc: 0.562]\n",
      "15958 [D loss: (0.792)(R 0.639, F 0.945)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.864] [G acc: 0.312]\n",
      "15959 [D loss: (0.499)(R 0.709, F 0.290)] [D acc: (0.656)(0.500, 0.812)] [G loss: 8.027] [G acc: 0.188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15960 [D loss: (0.776)(R 0.735, F 0.818)] [D acc: (0.625)(0.688, 0.562)] [G loss: 2.051] [G acc: 0.375]\n",
      "15961 [D loss: (0.657)(R 0.658, F 0.656)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.107] [G acc: 0.125]\n",
      "15962 [D loss: (0.640)(R 0.729, F 0.552)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.900] [G acc: 0.125]\n",
      "15963 [D loss: (0.735)(R 0.741, F 0.728)] [D acc: (0.562)(0.625, 0.500)] [G loss: 1.005] [G acc: 0.062]\n",
      "15964 [D loss: (0.669)(R 0.705, F 0.633)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.864] [G acc: 0.312]\n",
      "15965 [D loss: (0.719)(R 0.788, F 0.649)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.992] [G acc: 0.250]\n",
      "15966 [D loss: (0.672)(R 0.763, F 0.582)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.745] [G acc: 0.312]\n",
      "15967 [D loss: (0.737)(R 0.771, F 0.702)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.709] [G acc: 0.625]\n",
      "15968 [D loss: (0.654)(R 0.675, F 0.634)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.743] [G acc: 0.438]\n",
      "15969 [D loss: (0.738)(R 0.661, F 0.816)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.860] [G acc: 0.250]\n",
      "15970 [D loss: (0.662)(R 0.699, F 0.625)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.725] [G acc: 0.562]\n",
      "15971 [D loss: (0.650)(R 0.693, F 0.608)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.876] [G acc: 0.188]\n",
      "15972 [D loss: (0.689)(R 0.594, F 0.784)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.937] [G acc: 0.250]\n",
      "15973 [D loss: (0.611)(R 0.642, F 0.580)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.983] [G acc: 0.250]\n",
      "15974 [D loss: (0.599)(R 0.655, F 0.543)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.873] [G acc: 0.250]\n",
      "15975 [D loss: (0.593)(R 0.583, F 0.603)] [D acc: (0.844)(1.000, 0.688)] [G loss: 0.828] [G acc: 0.250]\n",
      "15976 [D loss: (0.602)(R 0.621, F 0.584)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.899] [G acc: 0.250]\n",
      "15977 [D loss: (0.599)(R 0.702, F 0.497)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.803] [G acc: 0.438]\n",
      "15978 [D loss: (0.565)(R 0.604, F 0.525)] [D acc: (0.844)(0.875, 0.812)] [G loss: 0.739] [G acc: 0.562]\n",
      "15979 [D loss: (0.669)(R 0.700, F 0.637)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.821] [G acc: 0.438]\n",
      "15980 [D loss: (0.645)(R 0.672, F 0.619)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.875] [G acc: 0.250]\n",
      "15981 [D loss: (0.671)(R 0.712, F 0.630)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.860] [G acc: 0.375]\n",
      "15982 [D loss: (0.682)(R 0.647, F 0.716)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.764] [G acc: 0.438]\n",
      "15983 [D loss: (0.664)(R 0.733, F 0.595)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.800] [G acc: 0.375]\n",
      "15984 [D loss: (0.857)(R 0.690, F 1.025)] [D acc: (0.562)(0.688, 0.438)] [G loss: 2.627] [G acc: 0.500]\n",
      "15985 [D loss: (0.386)(R 0.637, F 0.136)] [D acc: (0.812)(0.688, 0.938)] [G loss: 5.704] [G acc: 0.188]\n",
      "15986 [D loss: (0.627)(R 0.651, F 0.603)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.906] [G acc: 0.438]\n",
      "15987 [D loss: (0.605)(R 0.700, F 0.510)] [D acc: (0.625)(0.562, 0.688)] [G loss: 2.109] [G acc: 0.562]\n",
      "15988 [D loss: (0.698)(R 0.757, F 0.639)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.847] [G acc: 0.438]\n",
      "15989 [D loss: (0.683)(R 0.737, F 0.630)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.981] [G acc: 0.188]\n",
      "15990 [D loss: (0.589)(R 0.617, F 0.560)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.024] [G acc: 0.250]\n",
      "15991 [D loss: (0.677)(R 0.753, F 0.600)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.069] [G acc: 0.062]\n",
      "15992 [D loss: (0.701)(R 0.717, F 0.684)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.848] [G acc: 0.250]\n",
      "15993 [D loss: (0.603)(R 0.642, F 0.563)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.893] [G acc: 0.250]\n",
      "15994 [D loss: (0.737)(R 0.769, F 0.706)] [D acc: (0.531)(0.688, 0.375)] [G loss: 1.154] [G acc: 0.438]\n",
      "15995 [D loss: (0.714)(R 0.709, F 0.719)] [D acc: (0.594)(0.750, 0.438)] [G loss: 1.054] [G acc: 0.188]\n",
      "15996 [D loss: (0.594)(R 0.633, F 0.554)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.049] [G acc: 0.188]\n",
      "15997 [D loss: (0.634)(R 0.741, F 0.527)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.346] [G acc: 0.438]\n",
      "15998 [D loss: (0.672)(R 0.718, F 0.627)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.994] [G acc: 0.250]\n",
      "15999 [D loss: (0.693)(R 0.715, F 0.672)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.868] [G acc: 0.375]\n",
      "16000 [D loss: (0.728)(R 0.733, F 0.723)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.949] [G acc: 0.312]\n",
      "16001 [D loss: (0.713)(R 0.744, F 0.683)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.769] [G acc: 0.500]\n",
      "16002 [D loss: (0.681)(R 0.718, F 0.644)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.773] [G acc: 0.438]\n",
      "16003 [D loss: (0.672)(R 0.776, F 0.568)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.774] [G acc: 0.438]\n",
      "16004 [D loss: (0.859)(R 1.018, F 0.700)] [D acc: (0.406)(0.500, 0.312)] [G loss: 0.813] [G acc: 0.625]\n",
      "16005 [D loss: (0.650)(R 0.640, F 0.659)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.657] [G acc: 0.688]\n",
      "16006 [D loss: (0.675)(R 0.639, F 0.710)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.913] [G acc: 0.312]\n",
      "16007 [D loss: (0.687)(R 0.648, F 0.727)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.778] [G acc: 0.500]\n",
      "16008 [D loss: (0.691)(R 0.703, F 0.679)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.757] [G acc: 0.688]\n",
      "16009 [D loss: (0.627)(R 0.631, F 0.623)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.821] [G acc: 0.375]\n",
      "16010 [D loss: (0.751)(R 0.858, F 0.644)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.787] [G acc: 0.500]\n",
      "16011 [D loss: (0.755)(R 0.737, F 0.773)] [D acc: (0.312)(0.500, 0.125)] [G loss: 0.834] [G acc: 0.312]\n",
      "16012 [D loss: (0.705)(R 0.720, F 0.689)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.761] [G acc: 0.375]\n",
      "16013 [D loss: (0.669)(R 0.639, F 0.700)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.791] [G acc: 0.688]\n",
      "16014 [D loss: (0.667)(R 0.674, F 0.659)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.722] [G acc: 0.562]\n",
      "16015 [D loss: (0.664)(R 0.643, F 0.685)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.652] [G acc: 0.688]\n",
      "16016 [D loss: (0.721)(R 0.740, F 0.703)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.972] [G acc: 0.438]\n",
      "16017 [D loss: (0.520)(R 0.710, F 0.331)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.866] [G acc: 0.375]\n",
      "16018 [D loss: (0.563)(R 0.716, F 0.409)] [D acc: (0.625)(0.625, 0.625)] [G loss: 6.467] [G acc: 0.438]\n",
      "16019 [D loss: (0.600)(R 0.680, F 0.520)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.760] [G acc: 0.438]\n",
      "16020 [D loss: (0.620)(R 0.644, F 0.597)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.864] [G acc: 0.250]\n",
      "16021 [D loss: (0.613)(R 0.673, F 0.554)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.999] [G acc: 0.312]\n",
      "16022 [D loss: (0.717)(R 0.703, F 0.731)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.924] [G acc: 0.062]\n",
      "16023 [D loss: (0.725)(R 0.812, F 0.637)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.859] [G acc: 0.500]\n",
      "16024 [D loss: (0.659)(R 0.672, F 0.647)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.804] [G acc: 0.312]\n",
      "16025 [D loss: (0.690)(R 0.754, F 0.627)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.821] [G acc: 0.250]\n",
      "16026 [D loss: (0.607)(R 0.552, F 0.662)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.813] [G acc: 0.438]\n",
      "16027 [D loss: (0.717)(R 0.734, F 0.700)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.812] [G acc: 0.312]\n",
      "16028 [D loss: (0.698)(R 0.726, F 0.669)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.873] [G acc: 0.188]\n",
      "16029 [D loss: (0.651)(R 0.669, F 0.634)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.773] [G acc: 0.312]\n",
      "16030 [D loss: (0.645)(R 0.647, F 0.643)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.733] [G acc: 0.375]\n",
      "16031 [D loss: (0.694)(R 0.691, F 0.698)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.871] [G acc: 0.438]\n",
      "16032 [D loss: (0.707)(R 0.735, F 0.680)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.760] [G acc: 0.375]\n",
      "16033 [D loss: (0.705)(R 0.708, F 0.701)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.767] [G acc: 0.375]\n",
      "16034 [D loss: (0.692)(R 0.696, F 0.687)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.966] [G acc: 0.500]\n",
      "16035 [D loss: (0.565)(R 0.641, F 0.488)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.094] [G acc: 0.125]\n",
      "16036 [D loss: (0.605)(R 0.733, F 0.477)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.870] [G acc: 0.250]\n",
      "16037 [D loss: (0.689)(R 0.702, F 0.677)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.787] [G acc: 0.312]\n",
      "16038 [D loss: (0.633)(R 0.662, F 0.604)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.892] [G acc: 0.250]\n",
      "16039 [D loss: (0.692)(R 0.692, F 0.691)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.889] [G acc: 0.188]\n",
      "16040 [D loss: (0.678)(R 0.659, F 0.697)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.771] [G acc: 0.438]\n",
      "16041 [D loss: (0.753)(R 0.812, F 0.693)] [D acc: (0.406)(0.375, 0.438)] [G loss: 0.789] [G acc: 0.500]\n",
      "16042 [D loss: (0.685)(R 0.695, F 0.676)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.950] [G acc: 0.375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16043 [D loss: (0.652)(R 0.640, F 0.664)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.745] [G acc: 0.438]\n",
      "16044 [D loss: (0.710)(R 0.700, F 0.719)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.760] [G acc: 0.375]\n",
      "16045 [D loss: (0.650)(R 0.650, F 0.650)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.918] [G acc: 0.312]\n",
      "16046 [D loss: (0.668)(R 0.601, F 0.735)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.935] [G acc: 0.438]\n",
      "16047 [D loss: (0.510)(R 0.639, F 0.380)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.144] [G acc: 0.188]\n",
      "16048 [D loss: (0.521)(R 0.724, F 0.319)] [D acc: (0.688)(0.625, 0.750)] [G loss: 2.433] [G acc: 0.125]\n",
      "16049 [D loss: (0.501)(R 0.715, F 0.287)] [D acc: (0.719)(0.562, 0.875)] [G loss: 4.966] [G acc: 0.125]\n",
      "16050 [D loss: (0.658)(R 0.710, F 0.605)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.819] [G acc: 0.312]\n",
      "16051 [D loss: (0.616)(R 0.579, F 0.654)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.017] [G acc: 0.312]\n",
      "16052 [D loss: (0.662)(R 0.716, F 0.608)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.856] [G acc: 0.312]\n",
      "16053 [D loss: (0.637)(R 0.685, F 0.589)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.924] [G acc: 0.188]\n",
      "16054 [D loss: (0.654)(R 0.741, F 0.567)] [D acc: (0.750)(0.625, 0.875)] [G loss: 2.191] [G acc: 0.125]\n",
      "16055 [D loss: (0.597)(R 0.562, F 0.632)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.744] [G acc: 0.375]\n",
      "16056 [D loss: (0.707)(R 0.801, F 0.614)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.809] [G acc: 0.250]\n",
      "16057 [D loss: (0.654)(R 0.711, F 0.597)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.117] [G acc: 0.375]\n",
      "16058 [D loss: (0.675)(R 0.759, F 0.592)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.889] [G acc: 0.250]\n",
      "16059 [D loss: (0.649)(R 0.752, F 0.547)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.783] [G acc: 0.375]\n",
      "16060 [D loss: (0.626)(R 0.569, F 0.684)] [D acc: (0.625)(0.750, 0.500)] [G loss: 1.673] [G acc: 0.438]\n",
      "16061 [D loss: (0.627)(R 0.664, F 0.590)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.851] [G acc: 0.250]\n",
      "16062 [D loss: (0.651)(R 0.667, F 0.635)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.149] [G acc: 0.188]\n",
      "16063 [D loss: (0.586)(R 0.678, F 0.494)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.886] [G acc: 0.312]\n",
      "16064 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.989] [G acc: 0.188]\n",
      "16065 [D loss: (0.682)(R 0.751, F 0.614)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.883] [G acc: 0.188]\n",
      "16066 [D loss: (0.738)(R 0.852, F 0.623)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.871] [G acc: 0.438]\n",
      "16067 [D loss: (0.726)(R 0.751, F 0.700)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.804] [G acc: 0.312]\n",
      "16068 [D loss: (0.665)(R 0.678, F 0.651)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.765] [G acc: 0.438]\n",
      "16069 [D loss: (0.710)(R 0.717, F 0.704)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.860] [G acc: 0.375]\n",
      "16070 [D loss: (0.727)(R 0.754, F 0.700)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.830] [G acc: 0.312]\n",
      "16071 [D loss: (0.751)(R 0.751, F 0.751)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.804] [G acc: 0.562]\n",
      "16072 [D loss: (0.662)(R 0.654, F 0.671)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.638] [G acc: 0.750]\n",
      "16073 [D loss: (0.686)(R 0.687, F 0.684)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.679] [G acc: 0.625]\n",
      "16074 [D loss: (0.704)(R 0.648, F 0.761)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.718] [G acc: 0.562]\n",
      "16075 [D loss: (0.674)(R 0.616, F 0.733)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.729] [G acc: 0.500]\n",
      "16076 [D loss: (0.674)(R 0.647, F 0.701)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.788] [G acc: 0.375]\n",
      "16077 [D loss: (0.723)(R 0.695, F 0.752)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.794] [G acc: 0.562]\n",
      "16078 [D loss: (0.667)(R 0.621, F 0.713)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.776] [G acc: 0.500]\n",
      "16079 [D loss: (0.651)(R 0.606, F 0.695)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.766] [G acc: 0.438]\n",
      "16080 [D loss: (0.669)(R 0.564, F 0.773)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.732] [G acc: 0.625]\n",
      "16081 [D loss: (0.687)(R 0.654, F 0.721)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.949] [G acc: 0.375]\n",
      "16082 [D loss: (0.660)(R 0.638, F 0.683)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.760] [G acc: 0.375]\n",
      "16083 [D loss: (0.676)(R 0.625, F 0.727)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.785] [G acc: 0.438]\n",
      "16084 [D loss: (0.612)(R 0.596, F 0.628)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.790] [G acc: 0.312]\n",
      "16085 [D loss: (0.717)(R 0.643, F 0.791)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.903] [G acc: 0.562]\n",
      "16086 [D loss: (0.586)(R 0.780, F 0.393)] [D acc: (0.688)(0.500, 0.875)] [G loss: 1.466] [G acc: 0.188]\n",
      "16087 [D loss: (0.572)(R 0.706, F 0.438)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.717] [G acc: 0.312]\n",
      "16088 [D loss: (0.916)(R 1.186, F 0.646)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.822] [G acc: 0.375]\n",
      "16089 [D loss: (0.714)(R 0.782, F 0.647)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.767] [G acc: 0.438]\n",
      "16090 [D loss: (0.593)(R 0.510, F 0.676)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.797] [G acc: 0.250]\n",
      "16091 [D loss: (0.664)(R 0.642, F 0.686)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.816] [G acc: 0.250]\n",
      "16092 [D loss: (0.630)(R 0.578, F 0.682)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.723] [G acc: 0.438]\n",
      "16093 [D loss: (0.766)(R 0.814, F 0.718)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.757] [G acc: 0.375]\n",
      "16094 [D loss: (0.814)(R 0.949, F 0.679)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.695] [G acc: 0.562]\n",
      "16095 [D loss: (0.650)(R 0.576, F 0.724)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.662] [G acc: 0.500]\n",
      "16096 [D loss: (0.829)(R 0.882, F 0.777)] [D acc: (0.344)(0.500, 0.188)] [G loss: 0.743] [G acc: 0.438]\n",
      "16097 [D loss: (0.664)(R 0.600, F 0.728)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.689] [G acc: 0.625]\n",
      "16098 [D loss: (0.744)(R 0.681, F 0.807)] [D acc: (0.344)(0.562, 0.125)] [G loss: 0.663] [G acc: 0.625]\n",
      "16099 [D loss: (0.650)(R 0.588, F 0.713)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.658] [G acc: 0.688]\n",
      "16100 [D loss: (0.670)(R 0.581, F 0.759)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.724] [G acc: 0.562]\n",
      "16101 [D loss: (0.738)(R 0.548, F 0.929)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.668] [G acc: 0.562]\n",
      "16102 [D loss: (0.800)(R 0.857, F 0.743)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.700] [G acc: 0.625]\n",
      "16103 [D loss: (0.680)(R 0.629, F 0.730)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.741] [G acc: 0.562]\n",
      "16104 [D loss: (0.659)(R 0.599, F 0.719)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.743] [G acc: 0.688]\n",
      "16105 [D loss: (0.665)(R 0.589, F 0.740)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.681] [G acc: 0.500]\n",
      "16106 [D loss: (0.671)(R 0.591, F 0.752)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.725] [G acc: 0.500]\n",
      "16107 [D loss: (0.700)(R 0.683, F 0.716)] [D acc: (0.375)(0.500, 0.250)] [G loss: 0.732] [G acc: 0.438]\n",
      "16108 [D loss: (0.655)(R 0.673, F 0.637)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.825] [G acc: 0.500]\n",
      "16109 [D loss: (0.626)(R 0.554, F 0.698)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.711] [G acc: 0.625]\n",
      "16110 [D loss: (0.859)(R 0.635, F 1.083)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.744] [G acc: 0.375]\n",
      "16111 [D loss: (0.633)(R 0.637, F 0.628)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.681] [G acc: 0.562]\n",
      "16112 [D loss: (0.697)(R 0.672, F 0.722)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.848] [G acc: 0.375]\n",
      "16113 [D loss: (0.699)(R 0.692, F 0.705)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.743] [G acc: 0.438]\n",
      "16114 [D loss: (0.664)(R 0.651, F 0.677)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.825] [G acc: 0.375]\n",
      "16115 [D loss: (0.647)(R 0.584, F 0.710)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.753] [G acc: 0.500]\n",
      "16116 [D loss: (0.698)(R 0.669, F 0.727)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.798] [G acc: 0.312]\n",
      "16117 [D loss: (0.669)(R 0.631, F 0.708)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.693] [G acc: 0.688]\n",
      "16118 [D loss: (0.635)(R 0.521, F 0.750)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.772] [G acc: 0.312]\n",
      "16119 [D loss: (0.623)(R 0.579, F 0.667)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.682] [G acc: 0.625]\n",
      "16120 [D loss: (0.655)(R 0.627, F 0.682)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.695] [G acc: 0.562]\n",
      "16121 [D loss: (0.598)(R 0.426, F 0.770)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.744] [G acc: 0.500]\n",
      "16122 [D loss: (0.644)(R 0.602, F 0.686)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.726] [G acc: 0.562]\n",
      "16123 [D loss: (0.817)(R 0.633, F 1.001)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.684] [G acc: 0.562]\n",
      "16124 [D loss: (0.682)(R 0.642, F 0.722)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.682] [G acc: 0.562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16125 [D loss: (0.708)(R 0.708, F 0.709)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.677] [G acc: 0.688]\n",
      "16126 [D loss: (0.562)(R 0.516, F 0.608)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.638] [G acc: 0.938]\n",
      "16127 [D loss: (0.779)(R 0.724, F 0.835)] [D acc: (0.500)(0.438, 0.562)] [G loss: 1.038] [G acc: 0.438]\n",
      "16128 [D loss: (0.424)(R 0.491, F 0.358)] [D acc: (0.688)(0.688, 0.688)] [G loss: 4.920] [G acc: 0.062]\n",
      "16129 [D loss: (0.673)(R 0.768, F 0.578)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.764] [G acc: 0.375]\n",
      "16130 [D loss: (0.605)(R 0.510, F 0.699)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.724] [G acc: 0.438]\n",
      "16131 [D loss: (0.673)(R 0.679, F 0.667)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.807] [G acc: 0.188]\n",
      "16132 [D loss: (0.624)(R 0.545, F 0.704)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.767] [G acc: 0.312]\n",
      "16133 [D loss: (0.587)(R 0.531, F 0.643)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.677] [G acc: 0.562]\n",
      "16134 [D loss: (0.554)(R 0.434, F 0.674)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.706] [G acc: 0.250]\n",
      "16135 [D loss: (0.685)(R 0.654, F 0.715)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.788] [G acc: 0.438]\n",
      "16136 [D loss: (0.652)(R 0.501, F 0.803)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.764] [G acc: 0.188]\n",
      "16137 [D loss: (0.591)(R 0.532, F 0.651)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.729] [G acc: 0.375]\n",
      "16138 [D loss: (0.636)(R 0.597, F 0.675)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.658] [G acc: 0.312]\n",
      "16139 [D loss: (0.634)(R 0.582, F 0.687)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.658] [G acc: 0.625]\n",
      "16140 [D loss: (0.685)(R 0.617, F 0.753)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.676] [G acc: 0.500]\n",
      "16141 [D loss: (0.848)(R 0.574, F 1.121)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.745] [G acc: 0.250]\n",
      "16142 [D loss: (0.613)(R 0.530, F 0.697)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.626] [G acc: 0.625]\n",
      "16143 [D loss: (0.655)(R 0.644, F 0.667)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.890] [G acc: 0.312]\n",
      "16144 [D loss: (0.636)(R 0.602, F 0.671)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.677] [G acc: 0.438]\n",
      "16145 [D loss: (0.640)(R 0.604, F 0.675)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.605] [G acc: 0.500]\n",
      "16146 [D loss: (0.647)(R 0.598, F 0.696)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.684] [G acc: 0.562]\n",
      "16147 [D loss: (0.810)(R 0.669, F 0.950)] [D acc: (0.312)(0.375, 0.250)] [G loss: 0.690] [G acc: 0.438]\n",
      "16148 [D loss: (0.654)(R 0.612, F 0.696)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.717] [G acc: 0.312]\n",
      "16149 [D loss: (0.679)(R 0.669, F 0.689)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.717] [G acc: 0.438]\n",
      "16150 [D loss: (0.723)(R 0.586, F 0.860)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.639] [G acc: 0.438]\n",
      "16151 [D loss: (0.741)(R 0.686, F 0.797)] [D acc: (0.344)(0.250, 0.438)] [G loss: 0.662] [G acc: 0.562]\n",
      "16152 [D loss: (0.757)(R 0.455, F 1.060)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.306] [G acc: 0.500]\n",
      "16153 [D loss: (0.432)(R 0.600, F 0.264)] [D acc: (0.688)(0.438, 0.938)] [G loss: 4.603] [G acc: 0.312]\n",
      "16154 [D loss: (0.758)(R 0.633, F 0.883)] [D acc: (0.531)(0.438, 0.625)] [G loss: 2.306] [G acc: 0.188]\n",
      "16155 [D loss: (0.659)(R 0.649, F 0.669)] [D acc: (0.656)(0.500, 0.812)] [G loss: 3.747] [G acc: 0.250]\n",
      "16156 [D loss: (0.708)(R 0.631, F 0.785)] [D acc: (0.562)(0.500, 0.625)] [G loss: 5.811] [G acc: 0.188]\n",
      "16157 [D loss: (0.652)(R 0.620, F 0.685)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.747] [G acc: 0.250]\n",
      "16158 [D loss: (0.669)(R 0.706, F 0.632)] [D acc: (0.531)(0.250, 0.812)] [G loss: 0.735] [G acc: 0.250]\n",
      "16159 [D loss: (0.639)(R 0.688, F 0.589)] [D acc: (0.594)(0.250, 0.938)] [G loss: 0.765] [G acc: 0.062]\n",
      "16160 [D loss: (0.589)(R 0.549, F 0.628)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.699] [G acc: 0.375]\n",
      "16161 [D loss: (0.582)(R 0.569, F 0.596)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.773] [G acc: 0.125]\n",
      "16162 [D loss: (0.620)(R 0.582, F 0.658)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.810] [G acc: 0.188]\n",
      "16163 [D loss: (0.504)(R 0.383, F 0.626)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.176] [G acc: 0.062]\n",
      "16164 [D loss: (0.627)(R 0.627, F 0.628)] [D acc: (0.500)(0.312, 0.688)] [G loss: 0.794] [G acc: 0.188]\n",
      "16165 [D loss: (0.577)(R 0.557, F 0.596)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.776] [G acc: 0.250]\n",
      "16166 [D loss: (0.672)(R 0.685, F 0.658)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.722] [G acc: 0.250]\n",
      "16167 [D loss: (0.751)(R 0.645, F 0.858)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.744] [G acc: 0.250]\n",
      "16168 [D loss: (0.588)(R 0.565, F 0.610)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.761] [G acc: 0.312]\n",
      "16169 [D loss: (0.593)(R 0.537, F 0.648)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.775] [G acc: 0.188]\n",
      "16170 [D loss: (0.646)(R 0.641, F 0.652)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.759] [G acc: 0.250]\n",
      "16171 [D loss: (0.649)(R 0.639, F 0.660)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.700] [G acc: 0.250]\n",
      "16172 [D loss: (0.599)(R 0.531, F 0.667)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.803] [G acc: 0.062]\n",
      "16173 [D loss: (0.599)(R 0.553, F 0.646)] [D acc: (0.625)(0.438, 0.812)] [G loss: 2.132] [G acc: 0.312]\n",
      "16174 [D loss: (0.883)(R 0.639, F 1.127)] [D acc: (0.688)(0.625, 0.750)] [G loss: 2.869] [G acc: 0.125]\n",
      "16175 [D loss: (0.650)(R 0.479, F 0.821)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.935] [G acc: 0.125]\n",
      "16176 [D loss: (0.624)(R 0.649, F 0.599)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.813] [G acc: 0.125]\n",
      "16177 [D loss: (0.580)(R 0.591, F 0.570)] [D acc: (0.688)(0.438, 0.938)] [G loss: 0.775] [G acc: 0.250]\n",
      "16178 [D loss: (0.737)(R 0.564, F 0.909)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.808] [G acc: 0.188]\n",
      "16179 [D loss: (0.590)(R 0.515, F 0.664)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.754] [G acc: 0.125]\n",
      "16180 [D loss: (0.650)(R 0.630, F 0.669)] [D acc: (0.594)(0.375, 0.812)] [G loss: 1.019] [G acc: 0.188]\n",
      "16181 [D loss: (0.739)(R 0.852, F 0.626)] [D acc: (0.500)(0.250, 0.750)] [G loss: 0.870] [G acc: 0.062]\n",
      "16182 [D loss: (0.592)(R 0.592, F 0.591)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.804] [G acc: 0.062]\n",
      "16183 [D loss: (0.728)(R 0.464, F 0.992)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.860] [G acc: 0.125]\n",
      "16184 [D loss: (0.687)(R 0.767, F 0.606)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.784] [G acc: 0.188]\n",
      "16185 [D loss: (0.603)(R 0.590, F 0.616)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.841] [G acc: 0.062]\n",
      "16186 [D loss: (0.597)(R 0.609, F 0.585)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.819] [G acc: 0.125]\n",
      "16187 [D loss: (0.586)(R 0.545, F 0.627)] [D acc: (0.719)(0.500, 0.938)] [G loss: 0.806] [G acc: 0.312]\n",
      "16188 [D loss: (0.623)(R 0.466, F 0.781)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.849] [G acc: 0.188]\n",
      "16189 [D loss: (0.643)(R 0.673, F 0.612)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.944] [G acc: 0.312]\n",
      "16190 [D loss: (0.645)(R 0.545, F 0.746)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.831] [G acc: 0.125]\n",
      "16191 [D loss: (0.621)(R 0.620, F 0.621)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.914] [G acc: 0.000]\n",
      "16192 [D loss: (0.613)(R 0.612, F 0.614)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.795] [G acc: 0.125]\n",
      "16193 [D loss: (0.581)(R 0.649, F 0.513)] [D acc: (0.719)(0.438, 1.000)] [G loss: 0.799] [G acc: 0.188]\n",
      "16194 [D loss: (0.626)(R 0.673, F 0.580)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.788] [G acc: 0.250]\n",
      "16195 [D loss: (0.561)(R 0.517, F 0.604)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.703] [G acc: 0.250]\n",
      "16196 [D loss: (0.515)(R 0.418, F 0.611)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.825] [G acc: 0.125]\n",
      "16197 [D loss: (0.571)(R 0.547, F 0.596)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.826] [G acc: 0.125]\n",
      "16198 [D loss: (1.041)(R 0.665, F 1.418)] [D acc: (0.531)(0.250, 0.812)] [G loss: 0.873] [G acc: 0.125]\n",
      "16199 [D loss: (0.654)(R 0.712, F 0.596)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.961] [G acc: 0.000]\n",
      "16200 [D loss: (0.604)(R 0.588, F 0.619)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.815] [G acc: 0.062]\n",
      "16201 [D loss: (0.543)(R 0.474, F 0.612)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.842] [G acc: 0.125]\n",
      "16202 [D loss: (0.603)(R 0.634, F 0.572)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.759] [G acc: 0.312]\n",
      "16203 [D loss: (0.578)(R 0.584, F 0.571)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.847] [G acc: 0.125]\n",
      "16204 [D loss: (0.588)(R 0.556, F 0.621)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.746] [G acc: 0.250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16205 [D loss: (0.536)(R 0.470, F 0.602)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.853] [G acc: 0.125]\n",
      "16206 [D loss: (0.618)(R 0.570, F 0.667)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.792] [G acc: 0.375]\n",
      "16207 [D loss: (0.659)(R 0.564, F 0.753)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.868] [G acc: 0.188]\n",
      "16208 [D loss: (0.486)(R 0.413, F 0.558)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.852] [G acc: 0.250]\n",
      "16209 [D loss: (0.563)(R 0.558, F 0.567)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.802] [G acc: 0.375]\n",
      "16210 [D loss: (0.599)(R 0.556, F 0.642)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.891] [G acc: 0.188]\n",
      "16211 [D loss: (0.557)(R 0.448, F 0.666)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.930] [G acc: 0.000]\n",
      "16212 [D loss: (0.578)(R 0.669, F 0.487)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.990] [G acc: 0.062]\n",
      "16213 [D loss: (0.543)(R 0.500, F 0.586)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.830] [G acc: 0.188]\n",
      "16214 [D loss: (0.554)(R 0.532, F 0.576)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.928] [G acc: 0.125]\n",
      "16215 [D loss: (0.500)(R 0.477, F 0.523)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.775] [G acc: 0.375]\n",
      "16216 [D loss: (0.618)(R 0.669, F 0.566)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.889] [G acc: 0.125]\n",
      "16217 [D loss: (0.732)(R 0.575, F 0.889)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.010] [G acc: 0.000]\n",
      "16218 [D loss: (0.768)(R 0.702, F 0.835)] [D acc: (0.594)(0.438, 0.750)] [G loss: 1.143] [G acc: 0.000]\n",
      "16219 [D loss: (0.516)(R 0.518, F 0.514)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.000] [G acc: 0.062]\n",
      "16220 [D loss: (0.657)(R 0.794, F 0.520)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.833] [G acc: 0.250]\n",
      "16221 [D loss: (0.627)(R 0.685, F 0.569)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.997] [G acc: 0.062]\n",
      "16222 [D loss: (0.589)(R 0.616, F 0.562)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.956] [G acc: 0.188]\n",
      "16223 [D loss: (0.529)(R 0.532, F 0.527)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.929] [G acc: 0.188]\n",
      "16224 [D loss: (0.583)(R 0.557, F 0.609)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.942] [G acc: 0.312]\n",
      "16225 [D loss: (0.711)(R 0.654, F 0.768)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.884] [G acc: 0.188]\n",
      "16226 [D loss: (0.600)(R 0.657, F 0.544)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.923] [G acc: 0.375]\n",
      "16227 [D loss: (0.584)(R 0.429, F 0.738)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.892] [G acc: 0.188]\n",
      "16228 [D loss: (0.865)(R 0.693, F 1.036)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.750] [G acc: 0.500]\n",
      "16229 [D loss: (0.826)(R 0.417, F 1.235)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.424] [G acc: 0.062]\n",
      "16230 [D loss: (0.332)(R 0.490, F 0.173)] [D acc: (0.875)(0.812, 0.938)] [G loss: 6.465] [G acc: 0.125]\n",
      "16231 [D loss: (0.651)(R 0.729, F 0.574)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.910] [G acc: 0.188]\n",
      "16232 [D loss: (0.777)(R 0.646, F 0.909)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.972] [G acc: 0.062]\n",
      "16233 [D loss: (0.576)(R 0.618, F 0.533)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.867] [G acc: 0.188]\n",
      "16234 [D loss: (0.602)(R 0.448, F 0.755)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.035] [G acc: 0.250]\n",
      "16235 [D loss: (0.584)(R 0.585, F 0.583)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.045] [G acc: 0.250]\n",
      "16236 [D loss: (0.676)(R 0.704, F 0.648)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.063] [G acc: 0.125]\n",
      "16237 [D loss: (0.587)(R 0.642, F 0.531)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.070] [G acc: 0.312]\n",
      "16238 [D loss: (0.670)(R 0.654, F 0.686)] [D acc: (0.594)(0.500, 0.688)] [G loss: 1.066] [G acc: 0.250]\n",
      "16239 [D loss: (0.541)(R 0.505, F 0.577)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.825] [G acc: 0.312]\n",
      "16240 [D loss: (0.506)(R 0.538, F 0.474)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.016] [G acc: 0.000]\n",
      "16241 [D loss: (0.610)(R 0.704, F 0.516)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.995] [G acc: 0.188]\n",
      "16242 [D loss: (0.653)(R 0.646, F 0.661)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.083] [G acc: 0.250]\n",
      "16243 [D loss: (0.502)(R 0.445, F 0.559)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.887] [G acc: 0.375]\n",
      "16244 [D loss: (0.775)(R 0.569, F 0.981)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.966] [G acc: 0.250]\n",
      "16245 [D loss: (0.623)(R 0.651, F 0.594)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.879] [G acc: 0.312]\n",
      "16246 [D loss: (0.641)(R 0.614, F 0.667)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.932] [G acc: 0.312]\n",
      "16247 [D loss: (0.745)(R 0.933, F 0.557)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.099] [G acc: 0.062]\n",
      "16248 [D loss: (0.831)(R 0.791, F 0.871)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.708] [G acc: 0.500]\n",
      "16249 [D loss: (0.654)(R 0.564, F 0.744)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.972] [G acc: 0.312]\n",
      "16250 [D loss: (0.705)(R 0.710, F 0.699)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.879] [G acc: 0.312]\n",
      "16251 [D loss: (0.814)(R 0.768, F 0.860)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.848] [G acc: 0.312]\n",
      "16252 [D loss: (0.860)(R 0.547, F 1.173)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.815] [G acc: 0.312]\n",
      "16253 [D loss: (0.763)(R 0.695, F 0.830)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.925] [G acc: 0.312]\n",
      "16254 [D loss: (0.778)(R 0.770, F 0.786)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.823] [G acc: 0.250]\n",
      "16255 [D loss: (0.648)(R 0.641, F 0.654)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.835] [G acc: 0.438]\n",
      "16256 [D loss: (0.673)(R 0.645, F 0.702)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.960] [G acc: 0.250]\n",
      "16257 [D loss: (0.601)(R 0.686, F 0.515)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.298] [G acc: 0.125]\n",
      "16258 [D loss: (0.635)(R 0.747, F 0.522)] [D acc: (0.688)(0.438, 0.938)] [G loss: 0.950] [G acc: 0.062]\n",
      "16259 [D loss: (0.603)(R 0.605, F 0.600)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.802] [G acc: 0.500]\n",
      "16260 [D loss: (0.660)(R 0.629, F 0.691)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.901] [G acc: 0.250]\n",
      "16261 [D loss: (0.702)(R 0.668, F 0.737)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.978] [G acc: 0.312]\n",
      "16262 [D loss: (0.563)(R 0.588, F 0.537)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.915] [G acc: 0.188]\n",
      "16263 [D loss: (0.597)(R 0.482, F 0.712)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.778] [G acc: 0.562]\n",
      "16264 [D loss: (0.791)(R 0.733, F 0.850)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.761] [G acc: 0.438]\n",
      "16265 [D loss: (1.200)(R 0.974, F 1.426)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.677] [G acc: 0.562]\n",
      "16266 [D loss: (0.688)(R 0.602, F 0.774)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.828] [G acc: 0.188]\n",
      "16267 [D loss: (0.869)(R 0.745, F 0.992)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.575] [G acc: 0.750]\n",
      "16268 [D loss: (1.010)(R 0.648, F 1.372)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.634] [G acc: 0.562]\n",
      "16269 [D loss: (0.810)(R 0.712, F 0.908)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.578] [G acc: 0.500]\n",
      "16270 [D loss: (1.408)(R 0.667, F 2.149)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.854] [G acc: 0.438]\n",
      "16271 [D loss: (0.896)(R 0.838, F 0.954)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.826] [G acc: 0.500]\n",
      "16272 [D loss: (0.988)(R 0.939, F 1.037)] [D acc: (0.344)(0.312, 0.375)] [G loss: 0.587] [G acc: 0.625]\n",
      "16273 [D loss: (0.777)(R 0.561, F 0.993)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.527] [G acc: 0.750]\n",
      "16274 [D loss: (1.636)(R 0.627, F 2.644)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.561] [G acc: 0.625]\n",
      "16275 [D loss: (1.612)(R 0.665, F 2.560)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.661] [G acc: 0.812]\n",
      "16276 [D loss: (1.014)(R 0.660, F 1.368)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.710] [G acc: 0.438]\n",
      "16277 [D loss: (0.850)(R 0.723, F 0.978)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.884] [G acc: 0.312]\n",
      "16278 [D loss: (0.751)(R 0.653, F 0.850)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.747] [G acc: 0.500]\n",
      "16279 [D loss: (1.174)(R 0.861, F 1.488)] [D acc: (0.344)(0.625, 0.062)] [G loss: 0.718] [G acc: 0.562]\n",
      "16280 [D loss: (0.798)(R 0.658, F 0.939)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.750] [G acc: 0.562]\n",
      "16281 [D loss: (1.055)(R 0.602, F 1.508)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.681] [G acc: 0.625]\n",
      "16282 [D loss: (0.878)(R 0.702, F 1.055)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.468] [G acc: 0.875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16283 [D loss: (0.755)(R 0.647, F 0.863)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.650] [G acc: 0.562]\n",
      "16284 [D loss: (1.354)(R 0.670, F 2.038)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.524] [G acc: 0.625]\n",
      "16285 [D loss: (0.796)(R 0.579, F 1.013)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.602] [G acc: 0.750]\n",
      "16286 [D loss: (1.100)(R 0.704, F 1.496)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.714] [G acc: 0.562]\n",
      "16287 [D loss: (0.919)(R 0.763, F 1.076)] [D acc: (0.375)(0.375, 0.375)] [G loss: 0.674] [G acc: 0.562]\n",
      "16288 [D loss: (0.746)(R 0.621, F 0.870)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.770] [G acc: 0.438]\n",
      "16289 [D loss: (1.074)(R 0.760, F 1.389)] [D acc: (0.312)(0.500, 0.125)] [G loss: 0.670] [G acc: 0.375]\n",
      "16290 [D loss: (0.573)(R 0.661, F 0.486)] [D acc: (0.750)(0.750, 0.750)] [G loss: 3.882] [G acc: 0.375]\n",
      "16291 [D loss: (1.625)(R 2.130, F 1.120)] [D acc: (0.500)(0.562, 0.438)] [G loss: 3.916] [G acc: 0.250]\n",
      "16292 [D loss: (0.948)(R 0.647, F 1.250)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.695] [G acc: 0.625]\n",
      "16293 [D loss: (0.854)(R 0.629, F 1.078)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.842] [G acc: 0.438]\n",
      "16294 [D loss: (0.955)(R 0.647, F 1.263)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.779] [G acc: 0.562]\n",
      "16295 [D loss: (0.684)(R 0.555, F 0.814)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.812] [G acc: 0.188]\n",
      "16296 [D loss: (0.663)(R 0.650, F 0.676)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.739] [G acc: 0.562]\n",
      "16297 [D loss: (0.637)(R 0.563, F 0.711)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.739] [G acc: 0.562]\n",
      "16298 [D loss: (0.593)(R 0.589, F 0.597)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.897] [G acc: 0.250]\n",
      "16299 [D loss: (0.675)(R 0.702, F 0.649)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.838] [G acc: 0.312]\n",
      "16300 [D loss: (0.625)(R 0.571, F 0.679)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.703] [G acc: 0.562]\n",
      "16301 [D loss: (0.694)(R 0.717, F 0.671)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.904] [G acc: 0.125]\n",
      "16302 [D loss: (0.631)(R 0.596, F 0.666)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.599] [G acc: 0.750]\n",
      "16303 [D loss: (0.620)(R 0.597, F 0.642)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.752] [G acc: 0.500]\n",
      "16304 [D loss: (0.707)(R 0.703, F 0.711)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.852] [G acc: 0.250]\n",
      "16305 [D loss: (0.555)(R 0.500, F 0.609)] [D acc: (0.875)(0.938, 0.812)] [G loss: 1.505] [G acc: 0.562]\n",
      "16306 [D loss: (0.473)(R 0.637, F 0.308)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.098] [G acc: 0.312]\n",
      "16307 [D loss: (0.595)(R 0.674, F 0.517)] [D acc: (0.719)(0.500, 0.938)] [G loss: 1.522] [G acc: 0.125]\n",
      "16308 [D loss: (0.612)(R 0.692, F 0.531)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.998] [G acc: 0.125]\n",
      "16309 [D loss: (0.593)(R 0.638, F 0.548)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.951] [G acc: 0.250]\n",
      "16310 [D loss: (0.644)(R 0.665, F 0.624)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.950] [G acc: 0.438]\n",
      "16311 [D loss: (0.857)(R 1.170, F 0.544)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.909] [G acc: 0.125]\n",
      "16312 [D loss: (0.525)(R 0.486, F 0.564)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.961] [G acc: 0.125]\n",
      "16313 [D loss: (0.570)(R 0.578, F 0.562)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.080] [G acc: 0.062]\n",
      "16314 [D loss: (0.623)(R 0.677, F 0.568)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.898] [G acc: 0.375]\n",
      "16315 [D loss: (0.578)(R 0.608, F 0.548)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.989] [G acc: 0.062]\n",
      "16316 [D loss: (0.527)(R 0.542, F 0.513)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.996] [G acc: 0.250]\n",
      "16317 [D loss: (0.628)(R 0.626, F 0.629)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.973] [G acc: 0.188]\n",
      "16318 [D loss: (0.569)(R 0.630, F 0.507)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.935] [G acc: 0.125]\n",
      "16319 [D loss: (0.562)(R 0.631, F 0.493)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.057] [G acc: 0.250]\n",
      "16320 [D loss: (0.544)(R 0.600, F 0.488)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.405] [G acc: 0.250]\n",
      "16321 [D loss: (0.552)(R 0.662, F 0.442)] [D acc: (0.625)(0.688, 0.562)] [G loss: 3.595] [G acc: 0.250]\n",
      "16322 [D loss: (0.582)(R 0.572, F 0.592)] [D acc: (0.750)(0.812, 0.688)] [G loss: 4.375] [G acc: 0.000]\n",
      "16323 [D loss: (0.472)(R 0.701, F 0.244)] [D acc: (0.719)(0.500, 0.938)] [G loss: 1.079] [G acc: 0.125]\n",
      "16324 [D loss: (0.466)(R 0.603, F 0.329)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.172] [G acc: 0.188]\n",
      "16325 [D loss: (0.496)(R 0.551, F 0.441)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.104] [G acc: 0.188]\n",
      "16326 [D loss: (0.621)(R 0.699, F 0.542)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.059] [G acc: 0.250]\n",
      "16327 [D loss: (0.520)(R 0.555, F 0.485)] [D acc: (0.875)(0.938, 0.812)] [G loss: 1.391] [G acc: 0.125]\n",
      "16328 [D loss: (0.461)(R 0.435, F 0.486)] [D acc: (0.781)(0.938, 0.625)] [G loss: 1.119] [G acc: 0.250]\n",
      "16329 [D loss: (0.444)(R 0.448, F 0.440)] [D acc: (0.844)(0.938, 0.750)] [G loss: 1.116] [G acc: 0.250]\n",
      "16330 [D loss: (0.509)(R 0.479, F 0.538)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.234] [G acc: 0.312]\n",
      "16331 [D loss: (0.458)(R 0.435, F 0.481)] [D acc: (0.875)(0.938, 0.812)] [G loss: 1.587] [G acc: 0.188]\n",
      "16332 [D loss: (0.490)(R 0.590, F 0.390)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.041] [G acc: 0.312]\n",
      "16333 [D loss: (0.452)(R 0.431, F 0.473)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.532] [G acc: 0.188]\n",
      "16334 [D loss: (0.417)(R 0.516, F 0.319)] [D acc: (0.906)(0.812, 1.000)] [G loss: 1.538] [G acc: 0.125]\n",
      "16335 [D loss: (0.488)(R 0.647, F 0.330)] [D acc: (0.719)(0.500, 0.938)] [G loss: 1.144] [G acc: 0.250]\n",
      "16336 [D loss: (0.452)(R 0.453, F 0.452)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.908] [G acc: 0.125]\n",
      "16337 [D loss: (0.378)(R 0.394, F 0.363)] [D acc: (0.906)(0.938, 0.875)] [G loss: 1.991] [G acc: 0.250]\n",
      "16338 [D loss: (1.182)(R 1.972, F 0.392)] [D acc: (0.719)(0.500, 0.938)] [G loss: 1.221] [G acc: 0.312]\n",
      "16339 [D loss: (0.561)(R 0.589, F 0.534)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.270] [G acc: 0.312]\n",
      "16340 [D loss: (0.539)(R 0.600, F 0.478)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.129] [G acc: 0.312]\n",
      "16341 [D loss: (0.576)(R 0.511, F 0.640)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.203] [G acc: 0.250]\n",
      "16342 [D loss: (0.573)(R 0.687, F 0.459)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.081] [G acc: 0.250]\n",
      "16343 [D loss: (0.486)(R 0.413, F 0.559)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.377] [G acc: 0.188]\n",
      "16344 [D loss: (0.607)(R 0.568, F 0.645)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.875] [G acc: 0.438]\n",
      "16345 [D loss: (0.530)(R 0.485, F 0.576)] [D acc: (0.594)(0.750, 0.438)] [G loss: 1.188] [G acc: 0.562]\n",
      "16346 [D loss: (0.481)(R 0.622, F 0.341)] [D acc: (0.688)(0.625, 0.750)] [G loss: 3.817] [G acc: 0.250]\n",
      "16347 [D loss: (0.426)(R 0.523, F 0.329)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.288] [G acc: 0.250]\n",
      "16348 [D loss: (0.349)(R 0.404, F 0.295)] [D acc: (0.938)(0.938, 0.938)] [G loss: 1.301] [G acc: 0.125]\n",
      "16349 [D loss: (0.527)(R 0.532, F 0.522)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.489] [G acc: 0.250]\n",
      "16350 [D loss: (0.640)(R 0.599, F 0.680)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.230] [G acc: 0.375]\n",
      "16351 [D loss: (0.547)(R 0.563, F 0.531)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.234] [G acc: 0.438]\n",
      "16352 [D loss: (0.480)(R 0.532, F 0.428)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.148] [G acc: 0.375]\n",
      "16353 [D loss: (0.487)(R 0.531, F 0.443)] [D acc: (0.844)(0.938, 0.750)] [G loss: 1.429] [G acc: 0.250]\n",
      "16354 [D loss: (0.518)(R 0.625, F 0.412)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.034] [G acc: 0.250]\n",
      "16355 [D loss: (0.474)(R 0.478, F 0.470)] [D acc: (0.781)(0.938, 0.625)] [G loss: 1.449] [G acc: 0.188]\n",
      "16356 [D loss: (0.583)(R 0.615, F 0.551)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.136] [G acc: 0.062]\n",
      "16357 [D loss: (0.642)(R 0.688, F 0.595)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.048] [G acc: 0.188]\n",
      "16358 [D loss: (0.620)(R 0.675, F 0.565)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.301] [G acc: 0.375]\n",
      "16359 [D loss: (0.565)(R 0.584, F 0.547)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.870] [G acc: 0.250]\n",
      "16360 [D loss: (0.602)(R 0.639, F 0.566)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.829] [G acc: 0.500]\n",
      "16361 [D loss: (0.808)(R 0.674, F 0.942)] [D acc: (0.438)(0.500, 0.375)] [G loss: 1.089] [G acc: 0.188]\n",
      "16362 [D loss: (0.532)(R 0.463, F 0.601)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.893] [G acc: 0.562]\n",
      "16363 [D loss: (0.610)(R 0.608, F 0.612)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.034] [G acc: 0.438]\n",
      "16364 [D loss: (0.582)(R 0.533, F 0.631)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.558] [G acc: 0.375]\n",
      "16365 [D loss: (0.700)(R 0.619, F 0.780)] [D acc: (0.562)(0.625, 0.500)] [G loss: 5.424] [G acc: 0.312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16366 [D loss: (0.554)(R 0.485, F 0.622)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.987] [G acc: 0.500]\n",
      "16367 [D loss: (0.527)(R 0.443, F 0.612)] [D acc: (0.812)(0.938, 0.688)] [G loss: 1.161] [G acc: 0.312]\n",
      "16368 [D loss: (0.693)(R 0.604, F 0.782)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.957] [G acc: 0.562]\n",
      "16369 [D loss: (0.587)(R 0.536, F 0.638)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.652] [G acc: 0.500]\n",
      "16370 [D loss: (0.839)(R 0.910, F 0.767)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.880] [G acc: 0.375]\n",
      "16371 [D loss: (0.547)(R 0.596, F 0.498)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.783] [G acc: 0.500]\n",
      "16372 [D loss: (0.570)(R 0.473, F 0.667)] [D acc: (0.688)(0.812, 0.562)] [G loss: 1.096] [G acc: 0.250]\n",
      "16373 [D loss: (0.429)(R 0.402, F 0.457)] [D acc: (0.906)(0.938, 0.875)] [G loss: 1.082] [G acc: 0.312]\n",
      "16374 [D loss: (0.606)(R 0.717, F 0.495)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.166] [G acc: 0.312]\n",
      "16375 [D loss: (0.622)(R 0.684, F 0.560)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.890] [G acc: 0.188]\n",
      "16376 [D loss: (0.522)(R 0.763, F 0.281)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.891] [G acc: 0.500]\n",
      "16377 [D loss: (0.642)(R 0.695, F 0.590)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.997] [G acc: 0.250]\n",
      "16378 [D loss: (0.446)(R 0.328, F 0.564)] [D acc: (0.812)(1.000, 0.625)] [G loss: 1.144] [G acc: 0.312]\n",
      "16379 [D loss: (0.485)(R 0.438, F 0.532)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.840] [G acc: 0.312]\n",
      "16380 [D loss: (0.531)(R 0.469, F 0.593)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.858] [G acc: 0.375]\n",
      "16381 [D loss: (0.554)(R 0.483, F 0.626)] [D acc: (0.625)(0.750, 0.500)] [G loss: 1.006] [G acc: 0.375]\n",
      "16382 [D loss: (0.661)(R 0.635, F 0.687)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.680] [G acc: 0.625]\n",
      "16383 [D loss: (0.844)(R 0.651, F 1.037)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.881] [G acc: 0.688]\n",
      "16384 [D loss: (0.626)(R 0.607, F 0.646)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.643] [G acc: 0.625]\n",
      "16385 [D loss: (0.657)(R 0.574, F 0.740)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.691] [G acc: 0.625]\n",
      "16386 [D loss: (0.730)(R 0.500, F 0.959)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.765] [G acc: 0.625]\n",
      "16387 [D loss: (0.657)(R 0.665, F 0.650)] [D acc: (0.562)(0.625, 0.500)] [G loss: 1.921] [G acc: 0.438]\n",
      "16388 [D loss: (0.629)(R 0.592, F 0.667)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.740] [G acc: 0.500]\n",
      "16389 [D loss: (0.859)(R 0.710, F 1.008)] [D acc: (0.594)(0.750, 0.438)] [G loss: 1.237] [G acc: 0.562]\n",
      "16390 [D loss: (0.482)(R 0.644, F 0.319)] [D acc: (0.781)(0.688, 0.875)] [G loss: 5.477] [G acc: 0.125]\n",
      "16391 [D loss: (0.449)(R 0.568, F 0.330)] [D acc: (0.656)(0.625, 0.688)] [G loss: 3.013] [G acc: 0.312]\n",
      "16392 [D loss: (0.534)(R 0.555, F 0.512)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.339] [G acc: 0.250]\n",
      "16393 [D loss: (0.513)(R 0.554, F 0.472)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.752] [G acc: 0.625]\n",
      "16394 [D loss: (0.807)(R 0.864, F 0.750)] [D acc: (0.406)(0.562, 0.250)] [G loss: 1.118] [G acc: 0.438]\n",
      "16395 [D loss: (0.604)(R 0.469, F 0.739)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.807] [G acc: 0.312]\n",
      "16396 [D loss: (0.835)(R 1.019, F 0.651)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.830] [G acc: 0.500]\n",
      "16397 [D loss: (0.723)(R 0.568, F 0.877)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.746] [G acc: 0.688]\n",
      "16398 [D loss: (0.634)(R 0.547, F 0.721)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.762] [G acc: 0.438]\n",
      "16399 [D loss: (0.785)(R 0.847, F 0.724)] [D acc: (0.375)(0.375, 0.375)] [G loss: 0.705] [G acc: 0.500]\n",
      "16400 [D loss: (0.611)(R 0.506, F 0.716)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.971] [G acc: 0.438]\n",
      "16401 [D loss: (0.761)(R 0.606, F 0.916)] [D acc: (0.438)(0.688, 0.188)] [G loss: 0.801] [G acc: 0.438]\n",
      "16402 [D loss: (0.528)(R 0.375, F 0.681)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.653] [G acc: 0.562]\n",
      "16403 [D loss: (0.878)(R 0.755, F 1.000)] [D acc: (0.344)(0.562, 0.125)] [G loss: 0.784] [G acc: 0.375]\n",
      "16404 [D loss: (0.596)(R 0.514, F 0.679)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.713] [G acc: 0.500]\n",
      "16405 [D loss: (0.715)(R 0.744, F 0.685)] [D acc: (0.406)(0.375, 0.438)] [G loss: 0.655] [G acc: 0.750]\n",
      "16406 [D loss: (0.742)(R 0.699, F 0.785)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.685] [G acc: 0.625]\n",
      "16407 [D loss: (0.648)(R 0.527, F 0.769)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.603] [G acc: 0.938]\n",
      "16408 [D loss: (0.651)(R 0.636, F 0.665)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.698] [G acc: 0.500]\n",
      "16409 [D loss: (0.703)(R 0.483, F 0.923)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.832] [G acc: 0.562]\n",
      "16410 [D loss: (0.641)(R 0.573, F 0.710)] [D acc: (0.656)(0.875, 0.438)] [G loss: 1.153] [G acc: 0.250]\n",
      "16411 [D loss: (0.547)(R 0.575, F 0.519)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.886] [G acc: 0.562]\n",
      "16412 [D loss: (0.614)(R 0.702, F 0.526)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.011] [G acc: 0.312]\n",
      "16413 [D loss: (0.701)(R 0.753, F 0.649)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.946] [G acc: 0.375]\n",
      "16414 [D loss: (0.585)(R 0.691, F 0.479)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.806] [G acc: 0.500]\n",
      "16415 [D loss: (0.717)(R 0.760, F 0.674)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.641] [G acc: 0.750]\n",
      "16416 [D loss: (0.643)(R 0.538, F 0.749)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.793] [G acc: 0.438]\n",
      "16417 [D loss: (0.716)(R 0.741, F 0.690)] [D acc: (0.375)(0.375, 0.375)] [G loss: 0.715] [G acc: 0.625]\n",
      "16418 [D loss: (0.607)(R 0.524, F 0.690)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.756] [G acc: 0.500]\n",
      "16419 [D loss: (0.679)(R 0.644, F 0.713)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.685] [G acc: 0.625]\n",
      "16420 [D loss: (0.702)(R 0.726, F 0.678)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.628] [G acc: 0.688]\n",
      "16421 [D loss: (0.847)(R 0.953, F 0.741)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.756] [G acc: 0.562]\n",
      "16422 [D loss: (0.771)(R 0.634, F 0.908)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.676] [G acc: 0.688]\n",
      "16423 [D loss: (0.616)(R 0.466, F 0.767)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.630] [G acc: 0.500]\n",
      "16424 [D loss: (0.784)(R 0.617, F 0.951)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.785] [G acc: 0.562]\n",
      "16425 [D loss: (0.654)(R 0.640, F 0.667)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.756] [G acc: 0.438]\n",
      "16426 [D loss: (0.648)(R 0.573, F 0.723)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.771] [G acc: 0.562]\n",
      "16427 [D loss: (0.792)(R 0.645, F 0.938)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.845] [G acc: 0.500]\n",
      "16428 [D loss: (0.845)(R 0.720, F 0.971)] [D acc: (0.406)(0.625, 0.188)] [G loss: 0.630] [G acc: 0.812]\n",
      "16429 [D loss: (0.738)(R 0.711, F 0.765)] [D acc: (0.344)(0.562, 0.125)] [G loss: 0.602] [G acc: 0.938]\n",
      "16430 [D loss: (0.604)(R 0.498, F 0.711)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.659] [G acc: 0.688]\n",
      "16431 [D loss: (0.925)(R 0.545, F 1.305)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.853] [G acc: 0.562]\n",
      "16432 [D loss: (0.657)(R 0.599, F 0.716)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.671] [G acc: 0.688]\n",
      "16433 [D loss: (0.644)(R 0.561, F 0.726)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.641] [G acc: 0.812]\n",
      "16434 [D loss: (0.785)(R 0.851, F 0.719)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.651] [G acc: 0.688]\n",
      "16435 [D loss: (0.756)(R 0.755, F 0.757)] [D acc: (0.312)(0.438, 0.188)] [G loss: 0.681] [G acc: 0.625]\n",
      "16436 [D loss: (0.912)(R 0.621, F 1.203)] [D acc: (0.344)(0.500, 0.188)] [G loss: 0.655] [G acc: 0.812]\n",
      "16437 [D loss: (0.613)(R 0.494, F 0.733)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.626] [G acc: 0.812]\n",
      "16438 [D loss: (0.691)(R 0.592, F 0.791)] [D acc: (0.312)(0.500, 0.125)] [G loss: 0.654] [G acc: 0.750]\n",
      "16439 [D loss: (0.667)(R 0.563, F 0.770)] [D acc: (0.438)(0.688, 0.188)] [G loss: 0.659] [G acc: 0.625]\n",
      "16440 [D loss: (0.754)(R 0.674, F 0.834)] [D acc: (0.281)(0.438, 0.125)] [G loss: 0.689] [G acc: 0.562]\n",
      "16441 [D loss: (0.701)(R 0.594, F 0.808)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.729] [G acc: 0.562]\n",
      "16442 [D loss: (0.635)(R 0.538, F 0.732)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.659] [G acc: 0.688]\n",
      "16443 [D loss: (0.639)(R 0.555, F 0.723)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.659] [G acc: 0.625]\n",
      "16444 [D loss: (0.727)(R 0.600, F 0.854)] [D acc: (0.375)(0.500, 0.250)] [G loss: 0.642] [G acc: 0.875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16445 [D loss: (0.775)(R 0.577, F 0.973)] [D acc: (0.344)(0.625, 0.062)] [G loss: 0.678] [G acc: 0.500]\n",
      "16446 [D loss: (0.733)(R 0.645, F 0.821)] [D acc: (0.406)(0.812, 0.000)] [G loss: 0.666] [G acc: 0.750]\n",
      "16447 [D loss: (0.696)(R 0.641, F 0.751)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.596] [G acc: 0.688]\n",
      "16448 [D loss: (0.814)(R 0.642, F 0.985)] [D acc: (0.344)(0.500, 0.188)] [G loss: 0.650] [G acc: 0.500]\n",
      "16449 [D loss: (0.851)(R 0.649, F 1.052)] [D acc: (0.406)(0.625, 0.188)] [G loss: 0.578] [G acc: 0.750]\n",
      "16450 [D loss: (0.893)(R 0.610, F 1.177)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.633] [G acc: 0.688]\n",
      "16451 [D loss: (0.779)(R 0.674, F 0.883)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.647] [G acc: 0.500]\n",
      "16452 [D loss: (1.210)(R 0.651, F 1.770)] [D acc: (0.406)(0.312, 0.500)] [G loss: 0.730] [G acc: 0.375]\n",
      "16453 [D loss: (0.559)(R 0.626, F 0.492)] [D acc: (0.562)(0.625, 0.500)] [G loss: 4.180] [G acc: 0.188]\n",
      "16454 [D loss: (0.493)(R 0.638, F 0.348)] [D acc: (0.688)(0.625, 0.750)] [G loss: 5.295] [G acc: 0.312]\n",
      "16455 [D loss: (0.855)(R 0.613, F 1.097)] [D acc: (0.438)(0.688, 0.188)] [G loss: 0.673] [G acc: 0.562]\n",
      "16456 [D loss: (0.835)(R 0.701, F 0.970)] [D acc: (0.312)(0.438, 0.188)] [G loss: 0.594] [G acc: 0.688]\n",
      "16457 [D loss: (0.683)(R 0.626, F 0.739)] [D acc: (0.344)(0.625, 0.062)] [G loss: 0.652] [G acc: 0.750]\n",
      "16458 [D loss: (0.718)(R 0.660, F 0.776)] [D acc: (0.375)(0.562, 0.188)] [G loss: 0.691] [G acc: 0.562]\n",
      "16459 [D loss: (0.692)(R 0.689, F 0.695)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.664] [G acc: 0.750]\n",
      "16460 [D loss: (0.669)(R 0.617, F 0.722)] [D acc: (0.406)(0.500, 0.312)] [G loss: 0.695] [G acc: 0.562]\n",
      "16461 [D loss: (0.711)(R 0.690, F 0.732)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.614] [G acc: 0.812]\n",
      "16462 [D loss: (0.685)(R 0.638, F 0.731)] [D acc: (0.406)(0.688, 0.125)] [G loss: 0.644] [G acc: 0.562]\n",
      "16463 [D loss: (0.704)(R 0.654, F 0.755)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.683] [G acc: 0.625]\n",
      "16464 [D loss: (0.683)(R 0.617, F 0.750)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.666] [G acc: 0.625]\n",
      "16465 [D loss: (0.651)(R 0.583, F 0.718)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.668] [G acc: 0.688]\n",
      "16466 [D loss: (0.769)(R 0.695, F 0.843)] [D acc: (0.312)(0.375, 0.250)] [G loss: 0.632] [G acc: 0.812]\n",
      "16467 [D loss: (0.666)(R 0.641, F 0.692)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.673] [G acc: 0.625]\n",
      "16468 [D loss: (0.685)(R 0.643, F 0.727)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.686] [G acc: 0.562]\n",
      "16469 [D loss: (0.660)(R 0.585, F 0.735)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.672] [G acc: 0.500]\n",
      "16470 [D loss: (0.683)(R 0.591, F 0.775)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.686] [G acc: 0.500]\n",
      "16471 [D loss: (0.713)(R 0.671, F 0.755)] [D acc: (0.344)(0.375, 0.312)] [G loss: 0.695] [G acc: 0.562]\n",
      "16472 [D loss: (0.691)(R 0.685, F 0.696)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.689] [G acc: 0.375]\n",
      "16473 [D loss: (0.990)(R 0.861, F 1.119)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.684] [G acc: 0.625]\n",
      "16474 [D loss: (0.675)(R 0.622, F 0.728)] [D acc: (0.375)(0.625, 0.125)] [G loss: 0.697] [G acc: 0.500]\n",
      "16475 [D loss: (0.658)(R 0.611, F 0.704)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.646] [G acc: 0.562]\n",
      "16476 [D loss: (0.760)(R 0.639, F 0.880)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.716] [G acc: 0.438]\n",
      "16477 [D loss: (0.691)(R 0.701, F 0.682)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.676] [G acc: 0.438]\n",
      "16478 [D loss: (0.635)(R 0.568, F 0.702)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.684] [G acc: 0.688]\n",
      "16479 [D loss: (0.679)(R 0.657, F 0.700)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.703] [G acc: 0.375]\n",
      "16480 [D loss: (0.772)(R 0.532, F 1.013)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.691] [G acc: 0.438]\n",
      "16481 [D loss: (0.682)(R 0.672, F 0.691)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.705] [G acc: 0.188]\n",
      "16482 [D loss: (0.639)(R 0.575, F 0.702)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.725] [G acc: 0.312]\n",
      "16483 [D loss: (0.668)(R 0.652, F 0.685)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.770] [G acc: 0.312]\n",
      "16484 [D loss: (0.608)(R 0.551, F 0.665)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.723] [G acc: 0.125]\n",
      "16485 [D loss: (0.634)(R 0.583, F 0.685)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.725] [G acc: 0.375]\n",
      "16486 [D loss: (0.658)(R 0.658, F 0.658)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.723] [G acc: 0.312]\n",
      "16487 [D loss: (0.651)(R 0.588, F 0.713)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.709] [G acc: 0.312]\n",
      "16488 [D loss: (0.608)(R 0.485, F 0.731)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.713] [G acc: 0.438]\n",
      "16489 [D loss: (0.696)(R 0.714, F 0.677)] [D acc: (0.500)(0.312, 0.688)] [G loss: 0.699] [G acc: 0.562]\n",
      "16490 [D loss: (0.674)(R 0.659, F 0.689)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.657] [G acc: 0.500]\n",
      "16491 [D loss: (0.764)(R 0.527, F 1.001)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.678] [G acc: 0.438]\n",
      "16492 [D loss: (0.699)(R 0.703, F 0.695)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.733] [G acc: 0.250]\n",
      "16493 [D loss: (0.601)(R 0.478, F 0.724)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.633] [G acc: 0.625]\n",
      "16494 [D loss: (0.664)(R 0.593, F 0.735)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.711] [G acc: 0.250]\n",
      "16495 [D loss: (0.749)(R 0.517, F 0.981)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.775] [G acc: 0.188]\n",
      "16496 [D loss: (0.944)(R 0.637, F 1.252)] [D acc: (0.500)(0.312, 0.688)] [G loss: 0.720] [G acc: 0.312]\n",
      "16497 [D loss: (0.746)(R 0.629, F 0.863)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.698] [G acc: 0.312]\n",
      "16498 [D loss: (0.629)(R 0.601, F 0.657)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.726] [G acc: 0.250]\n",
      "16499 [D loss: (0.651)(R 0.618, F 0.683)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.741] [G acc: 0.438]\n",
      "16500 [D loss: (0.681)(R 0.712, F 0.650)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.763] [G acc: 0.312]\n",
      "16501 [D loss: (0.738)(R 0.632, F 0.843)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.742] [G acc: 0.250]\n",
      "16502 [D loss: (0.654)(R 0.644, F 0.664)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.645] [G acc: 0.562]\n",
      "16503 [D loss: (0.709)(R 0.786, F 0.632)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.698] [G acc: 0.250]\n",
      "16504 [D loss: (0.787)(R 0.592, F 0.982)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.714] [G acc: 0.312]\n",
      "16505 [D loss: (0.804)(R 0.629, F 0.978)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.778] [G acc: 0.375]\n",
      "16506 [D loss: (0.428)(R 0.615, F 0.242)] [D acc: (0.750)(0.562, 0.938)] [G loss: 4.186] [G acc: 0.125]\n",
      "16507 [D loss: (0.635)(R 0.617, F 0.654)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.124] [G acc: 0.062]\n",
      "16508 [D loss: (0.485)(R 0.591, F 0.380)] [D acc: (0.781)(0.688, 0.875)] [G loss: 2.253] [G acc: 0.000]\n",
      "16509 [D loss: (0.667)(R 0.646, F 0.687)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.792] [G acc: 0.188]\n",
      "16510 [D loss: (0.609)(R 0.588, F 0.630)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.772] [G acc: 0.312]\n",
      "16511 [D loss: (0.656)(R 0.638, F 0.674)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.755] [G acc: 0.188]\n",
      "16512 [D loss: (0.686)(R 0.696, F 0.677)] [D acc: (0.500)(0.250, 0.750)] [G loss: 0.732] [G acc: 0.375]\n",
      "16513 [D loss: (0.603)(R 0.559, F 0.648)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.757] [G acc: 0.188]\n",
      "16514 [D loss: (0.899)(R 0.615, F 1.184)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.785] [G acc: 0.312]\n",
      "16515 [D loss: (0.657)(R 0.663, F 0.651)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.680] [G acc: 0.438]\n",
      "16516 [D loss: (0.620)(R 0.583, F 0.657)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.768] [G acc: 0.188]\n",
      "16517 [D loss: (0.776)(R 0.663, F 0.888)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.771] [G acc: 0.375]\n",
      "16518 [D loss: (0.635)(R 0.607, F 0.663)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.738] [G acc: 0.188]\n",
      "16519 [D loss: (0.642)(R 0.622, F 0.661)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.785] [G acc: 0.188]\n",
      "16520 [D loss: (0.757)(R 0.691, F 0.824)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.746] [G acc: 0.188]\n",
      "16521 [D loss: (0.600)(R 0.538, F 0.661)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.774] [G acc: 0.125]\n",
      "16522 [D loss: (0.672)(R 0.680, F 0.664)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.727] [G acc: 0.312]\n",
      "16523 [D loss: (0.656)(R 0.629, F 0.682)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.850] [G acc: 0.188]\n",
      "16524 [D loss: (0.637)(R 0.605, F 0.669)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.704] [G acc: 0.375]\n",
      "16525 [D loss: (0.591)(R 0.548, F 0.634)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.720] [G acc: 0.312]\n",
      "16526 [D loss: (0.689)(R 0.690, F 0.687)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.753] [G acc: 0.125]\n",
      "16527 [D loss: (0.668)(R 0.595, F 0.741)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.747] [G acc: 0.250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16528 [D loss: (0.640)(R 0.638, F 0.643)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.660] [G acc: 0.562]\n",
      "16529 [D loss: (0.634)(R 0.622, F 0.646)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.784] [G acc: 0.188]\n",
      "16530 [D loss: (0.558)(R 0.487, F 0.629)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.775] [G acc: 0.188]\n",
      "16531 [D loss: (0.872)(R 0.810, F 0.933)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.732] [G acc: 0.250]\n",
      "16532 [D loss: (0.613)(R 0.558, F 0.669)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.799] [G acc: 0.000]\n",
      "16533 [D loss: (0.633)(R 0.645, F 0.622)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.746] [G acc: 0.250]\n",
      "16534 [D loss: (0.568)(R 0.545, F 0.590)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.750] [G acc: 0.312]\n",
      "16535 [D loss: (0.576)(R 0.548, F 0.603)] [D acc: (0.719)(0.500, 0.938)] [G loss: 0.787] [G acc: 0.125]\n",
      "16536 [D loss: (0.630)(R 0.612, F 0.647)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.733] [G acc: 0.312]\n",
      "16537 [D loss: (0.648)(R 0.538, F 0.757)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.687] [G acc: 0.562]\n",
      "16538 [D loss: (0.722)(R 0.578, F 0.866)] [D acc: (0.375)(0.438, 0.312)] [G loss: 1.191] [G acc: 0.188]\n",
      "16539 [D loss: (0.625)(R 0.672, F 0.578)] [D acc: (0.656)(0.625, 0.688)] [G loss: 5.555] [G acc: 0.125]\n",
      "16540 [D loss: (0.629)(R 0.678, F 0.580)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.820] [G acc: 0.125]\n",
      "16541 [D loss: (0.595)(R 0.556, F 0.634)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.801] [G acc: 0.125]\n",
      "16542 [D loss: (0.604)(R 0.531, F 0.677)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.677] [G acc: 0.375]\n",
      "16543 [D loss: (0.621)(R 0.554, F 0.687)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.819] [G acc: 0.062]\n",
      "16544 [D loss: (0.582)(R 0.575, F 0.588)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.822] [G acc: 0.188]\n",
      "16545 [D loss: (0.609)(R 0.557, F 0.662)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.668] [G acc: 0.375]\n",
      "16546 [D loss: (0.605)(R 0.595, F 0.614)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.737] [G acc: 0.250]\n",
      "16547 [D loss: (0.662)(R 0.535, F 0.789)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.744] [G acc: 0.312]\n",
      "16548 [D loss: (0.704)(R 0.660, F 0.747)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.779] [G acc: 0.188]\n",
      "16549 [D loss: (0.749)(R 0.560, F 0.939)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.652] [G acc: 0.375]\n",
      "16550 [D loss: (0.600)(R 0.574, F 0.625)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.776] [G acc: 0.188]\n",
      "16551 [D loss: (1.041)(R 0.971, F 1.111)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.901] [G acc: 0.312]\n",
      "16552 [D loss: (0.474)(R 0.548, F 0.399)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.686] [G acc: 0.188]\n",
      "16553 [D loss: (0.550)(R 0.554, F 0.547)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.910] [G acc: 0.250]\n",
      "16554 [D loss: (0.650)(R 0.685, F 0.614)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.837] [G acc: 0.125]\n",
      "16555 [D loss: (0.596)(R 0.609, F 0.583)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.821] [G acc: 0.250]\n",
      "16556 [D loss: (0.590)(R 0.530, F 0.650)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.924] [G acc: 0.125]\n",
      "16557 [D loss: (0.597)(R 0.650, F 0.543)] [D acc: (0.719)(0.438, 1.000)] [G loss: 0.857] [G acc: 0.125]\n",
      "16558 [D loss: (0.598)(R 0.581, F 0.615)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.792] [G acc: 0.188]\n",
      "16559 [D loss: (0.606)(R 0.604, F 0.608)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.945] [G acc: 0.062]\n",
      "16560 [D loss: (0.603)(R 0.595, F 0.610)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.848] [G acc: 0.188]\n",
      "16561 [D loss: (0.670)(R 0.678, F 0.661)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.901] [G acc: 0.125]\n",
      "16562 [D loss: (0.589)(R 0.549, F 0.630)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.870] [G acc: 0.062]\n",
      "16563 [D loss: (0.667)(R 0.720, F 0.614)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.835] [G acc: 0.250]\n",
      "16564 [D loss: (0.666)(R 0.646, F 0.687)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.894] [G acc: 0.062]\n",
      "16565 [D loss: (0.563)(R 0.468, F 0.659)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.920] [G acc: 0.125]\n",
      "16566 [D loss: (0.605)(R 0.607, F 0.603)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.905] [G acc: 0.125]\n",
      "16567 [D loss: (0.607)(R 0.622, F 0.592)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.963] [G acc: 0.125]\n",
      "16568 [D loss: (0.534)(R 0.504, F 0.564)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.866] [G acc: 0.250]\n",
      "16569 [D loss: (0.551)(R 0.495, F 0.607)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.933] [G acc: 0.188]\n",
      "16570 [D loss: (0.551)(R 0.478, F 0.623)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.775] [G acc: 0.188]\n",
      "16571 [D loss: (0.898)(R 1.228, F 0.569)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.769] [G acc: 0.250]\n",
      "16572 [D loss: (0.654)(R 0.567, F 0.741)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.872] [G acc: 0.062]\n",
      "16573 [D loss: (0.686)(R 0.572, F 0.799)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.870] [G acc: 0.188]\n",
      "16574 [D loss: (0.599)(R 0.570, F 0.628)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.962] [G acc: 0.125]\n",
      "16575 [D loss: (0.528)(R 0.443, F 0.612)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.872] [G acc: 0.125]\n",
      "16576 [D loss: (0.611)(R 0.568, F 0.654)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.894] [G acc: 0.188]\n",
      "16577 [D loss: (0.564)(R 0.567, F 0.561)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.806] [G acc: 0.375]\n",
      "16578 [D loss: (0.577)(R 0.621, F 0.533)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.989] [G acc: 0.125]\n",
      "16579 [D loss: (0.627)(R 0.621, F 0.633)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.992] [G acc: 0.062]\n",
      "16580 [D loss: (0.487)(R 0.427, F 0.547)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.952] [G acc: 0.125]\n",
      "16581 [D loss: (0.532)(R 0.515, F 0.549)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.945] [G acc: 0.188]\n",
      "16582 [D loss: (0.724)(R 0.627, F 0.821)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.798] [G acc: 0.312]\n",
      "16583 [D loss: (0.651)(R 0.625, F 0.677)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.933] [G acc: 0.125]\n",
      "16584 [D loss: (0.705)(R 0.647, F 0.764)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.915] [G acc: 0.125]\n",
      "16585 [D loss: (0.547)(R 0.572, F 0.523)] [D acc: (0.875)(0.812, 0.938)] [G loss: 0.850] [G acc: 0.250]\n",
      "16586 [D loss: (0.655)(R 0.582, F 0.728)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.903] [G acc: 0.312]\n",
      "16587 [D loss: (0.583)(R 0.544, F 0.622)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.025] [G acc: 0.188]\n",
      "16588 [D loss: (0.460)(R 0.678, F 0.241)] [D acc: (0.812)(0.625, 1.000)] [G loss: 1.615] [G acc: 0.188]\n",
      "16589 [D loss: (0.570)(R 0.805, F 0.335)] [D acc: (0.688)(0.625, 0.750)] [G loss: 4.050] [G acc: 0.375]\n",
      "16590 [D loss: (0.521)(R 0.649, F 0.394)] [D acc: (0.750)(0.500, 1.000)] [G loss: 0.937] [G acc: 0.250]\n",
      "16591 [D loss: (0.612)(R 0.674, F 0.549)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.984] [G acc: 0.125]\n",
      "16592 [D loss: (0.549)(R 0.648, F 0.449)] [D acc: (0.844)(0.688, 1.000)] [G loss: 0.928] [G acc: 0.250]\n",
      "16593 [D loss: (0.616)(R 0.740, F 0.491)] [D acc: (0.688)(0.438, 0.938)] [G loss: 0.997] [G acc: 0.125]\n",
      "16594 [D loss: (0.561)(R 0.575, F 0.548)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.892] [G acc: 0.125]\n",
      "16595 [D loss: (0.617)(R 0.691, F 0.543)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.843] [G acc: 0.375]\n",
      "16596 [D loss: (0.543)(R 0.491, F 0.595)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.069] [G acc: 0.125]\n",
      "16597 [D loss: (0.510)(R 0.414, F 0.606)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.063] [G acc: 0.125]\n",
      "16598 [D loss: (0.503)(R 0.447, F 0.559)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.896] [G acc: 0.250]\n",
      "16599 [D loss: (0.605)(R 0.603, F 0.606)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.847] [G acc: 0.188]\n",
      "16600 [D loss: (0.759)(R 0.646, F 0.872)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.971] [G acc: 0.312]\n",
      "16601 [D loss: (0.640)(R 0.743, F 0.536)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.848] [G acc: 0.375]\n",
      "16602 [D loss: (0.599)(R 0.497, F 0.702)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.795] [G acc: 0.312]\n",
      "16603 [D loss: (0.648)(R 0.620, F 0.677)] [D acc: (0.625)(0.750, 0.500)] [G loss: 1.140] [G acc: 0.188]\n",
      "16604 [D loss: (0.581)(R 0.676, F 0.485)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.149] [G acc: 0.125]\n",
      "16605 [D loss: (0.597)(R 0.750, F 0.444)] [D acc: (0.688)(0.500, 0.875)] [G loss: 1.081] [G acc: 0.250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16606 [D loss: (0.585)(R 0.645, F 0.525)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.959] [G acc: 0.125]\n",
      "16607 [D loss: (0.637)(R 0.624, F 0.650)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.798] [G acc: 0.438]\n",
      "16608 [D loss: (0.539)(R 0.511, F 0.566)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.847] [G acc: 0.375]\n",
      "16609 [D loss: (0.533)(R 0.493, F 0.572)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.947] [G acc: 0.188]\n",
      "16610 [D loss: (0.619)(R 0.504, F 0.734)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.830] [G acc: 0.312]\n",
      "16611 [D loss: (0.610)(R 0.652, F 0.567)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.870] [G acc: 0.375]\n",
      "16612 [D loss: (0.734)(R 0.705, F 0.764)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.942] [G acc: 0.250]\n",
      "16613 [D loss: (0.679)(R 0.586, F 0.771)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.847] [G acc: 0.188]\n",
      "16614 [D loss: (0.637)(R 0.583, F 0.692)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.883] [G acc: 0.312]\n",
      "16615 [D loss: (0.655)(R 0.736, F 0.574)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.809] [G acc: 0.438]\n",
      "16616 [D loss: (0.856)(R 0.788, F 0.924)] [D acc: (0.312)(0.375, 0.250)] [G loss: 0.748] [G acc: 0.500]\n",
      "16617 [D loss: (0.642)(R 0.655, F 0.630)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.757] [G acc: 0.375]\n",
      "16618 [D loss: (0.835)(R 0.699, F 0.972)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.683] [G acc: 0.500]\n",
      "16619 [D loss: (0.717)(R 0.692, F 0.743)] [D acc: (0.500)(0.500, 0.500)] [G loss: 1.463] [G acc: 0.188]\n",
      "16620 [D loss: (0.774)(R 1.007, F 0.541)] [D acc: (0.562)(0.375, 0.750)] [G loss: 1.015] [G acc: 0.250]\n",
      "16621 [D loss: (0.577)(R 0.550, F 0.603)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.782] [G acc: 0.250]\n",
      "16622 [D loss: (0.648)(R 0.547, F 0.749)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.821] [G acc: 0.375]\n",
      "16623 [D loss: (0.774)(R 0.818, F 0.731)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.780] [G acc: 0.312]\n",
      "16624 [D loss: (0.742)(R 0.703, F 0.780)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.712] [G acc: 0.500]\n",
      "16625 [D loss: (0.685)(R 0.707, F 0.664)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.710] [G acc: 0.438]\n",
      "16626 [D loss: (0.625)(R 0.611, F 0.638)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.736] [G acc: 0.375]\n",
      "16627 [D loss: (0.843)(R 0.781, F 0.905)] [D acc: (0.281)(0.312, 0.250)] [G loss: 0.667] [G acc: 0.562]\n",
      "16628 [D loss: (0.796)(R 0.702, F 0.890)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.808] [G acc: 0.312]\n",
      "16629 [D loss: (0.750)(R 0.824, F 0.677)] [D acc: (0.406)(0.188, 0.625)] [G loss: 1.053] [G acc: 0.125]\n",
      "16630 [D loss: (0.682)(R 0.756, F 0.608)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.766] [G acc: 0.375]\n",
      "16631 [D loss: (0.745)(R 0.849, F 0.641)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.799] [G acc: 0.375]\n",
      "16632 [D loss: (0.765)(R 0.805, F 0.726)] [D acc: (0.344)(0.250, 0.438)] [G loss: 0.841] [G acc: 0.250]\n",
      "16633 [D loss: (0.673)(R 0.665, F 0.681)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.840] [G acc: 0.375]\n",
      "16634 [D loss: (0.591)(R 0.573, F 0.610)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.741] [G acc: 0.375]\n",
      "16635 [D loss: (0.692)(R 0.658, F 0.726)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.807] [G acc: 0.312]\n",
      "16636 [D loss: (0.728)(R 0.709, F 0.747)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.711] [G acc: 0.438]\n",
      "16637 [D loss: (0.668)(R 0.553, F 0.783)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.888] [G acc: 0.562]\n",
      "16638 [D loss: (0.621)(R 0.528, F 0.714)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.759] [G acc: 0.500]\n",
      "16639 [D loss: (0.767)(R 0.683, F 0.851)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.963] [G acc: 0.188]\n",
      "16640 [D loss: (0.698)(R 0.658, F 0.737)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.888] [G acc: 0.312]\n",
      "16641 [D loss: (0.783)(R 0.782, F 0.785)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.910] [G acc: 0.250]\n",
      "16642 [D loss: (0.696)(R 0.741, F 0.652)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.868] [G acc: 0.312]\n",
      "16643 [D loss: (0.722)(R 0.835, F 0.609)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.804] [G acc: 0.375]\n",
      "16644 [D loss: (0.673)(R 0.646, F 0.701)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.699] [G acc: 0.438]\n",
      "16645 [D loss: (0.745)(R 0.719, F 0.771)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.695] [G acc: 0.438]\n",
      "16646 [D loss: (0.736)(R 0.813, F 0.660)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.788] [G acc: 0.375]\n",
      "16647 [D loss: (0.731)(R 0.750, F 0.711)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.770] [G acc: 0.625]\n",
      "16648 [D loss: (0.712)(R 0.791, F 0.634)] [D acc: (0.375)(0.250, 0.500)] [G loss: 0.738] [G acc: 0.375]\n",
      "16649 [D loss: (0.713)(R 0.759, F 0.667)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.798] [G acc: 0.312]\n",
      "16650 [D loss: (0.876)(R 0.867, F 0.884)] [D acc: (0.406)(0.250, 0.562)] [G loss: 0.813] [G acc: 0.312]\n",
      "16651 [D loss: (0.720)(R 0.746, F 0.693)] [D acc: (0.469)(0.438, 0.500)] [G loss: 1.291] [G acc: 0.062]\n",
      "16652 [D loss: (0.729)(R 0.807, F 0.651)] [D acc: (0.438)(0.250, 0.625)] [G loss: 1.037] [G acc: 0.312]\n",
      "16653 [D loss: (1.129)(R 1.661, F 0.596)] [D acc: (0.594)(0.312, 0.875)] [G loss: 0.737] [G acc: 0.438]\n",
      "16654 [D loss: (0.700)(R 0.759, F 0.641)] [D acc: (0.500)(0.312, 0.688)] [G loss: 0.724] [G acc: 0.438]\n",
      "16655 [D loss: (0.637)(R 0.646, F 0.628)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.863] [G acc: 0.312]\n",
      "16656 [D loss: (0.709)(R 0.701, F 0.718)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.739] [G acc: 0.500]\n",
      "16657 [D loss: (0.682)(R 0.705, F 0.659)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.780] [G acc: 0.375]\n",
      "16658 [D loss: (0.889)(R 1.103, F 0.675)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.786] [G acc: 0.188]\n",
      "16659 [D loss: (0.667)(R 0.647, F 0.687)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.718] [G acc: 0.375]\n",
      "16660 [D loss: (0.699)(R 0.678, F 0.720)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.739] [G acc: 0.500]\n",
      "16661 [D loss: (0.680)(R 0.741, F 0.620)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.787] [G acc: 0.312]\n",
      "16662 [D loss: (0.772)(R 0.648, F 0.896)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.773] [G acc: 0.438]\n",
      "16663 [D loss: (0.691)(R 0.711, F 0.671)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.613] [G acc: 0.562]\n",
      "16664 [D loss: (0.762)(R 0.749, F 0.776)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.876] [G acc: 0.250]\n",
      "16665 [D loss: (0.646)(R 0.655, F 0.638)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.597] [G acc: 0.562]\n",
      "16666 [D loss: (0.846)(R 0.692, F 1.000)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.658] [G acc: 0.500]\n",
      "16667 [D loss: (1.117)(R 0.702, F 1.532)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.974] [G acc: 0.250]\n",
      "16668 [D loss: (0.532)(R 0.691, F 0.374)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.267] [G acc: 0.000]\n",
      "16669 [D loss: (0.602)(R 0.739, F 0.465)] [D acc: (0.562)(0.312, 0.812)] [G loss: 0.894] [G acc: 0.375]\n",
      "16670 [D loss: (0.567)(R 0.726, F 0.407)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.832] [G acc: 0.312]\n",
      "16671 [D loss: (0.595)(R 0.633, F 0.558)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.954] [G acc: 0.250]\n",
      "16672 [D loss: (0.671)(R 0.736, F 0.606)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.950] [G acc: 0.250]\n",
      "16673 [D loss: (0.960)(R 0.840, F 1.080)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.694] [G acc: 0.625]\n",
      "16674 [D loss: (0.938)(R 0.722, F 1.153)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.796] [G acc: 0.375]\n",
      "16675 [D loss: (0.646)(R 0.668, F 0.624)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.895] [G acc: 0.438]\n",
      "16676 [D loss: (0.690)(R 0.721, F 0.659)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.650] [G acc: 0.438]\n",
      "16677 [D loss: (0.665)(R 0.622, F 0.708)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.877] [G acc: 0.375]\n",
      "16678 [D loss: (0.669)(R 0.702, F 0.637)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.989] [G acc: 0.312]\n",
      "16679 [D loss: (0.729)(R 0.873, F 0.585)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.893] [G acc: 0.375]\n",
      "16680 [D loss: (0.664)(R 0.737, F 0.592)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.794] [G acc: 0.500]\n",
      "16681 [D loss: (0.708)(R 0.780, F 0.637)] [D acc: (0.500)(0.312, 0.688)] [G loss: 0.729] [G acc: 0.375]\n",
      "16682 [D loss: (0.768)(R 0.773, F 0.763)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.587] [G acc: 0.688]\n",
      "16683 [D loss: (0.691)(R 0.684, F 0.699)] [D acc: (0.406)(0.500, 0.312)] [G loss: 0.500] [G acc: 0.625]\n",
      "16684 [D loss: (1.174)(R 0.711, F 1.637)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.695] [G acc: 0.625]\n",
      "16685 [D loss: (0.741)(R 0.671, F 0.810)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.924] [G acc: 0.312]\n",
      "16686 [D loss: (0.607)(R 0.743, F 0.472)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.564] [G acc: 0.438]\n",
      "16687 [D loss: (0.602)(R 0.692, F 0.511)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.599] [G acc: 0.375]\n",
      "16688 [D loss: (0.706)(R 0.725, F 0.688)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.668] [G acc: 0.688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16689 [D loss: (0.625)(R 0.668, F 0.582)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.729] [G acc: 0.562]\n",
      "16690 [D loss: (0.751)(R 0.712, F 0.791)] [D acc: (0.406)(0.375, 0.438)] [G loss: 0.964] [G acc: 0.375]\n",
      "16691 [D loss: (0.749)(R 0.650, F 0.848)] [D acc: (0.531)(0.875, 0.188)] [G loss: 1.296] [G acc: 0.500]\n",
      "16692 [D loss: (0.694)(R 0.728, F 0.659)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.896] [G acc: 0.312]\n",
      "16693 [D loss: (0.633)(R 0.637, F 0.630)] [D acc: (0.750)(0.938, 0.562)] [G loss: 0.905] [G acc: 0.438]\n",
      "16694 [D loss: (0.699)(R 0.670, F 0.727)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.877] [G acc: 0.188]\n",
      "16695 [D loss: (0.730)(R 0.692, F 0.769)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.779] [G acc: 0.438]\n",
      "16696 [D loss: (0.686)(R 0.607, F 0.764)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.697] [G acc: 0.625]\n",
      "16697 [D loss: (1.077)(R 1.464, F 0.690)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.688] [G acc: 0.562]\n",
      "16698 [D loss: (0.710)(R 0.648, F 0.771)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.777] [G acc: 0.438]\n",
      "16699 [D loss: (0.635)(R 0.644, F 0.626)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.832] [G acc: 0.375]\n",
      "16700 [D loss: (0.631)(R 0.641, F 0.621)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.651] [G acc: 0.688]\n",
      "16701 [D loss: (0.700)(R 0.654, F 0.747)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.813] [G acc: 0.438]\n",
      "16702 [D loss: (0.670)(R 0.576, F 0.764)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.694] [G acc: 0.562]\n",
      "16703 [D loss: (0.592)(R 0.618, F 0.566)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.706] [G acc: 0.750]\n",
      "16704 [D loss: (0.689)(R 0.707, F 0.672)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.763] [G acc: 0.500]\n",
      "16705 [D loss: (0.620)(R 0.600, F 0.640)] [D acc: (0.688)(0.875, 0.500)] [G loss: 1.098] [G acc: 0.312]\n",
      "16706 [D loss: (0.633)(R 0.653, F 0.612)] [D acc: (0.656)(0.812, 0.500)] [G loss: 1.029] [G acc: 0.312]\n",
      "16707 [D loss: (0.698)(R 0.789, F 0.606)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.726] [G acc: 0.562]\n",
      "16708 [D loss: (0.698)(R 0.711, F 0.686)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.957] [G acc: 0.375]\n",
      "16709 [D loss: (0.621)(R 0.603, F 0.640)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.017] [G acc: 0.375]\n",
      "16710 [D loss: (0.682)(R 0.652, F 0.711)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.991] [G acc: 0.125]\n",
      "16711 [D loss: (0.627)(R 0.589, F 0.665)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.809] [G acc: 0.250]\n",
      "16712 [D loss: (0.693)(R 0.766, F 0.620)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.842] [G acc: 0.438]\n",
      "16713 [D loss: (0.624)(R 0.624, F 0.624)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.832] [G acc: 0.375]\n",
      "16714 [D loss: (0.626)(R 0.603, F 0.649)] [D acc: (0.688)(0.812, 0.562)] [G loss: 1.004] [G acc: 0.312]\n",
      "16715 [D loss: (0.683)(R 0.698, F 0.667)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.723] [G acc: 0.562]\n",
      "16716 [D loss: (0.691)(R 0.771, F 0.611)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.826] [G acc: 0.375]\n",
      "16717 [D loss: (0.691)(R 0.646, F 0.735)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.718] [G acc: 0.625]\n",
      "16718 [D loss: (0.687)(R 0.643, F 0.731)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.786] [G acc: 0.438]\n",
      "16719 [D loss: (0.676)(R 0.596, F 0.756)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.827] [G acc: 0.312]\n",
      "16720 [D loss: (0.641)(R 0.579, F 0.704)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.756] [G acc: 0.438]\n",
      "16721 [D loss: (0.659)(R 0.634, F 0.684)] [D acc: (0.656)(0.875, 0.438)] [G loss: 1.001] [G acc: 0.562]\n",
      "16722 [D loss: (0.526)(R 0.669, F 0.383)] [D acc: (0.750)(0.812, 0.688)] [G loss: 5.712] [G acc: 0.250]\n",
      "16723 [D loss: (0.641)(R 0.651, F 0.631)] [D acc: (0.656)(0.812, 0.500)] [G loss: 1.023] [G acc: 0.188]\n",
      "16724 [D loss: (0.734)(R 0.792, F 0.677)] [D acc: (0.531)(0.625, 0.438)] [G loss: 2.239] [G acc: 0.562]\n",
      "16725 [D loss: (0.671)(R 0.657, F 0.685)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.842] [G acc: 0.562]\n",
      "16726 [D loss: (0.630)(R 0.636, F 0.623)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.922] [G acc: 0.375]\n",
      "16727 [D loss: (0.649)(R 0.628, F 0.670)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.910] [G acc: 0.500]\n",
      "16728 [D loss: (0.628)(R 0.620, F 0.637)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.769] [G acc: 0.562]\n",
      "16729 [D loss: (0.678)(R 0.646, F 0.710)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.733] [G acc: 0.438]\n",
      "16730 [D loss: (0.689)(R 0.675, F 0.703)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.817] [G acc: 0.562]\n",
      "16731 [D loss: (0.597)(R 0.676, F 0.518)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.888] [G acc: 0.312]\n",
      "16732 [D loss: (0.689)(R 0.746, F 0.632)] [D acc: (0.562)(0.562, 0.562)] [G loss: 1.005] [G acc: 0.375]\n",
      "16733 [D loss: (0.686)(R 0.687, F 0.685)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.715] [G acc: 0.500]\n",
      "16734 [D loss: (0.643)(R 0.621, F 0.665)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.775] [G acc: 0.438]\n",
      "16735 [D loss: (0.569)(R 0.579, F 0.558)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.772] [G acc: 0.562]\n",
      "16736 [D loss: (0.640)(R 0.693, F 0.588)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.743] [G acc: 0.375]\n",
      "16737 [D loss: (0.882)(R 1.083, F 0.681)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.750] [G acc: 0.375]\n",
      "16738 [D loss: (0.684)(R 0.711, F 0.658)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.834] [G acc: 0.375]\n",
      "16739 [D loss: (0.769)(R 0.811, F 0.728)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.662] [G acc: 0.812]\n",
      "16740 [D loss: (0.558)(R 0.465, F 0.651)] [D acc: (0.781)(0.938, 0.625)] [G loss: 0.749] [G acc: 0.625]\n",
      "16741 [D loss: (0.664)(R 0.646, F 0.682)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.789] [G acc: 0.500]\n",
      "16742 [D loss: (0.703)(R 0.694, F 0.712)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.700] [G acc: 0.875]\n",
      "16743 [D loss: (0.637)(R 0.566, F 0.708)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.725] [G acc: 0.562]\n",
      "16744 [D loss: (0.677)(R 0.646, F 0.707)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.663] [G acc: 0.625]\n",
      "16745 [D loss: (0.579)(R 0.529, F 0.630)] [D acc: (0.812)(0.938, 0.688)] [G loss: 0.761] [G acc: 0.562]\n",
      "16746 [D loss: (0.668)(R 0.622, F 0.714)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.711] [G acc: 0.312]\n",
      "16747 [D loss: (0.582)(R 0.473, F 0.690)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.828] [G acc: 0.500]\n",
      "16748 [D loss: (0.634)(R 0.586, F 0.682)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.840] [G acc: 0.562]\n",
      "16749 [D loss: (0.670)(R 0.676, F 0.664)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.788] [G acc: 0.500]\n",
      "16750 [D loss: (0.651)(R 0.609, F 0.692)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.778] [G acc: 0.500]\n",
      "16751 [D loss: (0.618)(R 0.575, F 0.661)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.700] [G acc: 0.500]\n",
      "16752 [D loss: (0.637)(R 0.524, F 0.750)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.674] [G acc: 0.750]\n",
      "16753 [D loss: (0.604)(R 0.561, F 0.648)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.714] [G acc: 0.688]\n",
      "16754 [D loss: (0.716)(R 0.637, F 0.795)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.896] [G acc: 0.500]\n",
      "16755 [D loss: (0.504)(R 0.685, F 0.322)] [D acc: (0.750)(0.812, 0.688)] [G loss: 7.096] [G acc: 0.312]\n",
      "16756 [D loss: (0.406)(R 0.569, F 0.243)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.076] [G acc: 0.438]\n",
      "16757 [D loss: (0.597)(R 0.544, F 0.651)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.697] [G acc: 0.562]\n",
      "16758 [D loss: (0.612)(R 0.493, F 0.731)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.845] [G acc: 0.375]\n",
      "16759 [D loss: (0.627)(R 0.617, F 0.637)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.876] [G acc: 0.375]\n",
      "16760 [D loss: (0.567)(R 0.552, F 0.581)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.807] [G acc: 0.438]\n",
      "16761 [D loss: (0.699)(R 0.583, F 0.816)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.648] [G acc: 0.812]\n",
      "16762 [D loss: (0.515)(R 0.470, F 0.559)] [D acc: (0.875)(0.938, 0.812)] [G loss: 0.781] [G acc: 0.375]\n",
      "16763 [D loss: (0.700)(R 0.749, F 0.651)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.908] [G acc: 0.375]\n",
      "16764 [D loss: (0.579)(R 0.567, F 0.592)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.774] [G acc: 0.500]\n",
      "16765 [D loss: (0.619)(R 0.600, F 0.638)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.839] [G acc: 0.312]\n",
      "16766 [D loss: (0.680)(R 0.662, F 0.698)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.646] [G acc: 0.625]\n",
      "16767 [D loss: (0.788)(R 0.933, F 0.643)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.742] [G acc: 0.562]\n",
      "16768 [D loss: (0.570)(R 0.476, F 0.663)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.632] [G acc: 0.688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16769 [D loss: (0.631)(R 0.489, F 0.772)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.826] [G acc: 0.250]\n",
      "16770 [D loss: (0.667)(R 0.659, F 0.675)] [D acc: (0.406)(0.375, 0.438)] [G loss: 0.772] [G acc: 0.375]\n",
      "16771 [D loss: (0.735)(R 0.680, F 0.790)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.748] [G acc: 0.500]\n",
      "16772 [D loss: (0.624)(R 0.512, F 0.736)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.794] [G acc: 0.250]\n",
      "16773 [D loss: (0.638)(R 0.632, F 0.643)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.772] [G acc: 0.375]\n",
      "16774 [D loss: (0.609)(R 0.550, F 0.667)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.917] [G acc: 0.375]\n",
      "16775 [D loss: (0.675)(R 0.567, F 0.783)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.754] [G acc: 0.375]\n",
      "16776 [D loss: (0.650)(R 0.646, F 0.653)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.876] [G acc: 0.188]\n",
      "16777 [D loss: (0.619)(R 0.559, F 0.678)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.794] [G acc: 0.375]\n",
      "16778 [D loss: (0.671)(R 0.661, F 0.680)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.796] [G acc: 0.500]\n",
      "16779 [D loss: (0.728)(R 0.736, F 0.721)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.773] [G acc: 0.500]\n",
      "16780 [D loss: (0.599)(R 0.551, F 0.648)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.798] [G acc: 0.312]\n",
      "16781 [D loss: (0.588)(R 0.593, F 0.583)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.777] [G acc: 0.250]\n",
      "16782 [D loss: (0.610)(R 0.559, F 0.661)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.761] [G acc: 0.375]\n",
      "16783 [D loss: (0.599)(R 0.537, F 0.661)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.716] [G acc: 0.562]\n",
      "16784 [D loss: (0.663)(R 0.569, F 0.756)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.708] [G acc: 0.438]\n",
      "16785 [D loss: (0.732)(R 0.453, F 1.010)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.692] [G acc: 0.562]\n",
      "16786 [D loss: (0.607)(R 0.502, F 0.712)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.764] [G acc: 0.375]\n",
      "16787 [D loss: (0.584)(R 0.481, F 0.688)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.692] [G acc: 0.500]\n",
      "16788 [D loss: (0.694)(R 0.666, F 0.722)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.645] [G acc: 0.750]\n",
      "16789 [D loss: (0.709)(R 0.654, F 0.763)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.531] [G acc: 0.875]\n",
      "16790 [D loss: (0.756)(R 0.684, F 0.828)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.853] [G acc: 0.375]\n",
      "16791 [D loss: (0.502)(R 0.738, F 0.266)] [D acc: (0.719)(0.625, 0.812)] [G loss: 2.939] [G acc: 0.375]\n",
      "16792 [D loss: (0.520)(R 0.583, F 0.457)] [D acc: (0.625)(0.688, 0.562)] [G loss: 2.695] [G acc: 0.312]\n",
      "16793 [D loss: (0.665)(R 0.657, F 0.672)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.679] [G acc: 0.625]\n",
      "16794 [D loss: (0.657)(R 0.661, F 0.652)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.434] [G acc: 0.188]\n",
      "16795 [D loss: (0.704)(R 0.681, F 0.727)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.706] [G acc: 0.438]\n",
      "16796 [D loss: (0.619)(R 0.540, F 0.698)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.699] [G acc: 0.562]\n",
      "16797 [D loss: (0.706)(R 0.660, F 0.752)] [D acc: (0.406)(0.625, 0.188)] [G loss: 0.590] [G acc: 0.938]\n",
      "16798 [D loss: (0.680)(R 0.636, F 0.724)] [D acc: (0.406)(0.625, 0.188)] [G loss: 0.652] [G acc: 0.812]\n",
      "16799 [D loss: (0.643)(R 0.566, F 0.720)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.684] [G acc: 0.625]\n",
      "16800 [D loss: (0.912)(R 0.622, F 1.201)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.624] [G acc: 0.750]\n",
      "16801 [D loss: (0.681)(R 0.646, F 0.715)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.699] [G acc: 0.688]\n",
      "16802 [D loss: (0.652)(R 0.604, F 0.701)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.694] [G acc: 0.562]\n",
      "16803 [D loss: (0.685)(R 0.649, F 0.722)] [D acc: (0.406)(0.688, 0.125)] [G loss: 0.754] [G acc: 0.438]\n",
      "16804 [D loss: (0.641)(R 0.599, F 0.683)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.669] [G acc: 0.375]\n",
      "16805 [D loss: (0.636)(R 0.590, F 0.682)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.798] [G acc: 0.188]\n",
      "16806 [D loss: (0.644)(R 0.554, F 0.734)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.663] [G acc: 0.875]\n",
      "16807 [D loss: (0.768)(R 0.679, F 0.856)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.767] [G acc: 0.312]\n",
      "16808 [D loss: (0.755)(R 0.809, F 0.701)] [D acc: (0.312)(0.312, 0.312)] [G loss: 0.704] [G acc: 0.625]\n",
      "16809 [D loss: (0.783)(R 0.622, F 0.944)] [D acc: (0.406)(0.688, 0.125)] [G loss: 0.589] [G acc: 0.750]\n",
      "16810 [D loss: (0.631)(R 0.566, F 0.695)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.735] [G acc: 0.312]\n",
      "16811 [D loss: (0.733)(R 0.765, F 0.701)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.730] [G acc: 0.438]\n",
      "16812 [D loss: (0.677)(R 0.657, F 0.697)] [D acc: (0.406)(0.500, 0.312)] [G loss: 0.693] [G acc: 0.625]\n",
      "16813 [D loss: (0.645)(R 0.649, F 0.641)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.910] [G acc: 0.250]\n",
      "16814 [D loss: (0.745)(R 0.774, F 0.717)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.718] [G acc: 0.562]\n",
      "16815 [D loss: (0.726)(R 0.748, F 0.705)] [D acc: (0.344)(0.312, 0.375)] [G loss: 0.687] [G acc: 0.562]\n",
      "16816 [D loss: (0.672)(R 0.637, F 0.708)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.805] [G acc: 0.375]\n",
      "16817 [D loss: (0.619)(R 0.600, F 0.637)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.726] [G acc: 0.375]\n",
      "16818 [D loss: (0.571)(R 0.504, F 0.638)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.757] [G acc: 0.375]\n",
      "16819 [D loss: (0.672)(R 0.710, F 0.635)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.777] [G acc: 0.250]\n",
      "16820 [D loss: (0.661)(R 0.647, F 0.676)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.745] [G acc: 0.188]\n",
      "16821 [D loss: (0.655)(R 0.654, F 0.656)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.703] [G acc: 0.562]\n",
      "16822 [D loss: (0.659)(R 0.695, F 0.623)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.690] [G acc: 0.562]\n",
      "16823 [D loss: (0.671)(R 0.673, F 0.669)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.733] [G acc: 0.312]\n",
      "16824 [D loss: (0.752)(R 0.724, F 0.780)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.746] [G acc: 0.250]\n",
      "16825 [D loss: (0.741)(R 0.804, F 0.678)] [D acc: (0.406)(0.375, 0.438)] [G loss: 0.702] [G acc: 0.625]\n",
      "16826 [D loss: (0.699)(R 0.694, F 0.705)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.744] [G acc: 0.625]\n",
      "16827 [D loss: (0.594)(R 0.562, F 0.626)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.717] [G acc: 0.438]\n",
      "16828 [D loss: (0.729)(R 0.711, F 0.746)] [D acc: (0.375)(0.375, 0.375)] [G loss: 0.704] [G acc: 0.500]\n",
      "16829 [D loss: (0.731)(R 0.635, F 0.827)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.722] [G acc: 0.438]\n",
      "16830 [D loss: (0.650)(R 0.646, F 0.655)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.763] [G acc: 0.438]\n",
      "16831 [D loss: (0.630)(R 0.590, F 0.671)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.732] [G acc: 0.375]\n",
      "16832 [D loss: (0.653)(R 0.611, F 0.696)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.741] [G acc: 0.375]\n",
      "16833 [D loss: (0.687)(R 0.689, F 0.685)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.732] [G acc: 0.312]\n",
      "16834 [D loss: (0.658)(R 0.646, F 0.669)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.745] [G acc: 0.375]\n",
      "16835 [D loss: (0.591)(R 0.507, F 0.674)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.656] [G acc: 0.500]\n",
      "16836 [D loss: (0.629)(R 0.587, F 0.672)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.604] [G acc: 0.500]\n",
      "16837 [D loss: (0.594)(R 0.542, F 0.646)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.638] [G acc: 0.438]\n",
      "16838 [D loss: (0.697)(R 0.663, F 0.731)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.829] [G acc: 0.188]\n",
      "16839 [D loss: (0.604)(R 0.637, F 0.571)] [D acc: (0.719)(0.500, 0.938)] [G loss: 0.738] [G acc: 0.312]\n",
      "16840 [D loss: (0.840)(R 0.633, F 1.047)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.811] [G acc: 0.250]\n",
      "16841 [D loss: (0.701)(R 0.564, F 0.838)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.830] [G acc: 0.188]\n",
      "16842 [D loss: (0.594)(R 0.597, F 0.590)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.738] [G acc: 0.312]\n",
      "16843 [D loss: (0.685)(R 0.645, F 0.725)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.765] [G acc: 0.250]\n",
      "16844 [D loss: (0.659)(R 0.631, F 0.688)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.632] [G acc: 0.438]\n",
      "16845 [D loss: (1.480)(R 1.767, F 1.193)] [D acc: (0.469)(0.438, 0.500)] [G loss: 1.009] [G acc: 0.312]\n",
      "16846 [D loss: (0.552)(R 0.557, F 0.546)] [D acc: (0.625)(0.625, 0.625)] [G loss: 5.079] [G acc: 0.125]\n",
      "16847 [D loss: (0.736)(R 0.777, F 0.696)] [D acc: (0.531)(0.250, 0.812)] [G loss: 0.644] [G acc: 0.562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16848 [D loss: (0.524)(R 0.741, F 0.308)] [D acc: (0.656)(0.375, 0.938)] [G loss: 1.015] [G acc: 0.250]\n",
      "16849 [D loss: (0.739)(R 0.749, F 0.730)] [D acc: (0.312)(0.188, 0.438)] [G loss: 0.719] [G acc: 0.500]\n",
      "16850 [D loss: (0.767)(R 0.766, F 0.768)] [D acc: (0.500)(0.312, 0.688)] [G loss: 0.754] [G acc: 0.438]\n",
      "16851 [D loss: (0.647)(R 0.659, F 0.636)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.737] [G acc: 0.375]\n",
      "16852 [D loss: (0.687)(R 0.672, F 0.701)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.707] [G acc: 0.562]\n",
      "16853 [D loss: (0.755)(R 0.801, F 0.709)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.766] [G acc: 0.188]\n",
      "16854 [D loss: (0.721)(R 0.685, F 0.758)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.733] [G acc: 0.500]\n",
      "16855 [D loss: (0.672)(R 0.657, F 0.687)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.661] [G acc: 0.562]\n",
      "16856 [D loss: (0.753)(R 0.690, F 0.816)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.750] [G acc: 0.438]\n",
      "16857 [D loss: (0.632)(R 0.575, F 0.689)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.741] [G acc: 0.375]\n",
      "16858 [D loss: (0.656)(R 0.677, F 0.635)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.736] [G acc: 0.250]\n",
      "16859 [D loss: (0.658)(R 0.659, F 0.657)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.621] [G acc: 0.500]\n",
      "16860 [D loss: (0.676)(R 0.709, F 0.642)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.741] [G acc: 0.188]\n",
      "16861 [D loss: (0.651)(R 0.686, F 0.615)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.920] [G acc: 0.438]\n",
      "16862 [D loss: (0.692)(R 0.710, F 0.674)] [D acc: (0.406)(0.312, 0.500)] [G loss: 0.693] [G acc: 0.438]\n",
      "16863 [D loss: (0.683)(R 0.690, F 0.676)] [D acc: (0.406)(0.312, 0.500)] [G loss: 0.732] [G acc: 0.312]\n",
      "16864 [D loss: (0.775)(R 0.684, F 0.867)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.741] [G acc: 0.375]\n",
      "16865 [D loss: (0.675)(R 0.710, F 0.640)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.704] [G acc: 0.375]\n",
      "16866 [D loss: (0.677)(R 0.584, F 0.770)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.814] [G acc: 0.375]\n",
      "16867 [D loss: (0.867)(R 0.674, F 1.059)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.712] [G acc: 0.438]\n",
      "16868 [D loss: (0.735)(R 0.822, F 0.648)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.756] [G acc: 0.312]\n",
      "16869 [D loss: (0.714)(R 0.727, F 0.701)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.938] [G acc: 0.438]\n",
      "16870 [D loss: (0.598)(R 0.630, F 0.565)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.784] [G acc: 0.312]\n",
      "16871 [D loss: (0.656)(R 0.694, F 0.618)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.754] [G acc: 0.312]\n",
      "16872 [D loss: (0.661)(R 0.738, F 0.585)] [D acc: (0.656)(0.375, 0.938)] [G loss: 0.788] [G acc: 0.375]\n",
      "16873 [D loss: (0.737)(R 0.715, F 0.759)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.743] [G acc: 0.438]\n",
      "16874 [D loss: (0.761)(R 0.803, F 0.719)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.716] [G acc: 0.500]\n",
      "16875 [D loss: (0.649)(R 0.656, F 0.642)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.752] [G acc: 0.375]\n",
      "16876 [D loss: (0.676)(R 0.676, F 0.675)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.700] [G acc: 0.438]\n",
      "16877 [D loss: (0.650)(R 0.641, F 0.659)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.716] [G acc: 0.438]\n",
      "16878 [D loss: (0.911)(R 0.693, F 1.128)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.871] [G acc: 0.062]\n",
      "16879 [D loss: (0.608)(R 0.615, F 0.601)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.795] [G acc: 0.250]\n",
      "16880 [D loss: (0.646)(R 0.632, F 0.660)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.774] [G acc: 0.250]\n",
      "16881 [D loss: (0.660)(R 0.650, F 0.671)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.771] [G acc: 0.125]\n",
      "16882 [D loss: (0.639)(R 0.585, F 0.693)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.772] [G acc: 0.438]\n",
      "16883 [D loss: (0.786)(R 0.624, F 0.949)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.735] [G acc: 0.438]\n",
      "16884 [D loss: (0.686)(R 0.685, F 0.687)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.794] [G acc: 0.312]\n",
      "16885 [D loss: (0.748)(R 0.763, F 0.734)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.626] [G acc: 0.688]\n",
      "16886 [D loss: (0.710)(R 0.687, F 0.732)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.690] [G acc: 0.500]\n",
      "16887 [D loss: (0.725)(R 0.583, F 0.867)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.742] [G acc: 0.562]\n",
      "16888 [D loss: (0.843)(R 0.649, F 1.037)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.713] [G acc: 0.438]\n",
      "16889 [D loss: (0.647)(R 0.664, F 0.629)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.691] [G acc: 0.375]\n",
      "16890 [D loss: (0.686)(R 0.615, F 0.756)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.962] [G acc: 0.250]\n",
      "16891 [D loss: (0.456)(R 0.718, F 0.193)] [D acc: (0.781)(0.562, 1.000)] [G loss: 2.433] [G acc: 0.125]\n",
      "16892 [D loss: (0.627)(R 0.690, F 0.565)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.036] [G acc: 0.438]\n",
      "16893 [D loss: (0.679)(R 0.712, F 0.645)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.857] [G acc: 0.250]\n",
      "16894 [D loss: (0.675)(R 0.726, F 0.624)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.777] [G acc: 0.312]\n",
      "16895 [D loss: (0.645)(R 0.634, F 0.655)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.771] [G acc: 0.125]\n",
      "16896 [D loss: (0.736)(R 0.781, F 0.690)] [D acc: (0.406)(0.375, 0.438)] [G loss: 0.762] [G acc: 0.188]\n",
      "16897 [D loss: (0.664)(R 0.691, F 0.637)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.780] [G acc: 0.250]\n",
      "16898 [D loss: (0.633)(R 0.600, F 0.666)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.762] [G acc: 0.312]\n",
      "16899 [D loss: (0.693)(R 0.713, F 0.673)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.786] [G acc: 0.188]\n",
      "16900 [D loss: (0.652)(R 0.637, F 0.666)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.717] [G acc: 0.438]\n",
      "16901 [D loss: (0.639)(R 0.627, F 0.650)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.811] [G acc: 0.062]\n",
      "16902 [D loss: (0.705)(R 0.754, F 0.656)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.738] [G acc: 0.312]\n",
      "16903 [D loss: (0.629)(R 0.650, F 0.608)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.764] [G acc: 0.375]\n",
      "16904 [D loss: (0.691)(R 0.684, F 0.697)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.753] [G acc: 0.188]\n",
      "16905 [D loss: (0.635)(R 0.631, F 0.640)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.037] [G acc: 0.000]\n",
      "16906 [D loss: (0.594)(R 0.591, F 0.596)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.802] [G acc: 0.375]\n",
      "16907 [D loss: (0.641)(R 0.657, F 0.625)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.771] [G acc: 0.250]\n",
      "16908 [D loss: (0.659)(R 0.680, F 0.637)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.855] [G acc: 0.188]\n",
      "16909 [D loss: (0.678)(R 0.703, F 0.654)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.891] [G acc: 0.000]\n",
      "16910 [D loss: (0.643)(R 0.637, F 0.648)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.824] [G acc: 0.125]\n",
      "16911 [D loss: (0.625)(R 0.639, F 0.612)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.806] [G acc: 0.125]\n",
      "16912 [D loss: (0.623)(R 0.608, F 0.639)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.790] [G acc: 0.312]\n",
      "16913 [D loss: (0.621)(R 0.639, F 0.604)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.811] [G acc: 0.188]\n",
      "16914 [D loss: (0.615)(R 0.614, F 0.616)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.789] [G acc: 0.375]\n",
      "16915 [D loss: (0.636)(R 0.633, F 0.639)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.770] [G acc: 0.250]\n",
      "16916 [D loss: (0.641)(R 0.632, F 0.649)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.870] [G acc: 0.125]\n",
      "16917 [D loss: (0.621)(R 0.665, F 0.578)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.784] [G acc: 0.250]\n",
      "16918 [D loss: (0.635)(R 0.635, F 0.635)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.835] [G acc: 0.062]\n",
      "16919 [D loss: (0.582)(R 0.528, F 0.635)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.782] [G acc: 0.062]\n",
      "16920 [D loss: (0.613)(R 0.558, F 0.667)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.720] [G acc: 0.438]\n",
      "16921 [D loss: (0.613)(R 0.522, F 0.704)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.721] [G acc: 0.438]\n",
      "16922 [D loss: (0.639)(R 0.549, F 0.729)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.760] [G acc: 0.312]\n",
      "16923 [D loss: (0.803)(R 0.720, F 0.886)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.570] [G acc: 0.688]\n",
      "16924 [D loss: (0.894)(R 0.678, F 1.110)] [D acc: (0.438)(0.562, 0.312)] [G loss: 1.353] [G acc: 0.438]\n",
      "16925 [D loss: (0.492)(R 0.703, F 0.281)] [D acc: (0.781)(0.625, 0.938)] [G loss: 2.036] [G acc: 0.125]\n",
      "16926 [D loss: (0.575)(R 0.587, F 0.562)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.196] [G acc: 0.250]\n",
      "16927 [D loss: (0.712)(R 0.847, F 0.578)] [D acc: (0.594)(0.312, 0.875)] [G loss: 0.751] [G acc: 0.375]\n",
      "16928 [D loss: (0.609)(R 0.623, F 0.595)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.735] [G acc: 0.375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16929 [D loss: (0.614)(R 0.659, F 0.569)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.762] [G acc: 0.250]\n",
      "16930 [D loss: (0.617)(R 0.552, F 0.682)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.758] [G acc: 0.375]\n",
      "16931 [D loss: (0.570)(R 0.538, F 0.602)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.908] [G acc: 0.250]\n",
      "16932 [D loss: (0.636)(R 0.638, F 0.634)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.955] [G acc: 0.312]\n",
      "16933 [D loss: (0.678)(R 0.678, F 0.679)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.845] [G acc: 0.062]\n",
      "16934 [D loss: (0.668)(R 0.708, F 0.628)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.766] [G acc: 0.375]\n",
      "16935 [D loss: (0.626)(R 0.678, F 0.574)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.834] [G acc: 0.125]\n",
      "16936 [D loss: (0.656)(R 0.527, F 0.786)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.877] [G acc: 0.062]\n",
      "16937 [D loss: (0.581)(R 0.648, F 0.514)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.816] [G acc: 0.250]\n",
      "16938 [D loss: (0.696)(R 0.688, F 0.703)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.973] [G acc: 0.000]\n",
      "16939 [D loss: (0.611)(R 0.664, F 0.558)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.848] [G acc: 0.250]\n",
      "16940 [D loss: (0.683)(R 0.766, F 0.600)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.850] [G acc: 0.250]\n",
      "16941 [D loss: (0.713)(R 0.800, F 0.626)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.030] [G acc: 0.312]\n",
      "16942 [D loss: (0.571)(R 0.512, F 0.630)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.819] [G acc: 0.125]\n",
      "16943 [D loss: (0.662)(R 0.655, F 0.669)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.863] [G acc: 0.188]\n",
      "16944 [D loss: (0.701)(R 0.623, F 0.779)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.867] [G acc: 0.125]\n",
      "16945 [D loss: (0.652)(R 0.711, F 0.592)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.788] [G acc: 0.250]\n",
      "16946 [D loss: (0.577)(R 0.472, F 0.683)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.851] [G acc: 0.125]\n",
      "16947 [D loss: (0.631)(R 0.727, F 0.535)] [D acc: (0.750)(0.500, 1.000)] [G loss: 0.757] [G acc: 0.250]\n",
      "16948 [D loss: (0.571)(R 0.562, F 0.581)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.827] [G acc: 0.250]\n",
      "16949 [D loss: (0.675)(R 0.727, F 0.624)] [D acc: (0.562)(0.312, 0.812)] [G loss: 0.860] [G acc: 0.188]\n",
      "16950 [D loss: (0.643)(R 0.714, F 0.572)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.852] [G acc: 0.125]\n",
      "16951 [D loss: (0.687)(R 0.645, F 0.728)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.832] [G acc: 0.125]\n",
      "16952 [D loss: (0.702)(R 0.761, F 0.644)] [D acc: (0.562)(0.312, 0.812)] [G loss: 0.786] [G acc: 0.250]\n",
      "16953 [D loss: (0.618)(R 0.520, F 0.715)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.846] [G acc: 0.062]\n",
      "16954 [D loss: (0.626)(R 0.597, F 0.654)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.875] [G acc: 0.250]\n",
      "16955 [D loss: (1.070)(R 0.772, F 1.368)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.698] [G acc: 0.375]\n",
      "16956 [D loss: (0.595)(R 0.544, F 0.645)] [D acc: (0.594)(0.500, 0.688)] [G loss: 1.310] [G acc: 0.188]\n",
      "16957 [D loss: (0.636)(R 0.586, F 0.686)] [D acc: (0.719)(0.688, 0.750)] [G loss: 2.922] [G acc: 0.062]\n",
      "16958 [D loss: (0.465)(R 0.524, F 0.405)] [D acc: (0.719)(0.500, 0.938)] [G loss: 2.729] [G acc: 0.000]\n",
      "16959 [D loss: (0.589)(R 0.641, F 0.538)] [D acc: (0.719)(0.438, 1.000)] [G loss: 0.863] [G acc: 0.000]\n",
      "16960 [D loss: (0.597)(R 0.652, F 0.542)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.774] [G acc: 0.188]\n",
      "16961 [D loss: (0.635)(R 0.731, F 0.539)] [D acc: (0.625)(0.250, 1.000)] [G loss: 0.849] [G acc: 0.062]\n",
      "16962 [D loss: (0.660)(R 0.738, F 0.581)] [D acc: (0.562)(0.250, 0.875)] [G loss: 0.885] [G acc: 0.062]\n",
      "16963 [D loss: (0.672)(R 0.547, F 0.796)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.869] [G acc: 0.000]\n",
      "16964 [D loss: (0.592)(R 0.645, F 0.538)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.869] [G acc: 0.125]\n",
      "16965 [D loss: (0.543)(R 0.523, F 0.564)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.875] [G acc: 0.125]\n",
      "16966 [D loss: (0.678)(R 0.762, F 0.594)] [D acc: (0.562)(0.312, 0.812)] [G loss: 0.912] [G acc: 0.125]\n",
      "16967 [D loss: (0.581)(R 0.605, F 0.557)] [D acc: (0.750)(0.500, 1.000)] [G loss: 0.848] [G acc: 0.062]\n",
      "16968 [D loss: (0.740)(R 0.912, F 0.568)] [D acc: (0.594)(0.312, 0.875)] [G loss: 0.905] [G acc: 0.062]\n",
      "16969 [D loss: (0.628)(R 0.646, F 0.611)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.842] [G acc: 0.125]\n",
      "16970 [D loss: (0.699)(R 0.773, F 0.624)] [D acc: (0.500)(0.250, 0.750)] [G loss: 0.837] [G acc: 0.125]\n",
      "16971 [D loss: (0.642)(R 0.671, F 0.612)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.817] [G acc: 0.188]\n",
      "16972 [D loss: (0.592)(R 0.629, F 0.554)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.827] [G acc: 0.250]\n",
      "16973 [D loss: (0.614)(R 0.639, F 0.589)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.843] [G acc: 0.250]\n",
      "16974 [D loss: (0.656)(R 0.678, F 0.634)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.901] [G acc: 0.125]\n",
      "16975 [D loss: (0.628)(R 0.642, F 0.613)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.936] [G acc: 0.062]\n",
      "16976 [D loss: (0.507)(R 0.479, F 0.536)] [D acc: (0.844)(0.688, 1.000)] [G loss: 0.758] [G acc: 0.312]\n",
      "16977 [D loss: (0.550)(R 0.516, F 0.584)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.854] [G acc: 0.125]\n",
      "16978 [D loss: (0.589)(R 0.617, F 0.560)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.927] [G acc: 0.062]\n",
      "16979 [D loss: (0.641)(R 0.678, F 0.604)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.978] [G acc: 0.125]\n",
      "16980 [D loss: (0.577)(R 0.606, F 0.549)] [D acc: (0.719)(0.500, 0.938)] [G loss: 0.919] [G acc: 0.125]\n",
      "16981 [D loss: (0.583)(R 0.689, F 0.476)] [D acc: (0.656)(0.312, 1.000)] [G loss: 1.033] [G acc: 0.188]\n",
      "16982 [D loss: (0.584)(R 0.579, F 0.589)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.993] [G acc: 0.125]\n",
      "16983 [D loss: (0.603)(R 0.671, F 0.534)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.962] [G acc: 0.062]\n",
      "16984 [D loss: (0.625)(R 0.616, F 0.634)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.888] [G acc: 0.188]\n",
      "16985 [D loss: (0.556)(R 0.567, F 0.545)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.858] [G acc: 0.250]\n",
      "16986 [D loss: (0.504)(R 0.440, F 0.569)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.837] [G acc: 0.250]\n",
      "16987 [D loss: (0.642)(R 0.708, F 0.575)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.721] [G acc: 0.500]\n",
      "16988 [D loss: (0.728)(R 0.758, F 0.699)] [D acc: (0.562)(0.375, 0.750)] [G loss: 1.006] [G acc: 0.062]\n",
      "16989 [D loss: (0.632)(R 0.644, F 0.619)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.739] [G acc: 0.438]\n",
      "16990 [D loss: (0.676)(R 0.602, F 0.749)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.972] [G acc: 0.125]\n",
      "16991 [D loss: (0.660)(R 0.695, F 0.625)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.811] [G acc: 0.250]\n",
      "16992 [D loss: (0.568)(R 0.603, F 0.533)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.952] [G acc: 0.062]\n",
      "16993 [D loss: (0.655)(R 0.658, F 0.652)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.861] [G acc: 0.250]\n",
      "16994 [D loss: (0.786)(R 0.675, F 0.897)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.911] [G acc: 0.125]\n",
      "16995 [D loss: (0.612)(R 0.665, F 0.558)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.889] [G acc: 0.188]\n",
      "16996 [D loss: (0.582)(R 0.644, F 0.520)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.943] [G acc: 0.125]\n",
      "16997 [D loss: (0.776)(R 0.795, F 0.757)] [D acc: (0.562)(0.312, 0.812)] [G loss: 0.920] [G acc: 0.125]\n",
      "16998 [D loss: (0.658)(R 0.640, F 0.676)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.823] [G acc: 0.125]\n",
      "16999 [D loss: (0.676)(R 0.669, F 0.684)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.791] [G acc: 0.375]\n",
      "17000 [D loss: (0.732)(R 0.727, F 0.736)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.677] [G acc: 0.562]\n",
      "17001 [D loss: (0.697)(R 0.688, F 0.707)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.891] [G acc: 0.188]\n",
      "17002 [D loss: (0.651)(R 0.726, F 0.576)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.967] [G acc: 0.125]\n",
      "17003 [D loss: (0.662)(R 0.745, F 0.580)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.850] [G acc: 0.188]\n",
      "17004 [D loss: (0.696)(R 0.745, F 0.646)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.864] [G acc: 0.312]\n",
      "17005 [D loss: (0.630)(R 0.657, F 0.603)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.697] [G acc: 0.500]\n",
      "17006 [D loss: (0.650)(R 0.657, F 0.642)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.751] [G acc: 0.375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17007 [D loss: (0.688)(R 0.627, F 0.749)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.763] [G acc: 0.250]\n",
      "17008 [D loss: (0.644)(R 0.605, F 0.683)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.485] [G acc: 0.750]\n",
      "17009 [D loss: (0.822)(R 0.848, F 0.795)] [D acc: (0.219)(0.062, 0.375)] [G loss: 0.539] [G acc: 0.688]\n",
      "17010 [D loss: (0.684)(R 0.649, F 0.719)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.781] [G acc: 0.500]\n",
      "17011 [D loss: (1.042)(R 0.684, F 1.399)] [D acc: (0.375)(0.438, 0.312)] [G loss: 0.682] [G acc: 0.500]\n",
      "17012 [D loss: (1.036)(R 0.632, F 1.440)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.719] [G acc: 0.438]\n",
      "17013 [D loss: (0.927)(R 0.870, F 0.984)] [D acc: (0.344)(0.312, 0.375)] [G loss: 0.759] [G acc: 0.188]\n",
      "17014 [D loss: (0.883)(R 0.794, F 0.972)] [D acc: (0.438)(0.312, 0.562)] [G loss: 0.628] [G acc: 0.562]\n",
      "17015 [D loss: (0.944)(R 0.593, F 1.296)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.436] [G acc: 0.812]\n",
      "17016 [D loss: (1.011)(R 0.694, F 1.328)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.902] [G acc: 0.312]\n",
      "17017 [D loss: (0.602)(R 0.628, F 0.576)] [D acc: (0.531)(0.375, 0.688)] [G loss: 1.543] [G acc: 0.062]\n",
      "17018 [D loss: (0.975)(R 0.672, F 1.278)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.569] [G acc: 0.750]\n",
      "17019 [D loss: (1.089)(R 0.782, F 1.396)] [D acc: (0.344)(0.312, 0.375)] [G loss: 0.727] [G acc: 0.312]\n",
      "17020 [D loss: (0.621)(R 0.632, F 0.609)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.433] [G acc: 0.812]\n",
      "17021 [D loss: (0.939)(R 0.729, F 1.150)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.645] [G acc: 0.500]\n",
      "17022 [D loss: (0.939)(R 0.825, F 1.054)] [D acc: (0.406)(0.312, 0.500)] [G loss: 0.690] [G acc: 0.500]\n",
      "17023 [D loss: (0.703)(R 0.621, F 0.786)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.817] [G acc: 0.562]\n",
      "17024 [D loss: (0.751)(R 0.824, F 0.679)] [D acc: (0.438)(0.250, 0.625)] [G loss: 0.707] [G acc: 0.312]\n",
      "17025 [D loss: (0.833)(R 0.677, F 0.990)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.719] [G acc: 0.438]\n",
      "17026 [D loss: (0.734)(R 0.681, F 0.786)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.435] [G acc: 0.875]\n",
      "17027 [D loss: (0.930)(R 0.740, F 1.120)] [D acc: (0.312)(0.312, 0.312)] [G loss: 0.586] [G acc: 0.500]\n",
      "17028 [D loss: (0.878)(R 0.772, F 0.984)] [D acc: (0.281)(0.312, 0.250)] [G loss: 0.679] [G acc: 0.500]\n",
      "17029 [D loss: (1.162)(R 0.757, F 1.568)] [D acc: (0.344)(0.312, 0.375)] [G loss: 0.777] [G acc: 0.500]\n",
      "17030 [D loss: (0.761)(R 0.865, F 0.657)] [D acc: (0.562)(0.312, 0.812)] [G loss: 1.990] [G acc: 0.250]\n",
      "17031 [D loss: (0.743)(R 0.699, F 0.787)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.759] [G acc: 0.500]\n",
      "17032 [D loss: (0.831)(R 0.743, F 0.918)] [D acc: (0.344)(0.438, 0.250)] [G loss: 0.625] [G acc: 0.625]\n",
      "17033 [D loss: (0.803)(R 0.707, F 0.899)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.705] [G acc: 0.375]\n",
      "17034 [D loss: (0.784)(R 0.749, F 0.819)] [D acc: (0.344)(0.312, 0.375)] [G loss: 0.731] [G acc: 0.500]\n",
      "17035 [D loss: (0.798)(R 0.657, F 0.939)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.670] [G acc: 0.438]\n",
      "17036 [D loss: (0.746)(R 0.719, F 0.773)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.645] [G acc: 0.500]\n",
      "17037 [D loss: (0.824)(R 0.694, F 0.954)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.659] [G acc: 0.500]\n",
      "17038 [D loss: (0.692)(R 0.648, F 0.736)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.640] [G acc: 0.688]\n",
      "17039 [D loss: (0.903)(R 0.710, F 1.096)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.691] [G acc: 0.375]\n",
      "17040 [D loss: (0.747)(R 0.695, F 0.798)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.829] [G acc: 0.312]\n",
      "17041 [D loss: (0.688)(R 0.667, F 0.709)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.780] [G acc: 0.312]\n",
      "17042 [D loss: (0.715)(R 0.623, F 0.806)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.960] [G acc: 0.125]\n",
      "17043 [D loss: (0.740)(R 0.657, F 0.823)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.854] [G acc: 0.312]\n",
      "17044 [D loss: (0.685)(R 0.725, F 0.645)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.799] [G acc: 0.250]\n",
      "17045 [D loss: (0.757)(R 0.723, F 0.791)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.730] [G acc: 0.500]\n",
      "17046 [D loss: (0.776)(R 0.767, F 0.785)] [D acc: (0.312)(0.250, 0.375)] [G loss: 0.712] [G acc: 0.375]\n",
      "17047 [D loss: (0.773)(R 0.709, F 0.838)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.747] [G acc: 0.438]\n",
      "17048 [D loss: (0.888)(R 0.668, F 1.108)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.687] [G acc: 0.438]\n",
      "17049 [D loss: (0.739)(R 0.662, F 0.816)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.719] [G acc: 0.500]\n",
      "17050 [D loss: (0.881)(R 0.702, F 1.060)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.838] [G acc: 0.188]\n",
      "17051 [D loss: (0.824)(R 0.793, F 0.855)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.738] [G acc: 0.438]\n",
      "17052 [D loss: (0.637)(R 0.718, F 0.556)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.738] [G acc: 0.375]\n",
      "17053 [D loss: (0.766)(R 0.761, F 0.771)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.731] [G acc: 0.562]\n",
      "17054 [D loss: (0.652)(R 0.676, F 0.627)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.756] [G acc: 0.188]\n",
      "17055 [D loss: (0.759)(R 0.677, F 0.840)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.692] [G acc: 0.438]\n",
      "17056 [D loss: (0.834)(R 0.710, F 0.959)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.864] [G acc: 0.375]\n",
      "17057 [D loss: (0.767)(R 0.760, F 0.774)] [D acc: (0.562)(0.625, 0.500)] [G loss: 1.265] [G acc: 0.250]\n",
      "17058 [D loss: (0.493)(R 0.671, F 0.315)] [D acc: (0.781)(0.875, 0.688)] [G loss: 5.170] [G acc: 0.062]\n",
      "17059 [D loss: (0.712)(R 0.683, F 0.741)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.747] [G acc: 0.562]\n",
      "17060 [D loss: (0.698)(R 0.674, F 0.721)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.849] [G acc: 0.312]\n",
      "17061 [D loss: (0.870)(R 0.680, F 1.059)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.825] [G acc: 0.438]\n",
      "17062 [D loss: (0.738)(R 0.697, F 0.778)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.773] [G acc: 0.250]\n",
      "17063 [D loss: (0.934)(R 0.843, F 1.024)] [D acc: (0.375)(0.438, 0.312)] [G loss: 0.862] [G acc: 0.312]\n",
      "17064 [D loss: (0.620)(R 0.670, F 0.569)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.901] [G acc: 0.188]\n",
      "17065 [D loss: (0.634)(R 0.714, F 0.554)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.103] [G acc: 0.375]\n",
      "17066 [D loss: (0.663)(R 0.734, F 0.591)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.749] [G acc: 0.312]\n",
      "17067 [D loss: (0.655)(R 0.684, F 0.625)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.700] [G acc: 0.562]\n",
      "17068 [D loss: (0.641)(R 0.649, F 0.632)] [D acc: (0.750)(0.875, 0.625)] [G loss: 1.881] [G acc: 0.625]\n",
      "17069 [D loss: (0.482)(R 0.711, F 0.253)] [D acc: (0.750)(0.625, 0.875)] [G loss: 3.371] [G acc: 0.188]\n",
      "17070 [D loss: (0.684)(R 0.794, F 0.574)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.075] [G acc: 0.312]\n",
      "17071 [D loss: (0.600)(R 0.737, F 0.463)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.069] [G acc: 0.188]\n",
      "17072 [D loss: (0.622)(R 0.678, F 0.566)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.140] [G acc: 0.312]\n",
      "17073 [D loss: (0.600)(R 0.636, F 0.564)] [D acc: (0.781)(0.938, 0.625)] [G loss: 0.799] [G acc: 0.250]\n",
      "17074 [D loss: (0.582)(R 0.678, F 0.486)] [D acc: (0.875)(0.750, 1.000)] [G loss: 1.376] [G acc: 0.062]\n",
      "17075 [D loss: (0.563)(R 0.645, F 0.481)] [D acc: (0.875)(0.938, 0.812)] [G loss: 1.029] [G acc: 0.250]\n",
      "17076 [D loss: (0.591)(R 0.690, F 0.493)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.191] [G acc: 0.125]\n",
      "17077 [D loss: (0.598)(R 0.722, F 0.473)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.911] [G acc: 0.250]\n",
      "17078 [D loss: (0.690)(R 0.840, F 0.539)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.277] [G acc: 0.125]\n",
      "17079 [D loss: (0.606)(R 0.701, F 0.510)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.731] [G acc: 0.375]\n",
      "17080 [D loss: (0.521)(R 0.712, F 0.331)] [D acc: (0.781)(0.688, 0.875)] [G loss: 2.111] [G acc: 0.188]\n",
      "17081 [D loss: (0.637)(R 0.915, F 0.358)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.070] [G acc: 0.188]\n",
      "17082 [D loss: (0.612)(R 0.752, F 0.472)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.043] [G acc: 0.188]\n",
      "17083 [D loss: (0.544)(R 0.619, F 0.470)] [D acc: (0.875)(0.938, 0.812)] [G loss: 0.905] [G acc: 0.188]\n",
      "17084 [D loss: (0.599)(R 0.741, F 0.458)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.003] [G acc: 0.250]\n",
      "17085 [D loss: (0.594)(R 0.681, F 0.507)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.103] [G acc: 0.250]\n",
      "17086 [D loss: (0.529)(R 0.658, F 0.399)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.093] [G acc: 0.062]\n",
      "17087 [D loss: (0.634)(R 0.759, F 0.510)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.030] [G acc: 0.062]\n",
      "17088 [D loss: (0.612)(R 0.671, F 0.554)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.096] [G acc: 0.188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17089 [D loss: (0.594)(R 0.675, F 0.513)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.538] [G acc: 0.188]\n",
      "17090 [D loss: (0.596)(R 0.686, F 0.506)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.242] [G acc: 0.250]\n",
      "17091 [D loss: (0.632)(R 0.740, F 0.525)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.921] [G acc: 0.188]\n",
      "17092 [D loss: (0.559)(R 0.632, F 0.485)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.039] [G acc: 0.250]\n",
      "17093 [D loss: (0.676)(R 0.802, F 0.550)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.358] [G acc: 0.188]\n",
      "17094 [D loss: (0.579)(R 0.668, F 0.491)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.065] [G acc: 0.312]\n",
      "17095 [D loss: (0.633)(R 0.740, F 0.526)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.243] [G acc: 0.125]\n",
      "17096 [D loss: (0.701)(R 0.898, F 0.503)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.486] [G acc: 0.375]\n",
      "17097 [D loss: (0.428)(R 0.740, F 0.116)] [D acc: (0.688)(0.500, 0.875)] [G loss: 2.642] [G acc: 0.125]\n",
      "17098 [D loss: (0.569)(R 0.608, F 0.531)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.624] [G acc: 0.375]\n",
      "17099 [D loss: (0.448)(R 0.645, F 0.251)] [D acc: (0.906)(0.875, 0.938)] [G loss: 1.361] [G acc: 0.125]\n",
      "17100 [D loss: (0.524)(R 0.663, F 0.385)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.309] [G acc: 0.312]\n",
      "17101 [D loss: (0.625)(R 0.764, F 0.485)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.328] [G acc: 0.250]\n",
      "17102 [D loss: (0.539)(R 0.638, F 0.440)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.901] [G acc: 0.312]\n",
      "17103 [D loss: (0.504)(R 0.608, F 0.400)] [D acc: (0.844)(0.938, 0.750)] [G loss: 1.104] [G acc: 0.188]\n",
      "17104 [D loss: (0.592)(R 0.697, F 0.486)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.130] [G acc: 0.250]\n",
      "17105 [D loss: (0.626)(R 0.808, F 0.443)] [D acc: (0.812)(0.750, 0.875)] [G loss: 5.447] [G acc: 0.375]\n",
      "17106 [D loss: (0.464)(R 0.644, F 0.284)] [D acc: (0.781)(0.750, 0.812)] [G loss: 2.471] [G acc: 0.375]\n",
      "17107 [D loss: (0.480)(R 0.621, F 0.339)] [D acc: (0.938)(0.938, 0.938)] [G loss: 1.943] [G acc: 0.188]\n",
      "17108 [D loss: (0.544)(R 0.717, F 0.371)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.524] [G acc: 0.312]\n",
      "17109 [D loss: (0.484)(R 0.650, F 0.317)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.265] [G acc: 0.250]\n",
      "17110 [D loss: (0.531)(R 0.698, F 0.364)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.408] [G acc: 0.250]\n",
      "17111 [D loss: (0.619)(R 0.779, F 0.458)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.421] [G acc: 0.375]\n",
      "17112 [D loss: (1.058)(R 1.717, F 0.399)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.865] [G acc: 0.375]\n",
      "17113 [D loss: (0.790)(R 1.010, F 0.569)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.318] [G acc: 0.188]\n",
      "17114 [D loss: (0.569)(R 0.606, F 0.531)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.971] [G acc: 0.312]\n",
      "17115 [D loss: (0.589)(R 0.664, F 0.514)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.744] [G acc: 0.500]\n",
      "17116 [D loss: (0.604)(R 0.649, F 0.558)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.972] [G acc: 0.312]\n",
      "17117 [D loss: (0.570)(R 0.646, F 0.494)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.199] [G acc: 0.125]\n",
      "17118 [D loss: (0.705)(R 0.876, F 0.533)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.035] [G acc: 0.375]\n",
      "17119 [D loss: (0.637)(R 0.707, F 0.566)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.956] [G acc: 0.375]\n",
      "17120 [D loss: (0.582)(R 0.652, F 0.512)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.004] [G acc: 0.312]\n",
      "17121 [D loss: (0.544)(R 0.611, F 0.477)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.914] [G acc: 0.312]\n",
      "17122 [D loss: (0.638)(R 0.796, F 0.479)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.202] [G acc: 0.188]\n",
      "17123 [D loss: (0.681)(R 0.909, F 0.454)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.971] [G acc: 0.375]\n",
      "17124 [D loss: (0.552)(R 0.600, F 0.503)] [D acc: (0.750)(0.938, 0.562)] [G loss: 0.756] [G acc: 0.500]\n",
      "17125 [D loss: (0.627)(R 0.661, F 0.594)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.722] [G acc: 0.438]\n",
      "17126 [D loss: (0.639)(R 0.594, F 0.684)] [D acc: (0.688)(0.875, 0.500)] [G loss: 1.167] [G acc: 0.250]\n",
      "17127 [D loss: (0.617)(R 0.691, F 0.544)] [D acc: (0.500)(0.625, 0.375)] [G loss: 2.350] [G acc: 0.312]\n",
      "17128 [D loss: (0.459)(R 0.695, F 0.223)] [D acc: (0.750)(0.625, 0.875)] [G loss: 3.527] [G acc: 0.188]\n",
      "17129 [D loss: (0.476)(R 0.605, F 0.347)] [D acc: (0.812)(0.875, 0.750)] [G loss: 5.362] [G acc: 0.188]\n",
      "17130 [D loss: (0.572)(R 0.562, F 0.582)] [D acc: (0.688)(0.812, 0.562)] [G loss: 1.111] [G acc: 0.312]\n",
      "17131 [D loss: (0.601)(R 0.656, F 0.546)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.081] [G acc: 0.250]\n",
      "17132 [D loss: (0.632)(R 0.812, F 0.453)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.271] [G acc: 0.375]\n",
      "17133 [D loss: (0.546)(R 0.652, F 0.440)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.014] [G acc: 0.438]\n",
      "17134 [D loss: (0.731)(R 0.771, F 0.692)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.913] [G acc: 0.312]\n",
      "17135 [D loss: (0.605)(R 0.614, F 0.596)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.797] [G acc: 0.312]\n",
      "17136 [D loss: (0.668)(R 0.670, F 0.665)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.888] [G acc: 0.250]\n",
      "17137 [D loss: (0.617)(R 0.632, F 0.602)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.041] [G acc: 0.250]\n",
      "17138 [D loss: (0.721)(R 0.774, F 0.667)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.895] [G acc: 0.188]\n",
      "17139 [D loss: (0.690)(R 0.696, F 0.684)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.731] [G acc: 0.562]\n",
      "17140 [D loss: (0.717)(R 0.825, F 0.609)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.712] [G acc: 0.438]\n",
      "17141 [D loss: (0.646)(R 0.635, F 0.656)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.854] [G acc: 0.500]\n",
      "17142 [D loss: (0.675)(R 0.636, F 0.714)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.838] [G acc: 0.500]\n",
      "17143 [D loss: (0.806)(R 1.012, F 0.599)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.858] [G acc: 0.188]\n",
      "17144 [D loss: (0.681)(R 0.598, F 0.764)] [D acc: (0.500)(0.750, 0.250)] [G loss: 1.098] [G acc: 0.188]\n",
      "17145 [D loss: (0.542)(R 0.576, F 0.507)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.994] [G acc: 0.438]\n",
      "17146 [D loss: (0.609)(R 0.671, F 0.547)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.154] [G acc: 0.375]\n",
      "17147 [D loss: (0.574)(R 0.733, F 0.415)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.870] [G acc: 0.375]\n",
      "17148 [D loss: (0.785)(R 0.863, F 0.707)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.796] [G acc: 0.500]\n",
      "17149 [D loss: (0.582)(R 0.512, F 0.651)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.799] [G acc: 0.625]\n",
      "17150 [D loss: (0.639)(R 0.652, F 0.626)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.824] [G acc: 0.375]\n",
      "17151 [D loss: (0.639)(R 0.650, F 0.629)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.839] [G acc: 0.500]\n",
      "17152 [D loss: (0.639)(R 0.594, F 0.684)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.836] [G acc: 0.312]\n",
      "17153 [D loss: (0.627)(R 0.582, F 0.673)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.843] [G acc: 0.438]\n",
      "17154 [D loss: (0.725)(R 0.626, F 0.825)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.964] [G acc: 0.188]\n",
      "17155 [D loss: (0.711)(R 0.794, F 0.629)] [D acc: (0.406)(0.312, 0.500)] [G loss: 1.082] [G acc: 0.562]\n",
      "17156 [D loss: (0.581)(R 0.683, F 0.479)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.604] [G acc: 0.438]\n",
      "17157 [D loss: (0.574)(R 0.669, F 0.480)] [D acc: (0.625)(0.625, 0.625)] [G loss: 6.086] [G acc: 0.125]\n",
      "17158 [D loss: (0.606)(R 0.699, F 0.512)] [D acc: (0.594)(0.688, 0.500)] [G loss: 2.368] [G acc: 0.438]\n",
      "17159 [D loss: (1.096)(R 1.515, F 0.677)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.803] [G acc: 0.438]\n",
      "17160 [D loss: (0.722)(R 0.905, F 0.540)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.742] [G acc: 0.688]\n",
      "17161 [D loss: (0.707)(R 0.786, F 0.628)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.718] [G acc: 0.562]\n",
      "17162 [D loss: (0.609)(R 0.590, F 0.628)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.710] [G acc: 0.625]\n",
      "17163 [D loss: (0.640)(R 0.649, F 0.630)] [D acc: (0.562)(0.625, 0.500)] [G loss: 1.047] [G acc: 0.500]\n",
      "17164 [D loss: (0.608)(R 0.525, F 0.691)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.789] [G acc: 0.312]\n",
      "17165 [D loss: (0.657)(R 0.619, F 0.695)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.748] [G acc: 0.625]\n",
      "17166 [D loss: (1.241)(R 1.805, F 0.678)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.822] [G acc: 0.562]\n",
      "17167 [D loss: (0.665)(R 0.561, F 0.769)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.652] [G acc: 0.688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17168 [D loss: (0.693)(R 0.612, F 0.774)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.679] [G acc: 0.750]\n",
      "17169 [D loss: (0.675)(R 0.631, F 0.719)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.705] [G acc: 0.688]\n",
      "17170 [D loss: (0.651)(R 0.564, F 0.738)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.908] [G acc: 0.688]\n",
      "17171 [D loss: (0.686)(R 0.648, F 0.725)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.637] [G acc: 0.688]\n",
      "17172 [D loss: (0.711)(R 0.761, F 0.662)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.789] [G acc: 0.438]\n",
      "17173 [D loss: (0.708)(R 0.655, F 0.761)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.742] [G acc: 0.438]\n",
      "17174 [D loss: (0.679)(R 0.624, F 0.733)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.754] [G acc: 0.500]\n",
      "17175 [D loss: (0.639)(R 0.642, F 0.636)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.763] [G acc: 0.438]\n",
      "17176 [D loss: (0.810)(R 0.780, F 0.841)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.743] [G acc: 0.438]\n",
      "17177 [D loss: (0.639)(R 0.551, F 0.728)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.779] [G acc: 0.438]\n",
      "17178 [D loss: (0.711)(R 0.717, F 0.705)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.674] [G acc: 0.625]\n",
      "17179 [D loss: (0.671)(R 0.658, F 0.684)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.716] [G acc: 0.500]\n",
      "17180 [D loss: (0.683)(R 0.702, F 0.665)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.756] [G acc: 0.562]\n",
      "17181 [D loss: (0.722)(R 0.713, F 0.730)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.700] [G acc: 0.500]\n",
      "17182 [D loss: (0.748)(R 0.745, F 0.752)] [D acc: (0.344)(0.438, 0.250)] [G loss: 0.732] [G acc: 0.562]\n",
      "17183 [D loss: (0.837)(R 0.666, F 1.008)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.706] [G acc: 0.625]\n",
      "17184 [D loss: (0.687)(R 0.652, F 0.722)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.592] [G acc: 0.938]\n",
      "17185 [D loss: (0.705)(R 0.694, F 0.716)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.942] [G acc: 0.562]\n",
      "17186 [D loss: (0.629)(R 0.681, F 0.577)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.951] [G acc: 0.562]\n",
      "17187 [D loss: (0.699)(R 0.651, F 0.746)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.700] [G acc: 0.750]\n",
      "17188 [D loss: (0.661)(R 0.653, F 0.668)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.733] [G acc: 0.625]\n",
      "17189 [D loss: (0.639)(R 0.604, F 0.674)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.638] [G acc: 0.688]\n",
      "17190 [D loss: (0.703)(R 0.685, F 0.720)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.697] [G acc: 0.688]\n",
      "17191 [D loss: (0.621)(R 0.542, F 0.700)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.663] [G acc: 0.812]\n",
      "17192 [D loss: (0.745)(R 0.814, F 0.677)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.675] [G acc: 0.688]\n",
      "17193 [D loss: (0.634)(R 0.575, F 0.692)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.655] [G acc: 0.750]\n",
      "17194 [D loss: (0.663)(R 0.563, F 0.763)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.688] [G acc: 0.625]\n",
      "17195 [D loss: (0.713)(R 0.723, F 0.702)] [D acc: (0.406)(0.500, 0.312)] [G loss: 0.679] [G acc: 0.500]\n",
      "17196 [D loss: (0.721)(R 0.645, F 0.798)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.698] [G acc: 0.750]\n",
      "17197 [D loss: (0.663)(R 0.563, F 0.763)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.739] [G acc: 0.500]\n",
      "17198 [D loss: (0.651)(R 0.634, F 0.668)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.672] [G acc: 0.625]\n",
      "17199 [D loss: (0.683)(R 0.654, F 0.712)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.735] [G acc: 0.688]\n",
      "17200 [D loss: (0.716)(R 0.716, F 0.716)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.804] [G acc: 0.438]\n",
      "17201 [D loss: (0.721)(R 0.705, F 0.737)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.667] [G acc: 0.750]\n",
      "17202 [D loss: (0.696)(R 0.622, F 0.770)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.719] [G acc: 0.625]\n",
      "17203 [D loss: (0.660)(R 0.594, F 0.726)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.793] [G acc: 0.625]\n",
      "17204 [D loss: (0.678)(R 0.676, F 0.681)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.719] [G acc: 0.688]\n",
      "17205 [D loss: (0.738)(R 0.659, F 0.817)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.786] [G acc: 0.438]\n",
      "17206 [D loss: (0.710)(R 0.724, F 0.697)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.733] [G acc: 0.500]\n",
      "17207 [D loss: (0.607)(R 0.601, F 0.612)] [D acc: (0.656)(0.812, 0.500)] [G loss: 1.038] [G acc: 0.625]\n",
      "17208 [D loss: (0.499)(R 0.660, F 0.337)] [D acc: (0.656)(0.562, 0.750)] [G loss: 3.388] [G acc: 0.188]\n",
      "17209 [D loss: (0.574)(R 0.598, F 0.549)] [D acc: (0.594)(0.750, 0.438)] [G loss: 1.276] [G acc: 0.500]\n",
      "17210 [D loss: (0.644)(R 0.575, F 0.713)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.934] [G acc: 0.438]\n",
      "17211 [D loss: (0.658)(R 0.554, F 0.763)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.749] [G acc: 0.500]\n",
      "17212 [D loss: (0.635)(R 0.592, F 0.677)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.670] [G acc: 0.750]\n",
      "17213 [D loss: (0.653)(R 0.611, F 0.695)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.707] [G acc: 0.562]\n",
      "17214 [D loss: (0.753)(R 0.718, F 0.788)] [D acc: (0.250)(0.375, 0.125)] [G loss: 0.710] [G acc: 0.688]\n",
      "17215 [D loss: (0.742)(R 0.664, F 0.819)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.695] [G acc: 0.812]\n",
      "17216 [D loss: (0.618)(R 0.513, F 0.723)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.705] [G acc: 0.500]\n",
      "17217 [D loss: (0.670)(R 0.599, F 0.742)] [D acc: (0.531)(0.812, 0.250)] [G loss: 1.228] [G acc: 0.688]\n",
      "17218 [D loss: (0.700)(R 0.627, F 0.772)] [D acc: (0.438)(0.688, 0.188)] [G loss: 0.755] [G acc: 0.562]\n",
      "17219 [D loss: (0.684)(R 0.595, F 0.774)] [D acc: (0.562)(0.938, 0.188)] [G loss: 0.828] [G acc: 0.312]\n",
      "17220 [D loss: (0.695)(R 0.630, F 0.760)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.706] [G acc: 0.500]\n",
      "17221 [D loss: (0.679)(R 0.598, F 0.760)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.651] [G acc: 0.750]\n",
      "17222 [D loss: (0.534)(R 0.462, F 0.605)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.745] [G acc: 0.562]\n",
      "17223 [D loss: (0.705)(R 0.534, F 0.875)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.641] [G acc: 0.812]\n",
      "17224 [D loss: (0.840)(R 0.798, F 0.882)] [D acc: (0.344)(0.625, 0.062)] [G loss: 0.660] [G acc: 0.750]\n",
      "17225 [D loss: (0.695)(R 0.615, F 0.776)] [D acc: (0.438)(0.812, 0.062)] [G loss: 0.665] [G acc: 0.625]\n",
      "17226 [D loss: (0.655)(R 0.541, F 0.769)] [D acc: (0.438)(0.688, 0.188)] [G loss: 0.686] [G acc: 0.688]\n",
      "17227 [D loss: (0.763)(R 0.791, F 0.735)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.644] [G acc: 0.625]\n",
      "17228 [D loss: (0.647)(R 0.528, F 0.765)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.706] [G acc: 0.562]\n",
      "17229 [D loss: (0.699)(R 0.607, F 0.790)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.659] [G acc: 0.750]\n",
      "17230 [D loss: (0.696)(R 0.637, F 0.756)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.609] [G acc: 0.750]\n",
      "17231 [D loss: (0.685)(R 0.594, F 0.777)] [D acc: (0.406)(0.688, 0.125)] [G loss: 0.826] [G acc: 0.625]\n",
      "17232 [D loss: (0.671)(R 0.575, F 0.766)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.707] [G acc: 0.750]\n",
      "17233 [D loss: (0.678)(R 0.570, F 0.787)] [D acc: (0.594)(1.000, 0.188)] [G loss: 0.654] [G acc: 0.750]\n",
      "17234 [D loss: (0.665)(R 0.566, F 0.765)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.604] [G acc: 0.875]\n",
      "17235 [D loss: (0.665)(R 0.567, F 0.763)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.678] [G acc: 0.750]\n",
      "17236 [D loss: (0.684)(R 0.585, F 0.784)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.611] [G acc: 0.750]\n",
      "17237 [D loss: (0.768)(R 0.574, F 0.962)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.633] [G acc: 0.812]\n",
      "17238 [D loss: (0.709)(R 0.678, F 0.740)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.592] [G acc: 0.875]\n",
      "17239 [D loss: (0.713)(R 0.608, F 0.818)] [D acc: (0.438)(0.688, 0.188)] [G loss: 0.690] [G acc: 0.688]\n",
      "17240 [D loss: (0.672)(R 0.657, F 0.687)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.665] [G acc: 0.750]\n",
      "17241 [D loss: (0.701)(R 0.580, F 0.822)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.591] [G acc: 0.688]\n",
      "17242 [D loss: (0.711)(R 0.613, F 0.809)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.694] [G acc: 0.500]\n",
      "17243 [D loss: (0.675)(R 0.556, F 0.795)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.712] [G acc: 0.625]\n",
      "17244 [D loss: (0.657)(R 0.608, F 0.706)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.693] [G acc: 0.688]\n",
      "17245 [D loss: (0.736)(R 0.614, F 0.858)] [D acc: (0.438)(0.812, 0.062)] [G loss: 0.636] [G acc: 0.812]\n",
      "17246 [D loss: (0.647)(R 0.523, F 0.770)] [D acc: (0.562)(0.938, 0.188)] [G loss: 0.585] [G acc: 0.812]\n",
      "17247 [D loss: (0.700)(R 0.593, F 0.806)] [D acc: (0.594)(0.812, 0.375)] [G loss: 1.019] [G acc: 0.438]\n",
      "17248 [D loss: (0.510)(R 0.610, F 0.410)] [D acc: (0.562)(0.562, 0.562)] [G loss: 2.438] [G acc: 0.375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17249 [D loss: (0.656)(R 0.594, F 0.717)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.701] [G acc: 0.750]\n",
      "17250 [D loss: (0.751)(R 0.793, F 0.710)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.690] [G acc: 0.562]\n",
      "17251 [D loss: (0.662)(R 0.617, F 0.707)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.716] [G acc: 0.500]\n",
      "17252 [D loss: (0.672)(R 0.618, F 0.726)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.703] [G acc: 0.688]\n",
      "17253 [D loss: (0.720)(R 0.603, F 0.837)] [D acc: (0.406)(0.688, 0.125)] [G loss: 0.749] [G acc: 0.375]\n",
      "17254 [D loss: (0.665)(R 0.631, F 0.699)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.630] [G acc: 0.875]\n",
      "17255 [D loss: (0.697)(R 0.628, F 0.766)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.682] [G acc: 0.688]\n",
      "17256 [D loss: (0.638)(R 0.634, F 0.641)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.658] [G acc: 0.812]\n",
      "17257 [D loss: (0.685)(R 0.621, F 0.749)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.683] [G acc: 0.750]\n",
      "17258 [D loss: (0.648)(R 0.584, F 0.712)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.642] [G acc: 0.688]\n",
      "17259 [D loss: (0.725)(R 0.597, F 0.853)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.669] [G acc: 0.562]\n",
      "17260 [D loss: (0.647)(R 0.613, F 0.680)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.647] [G acc: 0.688]\n",
      "17261 [D loss: (0.713)(R 0.615, F 0.811)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.612] [G acc: 0.688]\n",
      "17262 [D loss: (0.702)(R 0.629, F 0.776)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.621] [G acc: 0.812]\n",
      "17263 [D loss: (0.730)(R 0.692, F 0.769)] [D acc: (0.438)(0.688, 0.188)] [G loss: 0.697] [G acc: 0.750]\n",
      "17264 [D loss: (0.677)(R 0.656, F 0.698)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.656] [G acc: 0.562]\n",
      "17265 [D loss: (0.771)(R 0.594, F 0.948)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.639] [G acc: 0.750]\n",
      "17266 [D loss: (0.690)(R 0.674, F 0.707)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.743] [G acc: 0.562]\n",
      "17267 [D loss: (0.706)(R 0.615, F 0.798)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.660] [G acc: 0.688]\n",
      "17268 [D loss: (0.671)(R 0.576, F 0.765)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.553] [G acc: 0.938]\n",
      "17269 [D loss: (0.850)(R 0.654, F 1.046)] [D acc: (0.406)(0.812, 0.000)] [G loss: 0.778] [G acc: 0.438]\n",
      "17270 [D loss: (0.678)(R 0.625, F 0.732)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.786] [G acc: 0.562]\n",
      "17271 [D loss: (0.732)(R 0.667, F 0.798)] [D acc: (0.375)(0.625, 0.125)] [G loss: 0.827] [G acc: 0.500]\n",
      "17272 [D loss: (0.820)(R 0.677, F 0.964)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.722] [G acc: 0.625]\n",
      "17273 [D loss: (0.748)(R 0.855, F 0.642)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.865] [G acc: 0.562]\n",
      "17274 [D loss: (0.740)(R 0.653, F 0.827)] [D acc: (0.438)(0.625, 0.250)] [G loss: 2.424] [G acc: 0.375]\n",
      "17275 [D loss: (0.609)(R 0.788, F 0.431)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.745] [G acc: 0.438]\n",
      "17276 [D loss: (0.643)(R 0.666, F 0.620)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.761] [G acc: 0.438]\n",
      "17277 [D loss: (0.644)(R 0.653, F 0.634)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.685] [G acc: 0.625]\n",
      "17278 [D loss: (0.673)(R 0.706, F 0.639)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.756] [G acc: 0.562]\n",
      "17279 [D loss: (0.674)(R 0.675, F 0.673)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.790] [G acc: 0.438]\n",
      "17280 [D loss: (0.645)(R 0.631, F 0.658)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.699] [G acc: 0.500]\n",
      "17281 [D loss: (0.680)(R 0.691, F 0.669)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.718] [G acc: 0.500]\n",
      "17282 [D loss: (0.650)(R 0.633, F 0.667)] [D acc: (0.625)(0.750, 0.500)] [G loss: 1.072] [G acc: 0.250]\n",
      "17283 [D loss: (0.742)(R 0.748, F 0.735)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.679] [G acc: 0.625]\n",
      "17284 [D loss: (0.717)(R 0.685, F 0.749)] [D acc: (0.375)(0.625, 0.125)] [G loss: 0.651] [G acc: 0.750]\n",
      "17285 [D loss: (0.680)(R 0.607, F 0.753)] [D acc: (0.469)(0.875, 0.062)] [G loss: 0.636] [G acc: 0.750]\n",
      "17286 [D loss: (0.700)(R 0.679, F 0.722)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.715] [G acc: 0.562]\n",
      "17287 [D loss: (0.695)(R 0.675, F 0.716)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.645] [G acc: 0.750]\n",
      "17288 [D loss: (0.663)(R 0.591, F 0.735)] [D acc: (0.500)(0.875, 0.125)] [G loss: 0.652] [G acc: 0.688]\n",
      "17289 [D loss: (0.618)(R 0.544, F 0.691)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.680] [G acc: 0.750]\n",
      "17290 [D loss: (0.678)(R 0.626, F 0.730)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.662] [G acc: 0.750]\n",
      "17291 [D loss: (0.718)(R 0.710, F 0.725)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.651] [G acc: 0.688]\n",
      "17292 [D loss: (0.698)(R 0.605, F 0.792)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.663] [G acc: 0.750]\n",
      "17293 [D loss: (0.664)(R 0.600, F 0.727)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.677] [G acc: 0.688]\n",
      "17294 [D loss: (0.657)(R 0.594, F 0.719)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.720] [G acc: 0.500]\n",
      "17295 [D loss: (0.711)(R 0.695, F 0.727)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.701] [G acc: 0.562]\n",
      "17296 [D loss: (0.706)(R 0.619, F 0.792)] [D acc: (0.406)(0.562, 0.250)] [G loss: 1.017] [G acc: 0.625]\n",
      "17297 [D loss: (0.671)(R 0.705, F 0.638)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.795] [G acc: 0.500]\n",
      "17298 [D loss: (0.649)(R 0.587, F 0.711)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.721] [G acc: 0.438]\n",
      "17299 [D loss: (0.663)(R 0.663, F 0.663)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.780] [G acc: 0.438]\n",
      "17300 [D loss: (0.702)(R 0.713, F 0.690)] [D acc: (0.406)(0.375, 0.438)] [G loss: 0.733] [G acc: 0.438]\n",
      "17301 [D loss: (0.689)(R 0.673, F 0.704)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.684] [G acc: 0.562]\n",
      "17302 [D loss: (0.652)(R 0.622, F 0.682)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.712] [G acc: 0.438]\n",
      "17303 [D loss: (0.682)(R 0.656, F 0.707)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.733] [G acc: 0.438]\n",
      "17304 [D loss: (0.635)(R 0.600, F 0.669)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.709] [G acc: 0.562]\n",
      "17305 [D loss: (0.653)(R 0.599, F 0.707)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.716] [G acc: 0.438]\n",
      "17306 [D loss: (0.646)(R 0.598, F 0.694)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.649] [G acc: 0.688]\n",
      "17307 [D loss: (0.719)(R 0.587, F 0.851)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.546] [G acc: 0.750]\n",
      "17308 [D loss: (0.761)(R 0.567, F 0.955)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.591] [G acc: 0.438]\n",
      "17309 [D loss: (0.641)(R 0.639, F 0.643)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.819] [G acc: 0.500]\n",
      "17310 [D loss: (0.576)(R 0.551, F 0.602)] [D acc: (0.719)(0.875, 0.562)] [G loss: 1.780] [G acc: 0.250]\n",
      "17311 [D loss: (0.585)(R 0.680, F 0.489)] [D acc: (0.656)(0.688, 0.625)] [G loss: 2.460] [G acc: 0.188]\n",
      "17312 [D loss: (0.621)(R 0.656, F 0.587)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.045] [G acc: 0.250]\n",
      "17313 [D loss: (0.641)(R 0.552, F 0.731)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.767] [G acc: 0.438]\n",
      "17314 [D loss: (0.651)(R 0.657, F 0.646)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.734] [G acc: 0.438]\n",
      "17315 [D loss: (0.629)(R 0.635, F 0.624)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.839] [G acc: 0.312]\n",
      "17316 [D loss: (0.615)(R 0.604, F 0.626)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.824] [G acc: 0.375]\n",
      "17317 [D loss: (0.680)(R 0.716, F 0.644)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.785] [G acc: 0.375]\n",
      "17318 [D loss: (0.670)(R 0.678, F 0.661)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.793] [G acc: 0.062]\n",
      "17319 [D loss: (0.685)(R 0.647, F 0.724)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.781] [G acc: 0.188]\n",
      "17320 [D loss: (0.600)(R 0.536, F 0.663)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.725] [G acc: 0.438]\n",
      "17321 [D loss: (0.653)(R 0.631, F 0.674)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.661] [G acc: 0.625]\n",
      "17322 [D loss: (0.731)(R 0.729, F 0.733)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.732] [G acc: 0.375]\n",
      "17323 [D loss: (0.690)(R 0.656, F 0.724)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.707] [G acc: 0.562]\n",
      "17324 [D loss: (0.645)(R 0.580, F 0.710)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.700] [G acc: 0.688]\n",
      "17325 [D loss: (0.705)(R 0.579, F 0.831)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.733] [G acc: 0.500]\n",
      "17326 [D loss: (0.952)(R 0.957, F 0.948)] [D acc: (0.344)(0.312, 0.375)] [G loss: 0.727] [G acc: 0.500]\n",
      "17327 [D loss: (0.681)(R 0.608, F 0.755)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.680] [G acc: 0.625]\n",
      "17328 [D loss: (0.794)(R 0.660, F 0.929)] [D acc: (0.375)(0.562, 0.188)] [G loss: 0.657] [G acc: 0.500]\n",
      "17329 [D loss: (0.677)(R 0.658, F 0.696)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.666] [G acc: 0.438]\n",
      "17330 [D loss: (0.679)(R 0.627, F 0.732)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.707] [G acc: 0.500]\n",
      "17331 [D loss: (0.830)(R 0.742, F 0.918)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.617] [G acc: 0.562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17332 [D loss: (0.889)(R 0.674, F 1.104)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.711] [G acc: 0.438]\n",
      "17333 [D loss: (0.807)(R 0.728, F 0.886)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.674] [G acc: 0.500]\n",
      "17334 [D loss: (0.732)(R 0.723, F 0.741)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.555] [G acc: 0.625]\n",
      "17335 [D loss: (1.057)(R 0.743, F 1.372)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.608] [G acc: 0.625]\n",
      "17336 [D loss: (0.706)(R 0.677, F 0.734)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.713] [G acc: 0.562]\n",
      "17337 [D loss: (0.603)(R 0.758, F 0.448)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.959] [G acc: 0.188]\n",
      "17338 [D loss: (0.728)(R 0.702, F 0.755)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.658] [G acc: 0.312]\n",
      "17339 [D loss: (0.740)(R 0.888, F 0.592)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.756] [G acc: 0.438]\n",
      "17340 [D loss: (0.677)(R 0.699, F 0.656)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.735] [G acc: 0.562]\n",
      "17341 [D loss: (0.680)(R 0.785, F 0.575)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.934] [G acc: 0.500]\n",
      "17342 [D loss: (0.673)(R 0.690, F 0.656)] [D acc: (0.500)(0.562, 0.438)] [G loss: 1.646] [G acc: 0.438]\n",
      "17343 [D loss: (0.772)(R 0.580, F 0.964)] [D acc: (0.656)(0.812, 0.500)] [G loss: 1.767] [G acc: 0.250]\n",
      "17344 [D loss: (0.730)(R 0.747, F 0.714)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.714] [G acc: 0.562]\n",
      "17345 [D loss: (0.761)(R 0.823, F 0.700)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.778] [G acc: 0.188]\n",
      "17346 [D loss: (0.913)(R 1.150, F 0.675)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.715] [G acc: 0.500]\n",
      "17347 [D loss: (0.667)(R 0.664, F 0.671)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.719] [G acc: 0.312]\n",
      "17348 [D loss: (0.704)(R 0.656, F 0.752)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.721] [G acc: 0.438]\n",
      "17349 [D loss: (0.879)(R 0.684, F 1.074)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.935] [G acc: 0.250]\n",
      "17350 [D loss: (0.635)(R 0.571, F 0.698)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.721] [G acc: 0.500]\n",
      "17351 [D loss: (0.635)(R 0.638, F 0.632)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.739] [G acc: 0.438]\n",
      "17352 [D loss: (0.702)(R 0.744, F 0.660)] [D acc: (0.406)(0.312, 0.500)] [G loss: 0.692] [G acc: 0.500]\n",
      "17353 [D loss: (0.693)(R 0.696, F 0.690)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.653] [G acc: 0.688]\n",
      "17354 [D loss: (0.630)(R 0.602, F 0.657)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.848] [G acc: 0.312]\n",
      "17355 [D loss: (0.678)(R 0.711, F 0.644)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.743] [G acc: 0.312]\n",
      "17356 [D loss: (0.681)(R 0.693, F 0.669)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.718] [G acc: 0.500]\n",
      "17357 [D loss: (0.656)(R 0.630, F 0.681)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.893] [G acc: 0.500]\n",
      "17358 [D loss: (0.713)(R 0.823, F 0.604)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.877] [G acc: 0.188]\n",
      "17359 [D loss: (0.651)(R 0.675, F 0.627)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.773] [G acc: 0.438]\n",
      "17360 [D loss: (0.616)(R 0.638, F 0.595)] [D acc: (0.844)(0.875, 0.812)] [G loss: 0.892] [G acc: 0.125]\n",
      "17361 [D loss: (0.667)(R 0.748, F 0.585)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.866] [G acc: 0.312]\n",
      "17362 [D loss: (0.660)(R 0.664, F 0.655)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.815] [G acc: 0.125]\n",
      "17363 [D loss: (0.691)(R 0.747, F 0.635)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.813] [G acc: 0.250]\n",
      "17364 [D loss: (0.716)(R 0.716, F 0.716)] [D acc: (0.406)(0.500, 0.312)] [G loss: 0.685] [G acc: 0.562]\n",
      "17365 [D loss: (0.670)(R 0.703, F 0.636)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.732] [G acc: 0.375]\n",
      "17366 [D loss: (0.696)(R 0.721, F 0.671)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.774] [G acc: 0.125]\n",
      "17367 [D loss: (0.664)(R 0.702, F 0.626)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.731] [G acc: 0.438]\n",
      "17368 [D loss: (0.655)(R 0.656, F 0.655)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.796] [G acc: 0.250]\n",
      "17369 [D loss: (0.653)(R 0.686, F 0.620)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.741] [G acc: 0.312]\n",
      "17370 [D loss: (0.702)(R 0.706, F 0.699)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.749] [G acc: 0.250]\n",
      "17371 [D loss: (0.677)(R 0.699, F 0.655)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.777] [G acc: 0.312]\n",
      "17372 [D loss: (0.621)(R 0.618, F 0.625)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.712] [G acc: 0.562]\n",
      "17373 [D loss: (0.639)(R 0.652, F 0.627)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.738] [G acc: 0.500]\n",
      "17374 [D loss: (0.654)(R 0.686, F 0.623)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.718] [G acc: 0.375]\n",
      "17375 [D loss: (0.670)(R 0.664, F 0.677)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.711] [G acc: 0.375]\n",
      "17376 [D loss: (0.632)(R 0.638, F 0.625)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.719] [G acc: 0.562]\n",
      "17377 [D loss: (0.616)(R 0.564, F 0.668)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.798] [G acc: 0.375]\n",
      "17378 [D loss: (0.585)(R 0.541, F 0.629)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.719] [G acc: 0.562]\n",
      "17379 [D loss: (0.646)(R 0.619, F 0.674)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.699] [G acc: 0.375]\n",
      "17380 [D loss: (0.617)(R 0.542, F 0.692)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.667] [G acc: 0.562]\n",
      "17381 [D loss: (0.622)(R 0.592, F 0.652)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.732] [G acc: 0.562]\n",
      "17382 [D loss: (0.562)(R 0.494, F 0.630)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.686] [G acc: 0.625]\n",
      "17383 [D loss: (0.597)(R 0.531, F 0.663)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.782] [G acc: 0.375]\n",
      "17384 [D loss: (0.981)(R 0.586, F 1.375)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.665] [G acc: 0.562]\n",
      "17385 [D loss: (0.730)(R 0.783, F 0.677)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.737] [G acc: 0.500]\n",
      "17386 [D loss: (0.642)(R 0.601, F 0.682)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.723] [G acc: 0.625]\n",
      "17387 [D loss: (0.902)(R 0.958, F 0.846)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.743] [G acc: 0.438]\n",
      "17388 [D loss: (0.596)(R 0.547, F 0.645)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.736] [G acc: 0.438]\n",
      "17389 [D loss: (0.697)(R 0.718, F 0.676)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.701] [G acc: 0.562]\n",
      "17390 [D loss: (0.663)(R 0.645, F 0.681)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.692] [G acc: 0.500]\n",
      "17391 [D loss: (0.682)(R 0.611, F 0.754)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.591] [G acc: 0.625]\n",
      "17392 [D loss: (0.605)(R 0.598, F 0.612)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.905] [G acc: 0.250]\n",
      "17393 [D loss: (0.512)(R 0.626, F 0.399)] [D acc: (0.656)(0.688, 0.625)] [G loss: 2.086] [G acc: 0.500]\n",
      "17394 [D loss: (0.410)(R 0.510, F 0.311)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.760] [G acc: 0.375]\n",
      "17395 [D loss: (0.605)(R 0.550, F 0.659)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.978] [G acc: 0.312]\n",
      "17396 [D loss: (0.744)(R 0.533, F 0.955)] [D acc: (0.656)(0.938, 0.375)] [G loss: 0.713] [G acc: 0.438]\n",
      "17397 [D loss: (0.623)(R 0.536, F 0.711)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.721] [G acc: 0.375]\n",
      "17398 [D loss: (0.606)(R 0.579, F 0.634)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.719] [G acc: 0.625]\n",
      "17399 [D loss: (0.546)(R 0.412, F 0.679)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.739] [G acc: 0.188]\n",
      "17400 [D loss: (0.709)(R 0.693, F 0.724)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.711] [G acc: 0.375]\n",
      "17401 [D loss: (0.609)(R 0.516, F 0.702)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.734] [G acc: 0.438]\n",
      "17402 [D loss: (0.659)(R 0.550, F 0.767)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.716] [G acc: 0.312]\n",
      "17403 [D loss: (0.880)(R 1.085, F 0.675)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.659] [G acc: 0.625]\n",
      "17404 [D loss: (0.631)(R 0.498, F 0.763)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.486] [G acc: 0.688]\n",
      "17405 [D loss: (0.578)(R 0.530, F 0.627)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.795] [G acc: 0.312]\n",
      "17406 [D loss: (0.689)(R 0.707, F 0.670)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.740] [G acc: 0.438]\n",
      "17407 [D loss: (0.616)(R 0.558, F 0.674)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.773] [G acc: 0.188]\n",
      "17408 [D loss: (0.647)(R 0.639, F 0.654)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.710] [G acc: 0.500]\n",
      "17409 [D loss: (0.761)(R 0.788, F 0.734)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.751] [G acc: 0.188]\n",
      "17410 [D loss: (0.582)(R 0.480, F 0.684)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.692] [G acc: 0.500]\n",
      "17411 [D loss: (0.633)(R 0.549, F 0.717)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.690] [G acc: 0.438]\n",
      "17412 [D loss: (0.630)(R 0.543, F 0.716)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.783] [G acc: 0.250]\n",
      "17413 [D loss: (0.618)(R 0.528, F 0.707)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.783] [G acc: 0.188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17414 [D loss: (0.668)(R 0.652, F 0.685)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.753] [G acc: 0.125]\n",
      "17415 [D loss: (0.632)(R 0.574, F 0.691)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.743] [G acc: 0.312]\n",
      "17416 [D loss: (0.718)(R 0.666, F 0.771)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.728] [G acc: 0.438]\n",
      "17417 [D loss: (0.665)(R 0.608, F 0.722)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.766] [G acc: 0.312]\n",
      "17418 [D loss: (0.620)(R 0.624, F 0.616)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.851] [G acc: 0.188]\n",
      "17419 [D loss: (0.564)(R 0.689, F 0.439)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.873] [G acc: 0.500]\n",
      "17420 [D loss: (0.672)(R 0.724, F 0.619)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.754] [G acc: 0.500]\n",
      "17421 [D loss: (0.659)(R 0.645, F 0.672)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.792] [G acc: 0.188]\n",
      "17422 [D loss: (0.824)(R 0.918, F 0.729)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.731] [G acc: 0.188]\n",
      "17423 [D loss: (0.623)(R 0.571, F 0.676)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.709] [G acc: 0.438]\n",
      "17424 [D loss: (0.636)(R 0.512, F 0.760)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.749] [G acc: 0.438]\n",
      "17425 [D loss: (0.591)(R 0.475, F 0.707)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.802] [G acc: 0.188]\n",
      "17426 [D loss: (0.707)(R 0.623, F 0.792)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.656] [G acc: 0.625]\n",
      "17427 [D loss: (0.996)(R 0.711, F 1.281)] [D acc: (0.281)(0.375, 0.188)] [G loss: 0.663] [G acc: 0.625]\n",
      "17428 [D loss: (0.693)(R 0.612, F 0.775)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.799] [G acc: 0.250]\n",
      "17429 [D loss: (0.547)(R 0.640, F 0.454)] [D acc: (0.688)(0.500, 0.875)] [G loss: 1.051] [G acc: 0.188]\n",
      "17430 [D loss: (0.643)(R 0.597, F 0.690)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.025] [G acc: 0.188]\n",
      "17431 [D loss: (0.716)(R 0.804, F 0.628)] [D acc: (0.500)(0.188, 0.812)] [G loss: 0.754] [G acc: 0.312]\n",
      "17432 [D loss: (0.646)(R 0.676, F 0.617)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.716] [G acc: 0.312]\n",
      "17433 [D loss: (0.693)(R 0.571, F 0.815)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.761] [G acc: 0.250]\n",
      "17434 [D loss: (0.742)(R 0.737, F 0.748)] [D acc: (0.406)(0.312, 0.500)] [G loss: 0.735] [G acc: 0.375]\n",
      "17435 [D loss: (0.940)(R 0.668, F 1.213)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.715] [G acc: 0.250]\n",
      "17436 [D loss: (0.775)(R 0.765, F 0.785)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.778] [G acc: 0.312]\n",
      "17437 [D loss: (0.622)(R 0.583, F 0.661)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.618] [G acc: 0.500]\n",
      "17438 [D loss: (0.659)(R 0.613, F 0.705)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.768] [G acc: 0.250]\n",
      "17439 [D loss: (0.640)(R 0.518, F 0.761)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.616] [G acc: 0.500]\n",
      "17440 [D loss: (1.256)(R 0.739, F 1.772)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.824] [G acc: 0.312]\n",
      "17441 [D loss: (0.739)(R 0.681, F 0.797)] [D acc: (0.625)(0.438, 0.812)] [G loss: 1.021] [G acc: 0.125]\n",
      "17442 [D loss: (0.707)(R 0.741, F 0.673)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.724] [G acc: 0.375]\n",
      "17443 [D loss: (0.766)(R 0.657, F 0.875)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.688] [G acc: 0.250]\n",
      "17444 [D loss: (0.880)(R 0.714, F 1.046)] [D acc: (0.406)(0.188, 0.625)] [G loss: 0.633] [G acc: 0.438]\n",
      "17445 [D loss: (1.093)(R 0.734, F 1.453)] [D acc: (0.344)(0.125, 0.562)] [G loss: 0.902] [G acc: 0.500]\n",
      "17446 [D loss: (0.704)(R 0.815, F 0.592)] [D acc: (0.531)(0.312, 0.750)] [G loss: 1.087] [G acc: 0.375]\n",
      "17447 [D loss: (1.055)(R 0.655, F 1.454)] [D acc: (0.438)(0.312, 0.562)] [G loss: 4.243] [G acc: 0.188]\n",
      "17448 [D loss: (0.631)(R 0.858, F 0.405)] [D acc: (0.562)(0.188, 0.938)] [G loss: 1.226] [G acc: 0.125]\n",
      "17449 [D loss: (0.716)(R 0.742, F 0.689)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.834] [G acc: 0.375]\n",
      "17450 [D loss: (0.822)(R 0.773, F 0.872)] [D acc: (0.344)(0.312, 0.375)] [G loss: 0.719] [G acc: 0.312]\n",
      "17451 [D loss: (0.760)(R 0.830, F 0.690)] [D acc: (0.344)(0.250, 0.438)] [G loss: 0.723] [G acc: 0.312]\n",
      "17452 [D loss: (0.795)(R 0.727, F 0.864)] [D acc: (0.375)(0.438, 0.312)] [G loss: 0.664] [G acc: 0.562]\n",
      "17453 [D loss: (0.779)(R 0.908, F 0.650)] [D acc: (0.375)(0.125, 0.625)] [G loss: 0.639] [G acc: 0.500]\n",
      "17454 [D loss: (0.733)(R 0.755, F 0.711)] [D acc: (0.250)(0.188, 0.312)] [G loss: 0.625] [G acc: 0.500]\n",
      "17455 [D loss: (0.782)(R 0.703, F 0.861)] [D acc: (0.406)(0.500, 0.312)] [G loss: 0.691] [G acc: 0.375]\n",
      "17456 [D loss: (0.707)(R 0.702, F 0.713)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.692] [G acc: 0.438]\n",
      "17457 [D loss: (0.734)(R 0.741, F 0.728)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.627] [G acc: 0.625]\n",
      "17458 [D loss: (0.690)(R 0.703, F 0.678)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.716] [G acc: 0.312]\n",
      "17459 [D loss: (0.811)(R 0.726, F 0.897)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.679] [G acc: 0.312]\n",
      "17460 [D loss: (0.734)(R 0.658, F 0.811)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.646] [G acc: 0.375]\n",
      "17461 [D loss: (0.775)(R 0.752, F 0.798)] [D acc: (0.375)(0.188, 0.562)] [G loss: 0.720] [G acc: 0.500]\n",
      "17462 [D loss: (0.727)(R 0.773, F 0.680)] [D acc: (0.375)(0.188, 0.562)] [G loss: 0.569] [G acc: 0.812]\n",
      "17463 [D loss: (0.672)(R 0.718, F 0.626)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.818] [G acc: 0.188]\n",
      "17464 [D loss: (0.670)(R 0.670, F 0.670)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.724] [G acc: 0.250]\n",
      "17465 [D loss: (0.950)(R 0.698, F 1.202)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.765] [G acc: 0.250]\n",
      "17466 [D loss: (0.691)(R 0.681, F 0.700)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.782] [G acc: 0.375]\n",
      "17467 [D loss: (0.699)(R 0.710, F 0.688)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.778] [G acc: 0.500]\n",
      "17468 [D loss: (0.927)(R 0.719, F 1.134)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.834] [G acc: 0.312]\n",
      "17469 [D loss: (0.720)(R 0.733, F 0.708)] [D acc: (0.406)(0.250, 0.562)] [G loss: 0.877] [G acc: 0.250]\n",
      "17470 [D loss: (0.566)(R 0.759, F 0.373)] [D acc: (0.594)(0.250, 0.938)] [G loss: 0.790] [G acc: 0.312]\n",
      "17471 [D loss: (0.635)(R 0.725, F 0.545)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.244] [G acc: 0.312]\n",
      "17472 [D loss: (0.635)(R 0.718, F 0.551)] [D acc: (0.469)(0.188, 0.750)] [G loss: 0.787] [G acc: 0.312]\n",
      "17473 [D loss: (0.689)(R 0.711, F 0.666)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.732] [G acc: 0.438]\n",
      "17474 [D loss: (0.674)(R 0.716, F 0.632)] [D acc: (0.562)(0.312, 0.812)] [G loss: 0.728] [G acc: 0.562]\n",
      "17475 [D loss: (0.743)(R 0.706, F 0.780)] [D acc: (0.344)(0.250, 0.438)] [G loss: 0.718] [G acc: 0.500]\n",
      "17476 [D loss: (0.686)(R 0.674, F 0.698)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.762] [G acc: 0.375]\n",
      "17477 [D loss: (0.692)(R 0.721, F 0.662)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.766] [G acc: 0.062]\n",
      "17478 [D loss: (0.707)(R 0.729, F 0.685)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.789] [G acc: 0.250]\n",
      "17479 [D loss: (0.672)(R 0.686, F 0.659)] [D acc: (0.562)(0.438, 0.688)] [G loss: 1.225] [G acc: 0.188]\n",
      "17480 [D loss: (0.602)(R 0.693, F 0.510)] [D acc: (0.406)(0.312, 0.500)] [G loss: 1.249] [G acc: 0.188]\n",
      "17481 [D loss: (0.535)(R 0.678, F 0.393)] [D acc: (0.625)(0.312, 0.938)] [G loss: 3.446] [G acc: 0.062]\n",
      "17482 [D loss: (0.557)(R 0.666, F 0.448)] [D acc: (0.750)(0.688, 0.812)] [G loss: 4.548] [G acc: 0.312]\n",
      "17483 [D loss: (0.691)(R 0.700, F 0.682)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.762] [G acc: 0.375]\n",
      "17484 [D loss: (0.614)(R 0.635, F 0.594)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.786] [G acc: 0.188]\n",
      "17485 [D loss: (0.612)(R 0.656, F 0.568)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.802] [G acc: 0.125]\n",
      "17486 [D loss: (0.693)(R 0.754, F 0.632)] [D acc: (0.469)(0.438, 0.500)] [G loss: 1.216] [G acc: 0.000]\n",
      "17487 [D loss: (0.636)(R 0.698, F 0.574)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.839] [G acc: 0.125]\n",
      "17488 [D loss: (0.607)(R 0.671, F 0.543)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.779] [G acc: 0.125]\n",
      "17489 [D loss: (0.700)(R 0.759, F 0.642)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.797] [G acc: 0.062]\n",
      "17490 [D loss: (0.671)(R 0.707, F 0.636)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.904] [G acc: 0.125]\n",
      "17491 [D loss: (0.654)(R 0.709, F 0.598)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.839] [G acc: 0.125]\n",
      "17492 [D loss: (0.674)(R 0.717, F 0.631)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.763] [G acc: 0.312]\n",
      "17493 [D loss: (0.675)(R 0.741, F 0.610)] [D acc: (0.750)(0.500, 1.000)] [G loss: 0.724] [G acc: 0.312]\n",
      "17494 [D loss: (0.656)(R 0.703, F 0.609)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.927] [G acc: 0.062]\n",
      "17495 [D loss: (0.669)(R 0.708, F 0.630)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.847] [G acc: 0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17496 [D loss: (0.620)(R 0.683, F 0.557)] [D acc: (0.844)(0.688, 1.000)] [G loss: 0.831] [G acc: 0.062]\n",
      "17497 [D loss: (0.680)(R 0.720, F 0.639)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.820] [G acc: 0.062]\n",
      "17498 [D loss: (0.789)(R 0.929, F 0.649)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.835] [G acc: 0.125]\n",
      "17499 [D loss: (0.696)(R 0.761, F 0.632)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.799] [G acc: 0.125]\n",
      "17500 [D loss: (0.642)(R 0.675, F 0.609)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.841] [G acc: 0.062]\n",
      "17501 [D loss: (0.624)(R 0.622, F 0.626)] [D acc: (0.875)(0.812, 0.938)] [G loss: 0.826] [G acc: 0.062]\n",
      "17502 [D loss: (0.657)(R 0.702, F 0.612)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.917] [G acc: 0.062]\n",
      "17503 [D loss: (0.648)(R 0.710, F 0.587)] [D acc: (0.719)(0.438, 1.000)] [G loss: 0.947] [G acc: 0.062]\n",
      "17504 [D loss: (0.658)(R 0.756, F 0.560)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.816] [G acc: 0.125]\n",
      "17505 [D loss: (0.657)(R 0.700, F 0.615)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.857] [G acc: 0.000]\n",
      "17506 [D loss: (0.685)(R 0.782, F 0.587)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.859] [G acc: 0.000]\n",
      "17507 [D loss: (0.664)(R 0.721, F 0.607)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.800] [G acc: 0.125]\n",
      "17508 [D loss: (0.594)(R 0.621, F 0.566)] [D acc: (0.875)(0.750, 1.000)] [G loss: 0.844] [G acc: 0.062]\n",
      "17509 [D loss: (0.657)(R 0.703, F 0.611)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.871] [G acc: 0.000]\n",
      "17510 [D loss: (0.642)(R 0.695, F 0.589)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.830] [G acc: 0.125]\n",
      "17511 [D loss: (0.691)(R 0.798, F 0.584)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.827] [G acc: 0.125]\n",
      "17512 [D loss: (0.700)(R 0.772, F 0.628)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.874] [G acc: 0.125]\n",
      "17513 [D loss: (0.640)(R 0.638, F 0.641)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.017] [G acc: 0.062]\n",
      "17514 [D loss: (0.623)(R 0.608, F 0.639)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.892] [G acc: 0.062]\n",
      "17515 [D loss: (0.632)(R 0.695, F 0.569)] [D acc: (0.844)(0.688, 1.000)] [G loss: 0.823] [G acc: 0.062]\n",
      "17516 [D loss: (0.650)(R 0.703, F 0.596)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.891] [G acc: 0.000]\n",
      "17517 [D loss: (0.595)(R 0.613, F 0.577)] [D acc: (0.875)(0.938, 0.812)] [G loss: 0.839] [G acc: 0.188]\n",
      "17518 [D loss: (0.669)(R 0.737, F 0.601)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.849] [G acc: 0.125]\n",
      "17519 [D loss: (0.662)(R 0.708, F 0.617)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.418] [G acc: 0.062]\n",
      "17520 [D loss: (0.415)(R 0.626, F 0.203)] [D acc: (0.906)(0.812, 1.000)] [G loss: 1.109] [G acc: 0.000]\n",
      "17521 [D loss: (0.634)(R 0.730, F 0.538)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.984] [G acc: 0.125]\n",
      "17522 [D loss: (0.596)(R 0.613, F 0.580)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.031] [G acc: 0.062]\n",
      "17523 [D loss: (0.662)(R 0.749, F 0.575)] [D acc: (0.656)(0.438, 0.875)] [G loss: 1.004] [G acc: 0.000]\n",
      "17524 [D loss: (0.621)(R 0.654, F 0.589)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.904] [G acc: 0.062]\n",
      "17525 [D loss: (0.592)(R 0.594, F 0.591)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.879] [G acc: 0.062]\n",
      "17526 [D loss: (0.589)(R 0.604, F 0.575)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.908] [G acc: 0.250]\n",
      "17527 [D loss: (0.623)(R 0.733, F 0.513)] [D acc: (0.688)(0.500, 0.875)] [G loss: 1.036] [G acc: 0.125]\n",
      "17528 [D loss: (0.524)(R 0.565, F 0.483)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.046] [G acc: 0.125]\n",
      "17529 [D loss: (0.548)(R 0.572, F 0.524)] [D acc: (0.844)(0.750, 0.938)] [G loss: 0.950] [G acc: 0.125]\n",
      "17530 [D loss: (0.553)(R 0.554, F 0.553)] [D acc: (0.875)(0.812, 0.938)] [G loss: 0.859] [G acc: 0.062]\n",
      "17531 [D loss: (0.626)(R 0.636, F 0.617)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.946] [G acc: 0.188]\n",
      "17532 [D loss: (0.600)(R 0.604, F 0.597)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.847] [G acc: 0.188]\n",
      "17533 [D loss: (0.669)(R 0.645, F 0.693)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.753] [G acc: 0.438]\n",
      "17534 [D loss: (0.600)(R 0.542, F 0.657)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.759] [G acc: 0.438]\n",
      "17535 [D loss: (0.566)(R 0.511, F 0.620)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.938] [G acc: 0.312]\n",
      "17536 [D loss: (0.581)(R 0.696, F 0.465)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.922] [G acc: 0.188]\n",
      "17537 [D loss: (0.614)(R 0.664, F 0.564)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.941] [G acc: 0.125]\n",
      "17538 [D loss: (0.603)(R 0.788, F 0.419)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.714] [G acc: 0.625]\n",
      "17539 [D loss: (0.544)(R 0.501, F 0.587)] [D acc: (0.594)(0.688, 0.500)] [G loss: 1.172] [G acc: 0.250]\n",
      "17540 [D loss: (0.457)(R 0.573, F 0.340)] [D acc: (0.812)(0.750, 0.875)] [G loss: 2.957] [G acc: 0.000]\n",
      "17541 [D loss: (0.627)(R 0.601, F 0.652)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.913] [G acc: 0.312]\n",
      "17542 [D loss: (0.602)(R 0.651, F 0.553)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.155] [G acc: 0.250]\n",
      "17543 [D loss: (0.636)(R 0.738, F 0.534)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.836] [G acc: 0.250]\n",
      "17544 [D loss: (0.575)(R 0.585, F 0.565)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.313] [G acc: 0.188]\n",
      "17545 [D loss: (0.592)(R 0.474, F 0.709)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.978] [G acc: 0.312]\n",
      "17546 [D loss: (0.695)(R 0.741, F 0.649)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.885] [G acc: 0.062]\n",
      "17547 [D loss: (0.683)(R 0.673, F 0.694)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.677] [G acc: 0.625]\n",
      "17548 [D loss: (0.649)(R 0.687, F 0.612)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.865] [G acc: 0.375]\n",
      "17549 [D loss: (0.584)(R 0.469, F 0.700)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.737] [G acc: 0.375]\n",
      "17550 [D loss: (0.638)(R 0.616, F 0.661)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.774] [G acc: 0.375]\n",
      "17551 [D loss: (0.713)(R 0.636, F 0.790)] [D acc: (0.438)(0.500, 0.375)] [G loss: 1.193] [G acc: 0.500]\n",
      "17552 [D loss: (0.578)(R 0.520, F 0.636)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.702] [G acc: 0.500]\n",
      "17553 [D loss: (0.646)(R 0.651, F 0.641)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.741] [G acc: 0.500]\n",
      "17554 [D loss: (0.601)(R 0.550, F 0.651)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.773] [G acc: 0.438]\n",
      "17555 [D loss: (0.603)(R 0.549, F 0.656)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.862] [G acc: 0.312]\n",
      "17556 [D loss: (0.619)(R 0.589, F 0.648)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.715] [G acc: 0.500]\n",
      "17557 [D loss: (0.686)(R 0.753, F 0.620)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.784] [G acc: 0.500]\n",
      "17558 [D loss: (0.628)(R 0.669, F 0.586)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.847] [G acc: 0.250]\n",
      "17559 [D loss: (0.533)(R 0.509, F 0.557)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.895] [G acc: 0.438]\n",
      "17560 [D loss: (0.635)(R 0.580, F 0.690)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.624] [G acc: 0.688]\n",
      "17561 [D loss: (0.684)(R 0.739, F 0.629)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.784] [G acc: 0.500]\n",
      "17562 [D loss: (0.598)(R 0.330, F 0.865)] [D acc: (0.656)(0.938, 0.375)] [G loss: 0.756] [G acc: 0.375]\n",
      "17563 [D loss: (0.630)(R 0.424, F 0.836)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.821] [G acc: 0.312]\n",
      "17564 [D loss: (0.577)(R 0.541, F 0.614)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.737] [G acc: 0.312]\n",
      "17565 [D loss: (0.885)(R 0.633, F 1.137)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.798] [G acc: 0.562]\n",
      "17566 [D loss: (0.563)(R 0.587, F 0.540)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.840] [G acc: 0.375]\n",
      "17567 [D loss: (0.628)(R 0.674, F 0.581)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.719] [G acc: 0.562]\n",
      "17568 [D loss: (0.601)(R 0.491, F 0.711)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.807] [G acc: 0.375]\n",
      "17569 [D loss: (0.681)(R 0.566, F 0.796)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.592] [G acc: 0.625]\n",
      "17570 [D loss: (0.932)(R 0.719, F 1.146)] [D acc: (0.406)(0.375, 0.438)] [G loss: 0.956] [G acc: 0.250]\n",
      "17571 [D loss: (0.516)(R 0.681, F 0.350)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.530] [G acc: 0.125]\n",
      "17572 [D loss: (0.675)(R 0.667, F 0.682)] [D acc: (0.562)(0.562, 0.562)] [G loss: 1.220] [G acc: 0.312]\n",
      "17573 [D loss: (0.672)(R 0.839, F 0.504)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.916] [G acc: 0.250]\n",
      "17574 [D loss: (0.630)(R 0.690, F 0.569)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.910] [G acc: 0.250]\n",
      "17575 [D loss: (0.687)(R 0.624, F 0.749)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.850] [G acc: 0.500]\n",
      "17576 [D loss: (0.694)(R 0.607, F 0.780)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.808] [G acc: 0.250]\n",
      "17577 [D loss: (0.733)(R 0.584, F 0.883)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.601] [G acc: 0.562]\n",
      "17578 [D loss: (0.898)(R 0.679, F 1.117)] [D acc: (0.375)(0.375, 0.375)] [G loss: 0.683] [G acc: 0.625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17579 [D loss: (0.862)(R 0.500, F 1.223)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.679] [G acc: 0.625]\n",
      "17580 [D loss: (0.708)(R 0.600, F 0.817)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.693] [G acc: 0.625]\n",
      "17581 [D loss: (0.754)(R 0.784, F 0.725)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.781] [G acc: 0.438]\n",
      "17582 [D loss: (0.728)(R 0.667, F 0.789)] [D acc: (0.406)(0.688, 0.125)] [G loss: 0.584] [G acc: 0.750]\n",
      "17583 [D loss: (0.725)(R 0.648, F 0.802)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.682] [G acc: 0.562]\n",
      "17584 [D loss: (0.681)(R 0.561, F 0.801)] [D acc: (0.438)(0.688, 0.188)] [G loss: 0.642] [G acc: 0.688]\n",
      "17585 [D loss: (0.674)(R 0.568, F 0.780)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.558] [G acc: 0.812]\n",
      "17586 [D loss: (0.771)(R 0.672, F 0.870)] [D acc: (0.344)(0.500, 0.188)] [G loss: 0.732] [G acc: 0.562]\n",
      "17587 [D loss: (0.811)(R 0.646, F 0.977)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.790] [G acc: 0.500]\n",
      "17588 [D loss: (0.840)(R 0.686, F 0.994)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.719] [G acc: 0.562]\n",
      "17589 [D loss: (0.707)(R 0.695, F 0.719)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.654] [G acc: 0.688]\n",
      "17590 [D loss: (0.682)(R 0.673, F 0.691)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.665] [G acc: 0.625]\n",
      "17591 [D loss: (0.708)(R 0.676, F 0.741)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.665] [G acc: 0.812]\n",
      "17592 [D loss: (0.729)(R 0.659, F 0.800)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.701] [G acc: 0.625]\n",
      "17593 [D loss: (0.725)(R 0.707, F 0.743)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.658] [G acc: 0.500]\n",
      "17594 [D loss: (0.681)(R 0.600, F 0.761)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.737] [G acc: 0.438]\n",
      "17595 [D loss: (0.740)(R 0.630, F 0.849)] [D acc: (0.438)(0.688, 0.188)] [G loss: 0.711] [G acc: 0.562]\n",
      "17596 [D loss: (0.754)(R 0.675, F 0.833)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.784] [G acc: 0.688]\n",
      "17597 [D loss: (0.666)(R 0.603, F 0.728)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.660] [G acc: 0.500]\n",
      "17598 [D loss: (0.607)(R 0.590, F 0.624)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.687] [G acc: 0.625]\n",
      "17599 [D loss: (0.706)(R 0.734, F 0.679)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.718] [G acc: 0.375]\n",
      "17600 [D loss: (0.680)(R 0.690, F 0.669)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.664] [G acc: 0.500]\n",
      "17601 [D loss: (0.708)(R 0.687, F 0.728)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.679] [G acc: 0.625]\n",
      "17602 [D loss: (0.696)(R 0.674, F 0.719)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.697] [G acc: 0.312]\n",
      "17603 [D loss: (0.654)(R 0.626, F 0.682)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.686] [G acc: 0.500]\n",
      "17604 [D loss: (0.772)(R 0.829, F 0.716)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.683] [G acc: 0.375]\n",
      "17605 [D loss: (0.691)(R 0.668, F 0.714)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.624] [G acc: 0.562]\n",
      "17606 [D loss: (0.749)(R 0.646, F 0.853)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.690] [G acc: 0.500]\n",
      "17607 [D loss: (0.679)(R 0.632, F 0.725)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.667] [G acc: 0.562]\n",
      "17608 [D loss: (0.781)(R 0.660, F 0.902)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.616] [G acc: 0.500]\n",
      "17609 [D loss: (0.759)(R 0.795, F 0.723)] [D acc: (0.375)(0.312, 0.438)] [G loss: 0.625] [G acc: 0.438]\n",
      "17610 [D loss: (0.936)(R 0.622, F 1.250)] [D acc: (0.750)(0.938, 0.562)] [G loss: 0.805] [G acc: 0.250]\n",
      "17611 [D loss: (0.557)(R 0.660, F 0.454)] [D acc: (0.656)(0.625, 0.688)] [G loss: 2.641] [G acc: 0.125]\n",
      "17612 [D loss: (0.531)(R 0.644, F 0.417)] [D acc: (0.719)(0.750, 0.688)] [G loss: 2.626] [G acc: 0.062]\n",
      "17613 [D loss: (0.715)(R 0.672, F 0.757)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.665] [G acc: 0.500]\n",
      "17614 [D loss: (0.713)(R 0.668, F 0.758)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.832] [G acc: 0.312]\n",
      "17615 [D loss: (0.685)(R 0.682, F 0.687)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.679] [G acc: 0.438]\n",
      "17616 [D loss: (0.665)(R 0.677, F 0.654)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.823] [G acc: 0.312]\n",
      "17617 [D loss: (0.742)(R 0.701, F 0.784)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.708] [G acc: 0.375]\n",
      "17618 [D loss: (0.669)(R 0.655, F 0.682)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.794] [G acc: 0.188]\n",
      "17619 [D loss: (0.650)(R 0.694, F 0.606)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.687] [G acc: 0.312]\n",
      "17620 [D loss: (0.626)(R 0.637, F 0.615)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.718] [G acc: 0.438]\n",
      "17621 [D loss: (0.758)(R 0.691, F 0.825)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.721] [G acc: 0.375]\n",
      "17622 [D loss: (0.777)(R 0.683, F 0.870)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.704] [G acc: 0.375]\n",
      "17623 [D loss: (0.711)(R 0.699, F 0.723)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.816] [G acc: 0.188]\n",
      "17624 [D loss: (0.674)(R 0.664, F 0.684)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.860] [G acc: 0.125]\n",
      "17625 [D loss: (0.651)(R 0.668, F 0.634)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.861] [G acc: 0.188]\n",
      "17626 [D loss: (0.602)(R 0.587, F 0.616)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.931] [G acc: 0.125]\n",
      "17627 [D loss: (0.680)(R 0.745, F 0.615)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.856] [G acc: 0.438]\n",
      "17628 [D loss: (0.603)(R 0.701, F 0.506)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.934] [G acc: 0.188]\n",
      "17629 [D loss: (0.644)(R 0.684, F 0.605)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.061] [G acc: 0.188]\n",
      "17630 [D loss: (0.573)(R 0.639, F 0.507)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.022] [G acc: 0.125]\n",
      "17631 [D loss: (0.616)(R 0.754, F 0.479)] [D acc: (0.688)(0.375, 1.000)] [G loss: 0.986] [G acc: 0.188]\n",
      "17632 [D loss: (0.640)(R 0.662, F 0.619)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.020] [G acc: 0.062]\n",
      "17633 [D loss: (0.640)(R 0.736, F 0.544)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.154] [G acc: 0.000]\n",
      "17634 [D loss: (0.606)(R 0.682, F 0.530)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.125] [G acc: 0.125]\n",
      "17635 [D loss: (0.635)(R 0.796, F 0.474)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.925] [G acc: 0.125]\n",
      "17636 [D loss: (0.578)(R 0.641, F 0.514)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.076] [G acc: 0.125]\n",
      "17637 [D loss: (0.582)(R 0.671, F 0.492)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.312] [G acc: 0.000]\n",
      "17638 [D loss: (0.649)(R 0.772, F 0.526)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.020] [G acc: 0.188]\n",
      "17639 [D loss: (0.590)(R 0.632, F 0.548)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.134] [G acc: 0.125]\n",
      "17640 [D loss: (0.589)(R 0.645, F 0.533)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.007] [G acc: 0.375]\n",
      "17641 [D loss: (0.636)(R 0.598, F 0.673)] [D acc: (0.750)(0.875, 0.625)] [G loss: 1.057] [G acc: 0.250]\n",
      "17642 [D loss: (0.591)(R 0.764, F 0.419)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.778] [G acc: 0.188]\n",
      "17643 [D loss: (0.401)(R 0.567, F 0.235)] [D acc: (0.875)(0.875, 0.875)] [G loss: 3.597] [G acc: 0.125]\n",
      "17644 [D loss: (0.589)(R 0.651, F 0.527)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.124] [G acc: 0.188]\n",
      "17645 [D loss: (0.705)(R 0.874, F 0.535)] [D acc: (0.438)(0.312, 0.562)] [G loss: 1.408] [G acc: 0.125]\n",
      "17646 [D loss: (0.626)(R 0.724, F 0.528)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.118] [G acc: 0.062]\n",
      "17647 [D loss: (0.650)(R 0.749, F 0.552)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.204] [G acc: 0.125]\n",
      "17648 [D loss: (0.497)(R 0.548, F 0.445)] [D acc: (0.906)(0.938, 0.875)] [G loss: 1.167] [G acc: 0.188]\n",
      "17649 [D loss: (0.620)(R 0.654, F 0.585)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.849] [G acc: 0.312]\n",
      "17650 [D loss: (0.495)(R 0.555, F 0.435)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.244] [G acc: 0.188]\n",
      "17651 [D loss: (0.594)(R 0.752, F 0.436)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.400] [G acc: 0.125]\n",
      "17652 [D loss: (0.646)(R 0.746, F 0.547)] [D acc: (0.594)(0.500, 0.688)] [G loss: 1.380] [G acc: 0.188]\n",
      "17653 [D loss: (0.516)(R 0.560, F 0.472)] [D acc: (0.812)(0.875, 0.750)] [G loss: 4.003] [G acc: 0.312]\n",
      "17654 [D loss: (0.556)(R 0.672, F 0.439)] [D acc: (0.625)(0.562, 0.688)] [G loss: 3.005] [G acc: 0.312]\n",
      "17655 [D loss: (0.623)(R 0.568, F 0.678)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.731] [G acc: 0.188]\n",
      "17656 [D loss: (0.647)(R 0.807, F 0.488)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.629] [G acc: 0.062]\n",
      "17657 [D loss: (0.528)(R 0.656, F 0.400)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.794] [G acc: 0.062]\n",
      "17658 [D loss: (0.501)(R 0.676, F 0.326)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.564] [G acc: 0.188]\n",
      "17659 [D loss: (0.469)(R 0.575, F 0.364)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.381] [G acc: 0.062]\n",
      "17660 [D loss: (0.470)(R 0.632, F 0.309)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.559] [G acc: 0.062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17661 [D loss: (0.487)(R 0.553, F 0.421)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.349] [G acc: 0.125]\n",
      "17662 [D loss: (0.586)(R 0.597, F 0.574)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.170] [G acc: 0.188]\n",
      "17663 [D loss: (0.460)(R 0.595, F 0.325)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.368] [G acc: 0.188]\n",
      "17664 [D loss: (0.502)(R 0.650, F 0.354)] [D acc: (0.844)(0.688, 1.000)] [G loss: 1.083] [G acc: 0.188]\n",
      "17665 [D loss: (0.493)(R 0.511, F 0.476)] [D acc: (0.844)(0.938, 0.750)] [G loss: 1.676] [G acc: 0.125]\n",
      "17666 [D loss: (0.484)(R 0.545, F 0.423)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.352] [G acc: 0.250]\n",
      "17667 [D loss: (0.529)(R 0.622, F 0.436)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.736] [G acc: 0.188]\n",
      "17668 [D loss: (0.441)(R 0.608, F 0.274)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.541] [G acc: 0.125]\n",
      "17669 [D loss: (0.406)(R 0.524, F 0.289)] [D acc: (0.906)(0.875, 0.938)] [G loss: 1.764] [G acc: 0.000]\n",
      "17670 [D loss: (0.476)(R 0.485, F 0.467)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.553] [G acc: 0.250]\n",
      "17671 [D loss: (0.421)(R 0.580, F 0.263)] [D acc: (0.812)(0.625, 1.000)] [G loss: 1.604] [G acc: 0.250]\n",
      "17672 [D loss: (0.413)(R 0.540, F 0.286)] [D acc: (0.844)(0.688, 1.000)] [G loss: 1.754] [G acc: 0.188]\n",
      "17673 [D loss: (0.479)(R 0.562, F 0.395)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.355] [G acc: 0.312]\n",
      "17674 [D loss: (0.509)(R 0.421, F 0.597)] [D acc: (0.750)(0.938, 0.562)] [G loss: 1.577] [G acc: 0.188]\n",
      "17675 [D loss: (0.399)(R 0.357, F 0.441)] [D acc: (0.906)(1.000, 0.812)] [G loss: 1.004] [G acc: 0.250]\n",
      "17676 [D loss: (0.461)(R 0.427, F 0.495)] [D acc: (0.750)(0.812, 0.688)] [G loss: 3.179] [G acc: 0.250]\n",
      "17677 [D loss: (0.449)(R 0.525, F 0.373)] [D acc: (0.719)(0.750, 0.688)] [G loss: 6.165] [G acc: 0.125]\n",
      "17678 [D loss: (0.539)(R 0.577, F 0.501)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.304] [G acc: 0.188]\n",
      "17679 [D loss: (0.703)(R 0.879, F 0.526)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.271] [G acc: 0.250]\n",
      "17680 [D loss: (1.052)(R 0.695, F 1.409)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.335] [G acc: 0.250]\n",
      "17681 [D loss: (0.497)(R 0.482, F 0.511)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.279] [G acc: 0.125]\n",
      "17682 [D loss: (0.514)(R 0.437, F 0.591)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.904] [G acc: 0.375]\n",
      "17683 [D loss: (0.588)(R 0.521, F 0.655)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.709] [G acc: 0.625]\n",
      "17684 [D loss: (0.620)(R 0.566, F 0.674)] [D acc: (0.688)(0.812, 0.562)] [G loss: 2.169] [G acc: 0.250]\n",
      "17685 [D loss: (0.467)(R 0.617, F 0.318)] [D acc: (0.781)(0.750, 0.812)] [G loss: 2.011] [G acc: 0.250]\n",
      "17686 [D loss: (0.349)(R 0.424, F 0.275)] [D acc: (0.875)(0.875, 0.875)] [G loss: 2.426] [G acc: 0.188]\n",
      "17687 [D loss: (0.702)(R 0.563, F 0.841)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.848] [G acc: 0.125]\n",
      "17688 [D loss: (0.444)(R 0.402, F 0.487)] [D acc: (0.781)(0.938, 0.625)] [G loss: 1.245] [G acc: 0.188]\n",
      "17689 [D loss: (0.643)(R 0.742, F 0.543)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.237] [G acc: 0.375]\n",
      "17690 [D loss: (0.419)(R 0.414, F 0.424)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.147] [G acc: 0.125]\n",
      "17691 [D loss: (0.509)(R 0.507, F 0.511)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.073] [G acc: 0.438]\n",
      "17692 [D loss: (1.054)(R 1.366, F 0.743)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.896] [G acc: 0.312]\n",
      "17693 [D loss: (0.645)(R 0.537, F 0.753)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.631] [G acc: 0.812]\n",
      "17694 [D loss: (0.630)(R 0.660, F 0.600)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.968] [G acc: 0.562]\n",
      "17695 [D loss: (0.716)(R 0.717, F 0.716)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.995] [G acc: 0.562]\n",
      "17696 [D loss: (0.480)(R 0.334, F 0.625)] [D acc: (0.812)(0.938, 0.688)] [G loss: 0.939] [G acc: 0.562]\n",
      "17697 [D loss: (0.525)(R 0.586, F 0.464)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.055] [G acc: 0.500]\n",
      "17698 [D loss: (0.550)(R 0.613, F 0.487)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.942] [G acc: 0.375]\n",
      "17699 [D loss: (0.625)(R 0.585, F 0.666)] [D acc: (0.562)(0.688, 0.438)] [G loss: 1.026] [G acc: 0.250]\n",
      "17700 [D loss: (0.616)(R 0.606, F 0.626)] [D acc: (0.562)(0.562, 0.562)] [G loss: 1.016] [G acc: 0.250]\n",
      "17701 [D loss: (0.716)(R 0.602, F 0.831)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.725] [G acc: 0.375]\n",
      "17702 [D loss: (0.625)(R 0.548, F 0.703)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.826] [G acc: 0.250]\n",
      "17703 [D loss: (0.828)(R 0.588, F 1.067)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.806] [G acc: 0.375]\n",
      "17704 [D loss: (0.680)(R 0.606, F 0.754)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.812] [G acc: 0.562]\n",
      "17705 [D loss: (0.998)(R 1.292, F 0.705)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.566] [G acc: 0.750]\n",
      "17706 [D loss: (0.829)(R 0.834, F 0.824)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.601] [G acc: 0.812]\n",
      "17707 [D loss: (0.706)(R 0.547, F 0.865)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.825] [G acc: 0.750]\n",
      "17708 [D loss: (0.673)(R 0.450, F 0.895)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.610] [G acc: 0.750]\n",
      "17709 [D loss: (0.803)(R 0.641, F 0.964)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.606] [G acc: 0.750]\n",
      "17710 [D loss: (0.583)(R 0.597, F 0.568)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.708] [G acc: 0.625]\n",
      "17711 [D loss: (0.812)(R 0.823, F 0.802)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.679] [G acc: 0.750]\n",
      "17712 [D loss: (0.651)(R 0.537, F 0.765)] [D acc: (0.562)(0.938, 0.188)] [G loss: 0.802] [G acc: 0.562]\n",
      "17713 [D loss: (0.687)(R 0.658, F 0.716)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.659] [G acc: 0.625]\n",
      "17714 [D loss: (0.669)(R 0.610, F 0.728)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.550] [G acc: 0.938]\n",
      "17715 [D loss: (0.667)(R 0.500, F 0.833)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.765] [G acc: 0.625]\n",
      "17716 [D loss: (0.705)(R 0.596, F 0.813)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.586] [G acc: 0.812]\n",
      "17717 [D loss: (0.687)(R 0.519, F 0.855)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.543] [G acc: 0.938]\n",
      "17718 [D loss: (0.822)(R 0.535, F 1.108)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.849] [G acc: 0.500]\n",
      "17719 [D loss: (0.411)(R 0.483, F 0.339)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.203] [G acc: 0.250]\n",
      "17720 [D loss: (0.632)(R 0.577, F 0.687)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.663] [G acc: 0.812]\n",
      "17721 [D loss: (0.660)(R 0.591, F 0.729)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.635] [G acc: 0.562]\n",
      "17722 [D loss: (0.991)(R 0.551, F 1.430)] [D acc: (0.375)(0.750, 0.000)] [G loss: 0.569] [G acc: 0.875]\n",
      "17723 [D loss: (0.774)(R 0.571, F 0.976)] [D acc: (0.531)(0.938, 0.125)] [G loss: 0.554] [G acc: 1.000]\n",
      "17724 [D loss: (0.805)(R 0.774, F 0.835)] [D acc: (0.375)(0.625, 0.125)] [G loss: 0.691] [G acc: 0.625]\n",
      "17725 [D loss: (0.707)(R 0.610, F 0.804)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.633] [G acc: 0.812]\n",
      "17726 [D loss: (0.656)(R 0.519, F 0.793)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.651] [G acc: 0.688]\n",
      "17727 [D loss: (0.683)(R 0.570, F 0.797)] [D acc: (0.438)(0.812, 0.062)] [G loss: 0.642] [G acc: 0.750]\n",
      "17728 [D loss: (0.855)(R 0.939, F 0.771)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.599] [G acc: 0.938]\n",
      "17729 [D loss: (0.692)(R 0.559, F 0.825)] [D acc: (0.375)(0.625, 0.125)] [G loss: 0.600] [G acc: 0.875]\n",
      "17730 [D loss: (0.669)(R 0.542, F 0.795)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.657] [G acc: 0.688]\n",
      "17731 [D loss: (0.710)(R 0.558, F 0.863)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.616] [G acc: 0.750]\n",
      "17732 [D loss: (0.684)(R 0.504, F 0.863)] [D acc: (0.406)(0.750, 0.062)] [G loss: 0.673] [G acc: 0.750]\n",
      "17733 [D loss: (0.535)(R 0.568, F 0.501)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.467] [G acc: 0.562]\n",
      "17734 [D loss: (0.613)(R 0.529, F 0.697)] [D acc: (0.594)(0.688, 0.500)] [G loss: 3.591] [G acc: 0.562]\n",
      "17735 [D loss: (0.507)(R 0.568, F 0.446)] [D acc: (0.719)(0.812, 0.625)] [G loss: 6.730] [G acc: 0.438]\n",
      "17736 [D loss: (0.642)(R 0.533, F 0.752)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.656] [G acc: 0.625]\n",
      "17737 [D loss: (0.646)(R 0.527, F 0.765)] [D acc: (0.562)(0.938, 0.188)] [G loss: 0.671] [G acc: 0.562]\n",
      "17738 [D loss: (0.659)(R 0.508, F 0.810)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.616] [G acc: 0.875]\n",
      "17739 [D loss: (0.712)(R 0.535, F 0.889)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.636] [G acc: 0.750]\n",
      "17740 [D loss: (0.669)(R 0.548, F 0.790)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.643] [G acc: 0.688]\n",
      "17741 [D loss: (0.653)(R 0.590, F 0.716)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.678] [G acc: 0.625]\n",
      "17742 [D loss: (0.721)(R 0.559, F 0.883)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.652] [G acc: 0.688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17743 [D loss: (0.631)(R 0.501, F 0.760)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.633] [G acc: 0.750]\n",
      "17744 [D loss: (0.656)(R 0.493, F 0.819)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.623] [G acc: 0.812]\n",
      "17745 [D loss: (0.757)(R 0.485, F 1.028)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.643] [G acc: 0.688]\n",
      "17746 [D loss: (0.669)(R 0.593, F 0.745)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.698] [G acc: 0.625]\n",
      "17747 [D loss: (0.558)(R 0.432, F 0.685)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.700] [G acc: 0.500]\n",
      "17748 [D loss: (0.658)(R 0.650, F 0.665)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.640] [G acc: 0.812]\n",
      "17749 [D loss: (0.654)(R 0.584, F 0.725)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.733] [G acc: 0.438]\n",
      "17750 [D loss: (0.660)(R 0.537, F 0.784)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.672] [G acc: 0.688]\n",
      "17751 [D loss: (0.768)(R 0.652, F 0.885)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.673] [G acc: 0.688]\n",
      "17752 [D loss: (0.634)(R 0.564, F 0.703)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.686] [G acc: 0.625]\n",
      "17753 [D loss: (0.679)(R 0.594, F 0.763)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.719] [G acc: 0.500]\n",
      "17754 [D loss: (0.637)(R 0.611, F 0.662)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.691] [G acc: 0.438]\n",
      "17755 [D loss: (0.697)(R 0.637, F 0.756)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.709] [G acc: 0.562]\n",
      "17756 [D loss: (0.642)(R 0.670, F 0.614)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.737] [G acc: 0.688]\n",
      "17757 [D loss: (0.540)(R 0.514, F 0.567)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.982] [G acc: 0.500]\n",
      "17758 [D loss: (0.591)(R 0.524, F 0.658)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.590] [G acc: 0.750]\n",
      "17759 [D loss: (0.586)(R 0.541, F 0.631)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.647] [G acc: 0.625]\n",
      "17760 [D loss: (0.682)(R 0.569, F 0.794)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.812] [G acc: 0.438]\n",
      "17761 [D loss: (0.566)(R 0.537, F 0.595)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.736] [G acc: 0.250]\n",
      "17762 [D loss: (0.393)(R 0.569, F 0.217)] [D acc: (0.844)(0.875, 0.812)] [G loss: 8.210] [G acc: 0.188]\n",
      "17763 [D loss: (0.685)(R 0.784, F 0.586)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.764] [G acc: 0.438]\n",
      "17764 [D loss: (0.631)(R 0.636, F 0.626)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.820] [G acc: 0.250]\n",
      "17765 [D loss: (0.609)(R 0.533, F 0.685)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.706] [G acc: 0.500]\n",
      "17766 [D loss: (0.641)(R 0.623, F 0.659)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.906] [G acc: 0.312]\n",
      "17767 [D loss: (0.655)(R 0.636, F 0.675)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.117] [G acc: 0.250]\n",
      "17768 [D loss: (0.610)(R 0.512, F 0.708)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.650] [G acc: 0.625]\n",
      "17769 [D loss: (0.470)(R 0.397, F 0.543)] [D acc: (0.906)(1.000, 0.812)] [G loss: 0.744] [G acc: 0.375]\n",
      "17770 [D loss: (0.652)(R 0.578, F 0.726)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.699] [G acc: 0.562]\n",
      "17771 [D loss: (0.701)(R 0.609, F 0.792)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.679] [G acc: 0.500]\n",
      "17772 [D loss: (0.699)(R 0.618, F 0.779)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.728] [G acc: 0.375]\n",
      "17773 [D loss: (0.612)(R 0.572, F 0.652)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.733] [G acc: 0.562]\n",
      "17774 [D loss: (0.574)(R 0.510, F 0.638)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.922] [G acc: 0.250]\n",
      "17775 [D loss: (0.634)(R 0.724, F 0.544)] [D acc: (0.688)(0.688, 0.688)] [G loss: 2.263] [G acc: 0.188]\n",
      "17776 [D loss: (0.708)(R 0.629, F 0.788)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.792] [G acc: 0.438]\n",
      "17777 [D loss: (0.686)(R 0.761, F 0.610)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.858] [G acc: 0.375]\n",
      "17778 [D loss: (0.619)(R 0.547, F 0.691)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.822] [G acc: 0.625]\n",
      "17779 [D loss: (0.614)(R 0.555, F 0.674)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.847] [G acc: 0.500]\n",
      "17780 [D loss: (0.598)(R 0.618, F 0.579)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.715] [G acc: 0.500]\n",
      "17781 [D loss: (0.642)(R 0.632, F 0.653)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.609] [G acc: 0.625]\n",
      "17782 [D loss: (0.965)(R 0.509, F 1.420)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.883] [G acc: 0.312]\n",
      "17783 [D loss: (0.620)(R 0.549, F 0.691)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.707] [G acc: 0.625]\n",
      "17784 [D loss: (0.539)(R 0.478, F 0.600)] [D acc: (0.844)(0.938, 0.750)] [G loss: 0.831] [G acc: 0.312]\n",
      "17785 [D loss: (0.636)(R 0.580, F 0.691)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.873] [G acc: 0.062]\n",
      "17786 [D loss: (0.593)(R 0.575, F 0.611)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.897] [G acc: 0.312]\n",
      "17787 [D loss: (0.628)(R 0.663, F 0.594)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.869] [G acc: 0.375]\n",
      "17788 [D loss: (0.523)(R 0.462, F 0.583)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.904] [G acc: 0.500]\n",
      "17789 [D loss: (0.685)(R 0.704, F 0.667)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.865] [G acc: 0.375]\n",
      "17790 [D loss: (0.696)(R 0.716, F 0.676)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.896] [G acc: 0.188]\n",
      "17791 [D loss: (0.559)(R 0.511, F 0.608)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.843] [G acc: 0.438]\n",
      "17792 [D loss: (0.649)(R 0.656, F 0.643)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.935] [G acc: 0.375]\n",
      "17793 [D loss: (0.585)(R 0.531, F 0.639)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.850] [G acc: 0.312]\n",
      "17794 [D loss: (0.572)(R 0.502, F 0.643)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.719] [G acc: 0.625]\n",
      "17795 [D loss: (0.703)(R 0.398, F 1.009)] [D acc: (0.625)(0.812, 0.438)] [G loss: 1.432] [G acc: 0.250]\n",
      "17796 [D loss: (0.381)(R 0.594, F 0.168)] [D acc: (0.781)(0.688, 0.875)] [G loss: 6.377] [G acc: 0.250]\n",
      "17797 [D loss: (0.614)(R 0.580, F 0.648)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.321] [G acc: 0.312]\n",
      "17798 [D loss: (0.568)(R 0.516, F 0.620)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.317] [G acc: 0.250]\n",
      "17799 [D loss: (0.652)(R 0.629, F 0.676)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.919] [G acc: 0.188]\n",
      "17800 [D loss: (0.498)(R 0.425, F 0.571)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.804] [G acc: 0.438]\n",
      "17801 [D loss: (0.489)(R 0.306, F 0.673)] [D acc: (0.719)(0.875, 0.562)] [G loss: 1.034] [G acc: 0.188]\n",
      "17802 [D loss: (0.537)(R 0.504, F 0.569)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.781] [G acc: 0.250]\n",
      "17803 [D loss: (0.594)(R 0.621, F 0.566)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.126] [G acc: 0.312]\n",
      "17804 [D loss: (0.540)(R 0.544, F 0.536)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.926] [G acc: 0.500]\n",
      "17805 [D loss: (0.637)(R 0.736, F 0.538)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.048] [G acc: 0.188]\n",
      "17806 [D loss: (0.511)(R 0.380, F 0.642)] [D acc: (0.781)(1.000, 0.562)] [G loss: 0.858] [G acc: 0.438]\n",
      "17807 [D loss: (0.550)(R 0.490, F 0.611)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.976] [G acc: 0.250]\n",
      "17808 [D loss: (0.539)(R 0.475, F 0.603)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.077] [G acc: 0.250]\n",
      "17809 [D loss: (0.934)(R 0.529, F 1.338)] [D acc: (0.500)(0.562, 0.438)] [G loss: 1.256] [G acc: 0.188]\n",
      "17810 [D loss: (0.573)(R 0.509, F 0.637)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.983] [G acc: 0.125]\n",
      "17811 [D loss: (0.708)(R 0.778, F 0.638)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.054] [G acc: 0.188]\n",
      "17812 [D loss: (0.656)(R 0.555, F 0.757)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.839] [G acc: 0.312]\n",
      "17813 [D loss: (0.566)(R 0.402, F 0.729)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.842] [G acc: 0.250]\n",
      "17814 [D loss: (0.831)(R 0.692, F 0.970)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.706] [G acc: 0.562]\n",
      "17815 [D loss: (0.554)(R 0.443, F 0.666)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.071] [G acc: 0.125]\n",
      "17816 [D loss: (0.743)(R 0.564, F 0.923)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.379] [G acc: 0.375]\n",
      "17817 [D loss: (0.614)(R 0.592, F 0.636)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.697] [G acc: 0.375]\n",
      "17818 [D loss: (0.629)(R 0.731, F 0.527)] [D acc: (0.531)(0.500, 0.562)] [G loss: 1.358] [G acc: 0.312]\n",
      "17819 [D loss: (0.723)(R 0.704, F 0.741)] [D acc: (0.406)(0.562, 0.250)] [G loss: 1.367] [G acc: 0.188]\n",
      "17820 [D loss: (0.634)(R 0.416, F 0.853)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.877] [G acc: 0.312]\n",
      "17821 [D loss: (0.623)(R 0.689, F 0.557)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.697] [G acc: 0.500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17822 [D loss: (0.668)(R 0.661, F 0.676)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.678] [G acc: 0.562]\n",
      "17823 [D loss: (0.792)(R 0.637, F 0.948)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.660] [G acc: 0.562]\n",
      "17824 [D loss: (0.621)(R 0.473, F 0.768)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.768] [G acc: 0.562]\n",
      "17825 [D loss: (0.699)(R 0.650, F 0.748)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.672] [G acc: 0.562]\n",
      "17826 [D loss: (0.537)(R 0.390, F 0.684)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.881] [G acc: 0.438]\n",
      "17827 [D loss: (0.552)(R 0.437, F 0.668)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.767] [G acc: 0.625]\n",
      "17828 [D loss: (0.717)(R 0.745, F 0.689)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.990] [G acc: 0.312]\n",
      "17829 [D loss: (0.540)(R 0.475, F 0.606)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.784] [G acc: 0.375]\n",
      "17830 [D loss: (0.758)(R 0.687, F 0.828)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.690] [G acc: 0.688]\n",
      "17831 [D loss: (0.710)(R 0.642, F 0.778)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.732] [G acc: 0.438]\n",
      "17832 [D loss: (0.605)(R 0.421, F 0.788)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.707] [G acc: 0.562]\n",
      "17833 [D loss: (0.594)(R 0.515, F 0.673)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.722] [G acc: 0.562]\n",
      "17834 [D loss: (0.712)(R 0.692, F 0.733)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.719] [G acc: 0.562]\n",
      "17835 [D loss: (0.598)(R 0.482, F 0.714)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.955] [G acc: 0.625]\n",
      "17836 [D loss: (0.615)(R 0.675, F 0.555)] [D acc: (0.594)(0.438, 0.750)] [G loss: 3.333] [G acc: 0.250]\n",
      "17837 [D loss: (0.717)(R 0.709, F 0.725)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.703] [G acc: 0.688]\n",
      "17838 [D loss: (0.673)(R 0.690, F 0.656)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.683] [G acc: 0.438]\n",
      "17839 [D loss: (0.845)(R 0.764, F 0.925)] [D acc: (0.375)(0.562, 0.188)] [G loss: 0.676] [G acc: 0.625]\n",
      "17840 [D loss: (0.827)(R 0.684, F 0.970)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.655] [G acc: 0.625]\n",
      "17841 [D loss: (0.600)(R 0.581, F 0.619)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.700] [G acc: 0.562]\n",
      "17842 [D loss: (0.680)(R 0.609, F 0.750)] [D acc: (0.406)(0.500, 0.312)] [G loss: 0.717] [G acc: 0.438]\n",
      "17843 [D loss: (0.689)(R 0.618, F 0.759)] [D acc: (0.469)(0.688, 0.250)] [G loss: 1.123] [G acc: 0.312]\n",
      "17844 [D loss: (0.567)(R 0.627, F 0.507)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.563] [G acc: 0.438]\n",
      "17845 [D loss: (0.559)(R 0.700, F 0.418)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.696] [G acc: 0.188]\n",
      "17846 [D loss: (0.598)(R 0.604, F 0.592)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.062] [G acc: 0.188]\n",
      "17847 [D loss: (0.507)(R 0.562, F 0.452)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.072] [G acc: 0.188]\n",
      "17848 [D loss: (0.515)(R 0.526, F 0.505)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.488] [G acc: 0.188]\n",
      "17849 [D loss: (0.629)(R 0.619, F 0.640)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.966] [G acc: 0.500]\n",
      "17850 [D loss: (0.554)(R 0.524, F 0.584)] [D acc: (0.688)(0.875, 0.500)] [G loss: 1.017] [G acc: 0.250]\n",
      "17851 [D loss: (0.672)(R 0.839, F 0.506)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.813] [G acc: 0.375]\n",
      "17852 [D loss: (0.670)(R 0.633, F 0.707)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.836] [G acc: 0.375]\n",
      "17853 [D loss: (0.756)(R 0.721, F 0.791)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.745] [G acc: 0.375]\n",
      "17854 [D loss: (0.658)(R 0.626, F 0.689)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.730] [G acc: 0.625]\n",
      "17855 [D loss: (0.637)(R 0.649, F 0.625)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.691] [G acc: 0.562]\n",
      "17856 [D loss: (0.725)(R 0.702, F 0.748)] [D acc: (0.406)(0.500, 0.312)] [G loss: 0.691] [G acc: 0.625]\n",
      "17857 [D loss: (0.599)(R 0.649, F 0.549)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.729] [G acc: 0.312]\n",
      "17858 [D loss: (0.599)(R 0.598, F 0.600)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.785] [G acc: 0.438]\n",
      "17859 [D loss: (0.614)(R 0.489, F 0.740)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.816] [G acc: 0.250]\n",
      "17860 [D loss: (0.718)(R 0.670, F 0.767)] [D acc: (0.375)(0.500, 0.250)] [G loss: 0.959] [G acc: 0.312]\n",
      "17861 [D loss: (0.902)(R 0.951, F 0.853)] [D acc: (0.469)(0.312, 0.625)] [G loss: 1.931] [G acc: 0.500]\n",
      "17862 [D loss: (0.629)(R 0.863, F 0.394)] [D acc: (0.688)(0.750, 0.625)] [G loss: 7.805] [G acc: 0.188]\n",
      "17863 [D loss: (0.617)(R 0.578, F 0.656)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.583] [G acc: 0.750]\n",
      "17864 [D loss: (0.615)(R 0.582, F 0.648)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.744] [G acc: 0.375]\n",
      "17865 [D loss: (0.654)(R 0.650, F 0.658)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.901] [G acc: 0.312]\n",
      "17866 [D loss: (0.702)(R 0.721, F 0.683)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.832] [G acc: 0.312]\n",
      "17867 [D loss: (0.626)(R 0.643, F 0.609)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.956] [G acc: 0.250]\n",
      "17868 [D loss: (0.689)(R 0.635, F 0.742)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.718] [G acc: 0.688]\n",
      "17869 [D loss: (0.642)(R 0.668, F 0.616)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.887] [G acc: 0.250]\n",
      "17870 [D loss: (0.657)(R 0.605, F 0.710)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.663] [G acc: 0.500]\n",
      "17871 [D loss: (0.685)(R 0.569, F 0.801)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.709] [G acc: 0.375]\n",
      "17872 [D loss: (0.685)(R 0.490, F 0.880)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.753] [G acc: 0.500]\n",
      "17873 [D loss: (0.701)(R 0.610, F 0.792)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.853] [G acc: 0.438]\n",
      "17874 [D loss: (0.609)(R 0.565, F 0.653)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.790] [G acc: 0.188]\n",
      "17875 [D loss: (0.556)(R 0.474, F 0.637)] [D acc: (0.781)(0.938, 0.625)] [G loss: 0.857] [G acc: 0.250]\n",
      "17876 [D loss: (0.636)(R 0.657, F 0.616)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.808] [G acc: 0.250]\n",
      "17877 [D loss: (0.561)(R 0.520, F 0.602)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.967] [G acc: 0.312]\n",
      "17878 [D loss: (0.635)(R 0.595, F 0.675)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.804] [G acc: 0.250]\n",
      "17879 [D loss: (0.619)(R 0.586, F 0.652)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.763] [G acc: 0.438]\n",
      "17880 [D loss: (0.636)(R 0.581, F 0.692)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.798] [G acc: 0.250]\n",
      "17881 [D loss: (0.566)(R 0.525, F 0.608)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.941] [G acc: 0.312]\n",
      "17882 [D loss: (0.878)(R 1.264, F 0.493)] [D acc: (0.594)(0.312, 0.875)] [G loss: 1.769] [G acc: 0.125]\n",
      "17883 [D loss: (0.700)(R 0.664, F 0.736)] [D acc: (0.562)(0.500, 0.625)] [G loss: 1.248] [G acc: 0.375]\n",
      "17884 [D loss: (0.596)(R 0.632, F 0.560)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.264] [G acc: 0.125]\n",
      "17885 [D loss: (0.615)(R 0.590, F 0.640)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.794] [G acc: 0.188]\n",
      "17886 [D loss: (0.667)(R 0.713, F 0.620)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.741] [G acc: 0.375]\n",
      "17887 [D loss: (0.726)(R 0.666, F 0.786)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.764] [G acc: 0.312]\n",
      "17888 [D loss: (0.616)(R 0.532, F 0.699)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.896] [G acc: 0.375]\n",
      "17889 [D loss: (0.567)(R 0.589, F 0.545)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.742] [G acc: 0.312]\n",
      "17890 [D loss: (0.682)(R 0.520, F 0.844)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.781] [G acc: 0.188]\n",
      "17891 [D loss: (0.708)(R 0.704, F 0.712)] [D acc: (0.344)(0.250, 0.438)] [G loss: 0.839] [G acc: 0.250]\n",
      "17892 [D loss: (0.730)(R 0.686, F 0.774)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.762] [G acc: 0.250]\n",
      "17893 [D loss: (0.646)(R 0.544, F 0.748)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.795] [G acc: 0.312]\n",
      "17894 [D loss: (0.667)(R 0.700, F 0.634)] [D acc: (0.562)(0.312, 0.812)] [G loss: 0.870] [G acc: 0.250]\n",
      "17895 [D loss: (0.677)(R 0.685, F 0.669)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.774] [G acc: 0.312]\n",
      "17896 [D loss: (0.699)(R 0.630, F 0.767)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.951] [G acc: 0.312]\n",
      "17897 [D loss: (0.896)(R 0.478, F 1.313)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.896] [G acc: 0.188]\n",
      "17898 [D loss: (0.627)(R 0.603, F 0.651)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.885] [G acc: 0.062]\n",
      "17899 [D loss: (0.642)(R 0.702, F 0.581)] [D acc: (0.656)(0.375, 0.938)] [G loss: 0.864] [G acc: 0.188]\n",
      "17900 [D loss: (0.635)(R 0.634, F 0.636)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.832] [G acc: 0.062]\n",
      "17901 [D loss: (0.639)(R 0.676, F 0.602)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.911] [G acc: 0.125]\n",
      "17902 [D loss: (0.634)(R 0.671, F 0.597)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.965] [G acc: 0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17903 [D loss: (0.696)(R 0.749, F 0.643)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.844] [G acc: 0.125]\n",
      "17904 [D loss: (0.547)(R 0.535, F 0.559)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.899] [G acc: 0.062]\n",
      "17905 [D loss: (0.694)(R 0.766, F 0.622)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.869] [G acc: 0.250]\n",
      "17906 [D loss: (0.613)(R 0.633, F 0.593)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.018] [G acc: 0.125]\n",
      "17907 [D loss: (0.569)(R 0.581, F 0.556)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.022] [G acc: 0.062]\n",
      "17908 [D loss: (0.615)(R 0.644, F 0.586)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.986] [G acc: 0.062]\n",
      "17909 [D loss: (0.629)(R 0.517, F 0.741)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.892] [G acc: 0.250]\n",
      "17910 [D loss: (0.604)(R 0.610, F 0.599)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.935] [G acc: 0.125]\n",
      "17911 [D loss: (0.574)(R 0.603, F 0.544)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.810] [G acc: 0.312]\n",
      "17912 [D loss: (0.693)(R 0.781, F 0.605)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.830] [G acc: 0.188]\n",
      "17913 [D loss: (0.736)(R 0.773, F 0.700)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.004] [G acc: 0.375]\n",
      "17914 [D loss: (0.419)(R 0.598, F 0.240)] [D acc: (0.656)(0.438, 0.875)] [G loss: 4.634] [G acc: 0.125]\n",
      "17915 [D loss: (0.527)(R 0.539, F 0.515)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.288] [G acc: 0.250]\n",
      "17916 [D loss: (0.578)(R 0.629, F 0.528)] [D acc: (0.812)(0.625, 1.000)] [G loss: 1.004] [G acc: 0.250]\n",
      "17917 [D loss: (0.706)(R 0.827, F 0.586)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.438] [G acc: 0.250]\n",
      "17918 [D loss: (0.644)(R 0.650, F 0.639)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.728] [G acc: 0.375]\n",
      "17919 [D loss: (0.627)(R 0.617, F 0.636)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.849] [G acc: 0.250]\n",
      "17920 [D loss: (0.599)(R 0.652, F 0.546)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.830] [G acc: 0.250]\n",
      "17921 [D loss: (0.560)(R 0.424, F 0.696)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.045] [G acc: 0.125]\n",
      "17922 [D loss: (0.585)(R 0.558, F 0.612)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.917] [G acc: 0.250]\n",
      "17923 [D loss: (0.633)(R 0.643, F 0.623)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.697] [G acc: 0.312]\n",
      "17924 [D loss: (0.606)(R 0.612, F 0.600)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.892] [G acc: 0.125]\n",
      "17925 [D loss: (0.566)(R 0.593, F 0.538)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.840] [G acc: 0.188]\n",
      "17926 [D loss: (0.590)(R 0.619, F 0.560)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.846] [G acc: 0.188]\n",
      "17927 [D loss: (0.700)(R 0.762, F 0.637)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.049] [G acc: 0.188]\n",
      "17928 [D loss: (0.526)(R 0.442, F 0.609)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.010] [G acc: 0.375]\n",
      "17929 [D loss: (0.490)(R 0.425, F 0.556)] [D acc: (0.875)(0.875, 0.875)] [G loss: 0.938] [G acc: 0.188]\n",
      "17930 [D loss: (0.636)(R 0.535, F 0.737)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.918] [G acc: 0.188]\n",
      "17931 [D loss: (0.601)(R 0.574, F 0.627)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.873] [G acc: 0.188]\n",
      "17932 [D loss: (0.625)(R 0.702, F 0.548)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.921] [G acc: 0.125]\n",
      "17933 [D loss: (0.531)(R 0.609, F 0.453)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.875] [G acc: 0.188]\n",
      "17934 [D loss: (0.556)(R 0.592, F 0.519)] [D acc: (0.656)(0.438, 0.875)] [G loss: 1.108] [G acc: 0.000]\n",
      "17935 [D loss: (0.532)(R 0.563, F 0.502)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.920] [G acc: 0.062]\n",
      "17936 [D loss: (0.472)(R 0.493, F 0.450)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.952] [G acc: 0.062]\n",
      "17937 [D loss: (0.520)(R 0.433, F 0.607)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.904] [G acc: 0.188]\n",
      "17938 [D loss: (0.540)(R 0.483, F 0.597)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.879] [G acc: 0.188]\n",
      "17939 [D loss: (0.481)(R 0.416, F 0.545)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.932] [G acc: 0.188]\n",
      "17940 [D loss: (0.609)(R 0.667, F 0.550)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.881] [G acc: 0.125]\n",
      "17941 [D loss: (0.629)(R 0.725, F 0.533)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.710] [G acc: 0.438]\n",
      "17942 [D loss: (0.607)(R 0.618, F 0.595)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.072] [G acc: 0.250]\n",
      "17943 [D loss: (0.562)(R 0.560, F 0.563)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.904] [G acc: 0.375]\n",
      "17944 [D loss: (0.498)(R 0.565, F 0.430)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.261] [G acc: 0.062]\n",
      "17945 [D loss: (0.567)(R 0.586, F 0.548)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.066] [G acc: 0.125]\n",
      "17946 [D loss: (0.595)(R 0.559, F 0.631)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.884] [G acc: 0.188]\n",
      "17947 [D loss: (0.488)(R 0.474, F 0.501)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.798] [G acc: 0.562]\n",
      "17948 [D loss: (0.946)(R 0.730, F 1.161)] [D acc: (0.469)(0.375, 0.562)] [G loss: 3.374] [G acc: 0.500]\n",
      "17949 [D loss: (0.456)(R 0.593, F 0.319)] [D acc: (0.719)(0.688, 0.750)] [G loss: 5.217] [G acc: 0.188]\n",
      "17950 [D loss: (0.484)(R 0.375, F 0.594)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.070] [G acc: 0.188]\n",
      "17951 [D loss: (0.458)(R 0.449, F 0.466)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.125] [G acc: 0.062]\n",
      "17952 [D loss: (0.545)(R 0.584, F 0.506)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.899] [G acc: 0.250]\n",
      "17953 [D loss: (0.528)(R 0.479, F 0.578)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.046] [G acc: 0.438]\n",
      "17954 [D loss: (0.610)(R 0.701, F 0.518)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.886] [G acc: 0.375]\n",
      "17955 [D loss: (0.491)(R 0.477, F 0.505)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.841] [G acc: 0.375]\n",
      "17956 [D loss: (0.881)(R 0.512, F 1.250)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.921] [G acc: 0.125]\n",
      "17957 [D loss: (0.663)(R 0.616, F 0.710)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.989] [G acc: 0.062]\n",
      "17958 [D loss: (0.692)(R 0.528, F 0.855)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.152] [G acc: 0.125]\n",
      "17959 [D loss: (1.106)(R 0.496, F 1.715)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.008] [G acc: 0.062]\n",
      "17960 [D loss: (0.565)(R 0.631, F 0.500)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.202] [G acc: 0.562]\n",
      "17961 [D loss: (0.525)(R 0.621, F 0.429)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.123] [G acc: 0.062]\n",
      "17962 [D loss: (0.548)(R 0.628, F 0.469)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.982] [G acc: 0.188]\n",
      "17963 [D loss: (0.474)(R 0.566, F 0.382)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.849] [G acc: 0.375]\n",
      "17964 [D loss: (0.562)(R 0.560, F 0.565)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.852] [G acc: 0.375]\n",
      "17965 [D loss: (0.592)(R 0.582, F 0.603)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.307] [G acc: 0.250]\n",
      "17966 [D loss: (0.545)(R 0.564, F 0.526)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.112] [G acc: 0.188]\n",
      "17967 [D loss: (0.704)(R 0.445, F 0.964)] [D acc: (0.688)(0.750, 0.625)] [G loss: 2.077] [G acc: 0.125]\n",
      "17968 [D loss: (0.435)(R 0.691, F 0.178)] [D acc: (0.688)(0.375, 1.000)] [G loss: 2.413] [G acc: 0.062]\n",
      "17969 [D loss: (0.722)(R 0.850, F 0.594)] [D acc: (0.594)(0.438, 0.750)] [G loss: 1.141] [G acc: 0.312]\n",
      "17970 [D loss: (0.450)(R 0.500, F 0.399)] [D acc: (0.938)(0.938, 0.938)] [G loss: 1.468] [G acc: 0.188]\n",
      "17971 [D loss: (0.539)(R 0.582, F 0.496)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.083] [G acc: 0.188]\n",
      "17972 [D loss: (0.643)(R 0.714, F 0.573)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.122] [G acc: 0.125]\n",
      "17973 [D loss: (0.566)(R 0.620, F 0.512)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.913] [G acc: 0.312]\n",
      "17974 [D loss: (0.529)(R 0.580, F 0.478)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.982] [G acc: 0.125]\n",
      "17975 [D loss: (0.587)(R 0.506, F 0.668)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.066] [G acc: 0.250]\n",
      "17976 [D loss: (0.615)(R 0.453, F 0.778)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.913] [G acc: 0.062]\n",
      "17977 [D loss: (0.501)(R 0.824, F 0.178)] [D acc: (0.656)(0.438, 0.875)] [G loss: 2.550] [G acc: 0.000]\n",
      "17978 [D loss: (0.471)(R 0.492, F 0.450)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.012] [G acc: 0.438]\n",
      "17979 [D loss: (0.532)(R 0.506, F 0.557)] [D acc: (0.875)(0.875, 0.875)] [G loss: 0.950] [G acc: 0.188]\n",
      "17980 [D loss: (0.640)(R 0.689, F 0.591)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.979] [G acc: 0.188]\n",
      "17981 [D loss: (0.535)(R 0.578, F 0.491)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.948] [G acc: 0.125]\n",
      "17982 [D loss: (0.688)(R 0.867, F 0.508)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.149] [G acc: 0.125]\n",
      "17983 [D loss: (0.786)(R 0.780, F 0.791)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.947] [G acc: 0.312]\n",
      "17984 [D loss: (0.532)(R 0.609, F 0.456)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.861] [G acc: 0.250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17985 [D loss: (0.736)(R 0.608, F 0.864)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.938] [G acc: 0.125]\n",
      "17986 [D loss: (0.539)(R 0.574, F 0.503)] [D acc: (0.750)(0.875, 0.625)] [G loss: 1.016] [G acc: 0.188]\n",
      "17987 [D loss: (0.625)(R 0.715, F 0.535)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.614] [G acc: 0.250]\n",
      "17988 [D loss: (0.428)(R 0.297, F 0.559)] [D acc: (0.750)(0.875, 0.625)] [G loss: 1.486] [G acc: 0.250]\n",
      "17989 [D loss: (0.458)(R 0.581, F 0.335)] [D acc: (0.781)(0.625, 0.938)] [G loss: 2.059] [G acc: 0.062]\n",
      "17990 [D loss: (0.565)(R 0.606, F 0.523)] [D acc: (0.594)(0.500, 0.688)] [G loss: 1.196] [G acc: 0.188]\n",
      "17991 [D loss: (0.540)(R 0.569, F 0.511)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.086] [G acc: 0.188]\n",
      "17992 [D loss: (0.485)(R 0.512, F 0.459)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.988] [G acc: 0.312]\n",
      "17993 [D loss: (0.740)(R 0.445, F 1.036)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.048] [G acc: 0.375]\n",
      "17994 [D loss: (0.744)(R 0.619, F 0.870)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.224] [G acc: 0.188]\n",
      "17995 [D loss: (0.518)(R 0.543, F 0.493)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.353] [G acc: 0.062]\n",
      "17996 [D loss: (0.665)(R 0.729, F 0.601)] [D acc: (0.594)(0.500, 0.688)] [G loss: 1.054] [G acc: 0.250]\n",
      "17997 [D loss: (0.624)(R 0.644, F 0.605)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.715] [G acc: 0.438]\n",
      "17998 [D loss: (0.451)(R 0.399, F 0.503)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.024] [G acc: 0.062]\n",
      "17999 [D loss: (0.502)(R 0.459, F 0.544)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.148] [G acc: 0.250]\n",
      "18000 [D loss: (0.586)(R 0.597, F 0.576)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.941] [G acc: 0.250]\n",
      "18001 [D loss: (0.781)(R 0.627, F 0.935)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.904] [G acc: 0.500]\n",
      "18002 [D loss: (0.572)(R 0.513, F 0.631)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.951] [G acc: 0.250]\n",
      "18003 [D loss: (0.890)(R 0.551, F 1.229)] [D acc: (0.562)(0.500, 0.625)] [G loss: 1.374] [G acc: 0.375]\n",
      "18004 [D loss: (0.466)(R 0.697, F 0.234)] [D acc: (0.781)(0.625, 0.938)] [G loss: 4.869] [G acc: 0.062]\n",
      "18005 [D loss: (0.690)(R 0.587, F 0.793)] [D acc: (0.656)(0.750, 0.562)] [G loss: 3.360] [G acc: 0.438]\n",
      "18006 [D loss: (1.071)(R 1.105, F 1.036)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.882] [G acc: 0.250]\n",
      "18007 [D loss: (0.696)(R 0.796, F 0.596)] [D acc: (0.562)(0.500, 0.625)] [G loss: 1.005] [G acc: 0.250]\n",
      "18008 [D loss: (0.598)(R 0.694, F 0.503)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.868] [G acc: 0.125]\n",
      "18009 [D loss: (0.586)(R 0.524, F 0.648)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.255] [G acc: 0.312]\n",
      "18010 [D loss: (0.633)(R 0.721, F 0.545)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.870] [G acc: 0.250]\n",
      "18011 [D loss: (0.513)(R 0.518, F 0.507)] [D acc: (0.906)(0.812, 1.000)] [G loss: 1.279] [G acc: 0.188]\n",
      "18012 [D loss: (0.618)(R 0.562, F 0.674)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.764] [G acc: 0.312]\n",
      "18013 [D loss: (0.553)(R 0.524, F 0.583)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.694] [G acc: 0.500]\n",
      "18014 [D loss: (0.583)(R 0.502, F 0.664)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.888] [G acc: 0.125]\n",
      "18015 [D loss: (0.637)(R 0.629, F 0.645)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.624] [G acc: 0.375]\n",
      "18016 [D loss: (0.802)(R 0.784, F 0.820)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.784] [G acc: 0.188]\n",
      "18017 [D loss: (0.572)(R 0.549, F 0.596)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.775] [G acc: 0.438]\n",
      "18018 [D loss: (0.484)(R 0.662, F 0.305)] [D acc: (0.812)(0.625, 1.000)] [G loss: 1.098] [G acc: 0.062]\n",
      "18019 [D loss: (0.509)(R 0.537, F 0.480)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.981] [G acc: 0.250]\n",
      "18020 [D loss: (0.546)(R 0.504, F 0.588)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.814] [G acc: 0.375]\n",
      "18021 [D loss: (0.832)(R 0.439, F 1.225)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.967] [G acc: 0.250]\n",
      "18022 [D loss: (0.531)(R 0.494, F 0.569)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.266] [G acc: 0.375]\n",
      "18023 [D loss: (0.551)(R 0.637, F 0.464)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.886] [G acc: 0.375]\n",
      "18024 [D loss: (0.519)(R 0.727, F 0.311)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.951] [G acc: 0.250]\n",
      "18025 [D loss: (0.650)(R 0.713, F 0.586)] [D acc: (0.594)(0.500, 0.688)] [G loss: 1.084] [G acc: 0.125]\n",
      "18026 [D loss: (0.609)(R 0.650, F 0.568)] [D acc: (0.625)(0.438, 0.812)] [G loss: 1.211] [G acc: 0.375]\n",
      "18027 [D loss: (0.651)(R 0.667, F 0.635)] [D acc: (0.469)(0.438, 0.500)] [G loss: 1.001] [G acc: 0.188]\n",
      "18028 [D loss: (0.822)(R 0.549, F 1.096)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.805] [G acc: 0.438]\n",
      "18029 [D loss: (0.661)(R 0.632, F 0.690)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.951] [G acc: 0.312]\n",
      "18030 [D loss: (0.649)(R 0.593, F 0.704)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.636] [G acc: 0.562]\n",
      "18031 [D loss: (0.702)(R 0.715, F 0.689)] [D acc: (0.562)(0.438, 0.688)] [G loss: 1.347] [G acc: 0.562]\n",
      "18032 [D loss: (0.594)(R 0.584, F 0.605)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.887] [G acc: 0.312]\n",
      "18033 [D loss: (0.567)(R 0.475, F 0.659)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.840] [G acc: 0.250]\n",
      "18034 [D loss: (0.744)(R 0.755, F 0.732)] [D acc: (0.375)(0.312, 0.438)] [G loss: 0.902] [G acc: 0.250]\n",
      "18035 [D loss: (0.695)(R 0.719, F 0.672)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.806] [G acc: 0.312]\n",
      "18036 [D loss: (0.667)(R 0.660, F 0.674)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.808] [G acc: 0.375]\n",
      "18037 [D loss: (0.744)(R 0.689, F 0.799)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.975] [G acc: 0.188]\n",
      "18038 [D loss: (0.757)(R 0.761, F 0.754)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.742] [G acc: 0.500]\n",
      "18039 [D loss: (0.705)(R 0.722, F 0.687)] [D acc: (0.406)(0.312, 0.500)] [G loss: 0.718] [G acc: 0.500]\n",
      "18040 [D loss: (0.757)(R 0.635, F 0.878)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.705] [G acc: 0.625]\n",
      "18041 [D loss: (0.757)(R 0.613, F 0.901)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.781] [G acc: 0.312]\n",
      "18042 [D loss: (0.537)(R 0.480, F 0.595)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.027] [G acc: 0.062]\n",
      "18043 [D loss: (0.794)(R 0.568, F 1.020)] [D acc: (0.375)(0.438, 0.312)] [G loss: 0.610] [G acc: 0.562]\n",
      "18044 [D loss: (0.944)(R 0.468, F 1.421)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.773] [G acc: 0.250]\n",
      "18045 [D loss: (0.805)(R 0.846, F 0.764)] [D acc: (0.375)(0.188, 0.562)] [G loss: 0.736] [G acc: 0.438]\n",
      "18046 [D loss: (0.676)(R 0.649, F 0.704)] [D acc: (0.406)(0.375, 0.438)] [G loss: 0.759] [G acc: 0.375]\n",
      "18047 [D loss: (0.735)(R 0.646, F 0.823)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.560] [G acc: 0.562]\n",
      "18048 [D loss: (0.581)(R 0.583, F 0.578)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.756] [G acc: 0.500]\n",
      "18049 [D loss: (0.858)(R 0.729, F 0.987)] [D acc: (0.312)(0.250, 0.375)] [G loss: 1.316] [G acc: 0.375]\n",
      "18050 [D loss: (0.689)(R 0.717, F 0.660)] [D acc: (0.594)(0.375, 0.812)] [G loss: 4.283] [G acc: 0.000]\n",
      "18051 [D loss: (0.623)(R 0.555, F 0.691)] [D acc: (0.562)(0.625, 0.500)] [G loss: 4.193] [G acc: 0.188]\n",
      "18052 [D loss: (0.555)(R 0.536, F 0.575)] [D acc: (0.688)(0.500, 0.875)] [G loss: 1.073] [G acc: 0.250]\n",
      "18053 [D loss: (0.688)(R 0.678, F 0.698)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.900] [G acc: 0.000]\n",
      "18054 [D loss: (0.719)(R 0.687, F 0.750)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.897] [G acc: 0.125]\n",
      "18055 [D loss: (0.649)(R 0.622, F 0.677)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.874] [G acc: 0.000]\n",
      "18056 [D loss: (0.623)(R 0.608, F 0.639)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.819] [G acc: 0.062]\n",
      "18057 [D loss: (0.644)(R 0.669, F 0.618)] [D acc: (0.594)(0.312, 0.875)] [G loss: 0.834] [G acc: 0.125]\n",
      "18058 [D loss: (0.587)(R 0.593, F 0.582)] [D acc: (0.719)(0.500, 0.938)] [G loss: 0.975] [G acc: 0.375]\n",
      "18059 [D loss: (0.736)(R 0.904, F 0.568)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.790] [G acc: 0.250]\n",
      "18060 [D loss: (0.555)(R 0.470, F 0.640)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.791] [G acc: 0.062]\n",
      "18061 [D loss: (0.778)(R 0.959, F 0.597)] [D acc: (0.562)(0.312, 0.812)] [G loss: 0.777] [G acc: 0.250]\n",
      "18062 [D loss: (0.539)(R 0.513, F 0.564)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.741] [G acc: 0.375]\n",
      "18063 [D loss: (0.547)(R 0.490, F 0.604)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.717] [G acc: 0.375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18064 [D loss: (0.611)(R 0.482, F 0.739)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.750] [G acc: 0.375]\n",
      "18065 [D loss: (0.642)(R 0.617, F 0.666)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.597] [G acc: 0.562]\n",
      "18066 [D loss: (0.640)(R 0.517, F 0.763)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.610] [G acc: 0.562]\n",
      "18067 [D loss: (0.918)(R 0.625, F 1.211)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.847] [G acc: 0.312]\n",
      "18068 [D loss: (0.632)(R 0.522, F 0.741)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.751] [G acc: 0.250]\n",
      "18069 [D loss: (0.654)(R 0.640, F 0.669)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.844] [G acc: 0.562]\n",
      "18070 [D loss: (0.603)(R 0.496, F 0.711)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.887] [G acc: 0.500]\n",
      "18071 [D loss: (0.561)(R 0.678, F 0.443)] [D acc: (0.719)(0.500, 0.938)] [G loss: 0.876] [G acc: 0.062]\n",
      "18072 [D loss: (0.517)(R 0.436, F 0.598)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.790] [G acc: 0.312]\n",
      "18073 [D loss: (0.516)(R 0.528, F 0.505)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.873] [G acc: 0.062]\n",
      "18074 [D loss: (0.548)(R 0.509, F 0.587)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.770] [G acc: 0.125]\n",
      "18075 [D loss: (0.703)(R 0.588, F 0.817)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.815] [G acc: 0.250]\n",
      "18076 [D loss: (0.671)(R 0.634, F 0.709)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.627] [G acc: 0.500]\n",
      "18077 [D loss: (0.667)(R 0.551, F 0.784)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.833] [G acc: 0.438]\n",
      "18078 [D loss: (0.641)(R 0.605, F 0.677)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.876] [G acc: 0.062]\n",
      "18079 [D loss: (0.709)(R 0.703, F 0.715)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.791] [G acc: 0.312]\n",
      "18080 [D loss: (0.625)(R 0.508, F 0.742)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.600] [G acc: 0.500]\n",
      "18081 [D loss: (0.738)(R 0.618, F 0.858)] [D acc: (0.500)(0.562, 0.438)] [G loss: 1.021] [G acc: 0.125]\n",
      "18082 [D loss: (0.569)(R 0.692, F 0.445)] [D acc: (0.656)(0.375, 0.938)] [G loss: 1.166] [G acc: 0.062]\n",
      "18083 [D loss: (0.591)(R 0.659, F 0.522)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.862] [G acc: 0.312]\n",
      "18084 [D loss: (0.544)(R 0.610, F 0.478)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.870] [G acc: 0.188]\n",
      "18085 [D loss: (0.506)(R 0.469, F 0.543)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.880] [G acc: 0.188]\n",
      "18086 [D loss: (0.550)(R 0.532, F 0.567)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.830] [G acc: 0.062]\n",
      "18087 [D loss: (0.603)(R 0.526, F 0.680)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.848] [G acc: 0.125]\n",
      "18088 [D loss: (0.648)(R 0.527, F 0.769)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.800] [G acc: 0.250]\n",
      "18089 [D loss: (0.629)(R 0.448, F 0.811)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.827] [G acc: 0.125]\n",
      "18090 [D loss: (0.563)(R 0.501, F 0.625)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.727] [G acc: 0.375]\n",
      "18091 [D loss: (0.637)(R 0.683, F 0.591)] [D acc: (0.625)(0.312, 0.938)] [G loss: 0.777] [G acc: 0.250]\n",
      "18092 [D loss: (0.567)(R 0.498, F 0.635)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.829] [G acc: 0.188]\n",
      "18093 [D loss: (0.619)(R 0.624, F 0.615)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.880] [G acc: 0.188]\n",
      "18094 [D loss: (0.609)(R 0.548, F 0.670)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.823] [G acc: 0.062]\n",
      "18095 [D loss: (0.579)(R 0.502, F 0.655)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.844] [G acc: 0.250]\n",
      "18096 [D loss: (0.528)(R 0.435, F 0.621)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.701] [G acc: 0.250]\n",
      "18097 [D loss: (0.653)(R 0.542, F 0.764)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.881] [G acc: 0.188]\n",
      "18098 [D loss: (0.655)(R 0.665, F 0.646)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.813] [G acc: 0.312]\n",
      "18099 [D loss: (0.542)(R 0.488, F 0.596)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.766] [G acc: 0.312]\n",
      "18100 [D loss: (0.564)(R 0.551, F 0.576)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.835] [G acc: 0.000]\n",
      "18101 [D loss: (0.724)(R 0.593, F 0.854)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.706] [G acc: 0.500]\n",
      "18102 [D loss: (0.563)(R 0.509, F 0.618)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.596] [G acc: 0.688]\n",
      "18103 [D loss: (0.878)(R 0.848, F 0.908)] [D acc: (0.406)(0.375, 0.438)] [G loss: 0.859] [G acc: 0.188]\n",
      "18104 [D loss: (0.935)(R 0.518, F 1.353)] [D acc: (0.406)(0.500, 0.312)] [G loss: 0.814] [G acc: 0.562]\n",
      "18105 [D loss: (0.475)(R 0.492, F 0.457)] [D acc: (0.750)(0.625, 0.875)] [G loss: 6.943] [G acc: 0.062]\n",
      "18106 [D loss: (1.250)(R 0.513, F 1.986)] [D acc: (0.719)(0.688, 0.750)] [G loss: 2.734] [G acc: 0.188]\n",
      "18107 [D loss: (0.661)(R 0.741, F 0.582)] [D acc: (0.594)(0.312, 0.875)] [G loss: 1.062] [G acc: 0.000]\n",
      "18108 [D loss: (0.581)(R 0.586, F 0.577)] [D acc: (0.688)(0.438, 0.938)] [G loss: 0.836] [G acc: 0.188]\n",
      "18109 [D loss: (0.630)(R 0.700, F 0.561)] [D acc: (0.656)(0.375, 0.938)] [G loss: 0.816] [G acc: 0.188]\n",
      "18110 [D loss: (0.702)(R 0.759, F 0.645)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.902] [G acc: 0.062]\n",
      "18111 [D loss: (0.627)(R 0.692, F 0.563)] [D acc: (0.688)(0.438, 0.938)] [G loss: 0.798] [G acc: 0.312]\n",
      "18112 [D loss: (0.569)(R 0.511, F 0.627)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.856] [G acc: 0.062]\n",
      "18113 [D loss: (0.602)(R 0.634, F 0.571)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.670] [G acc: 0.625]\n",
      "18114 [D loss: (0.707)(R 0.728, F 0.686)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.774] [G acc: 0.250]\n",
      "18115 [D loss: (0.654)(R 0.737, F 0.572)] [D acc: (0.656)(0.375, 0.938)] [G loss: 0.782] [G acc: 0.188]\n",
      "18116 [D loss: (0.634)(R 0.653, F 0.614)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.818] [G acc: 0.125]\n",
      "18117 [D loss: (0.620)(R 0.525, F 0.715)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.807] [G acc: 0.188]\n",
      "18118 [D loss: (0.561)(R 0.515, F 0.607)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.977] [G acc: 0.188]\n",
      "18119 [D loss: (0.728)(R 0.872, F 0.583)] [D acc: (0.562)(0.250, 0.875)] [G loss: 0.737] [G acc: 0.312]\n",
      "18120 [D loss: (0.559)(R 0.557, F 0.561)] [D acc: (0.719)(0.500, 0.938)] [G loss: 0.865] [G acc: 0.125]\n",
      "18121 [D loss: (0.471)(R 0.390, F 0.553)] [D acc: (0.875)(0.750, 1.000)] [G loss: 0.778] [G acc: 0.250]\n",
      "18122 [D loss: (0.676)(R 0.532, F 0.820)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.868] [G acc: 0.062]\n",
      "18123 [D loss: (1.067)(R 0.664, F 1.471)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.653] [G acc: 0.625]\n",
      "18124 [D loss: (0.666)(R 0.653, F 0.678)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.762] [G acc: 0.250]\n",
      "18125 [D loss: (0.546)(R 0.501, F 0.592)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.817] [G acc: 0.188]\n",
      "18126 [D loss: (0.691)(R 0.817, F 0.565)] [D acc: (0.469)(0.188, 0.750)] [G loss: 0.417] [G acc: 0.750]\n",
      "18127 [D loss: (0.815)(R 0.698, F 0.932)] [D acc: (0.500)(0.188, 0.812)] [G loss: 0.593] [G acc: 0.500]\n",
      "18128 [D loss: (0.694)(R 0.722, F 0.667)] [D acc: (0.531)(0.250, 0.812)] [G loss: 0.562] [G acc: 0.688]\n",
      "18129 [D loss: (0.992)(R 0.530, F 1.455)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.974] [G acc: 0.250]\n",
      "18130 [D loss: (0.481)(R 0.623, F 0.340)] [D acc: (0.656)(0.375, 0.938)] [G loss: 1.047] [G acc: 0.188]\n",
      "18131 [D loss: (0.611)(R 0.734, F 0.489)] [D acc: (0.656)(0.375, 0.938)] [G loss: 0.881] [G acc: 0.062]\n",
      "18132 [D loss: (0.711)(R 0.657, F 0.765)] [D acc: (0.406)(0.312, 0.500)] [G loss: 0.754] [G acc: 0.312]\n",
      "18133 [D loss: (1.368)(R 0.797, F 1.940)] [D acc: (0.375)(0.312, 0.438)] [G loss: 0.962] [G acc: 0.250]\n",
      "18134 [D loss: (0.587)(R 0.680, F 0.493)] [D acc: (0.594)(0.312, 0.875)] [G loss: 1.045] [G acc: 0.188]\n",
      "18135 [D loss: (0.843)(R 0.711, F 0.974)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.932] [G acc: 0.375]\n",
      "18136 [D loss: (0.744)(R 0.649, F 0.839)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.851] [G acc: 0.250]\n",
      "18137 [D loss: (1.103)(R 0.720, F 1.485)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.788] [G acc: 0.438]\n",
      "18138 [D loss: (1.076)(R 0.782, F 1.370)] [D acc: (0.469)(0.250, 0.688)] [G loss: 0.628] [G acc: 0.500]\n",
      "18139 [D loss: (0.521)(R 0.717, F 0.324)] [D acc: (0.500)(0.250, 0.750)] [G loss: 0.960] [G acc: 0.375]\n",
      "18140 [D loss: (1.083)(R 0.695, F 1.471)] [D acc: (0.312)(0.250, 0.375)] [G loss: 1.045] [G acc: 0.562]\n",
      "18141 [D loss: (0.511)(R 0.595, F 0.426)] [D acc: (0.656)(0.500, 0.812)] [G loss: 2.031] [G acc: 0.125]\n",
      "18142 [D loss: (0.741)(R 0.876, F 0.607)] [D acc: (0.406)(0.062, 0.750)] [G loss: 2.902] [G acc: 0.500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18143 [D loss: (0.765)(R 0.781, F 0.748)] [D acc: (0.469)(0.188, 0.750)] [G loss: 0.819] [G acc: 0.312]\n",
      "18144 [D loss: (0.840)(R 0.927, F 0.752)] [D acc: (0.406)(0.312, 0.500)] [G loss: 0.941] [G acc: 0.312]\n",
      "18145 [D loss: (0.918)(R 0.665, F 1.171)] [D acc: (0.406)(0.375, 0.438)] [G loss: 0.956] [G acc: 0.250]\n",
      "18146 [D loss: (0.831)(R 0.745, F 0.918)] [D acc: (0.500)(0.188, 0.812)] [G loss: 0.891] [G acc: 0.188]\n",
      "18147 [D loss: (0.900)(R 0.787, F 1.013)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.767] [G acc: 0.312]\n",
      "18148 [D loss: (0.843)(R 0.926, F 0.760)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.627] [G acc: 0.375]\n",
      "18149 [D loss: (0.631)(R 0.654, F 0.609)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.926] [G acc: 0.562]\n",
      "18150 [D loss: (0.745)(R 0.882, F 0.608)] [D acc: (0.344)(0.000, 0.688)] [G loss: 0.756] [G acc: 0.312]\n",
      "18151 [D loss: (0.575)(R 0.662, F 0.489)] [D acc: (0.594)(0.312, 0.875)] [G loss: 1.363] [G acc: 0.375]\n",
      "18152 [D loss: (0.897)(R 0.703, F 1.090)] [D acc: (0.562)(0.438, 0.688)] [G loss: 2.328] [G acc: 0.250]\n",
      "18153 [D loss: (0.585)(R 0.719, F 0.451)] [D acc: (0.719)(0.438, 1.000)] [G loss: 1.814] [G acc: 0.062]\n",
      "18154 [D loss: (0.739)(R 0.787, F 0.692)] [D acc: (0.500)(0.250, 0.750)] [G loss: 1.516] [G acc: 0.188]\n",
      "18155 [D loss: (0.659)(R 0.775, F 0.544)] [D acc: (0.656)(0.375, 0.938)] [G loss: 1.947] [G acc: 0.250]\n",
      "18156 [D loss: (0.694)(R 0.717, F 0.671)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.976] [G acc: 0.125]\n",
      "18157 [D loss: (0.670)(R 0.714, F 0.626)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.770] [G acc: 0.250]\n",
      "18158 [D loss: (0.700)(R 0.713, F 0.687)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.746] [G acc: 0.312]\n",
      "18159 [D loss: (0.694)(R 0.727, F 0.662)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.743] [G acc: 0.188]\n",
      "18160 [D loss: (0.700)(R 0.731, F 0.668)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.725] [G acc: 0.438]\n",
      "18161 [D loss: (0.644)(R 0.620, F 0.668)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.745] [G acc: 0.375]\n",
      "18162 [D loss: (0.678)(R 0.691, F 0.665)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.716] [G acc: 0.375]\n",
      "18163 [D loss: (0.650)(R 0.654, F 0.645)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.838] [G acc: 0.188]\n",
      "18164 [D loss: (0.702)(R 0.726, F 0.678)] [D acc: (0.438)(0.312, 0.562)] [G loss: 0.720] [G acc: 0.375]\n",
      "18165 [D loss: (0.621)(R 0.571, F 0.672)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.720] [G acc: 0.375]\n",
      "18166 [D loss: (0.645)(R 0.604, F 0.686)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.746] [G acc: 0.188]\n",
      "18167 [D loss: (0.694)(R 0.704, F 0.683)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.721] [G acc: 0.312]\n",
      "18168 [D loss: (0.700)(R 0.712, F 0.687)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.679] [G acc: 0.562]\n",
      "18169 [D loss: (0.646)(R 0.608, F 0.683)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.696] [G acc: 0.500]\n",
      "18170 [D loss: (0.631)(R 0.557, F 0.706)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.745] [G acc: 0.188]\n",
      "18171 [D loss: (0.681)(R 0.592, F 0.771)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.744] [G acc: 0.062]\n",
      "18172 [D loss: (0.769)(R 0.610, F 0.928)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.794] [G acc: 0.188]\n",
      "18173 [D loss: (0.582)(R 0.512, F 0.652)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.743] [G acc: 0.188]\n",
      "18174 [D loss: (0.590)(R 0.520, F 0.659)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.741] [G acc: 0.250]\n",
      "18175 [D loss: (0.613)(R 0.625, F 0.601)] [D acc: (0.719)(0.500, 0.938)] [G loss: 0.795] [G acc: 0.250]\n",
      "18176 [D loss: (0.668)(R 0.703, F 0.634)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.818] [G acc: 0.188]\n",
      "18177 [D loss: (0.577)(R 0.594, F 0.560)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.796] [G acc: 0.125]\n",
      "18178 [D loss: (0.591)(R 0.607, F 0.575)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.791] [G acc: 0.250]\n",
      "18179 [D loss: (0.661)(R 0.688, F 0.633)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.848] [G acc: 0.125]\n",
      "18180 [D loss: (0.634)(R 0.675, F 0.593)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.866] [G acc: 0.062]\n",
      "18181 [D loss: (0.555)(R 0.563, F 0.548)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.943] [G acc: 0.062]\n",
      "18182 [D loss: (0.601)(R 0.590, F 0.612)] [D acc: (0.750)(0.625, 0.875)] [G loss: 3.121] [G acc: 0.250]\n",
      "18183 [D loss: (0.601)(R 0.628, F 0.574)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.850] [G acc: 0.188]\n",
      "18184 [D loss: (0.619)(R 0.517, F 0.722)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.836] [G acc: 0.312]\n",
      "18185 [D loss: (0.774)(R 0.781, F 0.768)] [D acc: (0.656)(0.375, 0.938)] [G loss: 1.080] [G acc: 0.250]\n",
      "18186 [D loss: (0.594)(R 0.657, F 0.530)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.961] [G acc: 0.125]\n",
      "18187 [D loss: (0.626)(R 0.649, F 0.603)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.790] [G acc: 0.250]\n",
      "18188 [D loss: (0.589)(R 0.578, F 0.600)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.785] [G acc: 0.250]\n",
      "18189 [D loss: (0.480)(R 0.653, F 0.307)] [D acc: (0.719)(0.500, 0.938)] [G loss: 1.185] [G acc: 0.125]\n",
      "18190 [D loss: (0.580)(R 0.649, F 0.511)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.594] [G acc: 0.500]\n",
      "18191 [D loss: (0.511)(R 0.610, F 0.412)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.196] [G acc: 0.062]\n",
      "18192 [D loss: (0.626)(R 0.586, F 0.667)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.856] [G acc: 0.500]\n",
      "18193 [D loss: (0.553)(R 0.547, F 0.560)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.913] [G acc: 0.250]\n",
      "18194 [D loss: (0.815)(R 0.529, F 1.101)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.756] [G acc: 0.375]\n",
      "18195 [D loss: (1.189)(R 0.621, F 1.758)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.949] [G acc: 0.375]\n",
      "18196 [D loss: (0.703)(R 0.625, F 0.781)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.884] [G acc: 0.188]\n",
      "18197 [D loss: (0.842)(R 0.584, F 1.101)] [D acc: (0.688)(0.812, 0.562)] [G loss: 2.074] [G acc: 0.438]\n",
      "18198 [D loss: (0.416)(R 0.651, F 0.181)] [D acc: (0.781)(0.625, 0.938)] [G loss: 4.821] [G acc: 0.188]\n",
      "18199 [D loss: (0.527)(R 0.511, F 0.542)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.212] [G acc: 0.125]\n",
      "18200 [D loss: (0.553)(R 0.555, F 0.550)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.288] [G acc: 0.375]\n",
      "18201 [D loss: (0.869)(R 0.725, F 1.014)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.840] [G acc: 0.312]\n",
      "18202 [D loss: (0.661)(R 0.591, F 0.730)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.753] [G acc: 0.375]\n",
      "18203 [D loss: (0.621)(R 0.637, F 0.606)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.750] [G acc: 0.250]\n",
      "18204 [D loss: (0.745)(R 0.623, F 0.867)] [D acc: (0.500)(0.625, 0.375)] [G loss: 1.192] [G acc: 0.312]\n",
      "18205 [D loss: (0.616)(R 0.744, F 0.488)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.991] [G acc: 0.188]\n",
      "18206 [D loss: (0.579)(R 0.649, F 0.510)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.882] [G acc: 0.188]\n",
      "18207 [D loss: (0.671)(R 0.688, F 0.654)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.740] [G acc: 0.375]\n",
      "18208 [D loss: (0.662)(R 0.747, F 0.578)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.743] [G acc: 0.375]\n",
      "18209 [D loss: (0.549)(R 0.526, F 0.571)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.408] [G acc: 0.062]\n",
      "18210 [D loss: (0.608)(R 0.554, F 0.661)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.758] [G acc: 0.312]\n",
      "18211 [D loss: (0.838)(R 1.004, F 0.671)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.908] [G acc: 0.125]\n",
      "18212 [D loss: (0.636)(R 0.649, F 0.624)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.799] [G acc: 0.375]\n",
      "18213 [D loss: (0.608)(R 0.601, F 0.614)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.784] [G acc: 0.312]\n",
      "18214 [D loss: (0.617)(R 0.619, F 0.615)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.986] [G acc: 0.312]\n",
      "18215 [D loss: (0.590)(R 0.624, F 0.556)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.786] [G acc: 0.312]\n",
      "18216 [D loss: (0.909)(R 1.102, F 0.716)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.808] [G acc: 0.188]\n",
      "18217 [D loss: (0.620)(R 0.551, F 0.689)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.042] [G acc: 0.125]\n",
      "18218 [D loss: (0.719)(R 0.700, F 0.737)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.869] [G acc: 0.250]\n",
      "18219 [D loss: (0.613)(R 0.671, F 0.555)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.844] [G acc: 0.312]\n",
      "18220 [D loss: (0.699)(R 0.766, F 0.632)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.837] [G acc: 0.188]\n",
      "18221 [D loss: (0.622)(R 0.594, F 0.650)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.861] [G acc: 0.250]\n",
      "18222 [D loss: (0.788)(R 0.582, F 0.994)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.856] [G acc: 0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18223 [D loss: (0.669)(R 0.708, F 0.630)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.855] [G acc: 0.188]\n",
      "18224 [D loss: (0.600)(R 0.660, F 0.540)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.895] [G acc: 0.188]\n",
      "18225 [D loss: (0.591)(R 0.661, F 0.522)] [D acc: (0.844)(0.688, 1.000)] [G loss: 0.785] [G acc: 0.312]\n",
      "18226 [D loss: (0.575)(R 0.561, F 0.589)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.035] [G acc: 0.062]\n",
      "18227 [D loss: (0.563)(R 0.682, F 0.444)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.306] [G acc: 0.375]\n",
      "18228 [D loss: (0.387)(R 0.551, F 0.222)] [D acc: (0.781)(0.625, 0.938)] [G loss: 5.892] [G acc: 0.125]\n",
      "18229 [D loss: (0.642)(R 0.582, F 0.701)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.974] [G acc: 0.375]\n",
      "18230 [D loss: (0.562)(R 0.596, F 0.528)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.947] [G acc: 0.250]\n",
      "18231 [D loss: (0.651)(R 0.561, F 0.740)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.950] [G acc: 0.250]\n",
      "18232 [D loss: (0.567)(R 0.624, F 0.510)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.723] [G acc: 0.250]\n",
      "18233 [D loss: (0.540)(R 0.781, F 0.299)] [D acc: (0.656)(0.312, 1.000)] [G loss: 1.078] [G acc: 0.250]\n",
      "18234 [D loss: (0.528)(R 0.642, F 0.414)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.898] [G acc: 0.438]\n",
      "18235 [D loss: (0.625)(R 0.613, F 0.636)] [D acc: (0.594)(0.688, 0.500)] [G loss: 1.162] [G acc: 0.375]\n",
      "18236 [D loss: (0.530)(R 0.581, F 0.480)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.988] [G acc: 0.312]\n",
      "18237 [D loss: (0.538)(R 0.593, F 0.482)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.327] [G acc: 0.250]\n",
      "18238 [D loss: (0.615)(R 0.613, F 0.617)] [D acc: (0.562)(0.625, 0.500)] [G loss: 1.127] [G acc: 0.188]\n",
      "18239 [D loss: (0.581)(R 0.596, F 0.566)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.046] [G acc: 0.250]\n",
      "18240 [D loss: (0.614)(R 0.698, F 0.529)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.552] [G acc: 0.250]\n",
      "18241 [D loss: (0.535)(R 0.573, F 0.496)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.100] [G acc: 0.188]\n",
      "18242 [D loss: (0.607)(R 0.794, F 0.419)] [D acc: (0.781)(0.562, 1.000)] [G loss: 0.811] [G acc: 0.562]\n",
      "18243 [D loss: (0.534)(R 0.629, F 0.439)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.694] [G acc: 0.500]\n",
      "18244 [D loss: (0.600)(R 0.435, F 0.766)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.013] [G acc: 0.188]\n",
      "18245 [D loss: (0.538)(R 0.574, F 0.502)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.428] [G acc: 0.125]\n",
      "18246 [D loss: (0.522)(R 0.620, F 0.424)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.282] [G acc: 0.125]\n",
      "18247 [D loss: (0.618)(R 0.846, F 0.389)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.214] [G acc: 0.125]\n",
      "18248 [D loss: (0.514)(R 0.583, F 0.445)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.071] [G acc: 0.250]\n",
      "18249 [D loss: (0.525)(R 0.677, F 0.374)] [D acc: (0.750)(0.625, 0.875)] [G loss: 6.366] [G acc: 0.375]\n",
      "18250 [D loss: (0.625)(R 0.574, F 0.677)] [D acc: (0.688)(0.875, 0.500)] [G loss: 1.431] [G acc: 0.250]\n",
      "18251 [D loss: (0.589)(R 0.785, F 0.392)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.535] [G acc: 0.375]\n",
      "18252 [D loss: (0.463)(R 0.521, F 0.404)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.755] [G acc: 0.688]\n",
      "18253 [D loss: (0.598)(R 0.526, F 0.671)] [D acc: (0.875)(1.000, 0.750)] [G loss: 0.955] [G acc: 0.438]\n",
      "18254 [D loss: (0.491)(R 0.550, F 0.431)] [D acc: (0.812)(0.812, 0.812)] [G loss: 2.031] [G acc: 0.188]\n",
      "18255 [D loss: (0.479)(R 0.832, F 0.126)] [D acc: (0.719)(0.500, 0.938)] [G loss: 3.361] [G acc: 0.188]\n",
      "18256 [D loss: (0.657)(R 0.596, F 0.719)] [D acc: (0.688)(0.875, 0.500)] [G loss: 1.340] [G acc: 0.250]\n",
      "18257 [D loss: (0.445)(R 0.514, F 0.375)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.107] [G acc: 0.188]\n",
      "18258 [D loss: (0.764)(R 1.030, F 0.497)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.507] [G acc: 0.062]\n",
      "18259 [D loss: (0.542)(R 0.586, F 0.498)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.008] [G acc: 0.188]\n",
      "18260 [D loss: (0.490)(R 0.492, F 0.489)] [D acc: (0.844)(0.938, 0.750)] [G loss: 1.237] [G acc: 0.188]\n",
      "18261 [D loss: (0.542)(R 0.670, F 0.415)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.158] [G acc: 0.312]\n",
      "18262 [D loss: (0.626)(R 0.870, F 0.382)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.577] [G acc: 0.188]\n",
      "18263 [D loss: (0.556)(R 0.630, F 0.482)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.242] [G acc: 0.125]\n",
      "18264 [D loss: (0.475)(R 0.472, F 0.478)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.007] [G acc: 0.312]\n",
      "18265 [D loss: (0.511)(R 0.470, F 0.552)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.984] [G acc: 0.312]\n",
      "18266 [D loss: (0.711)(R 0.739, F 0.684)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.131] [G acc: 0.250]\n",
      "18267 [D loss: (0.635)(R 0.680, F 0.590)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.042] [G acc: 0.188]\n",
      "18268 [D loss: (0.587)(R 0.709, F 0.465)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.210] [G acc: 0.062]\n",
      "18269 [D loss: (0.659)(R 0.815, F 0.504)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.183] [G acc: 0.125]\n",
      "18270 [D loss: (0.641)(R 0.745, F 0.537)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.697] [G acc: 0.688]\n",
      "18271 [D loss: (0.810)(R 1.092, F 0.528)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.379] [G acc: 0.438]\n",
      "18272 [D loss: (0.464)(R 0.451, F 0.478)] [D acc: (0.906)(0.938, 0.875)] [G loss: 3.502] [G acc: 0.188]\n",
      "18273 [D loss: (0.737)(R 0.686, F 0.787)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.003] [G acc: 0.250]\n",
      "18274 [D loss: (0.505)(R 0.435, F 0.575)] [D acc: (0.719)(0.875, 0.562)] [G loss: 1.075] [G acc: 0.312]\n",
      "18275 [D loss: (0.533)(R 0.535, F 0.531)] [D acc: (0.875)(0.938, 0.812)] [G loss: 0.931] [G acc: 0.438]\n",
      "18276 [D loss: (0.653)(R 0.863, F 0.444)] [D acc: (0.719)(0.500, 0.938)] [G loss: 0.966] [G acc: 0.375]\n",
      "18277 [D loss: (0.491)(R 0.553, F 0.429)] [D acc: (0.938)(0.938, 0.938)] [G loss: 1.038] [G acc: 0.188]\n",
      "18278 [D loss: (0.512)(R 0.511, F 0.513)] [D acc: (0.844)(0.875, 0.812)] [G loss: 0.944] [G acc: 0.625]\n",
      "18279 [D loss: (0.681)(R 0.649, F 0.713)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.013] [G acc: 0.125]\n",
      "18280 [D loss: (0.573)(R 0.607, F 0.540)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.930] [G acc: 0.375]\n",
      "18281 [D loss: (0.752)(R 0.591, F 0.913)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.879] [G acc: 0.438]\n",
      "18282 [D loss: (0.600)(R 0.594, F 0.605)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.008] [G acc: 0.188]\n",
      "18283 [D loss: (0.617)(R 0.578, F 0.657)] [D acc: (0.594)(0.750, 0.438)] [G loss: 1.057] [G acc: 0.312]\n",
      "18284 [D loss: (0.514)(R 0.580, F 0.449)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.949] [G acc: 0.250]\n",
      "18285 [D loss: (0.531)(R 0.664, F 0.397)] [D acc: (0.875)(0.812, 0.938)] [G loss: 0.991] [G acc: 0.188]\n",
      "18286 [D loss: (0.546)(R 0.529, F 0.564)] [D acc: (0.844)(0.938, 0.750)] [G loss: 0.875] [G acc: 0.375]\n",
      "18287 [D loss: (0.591)(R 0.574, F 0.607)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.850] [G acc: 0.250]\n",
      "18288 [D loss: (0.527)(R 0.497, F 0.557)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.013] [G acc: 0.500]\n",
      "18289 [D loss: (0.510)(R 0.652, F 0.369)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.361] [G acc: 0.188]\n",
      "18290 [D loss: (0.712)(R 0.869, F 0.555)] [D acc: (0.562)(0.562, 0.562)] [G loss: 1.003] [G acc: 0.250]\n",
      "18291 [D loss: (0.803)(R 1.037, F 0.568)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.763] [G acc: 0.375]\n",
      "18292 [D loss: (0.748)(R 0.682, F 0.815)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.955] [G acc: 0.250]\n",
      "18293 [D loss: (0.698)(R 0.783, F 0.613)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.810] [G acc: 0.500]\n",
      "18294 [D loss: (0.562)(R 0.453, F 0.671)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.745] [G acc: 0.438]\n",
      "18295 [D loss: (0.730)(R 0.832, F 0.627)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.802] [G acc: 0.625]\n",
      "18296 [D loss: (0.708)(R 0.762, F 0.655)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.746] [G acc: 0.500]\n",
      "18297 [D loss: (0.748)(R 0.769, F 0.728)] [D acc: (0.375)(0.500, 0.250)] [G loss: 0.864] [G acc: 0.500]\n",
      "18298 [D loss: (0.622)(R 0.567, F 0.678)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.825] [G acc: 0.500]\n",
      "18299 [D loss: (0.676)(R 0.696, F 0.656)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.728] [G acc: 0.500]\n",
      "18300 [D loss: (0.729)(R 0.636, F 0.823)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.702] [G acc: 0.562]\n",
      "18301 [D loss: (0.894)(R 0.624, F 1.163)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.783] [G acc: 0.500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18302 [D loss: (0.609)(R 0.584, F 0.634)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.681] [G acc: 0.750]\n",
      "18303 [D loss: (0.749)(R 0.832, F 0.665)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.705] [G acc: 0.688]\n",
      "18304 [D loss: (0.833)(R 0.965, F 0.701)] [D acc: (0.375)(0.438, 0.312)] [G loss: 0.601] [G acc: 0.812]\n",
      "18305 [D loss: (0.640)(R 0.689, F 0.590)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.688] [G acc: 0.625]\n",
      "18306 [D loss: (0.713)(R 0.618, F 0.807)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.621] [G acc: 0.625]\n",
      "18307 [D loss: (0.672)(R 0.686, F 0.657)] [D acc: (0.594)(0.750, 0.438)] [G loss: 1.285] [G acc: 0.625]\n",
      "18308 [D loss: (0.646)(R 0.664, F 0.627)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.929] [G acc: 0.438]\n",
      "18309 [D loss: (0.720)(R 0.757, F 0.683)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.467] [G acc: 0.875]\n",
      "18310 [D loss: (1.141)(R 0.846, F 1.435)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.624] [G acc: 0.875]\n",
      "18311 [D loss: (0.681)(R 0.704, F 0.659)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.576] [G acc: 0.688]\n",
      "18312 [D loss: (0.686)(R 0.639, F 0.732)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.641] [G acc: 0.688]\n",
      "18313 [D loss: (0.846)(R 0.677, F 1.015)] [D acc: (0.406)(0.688, 0.125)] [G loss: 0.672] [G acc: 0.750]\n",
      "18314 [D loss: (0.764)(R 0.662, F 0.866)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.792] [G acc: 0.500]\n",
      "18315 [D loss: (0.590)(R 0.664, F 0.515)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.874] [G acc: 0.375]\n",
      "18316 [D loss: (0.670)(R 0.592, F 0.748)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.639] [G acc: 0.688]\n",
      "18317 [D loss: (0.649)(R 0.638, F 0.660)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.680] [G acc: 0.750]\n",
      "18318 [D loss: (0.667)(R 0.634, F 0.700)] [D acc: (0.500)(0.750, 0.250)] [G loss: 1.039] [G acc: 0.438]\n",
      "18319 [D loss: (0.486)(R 0.603, F 0.369)] [D acc: (0.781)(0.812, 0.750)] [G loss: 4.406] [G acc: 0.438]\n",
      "18320 [D loss: (0.697)(R 0.706, F 0.687)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.708] [G acc: 0.812]\n",
      "18321 [D loss: (0.637)(R 0.578, F 0.696)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.742] [G acc: 0.562]\n",
      "18322 [D loss: (0.720)(R 0.709, F 0.731)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.692] [G acc: 0.688]\n",
      "18323 [D loss: (0.684)(R 0.596, F 0.772)] [D acc: (0.469)(0.875, 0.062)] [G loss: 0.648] [G acc: 0.812]\n",
      "18324 [D loss: (0.674)(R 0.597, F 0.752)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.746] [G acc: 0.625]\n",
      "18325 [D loss: (0.806)(R 0.900, F 0.712)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.657] [G acc: 0.750]\n",
      "18326 [D loss: (0.714)(R 0.702, F 0.725)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.716] [G acc: 0.562]\n",
      "18327 [D loss: (0.710)(R 0.668, F 0.752)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.794] [G acc: 0.375]\n",
      "18328 [D loss: (0.631)(R 0.577, F 0.685)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.661] [G acc: 0.750]\n",
      "18329 [D loss: (0.659)(R 0.614, F 0.704)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.751] [G acc: 0.438]\n",
      "18330 [D loss: (0.634)(R 0.582, F 0.686)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.828] [G acc: 0.375]\n",
      "18331 [D loss: (0.715)(R 0.702, F 0.727)] [D acc: (0.438)(0.688, 0.188)] [G loss: 0.729] [G acc: 0.438]\n",
      "18332 [D loss: (0.613)(R 0.633, F 0.592)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.685] [G acc: 0.500]\n",
      "18333 [D loss: (0.647)(R 0.603, F 0.691)] [D acc: (0.594)(0.875, 0.312)] [G loss: 1.208] [G acc: 0.562]\n",
      "18334 [D loss: (0.634)(R 0.727, F 0.542)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.635] [G acc: 0.625]\n",
      "18335 [D loss: (0.640)(R 0.685, F 0.595)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.847] [G acc: 0.438]\n",
      "18336 [D loss: (0.556)(R 0.469, F 0.643)] [D acc: (0.750)(1.000, 0.500)] [G loss: 0.890] [G acc: 0.250]\n",
      "18337 [D loss: (0.724)(R 0.768, F 0.680)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.700] [G acc: 0.562]\n",
      "18338 [D loss: (0.715)(R 0.696, F 0.735)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.682] [G acc: 0.562]\n",
      "18339 [D loss: (0.914)(R 0.653, F 1.175)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.698] [G acc: 0.625]\n",
      "18340 [D loss: (0.663)(R 0.608, F 0.718)] [D acc: (0.594)(0.875, 0.312)] [G loss: 3.410] [G acc: 0.500]\n",
      "18341 [D loss: (0.426)(R 0.583, F 0.270)] [D acc: (0.844)(0.875, 0.812)] [G loss: 5.980] [G acc: 0.250]\n",
      "18342 [D loss: (0.641)(R 0.718, F 0.565)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.297] [G acc: 0.438]\n",
      "18343 [D loss: (0.629)(R 0.602, F 0.657)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.919] [G acc: 0.500]\n",
      "18344 [D loss: (1.035)(R 0.685, F 1.385)] [D acc: (0.531)(0.500, 0.562)] [G loss: 1.083] [G acc: 0.438]\n",
      "18345 [D loss: (0.646)(R 0.617, F 0.676)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.840] [G acc: 0.250]\n",
      "18346 [D loss: (0.697)(R 0.664, F 0.731)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.727] [G acc: 0.562]\n",
      "18347 [D loss: (0.682)(R 0.609, F 0.755)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.765] [G acc: 0.438]\n",
      "18348 [D loss: (0.596)(R 0.593, F 0.599)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.630] [G acc: 0.750]\n",
      "18349 [D loss: (0.605)(R 0.534, F 0.676)] [D acc: (0.719)(1.000, 0.438)] [G loss: 0.808] [G acc: 0.312]\n",
      "18350 [D loss: (0.655)(R 0.652, F 0.658)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.680] [G acc: 0.812]\n",
      "18351 [D loss: (0.735)(R 0.736, F 0.734)] [D acc: (0.469)(0.750, 0.188)] [G loss: 1.047] [G acc: 0.375]\n",
      "18352 [D loss: (0.634)(R 0.665, F 0.603)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.776] [G acc: 0.250]\n",
      "18353 [D loss: (0.633)(R 0.643, F 0.623)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.768] [G acc: 0.438]\n",
      "18354 [D loss: (0.666)(R 0.680, F 0.651)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.868] [G acc: 0.312]\n",
      "18355 [D loss: (0.639)(R 0.623, F 0.656)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.795] [G acc: 0.312]\n",
      "18356 [D loss: (0.785)(R 0.636, F 0.933)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.853] [G acc: 0.250]\n",
      "18357 [D loss: (0.653)(R 0.682, F 0.624)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.859] [G acc: 0.312]\n",
      "18358 [D loss: (0.567)(R 0.573, F 0.561)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.953] [G acc: 0.125]\n",
      "18359 [D loss: (0.552)(R 0.556, F 0.547)] [D acc: (0.844)(0.875, 0.812)] [G loss: 0.713] [G acc: 0.438]\n",
      "18360 [D loss: (0.640)(R 0.620, F 0.660)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.817] [G acc: 0.438]\n",
      "18361 [D loss: (0.585)(R 0.562, F 0.609)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.824] [G acc: 0.312]\n",
      "18362 [D loss: (0.615)(R 0.581, F 0.648)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.851] [G acc: 0.250]\n",
      "18363 [D loss: (0.619)(R 0.592, F 0.646)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.764] [G acc: 0.312]\n",
      "18364 [D loss: (0.616)(R 0.578, F 0.653)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.791] [G acc: 0.438]\n",
      "18365 [D loss: (0.681)(R 0.700, F 0.662)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.850] [G acc: 0.312]\n",
      "18366 [D loss: (0.693)(R 0.751, F 0.634)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.663] [G acc: 0.500]\n",
      "18367 [D loss: (0.617)(R 0.577, F 0.658)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.958] [G acc: 0.312]\n",
      "18368 [D loss: (0.765)(R 0.753, F 0.777)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.004] [G acc: 0.250]\n",
      "18369 [D loss: (0.434)(R 0.612, F 0.256)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.211] [G acc: 0.625]\n",
      "18370 [D loss: (0.601)(R 0.584, F 0.618)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.030] [G acc: 0.188]\n",
      "18371 [D loss: (0.582)(R 0.641, F 0.524)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.181] [G acc: 0.250]\n",
      "18372 [D loss: (0.662)(R 0.743, F 0.582)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.938] [G acc: 0.250]\n",
      "18373 [D loss: (0.576)(R 0.541, F 0.611)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.846] [G acc: 0.312]\n",
      "18374 [D loss: (0.599)(R 0.556, F 0.642)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.881] [G acc: 0.312]\n",
      "18375 [D loss: (0.585)(R 0.527, F 0.644)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.606] [G acc: 0.750]\n",
      "18376 [D loss: (0.705)(R 0.720, F 0.690)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.772] [G acc: 0.500]\n",
      "18377 [D loss: (0.558)(R 0.413, F 0.703)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.963] [G acc: 0.375]\n",
      "18378 [D loss: (0.666)(R 0.735, F 0.597)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.064] [G acc: 0.375]\n",
      "18379 [D loss: (0.530)(R 0.714, F 0.346)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.688] [G acc: 0.562]\n",
      "18380 [D loss: (0.644)(R 0.643, F 0.646)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.083] [G acc: 0.125]\n",
      "18381 [D loss: (0.613)(R 0.637, F 0.588)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.894] [G acc: 0.375]\n",
      "18382 [D loss: (0.598)(R 0.419, F 0.777)] [D acc: (0.781)(0.938, 0.625)] [G loss: 0.827] [G acc: 0.188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18383 [D loss: (0.626)(R 0.660, F 0.591)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.886] [G acc: 0.375]\n",
      "18384 [D loss: (0.506)(R 0.415, F 0.598)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.863] [G acc: 0.500]\n",
      "18385 [D loss: (0.690)(R 0.548, F 0.831)] [D acc: (0.594)(0.812, 0.375)] [G loss: 1.482] [G acc: 0.250]\n",
      "18386 [D loss: (0.691)(R 0.694, F 0.688)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.703] [G acc: 0.625]\n",
      "18387 [D loss: (0.684)(R 0.693, F 0.675)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.743] [G acc: 0.562]\n",
      "18388 [D loss: (0.645)(R 0.624, F 0.666)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.798] [G acc: 0.562]\n",
      "18389 [D loss: (0.705)(R 0.833, F 0.576)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.870] [G acc: 0.188]\n",
      "18390 [D loss: (0.633)(R 0.567, F 0.699)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.848] [G acc: 0.125]\n",
      "18391 [D loss: (0.648)(R 0.656, F 0.640)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.862] [G acc: 0.188]\n",
      "18392 [D loss: (0.632)(R 0.664, F 0.600)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.776] [G acc: 0.312]\n",
      "18393 [D loss: (0.571)(R 0.447, F 0.695)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.805] [G acc: 0.500]\n",
      "18394 [D loss: (0.642)(R 0.585, F 0.699)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.741] [G acc: 0.500]\n",
      "18395 [D loss: (0.613)(R 0.516, F 0.710)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.781] [G acc: 0.500]\n",
      "18396 [D loss: (0.919)(R 0.514, F 1.324)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.800] [G acc: 0.312]\n",
      "18397 [D loss: (0.641)(R 0.622, F 0.659)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.714] [G acc: 0.500]\n",
      "18398 [D loss: (0.894)(R 0.631, F 1.157)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.897] [G acc: 0.500]\n",
      "18399 [D loss: (0.552)(R 0.589, F 0.515)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.081] [G acc: 0.125]\n",
      "18400 [D loss: (0.704)(R 0.705, F 0.702)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.805] [G acc: 0.188]\n",
      "18401 [D loss: (0.722)(R 0.636, F 0.809)] [D acc: (0.500)(0.500, 0.500)] [G loss: 2.029] [G acc: 0.250]\n",
      "18402 [D loss: (0.515)(R 0.899, F 0.132)] [D acc: (0.719)(0.500, 0.938)] [G loss: 9.898] [G acc: 0.062]\n",
      "18403 [D loss: (1.189)(R 0.601, F 1.776)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.932] [G acc: 0.250]\n",
      "18404 [D loss: (0.600)(R 0.681, F 0.520)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.265] [G acc: 0.312]\n",
      "18405 [D loss: (0.578)(R 0.655, F 0.502)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.856] [G acc: 0.375]\n",
      "18406 [D loss: (0.729)(R 0.631, F 0.827)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.803] [G acc: 0.375]\n",
      "18407 [D loss: (0.727)(R 0.766, F 0.689)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.958] [G acc: 0.312]\n",
      "18408 [D loss: (0.599)(R 0.709, F 0.490)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.154] [G acc: 0.312]\n",
      "18409 [D loss: (0.600)(R 0.628, F 0.573)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.769] [G acc: 0.312]\n",
      "18410 [D loss: (0.639)(R 0.663, F 0.614)] [D acc: (0.469)(0.375, 0.562)] [G loss: 1.068] [G acc: 0.062]\n",
      "18411 [D loss: (0.491)(R 0.644, F 0.339)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.960] [G acc: 0.000]\n",
      "18412 [D loss: (0.513)(R 0.832, F 0.194)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.968] [G acc: 0.438]\n",
      "18413 [D loss: (0.511)(R 0.498, F 0.525)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.864] [G acc: 0.312]\n",
      "18414 [D loss: (0.632)(R 0.559, F 0.705)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.858] [G acc: 0.250]\n",
      "18415 [D loss: (0.563)(R 0.632, F 0.493)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.878] [G acc: 0.125]\n",
      "18416 [D loss: (0.527)(R 0.505, F 0.548)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.996] [G acc: 0.062]\n",
      "18417 [D loss: (0.588)(R 0.652, F 0.524)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.882] [G acc: 0.375]\n",
      "18418 [D loss: (0.574)(R 0.617, F 0.531)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.908] [G acc: 0.125]\n",
      "18419 [D loss: (0.611)(R 0.630, F 0.592)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.831] [G acc: 0.125]\n",
      "18420 [D loss: (0.627)(R 0.638, F 0.616)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.811] [G acc: 0.438]\n",
      "18421 [D loss: (0.661)(R 0.648, F 0.675)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.957] [G acc: 0.188]\n",
      "18422 [D loss: (0.571)(R 0.609, F 0.533)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.989] [G acc: 0.250]\n",
      "18423 [D loss: (0.533)(R 0.591, F 0.475)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.964] [G acc: 0.062]\n",
      "18424 [D loss: (0.565)(R 0.644, F 0.486)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.101] [G acc: 0.562]\n",
      "18425 [D loss: (0.570)(R 0.751, F 0.389)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.459] [G acc: 0.188]\n",
      "18426 [D loss: (0.572)(R 0.551, F 0.594)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.916] [G acc: 0.188]\n",
      "18427 [D loss: (0.525)(R 0.540, F 0.510)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.357] [G acc: 0.375]\n",
      "18428 [D loss: (0.546)(R 0.579, F 0.513)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.430] [G acc: 0.062]\n",
      "18429 [D loss: (0.603)(R 0.676, F 0.529)] [D acc: (0.688)(0.500, 0.875)] [G loss: 1.075] [G acc: 0.250]\n",
      "18430 [D loss: (0.323)(R 0.419, F 0.228)] [D acc: (0.844)(0.750, 0.938)] [G loss: 2.240] [G acc: 0.125]\n",
      "18431 [D loss: (0.583)(R 0.558, F 0.608)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.973] [G acc: 0.250]\n",
      "18432 [D loss: (0.738)(R 0.829, F 0.647)] [D acc: (0.594)(0.438, 0.750)] [G loss: 2.036] [G acc: 0.250]\n",
      "18433 [D loss: (0.518)(R 0.500, F 0.535)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.041] [G acc: 0.188]\n",
      "18434 [D loss: (0.600)(R 0.695, F 0.506)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.944] [G acc: 0.125]\n",
      "18435 [D loss: (0.569)(R 0.539, F 0.598)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.916] [G acc: 0.188]\n",
      "18436 [D loss: (0.630)(R 0.709, F 0.551)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.088] [G acc: 0.125]\n",
      "18437 [D loss: (0.557)(R 0.574, F 0.539)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.151] [G acc: 0.125]\n",
      "18438 [D loss: (0.537)(R 0.569, F 0.504)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.974] [G acc: 0.250]\n",
      "18439 [D loss: (0.536)(R 0.502, F 0.571)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.057] [G acc: 0.062]\n",
      "18440 [D loss: (0.513)(R 0.541, F 0.484)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.786] [G acc: 0.375]\n",
      "18441 [D loss: (0.540)(R 0.573, F 0.508)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.890] [G acc: 0.125]\n",
      "18442 [D loss: (0.592)(R 0.645, F 0.539)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.074] [G acc: 0.000]\n",
      "18443 [D loss: (0.551)(R 0.568, F 0.533)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.134] [G acc: 0.125]\n",
      "18444 [D loss: (0.289)(R 0.417, F 0.162)] [D acc: (0.812)(0.750, 0.875)] [G loss: 2.987] [G acc: 0.188]\n",
      "18445 [D loss: (0.605)(R 0.582, F 0.627)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.911] [G acc: 0.438]\n",
      "18446 [D loss: (0.584)(R 0.536, F 0.633)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.828] [G acc: 0.250]\n",
      "18447 [D loss: (0.519)(R 0.450, F 0.589)] [D acc: (0.781)(0.938, 0.625)] [G loss: 0.806] [G acc: 0.500]\n",
      "18448 [D loss: (0.595)(R 0.535, F 0.655)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.897] [G acc: 0.250]\n",
      "18449 [D loss: (0.605)(R 0.544, F 0.665)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.826] [G acc: 0.188]\n",
      "18450 [D loss: (0.504)(R 0.460, F 0.549)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.958] [G acc: 0.062]\n",
      "18451 [D loss: (0.438)(R 0.286, F 0.590)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.902] [G acc: 0.188]\n",
      "18452 [D loss: (0.452)(R 0.355, F 0.549)] [D acc: (0.844)(0.938, 0.750)] [G loss: 0.853] [G acc: 0.188]\n",
      "18453 [D loss: (0.519)(R 0.510, F 0.527)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.797] [G acc: 0.438]\n",
      "18454 [D loss: (0.555)(R 0.582, F 0.528)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.887] [G acc: 0.375]\n",
      "18455 [D loss: (0.463)(R 0.399, F 0.527)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.126] [G acc: 0.250]\n",
      "18456 [D loss: (0.723)(R 0.375, F 1.071)] [D acc: (0.656)(0.812, 0.500)] [G loss: 1.153] [G acc: 0.188]\n",
      "18457 [D loss: (0.625)(R 0.890, F 0.361)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.683] [G acc: 0.000]\n",
      "18458 [D loss: (0.556)(R 0.622, F 0.490)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.849] [G acc: 0.375]\n",
      "18459 [D loss: (0.476)(R 0.420, F 0.532)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.054] [G acc: 0.438]\n",
      "18460 [D loss: (0.551)(R 0.416, F 0.685)] [D acc: (0.594)(0.688, 0.500)] [G loss: 1.131] [G acc: 0.188]\n",
      "18461 [D loss: (0.509)(R 0.533, F 0.484)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.687] [G acc: 0.062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18462 [D loss: (0.577)(R 0.553, F 0.602)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.690] [G acc: 0.562]\n",
      "18463 [D loss: (0.966)(R 0.827, F 1.105)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.926] [G acc: 0.375]\n",
      "18464 [D loss: (0.653)(R 0.541, F 0.766)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.039] [G acc: 0.188]\n",
      "18465 [D loss: (0.528)(R 0.490, F 0.567)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.774] [G acc: 0.438]\n",
      "18466 [D loss: (0.603)(R 0.488, F 0.717)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.041] [G acc: 0.375]\n",
      "18467 [D loss: (0.597)(R 0.556, F 0.638)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.348] [G acc: 0.000]\n",
      "18468 [D loss: (1.644)(R 0.814, F 2.473)] [D acc: (0.469)(0.312, 0.625)] [G loss: 1.062] [G acc: 0.125]\n",
      "18469 [D loss: (0.636)(R 0.789, F 0.483)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.791] [G acc: 0.438]\n",
      "18470 [D loss: (0.614)(R 0.644, F 0.585)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.843] [G acc: 0.188]\n",
      "18471 [D loss: (0.627)(R 0.567, F 0.687)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.983] [G acc: 0.312]\n",
      "18472 [D loss: (0.684)(R 0.727, F 0.642)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.883] [G acc: 0.250]\n",
      "18473 [D loss: (0.521)(R 0.427, F 0.614)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.723] [G acc: 0.375]\n",
      "18474 [D loss: (1.024)(R 0.441, F 1.606)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.919] [G acc: 0.125]\n",
      "18475 [D loss: (0.738)(R 0.601, F 0.875)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.938] [G acc: 0.188]\n",
      "18476 [D loss: (0.640)(R 0.569, F 0.711)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.989] [G acc: 0.188]\n",
      "18477 [D loss: (0.587)(R 0.608, F 0.566)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.703] [G acc: 0.562]\n",
      "18478 [D loss: (0.663)(R 0.587, F 0.739)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.812] [G acc: 0.375]\n",
      "18479 [D loss: (0.650)(R 0.652, F 0.647)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.878] [G acc: 0.312]\n",
      "18480 [D loss: (1.026)(R 0.731, F 1.320)] [D acc: (0.375)(0.438, 0.312)] [G loss: 1.054] [G acc: 0.375]\n",
      "18481 [D loss: (0.475)(R 0.498, F 0.453)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.679] [G acc: 0.562]\n",
      "18482 [D loss: (0.588)(R 0.526, F 0.650)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.933] [G acc: 0.438]\n",
      "18483 [D loss: (2.015)(R 0.732, F 3.297)] [D acc: (0.469)(0.500, 0.438)] [G loss: 1.716] [G acc: 0.438]\n",
      "18484 [D loss: (0.505)(R 0.714, F 0.295)] [D acc: (0.625)(0.375, 0.875)] [G loss: 1.976] [G acc: 0.125]\n",
      "18485 [D loss: (0.628)(R 0.594, F 0.661)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.874] [G acc: 0.375]\n",
      "18486 [D loss: (0.604)(R 0.586, F 0.623)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.759] [G acc: 0.438]\n",
      "18487 [D loss: (0.869)(R 0.854, F 0.883)] [D acc: (0.438)(0.250, 0.625)] [G loss: 0.795] [G acc: 0.500]\n",
      "18488 [D loss: (1.139)(R 0.709, F 1.569)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.605] [G acc: 0.562]\n",
      "18489 [D loss: (1.098)(R 0.702, F 1.494)] [D acc: (0.469)(0.375, 0.562)] [G loss: 1.439] [G acc: 0.375]\n",
      "18490 [D loss: (0.637)(R 0.716, F 0.557)] [D acc: (0.562)(0.375, 0.750)] [G loss: 1.695] [G acc: 0.188]\n",
      "18491 [D loss: (1.234)(R 0.806, F 1.663)] [D acc: (0.469)(0.438, 0.500)] [G loss: 1.127] [G acc: 0.125]\n",
      "18492 [D loss: (1.131)(R 0.753, F 1.510)] [D acc: (0.562)(0.500, 0.625)] [G loss: 1.629] [G acc: 0.125]\n",
      "18493 [D loss: (0.396)(R 0.547, F 0.245)] [D acc: (0.906)(0.812, 1.000)] [G loss: 1.719] [G acc: 0.000]\n",
      "18494 [D loss: (0.943)(R 0.656, F 1.230)] [D acc: (0.500)(0.438, 0.562)] [G loss: 1.123] [G acc: 0.125]\n",
      "18495 [D loss: (0.685)(R 0.801, F 0.570)] [D acc: (0.562)(0.250, 0.875)] [G loss: 0.963] [G acc: 0.125]\n",
      "18496 [D loss: (0.676)(R 0.761, F 0.592)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.323] [G acc: 0.438]\n",
      "18497 [D loss: (1.468)(R 0.636, F 2.300)] [D acc: (0.500)(0.500, 0.500)] [G loss: 1.177] [G acc: 0.188]\n",
      "18498 [D loss: (1.246)(R 0.824, F 1.667)] [D acc: (0.344)(0.312, 0.375)] [G loss: 1.289] [G acc: 0.375]\n",
      "18499 [D loss: (0.666)(R 0.706, F 0.626)] [D acc: (0.562)(0.375, 0.750)] [G loss: 1.146] [G acc: 0.125]\n",
      "18500 [D loss: (0.949)(R 0.683, F 1.215)] [D acc: (0.469)(0.438, 0.500)] [G loss: 1.183] [G acc: 0.125]\n",
      "18501 [D loss: (0.823)(R 0.714, F 0.933)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.597] [G acc: 0.438]\n",
      "18502 [D loss: (0.598)(R 0.565, F 0.630)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.699] [G acc: 0.375]\n",
      "18503 [D loss: (0.688)(R 0.707, F 0.668)] [D acc: (0.531)(0.562, 0.500)] [G loss: 1.052] [G acc: 0.188]\n",
      "18504 [D loss: (0.671)(R 0.752, F 0.590)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.986] [G acc: 0.062]\n",
      "18505 [D loss: (1.022)(R 0.667, F 1.377)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.990] [G acc: 0.125]\n",
      "18506 [D loss: (0.672)(R 0.759, F 0.586)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.939] [G acc: 0.250]\n",
      "18507 [D loss: (0.556)(R 0.590, F 0.522)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.908] [G acc: 0.250]\n",
      "18508 [D loss: (0.642)(R 0.649, F 0.635)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.853] [G acc: 0.188]\n",
      "18509 [D loss: (0.761)(R 0.728, F 0.795)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.719] [G acc: 0.375]\n",
      "18510 [D loss: (0.598)(R 0.566, F 0.630)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.692] [G acc: 0.312]\n",
      "18511 [D loss: (0.741)(R 0.665, F 0.818)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.685] [G acc: 0.500]\n",
      "18512 [D loss: (0.818)(R 0.647, F 0.989)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.790] [G acc: 0.375]\n",
      "18513 [D loss: (0.799)(R 0.615, F 0.982)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.825] [G acc: 0.312]\n",
      "18514 [D loss: (0.495)(R 0.593, F 0.396)] [D acc: (0.812)(0.625, 1.000)] [G loss: 0.892] [G acc: 0.188]\n",
      "18515 [D loss: (0.990)(R 0.627, F 1.353)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.754] [G acc: 0.312]\n",
      "18516 [D loss: (0.839)(R 0.502, F 1.176)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.652] [G acc: 0.438]\n",
      "18517 [D loss: (0.596)(R 0.578, F 0.613)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.743] [G acc: 0.500]\n",
      "18518 [D loss: (0.989)(R 0.611, F 1.367)] [D acc: (0.500)(0.500, 0.500)] [G loss: 1.038] [G acc: 0.125]\n",
      "18519 [D loss: (0.640)(R 0.665, F 0.616)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.274] [G acc: 0.062]\n",
      "18520 [D loss: (0.583)(R 0.562, F 0.604)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.729] [G acc: 0.375]\n",
      "18521 [D loss: (0.517)(R 0.522, F 0.512)] [D acc: (0.750)(0.688, 0.812)] [G loss: 2.021] [G acc: 0.125]\n",
      "18522 [D loss: (0.394)(R 0.675, F 0.112)] [D acc: (0.750)(0.500, 1.000)] [G loss: 2.344] [G acc: 0.000]\n",
      "18523 [D loss: (0.721)(R 0.492, F 0.950)] [D acc: (0.625)(0.625, 0.625)] [G loss: 4.429] [G acc: 0.062]\n",
      "18524 [D loss: (0.414)(R 0.535, F 0.293)] [D acc: (0.812)(0.625, 1.000)] [G loss: 0.831] [G acc: 0.250]\n",
      "18525 [D loss: (0.501)(R 0.603, F 0.399)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.030] [G acc: 0.125]\n",
      "18526 [D loss: (0.534)(R 0.565, F 0.503)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.086] [G acc: 0.125]\n",
      "18527 [D loss: (0.927)(R 1.393, F 0.461)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.162] [G acc: 0.062]\n",
      "18528 [D loss: (0.492)(R 0.418, F 0.566)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.019] [G acc: 0.188]\n",
      "18529 [D loss: (0.632)(R 0.602, F 0.662)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.937] [G acc: 0.062]\n",
      "18530 [D loss: (0.542)(R 0.506, F 0.579)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.816] [G acc: 0.500]\n",
      "18531 [D loss: (0.662)(R 0.738, F 0.585)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.731] [G acc: 0.500]\n",
      "18532 [D loss: (0.571)(R 0.620, F 0.523)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.847] [G acc: 0.375]\n",
      "18533 [D loss: (0.480)(R 0.403, F 0.557)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.834] [G acc: 0.375]\n",
      "18534 [D loss: (0.553)(R 0.553, F 0.553)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.046] [G acc: 0.312]\n",
      "18535 [D loss: (0.567)(R 0.607, F 0.527)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.939] [G acc: 0.438]\n",
      "18536 [D loss: (0.590)(R 0.391, F 0.790)] [D acc: (0.688)(0.812, 0.562)] [G loss: 1.183] [G acc: 0.188]\n",
      "18537 [D loss: (0.816)(R 1.009, F 0.623)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.932] [G acc: 0.188]\n",
      "18538 [D loss: (0.632)(R 0.648, F 0.616)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.915] [G acc: 0.250]\n",
      "18539 [D loss: (0.607)(R 0.463, F 0.750)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.998] [G acc: 0.250]\n",
      "18540 [D loss: (0.496)(R 0.529, F 0.462)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.238] [G acc: 0.125]\n",
      "18541 [D loss: (0.688)(R 0.494, F 0.881)] [D acc: (0.719)(0.875, 0.562)] [G loss: 1.060] [G acc: 0.312]\n",
      "18542 [D loss: (0.709)(R 0.577, F 0.841)] [D acc: (0.594)(0.688, 0.500)] [G loss: 1.309] [G acc: 0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18543 [D loss: (0.613)(R 0.745, F 0.480)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.353] [G acc: 0.438]\n",
      "18544 [D loss: (0.552)(R 0.715, F 0.389)] [D acc: (0.750)(0.625, 0.875)] [G loss: 2.416] [G acc: 0.000]\n",
      "18545 [D loss: (0.516)(R 0.547, F 0.486)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.035] [G acc: 0.188]\n",
      "18546 [D loss: (0.498)(R 0.632, F 0.365)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.238] [G acc: 0.188]\n",
      "18547 [D loss: (0.582)(R 0.578, F 0.585)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.974] [G acc: 0.250]\n",
      "18548 [D loss: (0.481)(R 0.408, F 0.553)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.948] [G acc: 0.375]\n",
      "18549 [D loss: (0.526)(R 0.537, F 0.514)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.261] [G acc: 0.250]\n",
      "18550 [D loss: (0.603)(R 0.697, F 0.508)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.036] [G acc: 0.312]\n",
      "18551 [D loss: (0.536)(R 0.540, F 0.533)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.264] [G acc: 0.188]\n",
      "18552 [D loss: (0.503)(R 0.543, F 0.462)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.238] [G acc: 0.125]\n",
      "18553 [D loss: (0.880)(R 1.216, F 0.544)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.159] [G acc: 0.188]\n",
      "18554 [D loss: (0.544)(R 0.559, F 0.530)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.984] [G acc: 0.188]\n",
      "18555 [D loss: (0.735)(R 0.848, F 0.622)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.170] [G acc: 0.125]\n",
      "18556 [D loss: (0.625)(R 0.546, F 0.704)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.002] [G acc: 0.125]\n",
      "18557 [D loss: (0.579)(R 0.558, F 0.601)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.015] [G acc: 0.250]\n",
      "18558 [D loss: (0.571)(R 0.393, F 0.749)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.021] [G acc: 0.250]\n",
      "18559 [D loss: (0.503)(R 0.636, F 0.369)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.071] [G acc: 0.062]\n",
      "18560 [D loss: (0.428)(R 0.390, F 0.465)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.227] [G acc: 0.250]\n",
      "18561 [D loss: (0.541)(R 0.529, F 0.552)] [D acc: (0.656)(0.812, 0.500)] [G loss: 1.073] [G acc: 0.250]\n",
      "18562 [D loss: (0.431)(R 0.418, F 0.444)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.133] [G acc: 0.125]\n",
      "18563 [D loss: (0.546)(R 0.594, F 0.498)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.931] [G acc: 0.250]\n",
      "18564 [D loss: (0.520)(R 0.578, F 0.461)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.156] [G acc: 0.250]\n",
      "18565 [D loss: (0.387)(R 0.400, F 0.375)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.919] [G acc: 0.125]\n",
      "18566 [D loss: (0.448)(R 0.446, F 0.449)] [D acc: (0.750)(0.938, 0.562)] [G loss: 2.006] [G acc: 0.062]\n",
      "18567 [D loss: (0.457)(R 0.423, F 0.492)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.172] [G acc: 0.125]\n",
      "18568 [D loss: (0.474)(R 0.563, F 0.385)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.213] [G acc: 0.250]\n",
      "18569 [D loss: (0.777)(R 0.525, F 1.029)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.245] [G acc: 0.125]\n",
      "18570 [D loss: (0.528)(R 0.610, F 0.447)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.352] [G acc: 0.125]\n",
      "18571 [D loss: (0.437)(R 0.476, F 0.398)] [D acc: (0.906)(1.000, 0.812)] [G loss: 1.110] [G acc: 0.125]\n",
      "18572 [D loss: (0.640)(R 0.694, F 0.586)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.044] [G acc: 0.125]\n",
      "18573 [D loss: (0.452)(R 0.537, F 0.367)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.426] [G acc: 0.188]\n",
      "18574 [D loss: (0.407)(R 0.434, F 0.379)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.198] [G acc: 0.188]\n",
      "18575 [D loss: (0.527)(R 0.514, F 0.539)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.425] [G acc: 0.188]\n",
      "18576 [D loss: (0.430)(R 0.564, F 0.296)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.741] [G acc: 0.188]\n",
      "18577 [D loss: (0.766)(R 0.595, F 0.936)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.337] [G acc: 0.062]\n",
      "18578 [D loss: (0.431)(R 0.466, F 0.396)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.700] [G acc: 0.188]\n",
      "18579 [D loss: (0.413)(R 0.384, F 0.443)] [D acc: (0.875)(1.000, 0.750)] [G loss: 1.335] [G acc: 0.125]\n",
      "18580 [D loss: (0.416)(R 0.325, F 0.507)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.488] [G acc: 0.188]\n",
      "18581 [D loss: (0.436)(R 0.460, F 0.413)] [D acc: (0.906)(0.875, 0.938)] [G loss: 1.611] [G acc: 0.125]\n",
      "18582 [D loss: (0.416)(R 0.450, F 0.382)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.721] [G acc: 0.125]\n",
      "18583 [D loss: (0.676)(R 0.611, F 0.740)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.617] [G acc: 0.188]\n",
      "18584 [D loss: (0.565)(R 0.565, F 0.565)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.562] [G acc: 0.188]\n",
      "18585 [D loss: (0.463)(R 0.522, F 0.403)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.240] [G acc: 0.188]\n",
      "18586 [D loss: (0.421)(R 0.443, F 0.398)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.614] [G acc: 0.250]\n",
      "18587 [D loss: (0.734)(R 1.157, F 0.311)] [D acc: (0.562)(0.375, 0.750)] [G loss: 8.822] [G acc: 0.250]\n",
      "18588 [D loss: (0.440)(R 0.447, F 0.432)] [D acc: (0.719)(0.812, 0.625)] [G loss: 2.008] [G acc: 0.125]\n",
      "18589 [D loss: (0.615)(R 0.794, F 0.436)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.295] [G acc: 0.125]\n",
      "18590 [D loss: (0.534)(R 0.533, F 0.535)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.336] [G acc: 0.250]\n",
      "18591 [D loss: (0.373)(R 0.436, F 0.311)] [D acc: (0.906)(0.875, 0.938)] [G loss: 1.393] [G acc: 0.250]\n",
      "18592 [D loss: (0.726)(R 0.750, F 0.703)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.313] [G acc: 0.250]\n",
      "18593 [D loss: (0.568)(R 0.464, F 0.672)] [D acc: (0.750)(0.875, 0.625)] [G loss: 1.072] [G acc: 0.312]\n",
      "18594 [D loss: (0.639)(R 0.463, F 0.816)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.040] [G acc: 0.250]\n",
      "18595 [D loss: (0.478)(R 0.557, F 0.399)] [D acc: (0.719)(0.625, 0.812)] [G loss: 2.293] [G acc: 0.125]\n",
      "18596 [D loss: (0.593)(R 0.948, F 0.237)] [D acc: (0.688)(0.500, 0.875)] [G loss: 6.589] [G acc: 0.250]\n",
      "18597 [D loss: (0.429)(R 0.504, F 0.354)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.226] [G acc: 0.250]\n",
      "18598 [D loss: (0.608)(R 0.657, F 0.559)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.534] [G acc: 0.312]\n",
      "18599 [D loss: (0.563)(R 0.632, F 0.494)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.352] [G acc: 0.312]\n",
      "18600 [D loss: (0.592)(R 0.764, F 0.420)] [D acc: (0.594)(0.438, 0.750)] [G loss: 1.143] [G acc: 0.188]\n",
      "18601 [D loss: (0.516)(R 0.445, F 0.586)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.848] [G acc: 0.375]\n",
      "18602 [D loss: (0.542)(R 0.469, F 0.616)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.717] [G acc: 0.562]\n",
      "18603 [D loss: (0.715)(R 0.891, F 0.539)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.089] [G acc: 0.312]\n",
      "18604 [D loss: (0.514)(R 0.547, F 0.480)] [D acc: (0.688)(0.812, 0.562)] [G loss: 1.020] [G acc: 0.500]\n",
      "18605 [D loss: (0.425)(R 0.359, F 0.490)] [D acc: (0.750)(0.938, 0.562)] [G loss: 1.036] [G acc: 0.250]\n",
      "18606 [D loss: (0.536)(R 0.494, F 0.578)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.025] [G acc: 0.250]\n",
      "18607 [D loss: (0.424)(R 0.344, F 0.505)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.395] [G acc: 0.188]\n",
      "18608 [D loss: (0.484)(R 0.446, F 0.523)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.132] [G acc: 0.250]\n",
      "18609 [D loss: (0.453)(R 0.384, F 0.521)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.217] [G acc: 0.188]\n",
      "18610 [D loss: (0.396)(R 0.425, F 0.367)] [D acc: (0.938)(0.875, 1.000)] [G loss: 1.292] [G acc: 0.125]\n",
      "18611 [D loss: (0.497)(R 0.439, F 0.555)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.153] [G acc: 0.312]\n",
      "18612 [D loss: (0.687)(R 0.892, F 0.482)] [D acc: (0.750)(0.812, 0.688)] [G loss: 2.433] [G acc: 0.375]\n",
      "18613 [D loss: (0.372)(R 0.495, F 0.248)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.430] [G acc: 0.125]\n",
      "18614 [D loss: (0.395)(R 0.435, F 0.355)] [D acc: (0.906)(0.812, 1.000)] [G loss: 1.524] [G acc: 0.188]\n",
      "18615 [D loss: (0.315)(R 0.393, F 0.237)] [D acc: (0.969)(1.000, 0.938)] [G loss: 0.955] [G acc: 0.312]\n",
      "18616 [D loss: (0.515)(R 0.417, F 0.613)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.121] [G acc: 0.250]\n",
      "18617 [D loss: (0.620)(R 0.745, F 0.495)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.400] [G acc: 0.125]\n",
      "18618 [D loss: (0.536)(R 0.663, F 0.410)] [D acc: (0.750)(0.750, 0.750)] [G loss: 3.350] [G acc: 0.125]\n",
      "18619 [D loss: (0.576)(R 0.500, F 0.653)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.016] [G acc: 0.375]\n",
      "18620 [D loss: (0.477)(R 0.545, F 0.409)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.464] [G acc: 0.312]\n",
      "18621 [D loss: (0.536)(R 0.431, F 0.640)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.635] [G acc: 0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18622 [D loss: (0.746)(R 0.651, F 0.841)] [D acc: (0.562)(0.500, 0.625)] [G loss: 1.012] [G acc: 0.188]\n",
      "18623 [D loss: (0.586)(R 0.579, F 0.593)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.985] [G acc: 0.250]\n",
      "18624 [D loss: (0.536)(R 0.512, F 0.560)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.519] [G acc: 0.375]\n",
      "18625 [D loss: (0.461)(R 0.487, F 0.435)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.759] [G acc: 0.125]\n",
      "18626 [D loss: (0.531)(R 0.204, F 0.857)] [D acc: (0.750)(1.000, 0.500)] [G loss: 1.465] [G acc: 0.125]\n",
      "18627 [D loss: (0.516)(R 0.686, F 0.345)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.018] [G acc: 0.500]\n",
      "18628 [D loss: (0.519)(R 0.726, F 0.313)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.941] [G acc: 0.250]\n",
      "18629 [D loss: (0.600)(R 0.615, F 0.585)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.336] [G acc: 0.188]\n",
      "18630 [D loss: (0.503)(R 0.550, F 0.455)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.402] [G acc: 0.188]\n",
      "18631 [D loss: (0.427)(R 0.495, F 0.359)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.462] [G acc: 0.250]\n",
      "18632 [D loss: (0.521)(R 0.512, F 0.531)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.936] [G acc: 0.438]\n",
      "18633 [D loss: (0.598)(R 0.579, F 0.616)] [D acc: (0.688)(0.812, 0.562)] [G loss: 1.807] [G acc: 0.062]\n",
      "18634 [D loss: (0.529)(R 0.367, F 0.691)] [D acc: (0.812)(0.938, 0.688)] [G loss: 1.563] [G acc: 0.375]\n",
      "18635 [D loss: (0.479)(R 0.648, F 0.310)] [D acc: (0.688)(0.562, 0.812)] [G loss: 3.529] [G acc: 0.250]\n",
      "18636 [D loss: (0.378)(R 0.498, F 0.259)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.594] [G acc: 0.250]\n",
      "18637 [D loss: (0.483)(R 0.547, F 0.419)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.696] [G acc: 0.250]\n",
      "18638 [D loss: (0.727)(R 0.843, F 0.612)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.813] [G acc: 0.500]\n",
      "18639 [D loss: (0.836)(R 0.713, F 0.959)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.019] [G acc: 0.250]\n",
      "18640 [D loss: (0.565)(R 0.418, F 0.712)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.592] [G acc: 0.812]\n",
      "18641 [D loss: (0.686)(R 0.566, F 0.806)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.632] [G acc: 0.750]\n",
      "18642 [D loss: (0.725)(R 0.526, F 0.923)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.900] [G acc: 0.438]\n",
      "18643 [D loss: (1.038)(R 0.482, F 1.594)] [D acc: (0.594)(0.750, 0.438)] [G loss: 1.180] [G acc: 0.125]\n",
      "18644 [D loss: (0.458)(R 0.408, F 0.507)] [D acc: (0.875)(0.875, 0.875)] [G loss: 0.855] [G acc: 0.438]\n",
      "18645 [D loss: (0.629)(R 0.686, F 0.572)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.226] [G acc: 0.312]\n",
      "18646 [D loss: (0.977)(R 1.399, F 0.555)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.608] [G acc: 0.625]\n",
      "18647 [D loss: (0.646)(R 0.734, F 0.557)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.850] [G acc: 0.500]\n",
      "18648 [D loss: (0.707)(R 0.583, F 0.832)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.886] [G acc: 0.500]\n",
      "18649 [D loss: (0.715)(R 0.892, F 0.538)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.857] [G acc: 0.562]\n",
      "18650 [D loss: (0.801)(R 0.564, F 1.037)] [D acc: (0.469)(0.750, 0.188)] [G loss: 1.763] [G acc: 0.438]\n",
      "18651 [D loss: (0.454)(R 0.635, F 0.273)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.947] [G acc: 0.125]\n",
      "18652 [D loss: (0.553)(R 0.533, F 0.572)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.039] [G acc: 0.250]\n",
      "18653 [D loss: (0.907)(R 1.080, F 0.734)] [D acc: (0.375)(0.438, 0.312)] [G loss: 0.845] [G acc: 0.562]\n",
      "18654 [D loss: (0.585)(R 0.514, F 0.656)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.777] [G acc: 0.438]\n",
      "18655 [D loss: (0.986)(R 0.748, F 1.224)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.589] [G acc: 0.750]\n",
      "18656 [D loss: (0.584)(R 0.549, F 0.620)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.622] [G acc: 0.688]\n",
      "18657 [D loss: (0.743)(R 0.754, F 0.733)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.873] [G acc: 0.375]\n",
      "18658 [D loss: (0.535)(R 0.606, F 0.464)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.277] [G acc: 0.438]\n",
      "18659 [D loss: (0.778)(R 0.630, F 0.926)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.496] [G acc: 0.188]\n",
      "18660 [D loss: (0.626)(R 0.560, F 0.693)] [D acc: (0.625)(0.750, 0.500)] [G loss: 1.068] [G acc: 0.188]\n",
      "18661 [D loss: (0.730)(R 0.682, F 0.779)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.692] [G acc: 0.688]\n",
      "18662 [D loss: (0.721)(R 0.851, F 0.591)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.704] [G acc: 0.500]\n",
      "18663 [D loss: (0.615)(R 0.514, F 0.717)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.860] [G acc: 0.438]\n",
      "18664 [D loss: (0.846)(R 0.554, F 1.137)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.907] [G acc: 0.500]\n",
      "18665 [D loss: (0.599)(R 0.733, F 0.465)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.966] [G acc: 0.438]\n",
      "18666 [D loss: (0.746)(R 0.757, F 0.735)] [D acc: (0.625)(0.750, 0.500)] [G loss: 1.230] [G acc: 0.250]\n",
      "18667 [D loss: (0.615)(R 0.531, F 0.699)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.714] [G acc: 0.562]\n",
      "18668 [D loss: (0.833)(R 0.651, F 1.014)] [D acc: (0.438)(0.688, 0.188)] [G loss: 0.811] [G acc: 0.375]\n",
      "18669 [D loss: (0.626)(R 0.564, F 0.688)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.734] [G acc: 0.500]\n",
      "18670 [D loss: (0.728)(R 0.708, F 0.749)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.686] [G acc: 0.688]\n",
      "18671 [D loss: (0.630)(R 0.619, F 0.640)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.940] [G acc: 0.250]\n",
      "18672 [D loss: (0.604)(R 0.543, F 0.666)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.876] [G acc: 0.438]\n",
      "18673 [D loss: (0.660)(R 0.565, F 0.755)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.812] [G acc: 0.438]\n",
      "18674 [D loss: (0.649)(R 0.624, F 0.674)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.863] [G acc: 0.438]\n",
      "18675 [D loss: (0.718)(R 0.652, F 0.784)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.749] [G acc: 0.625]\n",
      "18676 [D loss: (0.839)(R 0.700, F 0.979)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.992] [G acc: 0.375]\n",
      "18677 [D loss: (0.725)(R 0.848, F 0.602)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.957] [G acc: 0.438]\n",
      "18678 [D loss: (0.875)(R 0.801, F 0.948)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.853] [G acc: 0.375]\n",
      "18679 [D loss: (0.775)(R 0.718, F 0.832)] [D acc: (0.531)(0.625, 0.438)] [G loss: 1.028] [G acc: 0.188]\n",
      "18680 [D loss: (0.680)(R 0.733, F 0.627)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.660] [G acc: 0.625]\n",
      "18681 [D loss: (0.698)(R 0.661, F 0.734)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.742] [G acc: 0.438]\n",
      "18682 [D loss: (0.638)(R 0.634, F 0.643)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.682] [G acc: 0.625]\n",
      "18683 [D loss: (0.570)(R 0.616, F 0.524)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.694] [G acc: 0.562]\n",
      "18684 [D loss: (0.686)(R 0.661, F 0.711)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.653] [G acc: 0.688]\n",
      "18685 [D loss: (0.801)(R 0.685, F 0.918)] [D acc: (0.406)(0.688, 0.125)] [G loss: 0.669] [G acc: 0.688]\n",
      "18686 [D loss: (0.765)(R 0.678, F 0.853)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.595] [G acc: 0.750]\n",
      "18687 [D loss: (0.707)(R 0.560, F 0.854)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.666] [G acc: 0.625]\n",
      "18688 [D loss: (0.825)(R 0.628, F 1.022)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.671] [G acc: 0.688]\n",
      "18689 [D loss: (0.831)(R 0.589, F 1.073)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.697] [G acc: 0.625]\n",
      "18690 [D loss: (0.786)(R 0.727, F 0.845)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.801] [G acc: 0.438]\n",
      "18691 [D loss: (0.802)(R 0.843, F 0.761)] [D acc: (0.625)(0.562, 0.688)] [G loss: 3.624] [G acc: 0.375]\n",
      "18692 [D loss: (0.689)(R 0.779, F 0.600)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.830] [G acc: 0.562]\n",
      "18693 [D loss: (0.671)(R 0.606, F 0.736)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.949] [G acc: 0.500]\n",
      "18694 [D loss: (0.679)(R 0.622, F 0.736)] [D acc: (0.594)(0.875, 0.312)] [G loss: 2.393] [G acc: 0.312]\n",
      "18695 [D loss: (0.562)(R 0.601, F 0.522)] [D acc: (0.594)(0.688, 0.500)] [G loss: 1.626] [G acc: 0.500]\n",
      "18696 [D loss: (0.535)(R 0.660, F 0.410)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.911] [G acc: 0.250]\n",
      "18697 [D loss: (0.584)(R 0.721, F 0.446)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.860] [G acc: 0.500]\n",
      "18698 [D loss: (0.695)(R 0.609, F 0.781)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.554] [G acc: 0.875]\n",
      "18699 [D loss: (0.840)(R 0.895, F 0.785)] [D acc: (0.375)(0.438, 0.312)] [G loss: 0.617] [G acc: 0.688]\n",
      "18700 [D loss: (0.693)(R 0.595, F 0.792)] [D acc: (0.562)(0.938, 0.188)] [G loss: 0.655] [G acc: 0.562]\n",
      "18701 [D loss: (0.699)(R 0.604, F 0.795)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.665] [G acc: 0.875]\n",
      "18702 [D loss: (0.627)(R 0.546, F 0.708)] [D acc: (0.719)(1.000, 0.438)] [G loss: 0.687] [G acc: 0.688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18703 [D loss: (0.726)(R 0.726, F 0.727)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.668] [G acc: 0.688]\n",
      "18704 [D loss: (0.686)(R 0.613, F 0.760)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.670] [G acc: 0.812]\n",
      "18705 [D loss: (0.769)(R 0.743, F 0.794)] [D acc: (0.344)(0.562, 0.125)] [G loss: 0.689] [G acc: 0.750]\n",
      "18706 [D loss: (0.666)(R 0.633, F 0.699)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.816] [G acc: 0.750]\n",
      "18707 [D loss: (0.756)(R 0.775, F 0.738)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.716] [G acc: 0.688]\n",
      "18708 [D loss: (0.768)(R 0.759, F 0.777)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.846] [G acc: 0.625]\n",
      "18709 [D loss: (0.663)(R 0.605, F 0.721)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.765] [G acc: 0.562]\n",
      "18710 [D loss: (0.623)(R 0.595, F 0.651)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.878] [G acc: 0.312]\n",
      "18711 [D loss: (0.725)(R 0.606, F 0.843)] [D acc: (0.562)(0.938, 0.188)] [G loss: 0.750] [G acc: 0.625]\n",
      "18712 [D loss: (0.697)(R 0.688, F 0.705)] [D acc: (0.406)(0.500, 0.312)] [G loss: 1.015] [G acc: 0.375]\n",
      "18713 [D loss: (0.662)(R 0.710, F 0.615)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.798] [G acc: 0.750]\n",
      "18714 [D loss: (0.656)(R 0.590, F 0.722)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.763] [G acc: 0.562]\n",
      "18715 [D loss: (0.696)(R 0.670, F 0.721)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.935] [G acc: 0.562]\n",
      "18716 [D loss: (0.695)(R 0.637, F 0.752)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.860] [G acc: 0.562]\n",
      "18717 [D loss: (0.496)(R 0.600, F 0.392)] [D acc: (0.906)(0.938, 0.875)] [G loss: 0.903] [G acc: 0.375]\n",
      "18718 [D loss: (0.604)(R 0.609, F 0.599)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.801] [G acc: 0.500]\n",
      "18719 [D loss: (0.653)(R 0.668, F 0.639)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.707] [G acc: 0.562]\n",
      "18720 [D loss: (0.679)(R 0.702, F 0.656)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.810] [G acc: 0.375]\n",
      "18721 [D loss: (0.875)(R 1.077, F 0.673)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.748] [G acc: 0.438]\n",
      "18722 [D loss: (0.688)(R 0.650, F 0.727)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.781] [G acc: 0.438]\n",
      "18723 [D loss: (0.651)(R 0.605, F 0.696)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.656] [G acc: 0.812]\n",
      "18724 [D loss: (0.694)(R 0.731, F 0.657)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.706] [G acc: 0.625]\n",
      "18725 [D loss: (0.658)(R 0.655, F 0.661)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.686] [G acc: 0.688]\n",
      "18726 [D loss: (0.710)(R 0.724, F 0.697)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.711] [G acc: 0.562]\n",
      "18727 [D loss: (0.660)(R 0.605, F 0.716)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.622] [G acc: 0.812]\n",
      "18728 [D loss: (0.684)(R 0.660, F 0.707)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.802] [G acc: 0.312]\n",
      "18729 [D loss: (0.636)(R 0.613, F 0.659)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.825] [G acc: 0.625]\n",
      "18730 [D loss: (0.544)(R 0.639, F 0.449)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.952] [G acc: 0.188]\n",
      "18731 [D loss: (0.633)(R 0.731, F 0.535)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.374] [G acc: 0.062]\n",
      "18732 [D loss: (0.484)(R 0.649, F 0.319)] [D acc: (0.781)(0.750, 0.812)] [G loss: 2.509] [G acc: 0.000]\n",
      "18733 [D loss: (0.597)(R 0.589, F 0.605)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.900] [G acc: 0.188]\n",
      "18734 [D loss: (0.610)(R 0.589, F 0.632)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.847] [G acc: 0.250]\n",
      "18735 [D loss: (0.556)(R 0.565, F 0.548)] [D acc: (0.844)(0.938, 0.750)] [G loss: 1.055] [G acc: 0.250]\n",
      "18736 [D loss: (0.633)(R 0.660, F 0.605)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.971] [G acc: 0.125]\n",
      "18737 [D loss: (0.622)(R 0.671, F 0.574)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.059] [G acc: 0.125]\n",
      "18738 [D loss: (0.572)(R 0.611, F 0.532)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.992] [G acc: 0.188]\n",
      "18739 [D loss: (0.587)(R 0.636, F 0.538)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.990] [G acc: 0.125]\n",
      "18740 [D loss: (0.537)(R 0.554, F 0.520)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.373] [G acc: 0.250]\n",
      "18741 [D loss: (0.547)(R 0.591, F 0.502)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.260] [G acc: 0.188]\n",
      "18742 [D loss: (0.536)(R 0.479, F 0.593)] [D acc: (0.750)(0.875, 0.625)] [G loss: 1.624] [G acc: 0.000]\n",
      "18743 [D loss: (0.481)(R 0.470, F 0.492)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.179] [G acc: 0.125]\n",
      "18744 [D loss: (0.545)(R 0.631, F 0.459)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.000] [G acc: 0.312]\n",
      "18745 [D loss: (0.469)(R 0.541, F 0.398)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.513] [G acc: 0.000]\n",
      "18746 [D loss: (0.547)(R 0.573, F 0.520)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.056] [G acc: 0.250]\n",
      "18747 [D loss: (0.643)(R 0.638, F 0.648)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.716] [G acc: 0.438]\n",
      "18748 [D loss: (0.699)(R 0.583, F 0.816)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.636] [G acc: 0.562]\n",
      "18749 [D loss: (0.782)(R 0.655, F 0.909)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.857] [G acc: 0.375]\n",
      "18750 [D loss: (0.933)(R 0.739, F 1.126)] [D acc: (0.656)(0.812, 0.500)] [G loss: 1.143] [G acc: 0.312]\n",
      "18751 [D loss: (0.701)(R 0.773, F 0.628)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.658] [G acc: 0.562]\n",
      "18752 [D loss: (0.764)(R 0.852, F 0.677)] [D acc: (0.562)(0.438, 0.688)] [G loss: 1.083] [G acc: 0.312]\n",
      "18753 [D loss: (0.533)(R 0.816, F 0.250)] [D acc: (0.656)(0.500, 0.812)] [G loss: 2.244] [G acc: 0.188]\n",
      "18754 [D loss: (0.920)(R 0.544, F 1.296)] [D acc: (0.531)(0.688, 0.375)] [G loss: 6.935] [G acc: 0.312]\n",
      "18755 [D loss: (0.774)(R 0.806, F 0.741)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.735] [G acc: 0.688]\n",
      "18756 [D loss: (0.893)(R 0.656, F 1.130)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.836] [G acc: 0.500]\n",
      "18757 [D loss: (0.649)(R 0.564, F 0.734)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.873] [G acc: 0.312]\n",
      "18758 [D loss: (0.717)(R 0.805, F 0.630)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.686] [G acc: 0.562]\n",
      "18759 [D loss: (0.661)(R 0.617, F 0.705)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.542] [G acc: 0.750]\n",
      "18760 [D loss: (0.740)(R 0.642, F 0.838)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.942] [G acc: 0.500]\n",
      "18761 [D loss: (0.554)(R 0.579, F 0.529)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.016] [G acc: 0.312]\n",
      "18762 [D loss: (0.625)(R 0.670, F 0.581)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.065] [G acc: 0.438]\n",
      "18763 [D loss: (0.564)(R 0.570, F 0.559)] [D acc: (0.781)(0.938, 0.625)] [G loss: 0.903] [G acc: 0.500]\n",
      "18764 [D loss: (0.700)(R 0.704, F 0.697)] [D acc: (0.562)(0.562, 0.562)] [G loss: 1.355] [G acc: 0.500]\n",
      "18765 [D loss: (0.688)(R 0.992, F 0.384)] [D acc: (0.719)(0.688, 0.750)] [G loss: 4.336] [G acc: 0.188]\n",
      "18766 [D loss: (0.646)(R 0.617, F 0.674)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.856] [G acc: 0.438]\n",
      "18767 [D loss: (0.646)(R 0.605, F 0.687)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.762] [G acc: 0.375]\n",
      "18768 [D loss: (0.601)(R 0.683, F 0.520)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.801] [G acc: 0.375]\n",
      "18769 [D loss: (0.679)(R 0.667, F 0.690)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.818] [G acc: 0.625]\n",
      "18770 [D loss: (0.794)(R 0.916, F 0.672)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.754] [G acc: 0.625]\n",
      "18771 [D loss: (0.744)(R 0.788, F 0.700)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.639] [G acc: 0.688]\n",
      "18772 [D loss: (0.696)(R 0.685, F 0.707)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.711] [G acc: 0.500]\n",
      "18773 [D loss: (0.624)(R 0.593, F 0.655)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.687] [G acc: 0.500]\n",
      "18774 [D loss: (0.678)(R 0.680, F 0.677)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.811] [G acc: 0.250]\n",
      "18775 [D loss: (0.741)(R 0.754, F 0.727)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.784] [G acc: 0.438]\n",
      "18776 [D loss: (0.676)(R 0.650, F 0.702)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.700] [G acc: 0.688]\n",
      "18777 [D loss: (0.767)(R 0.882, F 0.652)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.718] [G acc: 0.500]\n",
      "18778 [D loss: (0.752)(R 0.796, F 0.707)] [D acc: (0.594)(0.812, 0.375)] [G loss: 1.096] [G acc: 0.625]\n",
      "18779 [D loss: (0.640)(R 0.618, F 0.662)] [D acc: (0.531)(0.750, 0.312)] [G loss: 1.117] [G acc: 0.438]\n",
      "18780 [D loss: (0.569)(R 0.829, F 0.309)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.139] [G acc: 0.375]\n",
      "18781 [D loss: (0.601)(R 0.635, F 0.568)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.905] [G acc: 0.312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18782 [D loss: (0.608)(R 0.552, F 0.664)] [D acc: (0.750)(0.938, 0.562)] [G loss: 0.894] [G acc: 0.375]\n",
      "18783 [D loss: (0.909)(R 0.878, F 0.939)] [D acc: (0.312)(0.500, 0.125)] [G loss: 0.700] [G acc: 0.562]\n",
      "18784 [D loss: (0.689)(R 0.679, F 0.699)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.740] [G acc: 0.562]\n",
      "18785 [D loss: (0.790)(R 0.779, F 0.801)] [D acc: (0.312)(0.500, 0.125)] [G loss: 0.761] [G acc: 0.625]\n",
      "18786 [D loss: (0.713)(R 0.678, F 0.747)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.709] [G acc: 0.688]\n",
      "18787 [D loss: (0.707)(R 0.648, F 0.767)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.654] [G acc: 0.750]\n",
      "18788 [D loss: (0.712)(R 0.661, F 0.762)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.624] [G acc: 0.812]\n",
      "18789 [D loss: (0.684)(R 0.572, F 0.796)] [D acc: (0.500)(0.938, 0.062)] [G loss: 0.743] [G acc: 0.625]\n",
      "18790 [D loss: (0.684)(R 0.658, F 0.711)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.696] [G acc: 0.562]\n",
      "18791 [D loss: (0.664)(R 0.628, F 0.700)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.665] [G acc: 0.688]\n",
      "18792 [D loss: (0.578)(R 0.590, F 0.567)] [D acc: (0.812)(0.938, 0.688)] [G loss: 0.794] [G acc: 0.500]\n",
      "18793 [D loss: (0.675)(R 0.619, F 0.730)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.714] [G acc: 0.438]\n",
      "18794 [D loss: (0.621)(R 0.602, F 0.641)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.833] [G acc: 0.438]\n",
      "18795 [D loss: (0.708)(R 0.689, F 0.727)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.716] [G acc: 0.562]\n",
      "18796 [D loss: (0.653)(R 0.603, F 0.703)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.766] [G acc: 0.562]\n",
      "18797 [D loss: (1.103)(R 0.580, F 1.626)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.790] [G acc: 0.500]\n",
      "18798 [D loss: (0.757)(R 0.786, F 0.727)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.717] [G acc: 0.562]\n",
      "18799 [D loss: (0.782)(R 0.686, F 0.877)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.710] [G acc: 0.625]\n",
      "18800 [D loss: (0.645)(R 0.541, F 0.748)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.716] [G acc: 0.375]\n",
      "18801 [D loss: (0.668)(R 0.610, F 0.726)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.743] [G acc: 0.562]\n",
      "18802 [D loss: (0.642)(R 0.599, F 0.685)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.783] [G acc: 0.438]\n",
      "18803 [D loss: (0.721)(R 0.692, F 0.750)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.855] [G acc: 0.438]\n",
      "18804 [D loss: (0.717)(R 0.704, F 0.730)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.693] [G acc: 0.562]\n",
      "18805 [D loss: (0.675)(R 0.614, F 0.736)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.625] [G acc: 0.750]\n",
      "18806 [D loss: (0.730)(R 0.657, F 0.803)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.854] [G acc: 0.500]\n",
      "18807 [D loss: (0.464)(R 0.666, F 0.262)] [D acc: (0.781)(0.688, 0.875)] [G loss: 4.666] [G acc: 0.000]\n",
      "18808 [D loss: (0.557)(R 0.667, F 0.448)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.836] [G acc: 0.250]\n",
      "18809 [D loss: (0.754)(R 0.751, F 0.756)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.761] [G acc: 0.375]\n",
      "18810 [D loss: (0.665)(R 0.604, F 0.726)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.751] [G acc: 0.688]\n",
      "18811 [D loss: (0.655)(R 0.570, F 0.740)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.713] [G acc: 0.625]\n",
      "18812 [D loss: (0.699)(R 0.667, F 0.731)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.660] [G acc: 0.688]\n",
      "18813 [D loss: (0.767)(R 0.790, F 0.744)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.721] [G acc: 0.625]\n",
      "18814 [D loss: (0.631)(R 0.497, F 0.765)] [D acc: (0.500)(0.938, 0.062)] [G loss: 0.675] [G acc: 0.812]\n",
      "18815 [D loss: (0.600)(R 0.491, F 0.709)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.741] [G acc: 0.500]\n",
      "18816 [D loss: (0.664)(R 0.610, F 0.718)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.668] [G acc: 0.750]\n",
      "18817 [D loss: (0.645)(R 0.611, F 0.679)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.776] [G acc: 0.438]\n",
      "18818 [D loss: (0.708)(R 0.664, F 0.751)] [D acc: (0.375)(0.625, 0.125)] [G loss: 0.715] [G acc: 0.688]\n",
      "18819 [D loss: (0.703)(R 0.646, F 0.761)] [D acc: (0.438)(0.688, 0.188)] [G loss: 0.645] [G acc: 0.625]\n",
      "18820 [D loss: (0.569)(R 0.455, F 0.683)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.715] [G acc: 0.562]\n",
      "18821 [D loss: (0.658)(R 0.571, F 0.744)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.729] [G acc: 0.438]\n",
      "18822 [D loss: (0.719)(R 0.697, F 0.742)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.665] [G acc: 0.750]\n",
      "18823 [D loss: (0.596)(R 0.515, F 0.676)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.652] [G acc: 0.438]\n",
      "18824 [D loss: (0.653)(R 0.599, F 0.707)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.619] [G acc: 0.562]\n",
      "18825 [D loss: (0.630)(R 0.526, F 0.733)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.728] [G acc: 0.250]\n",
      "18826 [D loss: (0.714)(R 0.636, F 0.793)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.646] [G acc: 0.688]\n",
      "18827 [D loss: (0.830)(R 0.595, F 1.066)] [D acc: (0.406)(0.625, 0.188)] [G loss: 0.711] [G acc: 0.625]\n",
      "18828 [D loss: (0.828)(R 0.668, F 0.988)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.788] [G acc: 0.125]\n",
      "18829 [D loss: (0.683)(R 0.737, F 0.628)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.750] [G acc: 0.375]\n",
      "18830 [D loss: (0.789)(R 0.892, F 0.685)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.635] [G acc: 0.875]\n",
      "18831 [D loss: (0.638)(R 0.603, F 0.673)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.816] [G acc: 0.250]\n",
      "18832 [D loss: (0.605)(R 0.566, F 0.644)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.827] [G acc: 0.125]\n",
      "18833 [D loss: (0.614)(R 0.619, F 0.610)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.792] [G acc: 0.375]\n",
      "18834 [D loss: (0.582)(R 0.533, F 0.631)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.725] [G acc: 0.438]\n",
      "18835 [D loss: (0.624)(R 0.608, F 0.640)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.834] [G acc: 0.375]\n",
      "18836 [D loss: (0.596)(R 0.685, F 0.507)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.963] [G acc: 0.125]\n",
      "18837 [D loss: (0.643)(R 0.670, F 0.616)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.763] [G acc: 0.250]\n",
      "18838 [D loss: (0.714)(R 0.739, F 0.688)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.776] [G acc: 0.250]\n",
      "18839 [D loss: (0.646)(R 0.652, F 0.641)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.761] [G acc: 0.312]\n",
      "18840 [D loss: (0.544)(R 0.465, F 0.623)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.739] [G acc: 0.375]\n",
      "18841 [D loss: (0.641)(R 0.655, F 0.627)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.733] [G acc: 0.625]\n",
      "18842 [D loss: (0.648)(R 0.624, F 0.672)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.707] [G acc: 0.562]\n",
      "18843 [D loss: (0.677)(R 0.658, F 0.696)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.707] [G acc: 0.438]\n",
      "18844 [D loss: (0.704)(R 0.572, F 0.837)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.683] [G acc: 0.375]\n",
      "18845 [D loss: (0.602)(R 0.551, F 0.654)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.869] [G acc: 0.125]\n",
      "18846 [D loss: (0.656)(R 0.524, F 0.787)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.591] [G acc: 0.625]\n",
      "18847 [D loss: (0.566)(R 0.551, F 0.582)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.126] [G acc: 0.188]\n",
      "18848 [D loss: (0.676)(R 0.667, F 0.684)] [D acc: (0.500)(0.438, 0.562)] [G loss: 1.488] [G acc: 0.625]\n",
      "18849 [D loss: (0.697)(R 0.660, F 0.734)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.626] [G acc: 0.562]\n",
      "18850 [D loss: (0.954)(R 0.563, F 1.346)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.966] [G acc: 0.188]\n",
      "18851 [D loss: (0.580)(R 0.682, F 0.479)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.012] [G acc: 0.250]\n",
      "18852 [D loss: (1.125)(R 0.655, F 1.595)] [D acc: (0.375)(0.375, 0.375)] [G loss: 0.426] [G acc: 0.750]\n",
      "18853 [D loss: (1.050)(R 0.785, F 1.315)] [D acc: (0.531)(0.375, 0.688)] [G loss: 1.764] [G acc: 0.188]\n",
      "18854 [D loss: (0.459)(R 0.656, F 0.262)] [D acc: (0.719)(0.562, 0.875)] [G loss: 3.168] [G acc: 0.125]\n",
      "18855 [D loss: (0.900)(R 0.901, F 0.899)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.777] [G acc: 0.500]\n",
      "18856 [D loss: (0.639)(R 0.618, F 0.660)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.712] [G acc: 0.312]\n",
      "18857 [D loss: (0.729)(R 0.710, F 0.748)] [D acc: (0.344)(0.375, 0.312)] [G loss: 0.748] [G acc: 0.312]\n",
      "18858 [D loss: (0.753)(R 0.751, F 0.756)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.800] [G acc: 0.188]\n",
      "18859 [D loss: (0.783)(R 0.688, F 0.878)] [D acc: (0.344)(0.438, 0.250)] [G loss: 0.752] [G acc: 0.438]\n",
      "18860 [D loss: (0.743)(R 0.693, F 0.793)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.771] [G acc: 0.375]\n",
      "18861 [D loss: (0.669)(R 0.638, F 0.700)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.750] [G acc: 0.438]\n",
      "18862 [D loss: (0.655)(R 0.648, F 0.663)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.899] [G acc: 0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18863 [D loss: (0.665)(R 0.715, F 0.616)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.789] [G acc: 0.312]\n",
      "18864 [D loss: (0.639)(R 0.623, F 0.655)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.812] [G acc: 0.375]\n",
      "18865 [D loss: (0.783)(R 0.873, F 0.692)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.673] [G acc: 0.375]\n",
      "18866 [D loss: (0.676)(R 0.644, F 0.707)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.741] [G acc: 0.375]\n",
      "18867 [D loss: (0.616)(R 0.609, F 0.623)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.451] [G acc: 0.688]\n",
      "18868 [D loss: (0.587)(R 0.565, F 0.610)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.674] [G acc: 0.625]\n",
      "18869 [D loss: (0.590)(R 0.602, F 0.577)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.916] [G acc: 0.375]\n",
      "18870 [D loss: (0.719)(R 0.706, F 0.732)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.250] [G acc: 0.500]\n",
      "18871 [D loss: (0.599)(R 0.468, F 0.731)] [D acc: (0.656)(0.688, 0.625)] [G loss: 2.228] [G acc: 0.312]\n",
      "18872 [D loss: (0.524)(R 0.665, F 0.384)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.993] [G acc: 0.125]\n",
      "18873 [D loss: (0.486)(R 0.614, F 0.358)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.791] [G acc: 0.312]\n",
      "18874 [D loss: (0.554)(R 0.670, F 0.437)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.185] [G acc: 0.250]\n",
      "18875 [D loss: (0.576)(R 0.693, F 0.460)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.956] [G acc: 0.188]\n",
      "18876 [D loss: (0.666)(R 0.771, F 0.562)] [D acc: (0.562)(0.312, 0.812)] [G loss: 0.873] [G acc: 0.250]\n",
      "18877 [D loss: (0.666)(R 0.595, F 0.737)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.800] [G acc: 0.188]\n",
      "18878 [D loss: (0.636)(R 0.640, F 0.632)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.692] [G acc: 0.438]\n",
      "18879 [D loss: (0.568)(R 0.653, F 0.484)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.397] [G acc: 0.125]\n",
      "18880 [D loss: (0.640)(R 0.714, F 0.566)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.775] [G acc: 0.312]\n",
      "18881 [D loss: (0.635)(R 0.641, F 0.628)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.708] [G acc: 0.562]\n",
      "18882 [D loss: (0.968)(R 0.623, F 1.312)] [D acc: (0.469)(0.500, 0.438)] [G loss: 1.353] [G acc: 0.438]\n",
      "18883 [D loss: (0.402)(R 0.606, F 0.198)] [D acc: (0.812)(0.625, 1.000)] [G loss: 1.577] [G acc: 0.125]\n",
      "18884 [D loss: (0.549)(R 0.601, F 0.497)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.336] [G acc: 0.125]\n",
      "18885 [D loss: (0.669)(R 0.737, F 0.601)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.787] [G acc: 0.250]\n",
      "18886 [D loss: (0.591)(R 0.554, F 0.627)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.857] [G acc: 0.125]\n",
      "18887 [D loss: (0.630)(R 0.647, F 0.612)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.854] [G acc: 0.312]\n",
      "18888 [D loss: (0.664)(R 0.703, F 0.625)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.782] [G acc: 0.250]\n",
      "18889 [D loss: (0.646)(R 0.580, F 0.711)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.801] [G acc: 0.375]\n",
      "18890 [D loss: (0.536)(R 0.499, F 0.573)] [D acc: (0.844)(0.938, 0.750)] [G loss: 0.734] [G acc: 0.250]\n",
      "18891 [D loss: (0.545)(R 0.488, F 0.602)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.940] [G acc: 0.125]\n",
      "18892 [D loss: (0.541)(R 0.495, F 0.588)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.847] [G acc: 0.375]\n",
      "18893 [D loss: (0.668)(R 0.617, F 0.718)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.910] [G acc: 0.250]\n",
      "18894 [D loss: (0.510)(R 0.611, F 0.408)] [D acc: (0.781)(0.750, 0.812)] [G loss: 2.021] [G acc: 0.188]\n",
      "18895 [D loss: (0.635)(R 0.479, F 0.791)] [D acc: (0.750)(0.938, 0.562)] [G loss: 3.426] [G acc: 0.375]\n",
      "18896 [D loss: (0.498)(R 0.485, F 0.511)] [D acc: (0.844)(0.875, 0.812)] [G loss: 0.697] [G acc: 0.625]\n",
      "18897 [D loss: (0.664)(R 0.579, F 0.750)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.775] [G acc: 0.438]\n",
      "18898 [D loss: (0.777)(R 0.578, F 0.976)] [D acc: (0.562)(0.625, 0.500)] [G loss: 1.017] [G acc: 0.562]\n",
      "18899 [D loss: (0.556)(R 0.688, F 0.425)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.852] [G acc: 0.000]\n",
      "18900 [D loss: (0.546)(R 0.632, F 0.460)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.413] [G acc: 0.125]\n",
      "18901 [D loss: (0.588)(R 0.608, F 0.568)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.062] [G acc: 0.250]\n",
      "18902 [D loss: (0.640)(R 0.729, F 0.551)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.854] [G acc: 0.312]\n",
      "18903 [D loss: (0.584)(R 0.513, F 0.654)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.817] [G acc: 0.438]\n",
      "18904 [D loss: (0.531)(R 0.514, F 0.548)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.699] [G acc: 0.625]\n",
      "18905 [D loss: (0.769)(R 0.507, F 1.031)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.894] [G acc: 0.438]\n",
      "18906 [D loss: (0.690)(R 0.531, F 0.850)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.878] [G acc: 0.125]\n",
      "18907 [D loss: (0.638)(R 0.658, F 0.617)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.020] [G acc: 0.188]\n",
      "18908 [D loss: (0.551)(R 0.501, F 0.600)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.284] [G acc: 0.312]\n",
      "18909 [D loss: (0.477)(R 0.553, F 0.401)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.360] [G acc: 0.125]\n",
      "18910 [D loss: (0.484)(R 0.518, F 0.450)] [D acc: (0.844)(0.750, 0.938)] [G loss: 0.949] [G acc: 0.312]\n",
      "18911 [D loss: (0.557)(R 0.595, F 0.518)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.222] [G acc: 0.438]\n",
      "18912 [D loss: (0.528)(R 0.607, F 0.449)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.664] [G acc: 0.188]\n",
      "18913 [D loss: (0.747)(R 0.826, F 0.668)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.016] [G acc: 0.375]\n",
      "18914 [D loss: (0.632)(R 0.669, F 0.596)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.986] [G acc: 0.188]\n",
      "18915 [D loss: (0.587)(R 0.670, F 0.503)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.015] [G acc: 0.312]\n",
      "18916 [D loss: (0.685)(R 0.601, F 0.768)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.883] [G acc: 0.562]\n",
      "18917 [D loss: (1.277)(R 1.901, F 0.654)] [D acc: (0.594)(0.688, 0.500)] [G loss: 1.022] [G acc: 0.188]\n",
      "18918 [D loss: (0.604)(R 0.522, F 0.686)] [D acc: (0.594)(0.750, 0.438)] [G loss: 2.501] [G acc: 0.562]\n",
      "18919 [D loss: (0.416)(R 0.584, F 0.249)] [D acc: (0.844)(0.750, 0.938)] [G loss: 4.398] [G acc: 0.250]\n",
      "18920 [D loss: (0.817)(R 1.126, F 0.508)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.810] [G acc: 0.500]\n",
      "18921 [D loss: (0.584)(R 0.697, F 0.470)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.763] [G acc: 0.438]\n",
      "18922 [D loss: (0.456)(R 0.498, F 0.414)] [D acc: (0.812)(0.938, 0.688)] [G loss: 0.831] [G acc: 0.438]\n",
      "18923 [D loss: (0.530)(R 0.696, F 0.365)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.965] [G acc: 0.375]\n",
      "18924 [D loss: (0.545)(R 0.552, F 0.538)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.048] [G acc: 0.438]\n",
      "18925 [D loss: (0.614)(R 0.615, F 0.612)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.997] [G acc: 0.250]\n",
      "18926 [D loss: (0.642)(R 0.680, F 0.605)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.979] [G acc: 0.188]\n",
      "18927 [D loss: (0.579)(R 0.595, F 0.564)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.019] [G acc: 0.312]\n",
      "18928 [D loss: (0.636)(R 0.633, F 0.639)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.966] [G acc: 0.375]\n",
      "18929 [D loss: (0.535)(R 0.563, F 0.507)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.928] [G acc: 0.312]\n",
      "18930 [D loss: (0.522)(R 0.563, F 0.481)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.699] [G acc: 0.625]\n",
      "18931 [D loss: (0.645)(R 0.735, F 0.556)] [D acc: (0.844)(0.875, 0.812)] [G loss: 0.962] [G acc: 0.375]\n",
      "18932 [D loss: (0.474)(R 0.446, F 0.503)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.930] [G acc: 0.188]\n",
      "18933 [D loss: (0.545)(R 0.510, F 0.580)] [D acc: (0.688)(0.812, 0.562)] [G loss: 1.151] [G acc: 0.188]\n",
      "18934 [D loss: (0.587)(R 0.596, F 0.579)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.122] [G acc: 0.188]\n",
      "18935 [D loss: (0.563)(R 0.622, F 0.504)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.782] [G acc: 0.438]\n",
      "18936 [D loss: (0.582)(R 0.543, F 0.621)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.861] [G acc: 0.375]\n",
      "18937 [D loss: (0.587)(R 0.623, F 0.551)] [D acc: (0.688)(0.625, 0.750)] [G loss: 2.498] [G acc: 0.562]\n",
      "18938 [D loss: (0.523)(R 0.692, F 0.354)] [D acc: (0.688)(0.625, 0.750)] [G loss: 8.940] [G acc: 0.250]\n",
      "18939 [D loss: (0.524)(R 0.586, F 0.463)] [D acc: (0.750)(0.812, 0.688)] [G loss: 3.092] [G acc: 0.375]\n",
      "18940 [D loss: (0.510)(R 0.610, F 0.409)] [D acc: (0.719)(0.812, 0.625)] [G loss: 2.159] [G acc: 0.312]\n",
      "18941 [D loss: (0.507)(R 0.571, F 0.444)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.757] [G acc: 0.625]\n",
      "18942 [D loss: (0.658)(R 0.610, F 0.706)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.131] [G acc: 0.312]\n",
      "18943 [D loss: (0.643)(R 0.727, F 0.559)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.066] [G acc: 0.250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18944 [D loss: (0.568)(R 0.566, F 0.570)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.021] [G acc: 0.250]\n",
      "18945 [D loss: (0.588)(R 0.615, F 0.561)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.912] [G acc: 0.312]\n",
      "18946 [D loss: (0.567)(R 0.605, F 0.529)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.867] [G acc: 0.438]\n",
      "18947 [D loss: (0.583)(R 0.623, F 0.543)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.034] [G acc: 0.312]\n",
      "18948 [D loss: (0.777)(R 0.548, F 1.006)] [D acc: (0.562)(0.750, 0.375)] [G loss: 1.032] [G acc: 0.250]\n",
      "18949 [D loss: (0.679)(R 0.643, F 0.715)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.823] [G acc: 0.375]\n",
      "18950 [D loss: (0.650)(R 0.643, F 0.658)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.007] [G acc: 0.188]\n",
      "18951 [D loss: (0.715)(R 0.584, F 0.847)] [D acc: (0.500)(0.750, 0.250)] [G loss: 1.204] [G acc: 0.312]\n",
      "18952 [D loss: (0.582)(R 0.642, F 0.522)] [D acc: (0.656)(0.625, 0.688)] [G loss: 2.968] [G acc: 0.250]\n",
      "18953 [D loss: (0.632)(R 0.642, F 0.623)] [D acc: (0.469)(0.562, 0.375)] [G loss: 2.932] [G acc: 0.250]\n",
      "18954 [D loss: (0.588)(R 0.699, F 0.478)] [D acc: (0.562)(0.625, 0.500)] [G loss: 1.906] [G acc: 0.312]\n",
      "18955 [D loss: (0.729)(R 0.499, F 0.959)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.570] [G acc: 0.812]\n",
      "18956 [D loss: (0.625)(R 0.608, F 0.642)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.597] [G acc: 0.812]\n",
      "18957 [D loss: (0.867)(R 0.705, F 1.028)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.946] [G acc: 0.500]\n",
      "18958 [D loss: (0.737)(R 0.756, F 0.719)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.703] [G acc: 0.625]\n",
      "18959 [D loss: (0.722)(R 0.622, F 0.823)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.516] [G acc: 0.875]\n",
      "18960 [D loss: (0.713)(R 0.640, F 0.787)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.647] [G acc: 0.500]\n",
      "18961 [D loss: (0.737)(R 0.590, F 0.885)] [D acc: (0.625)(0.875, 0.375)] [G loss: 1.086] [G acc: 0.438]\n",
      "18962 [D loss: (0.640)(R 0.690, F 0.590)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.781] [G acc: 0.500]\n",
      "18963 [D loss: (0.636)(R 0.634, F 0.638)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.943] [G acc: 0.375]\n",
      "18964 [D loss: (0.646)(R 0.631, F 0.660)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.738] [G acc: 0.562]\n",
      "18965 [D loss: (0.688)(R 0.576, F 0.800)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.640] [G acc: 0.562]\n",
      "18966 [D loss: (0.821)(R 0.564, F 1.078)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.740] [G acc: 0.438]\n",
      "18967 [D loss: (0.754)(R 0.755, F 0.753)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.725] [G acc: 0.688]\n",
      "18968 [D loss: (0.725)(R 0.724, F 0.726)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.659] [G acc: 0.750]\n",
      "18969 [D loss: (0.636)(R 0.535, F 0.737)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.702] [G acc: 0.562]\n",
      "18970 [D loss: (0.674)(R 0.641, F 0.706)] [D acc: (0.500)(0.688, 0.312)] [G loss: 1.374] [G acc: 0.438]\n",
      "18971 [D loss: (0.415)(R 0.638, F 0.193)] [D acc: (0.750)(0.688, 0.812)] [G loss: 5.933] [G acc: 0.250]\n",
      "18972 [D loss: (0.795)(R 0.631, F 0.959)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.749] [G acc: 0.625]\n",
      "18973 [D loss: (0.646)(R 0.602, F 0.690)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.802] [G acc: 0.438]\n",
      "18974 [D loss: (0.668)(R 0.643, F 0.693)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.721] [G acc: 0.438]\n",
      "18975 [D loss: (0.660)(R 0.632, F 0.688)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.621] [G acc: 0.812]\n",
      "18976 [D loss: (0.678)(R 0.615, F 0.741)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.641] [G acc: 0.750]\n",
      "18977 [D loss: (0.707)(R 0.744, F 0.671)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.764] [G acc: 0.625]\n",
      "18978 [D loss: (0.605)(R 0.535, F 0.676)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.778] [G acc: 0.375]\n",
      "18979 [D loss: (0.606)(R 0.584, F 0.628)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.868] [G acc: 0.500]\n",
      "18980 [D loss: (0.635)(R 0.521, F 0.750)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.770] [G acc: 0.438]\n",
      "18981 [D loss: (0.707)(R 0.694, F 0.720)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.513] [G acc: 0.938]\n",
      "18982 [D loss: (0.661)(R 0.601, F 0.721)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.735] [G acc: 0.625]\n",
      "18983 [D loss: (0.669)(R 0.580, F 0.759)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.770] [G acc: 0.375]\n",
      "18984 [D loss: (0.629)(R 0.545, F 0.713)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.670] [G acc: 0.625]\n",
      "18985 [D loss: (0.625)(R 0.524, F 0.727)] [D acc: (0.656)(0.938, 0.375)] [G loss: 0.690] [G acc: 0.562]\n",
      "18986 [D loss: (0.640)(R 0.571, F 0.710)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.640] [G acc: 0.812]\n",
      "18987 [D loss: (0.659)(R 0.537, F 0.780)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.656] [G acc: 0.625]\n",
      "18988 [D loss: (0.650)(R 0.558, F 0.742)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.628] [G acc: 0.812]\n",
      "18989 [D loss: (0.582)(R 0.498, F 0.666)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.703] [G acc: 0.562]\n",
      "18990 [D loss: (0.712)(R 0.716, F 0.707)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.578] [G acc: 0.562]\n",
      "18991 [D loss: (0.669)(R 0.640, F 0.697)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.668] [G acc: 0.500]\n",
      "18992 [D loss: (0.722)(R 0.627, F 0.818)] [D acc: (0.375)(0.625, 0.125)] [G loss: 0.806] [G acc: 0.500]\n",
      "18993 [D loss: (0.930)(R 0.816, F 1.044)] [D acc: (0.250)(0.438, 0.062)] [G loss: 0.571] [G acc: 0.812]\n",
      "18994 [D loss: (0.692)(R 0.578, F 0.807)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.952] [G acc: 0.375]\n",
      "18995 [D loss: (0.443)(R 0.592, F 0.295)] [D acc: (0.781)(0.875, 0.688)] [G loss: 3.459] [G acc: 0.188]\n",
      "18996 [D loss: (0.681)(R 0.556, F 0.806)] [D acc: (0.688)(0.812, 0.562)] [G loss: 1.531] [G acc: 0.312]\n",
      "18997 [D loss: (0.621)(R 0.675, F 0.567)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.137] [G acc: 0.125]\n",
      "18998 [D loss: (0.701)(R 0.665, F 0.738)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.678] [G acc: 0.625]\n",
      "18999 [D loss: (0.627)(R 0.531, F 0.722)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.680] [G acc: 0.500]\n",
      "19000 [D loss: (0.643)(R 0.584, F 0.703)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.709] [G acc: 0.625]\n",
      "19001 [D loss: (0.660)(R 0.600, F 0.721)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.703] [G acc: 0.625]\n",
      "19002 [D loss: (0.641)(R 0.567, F 0.716)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.803] [G acc: 0.250]\n",
      "19003 [D loss: (0.599)(R 0.565, F 0.634)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.067] [G acc: 0.500]\n",
      "19004 [D loss: (0.728)(R 0.694, F 0.761)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.702] [G acc: 0.438]\n",
      "19005 [D loss: (0.627)(R 0.651, F 0.604)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.718] [G acc: 0.625]\n",
      "19006 [D loss: (0.753)(R 0.679, F 0.827)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.774] [G acc: 0.438]\n",
      "19007 [D loss: (0.702)(R 0.709, F 0.695)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.746] [G acc: 0.375]\n",
      "19008 [D loss: (0.678)(R 0.648, F 0.709)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.750] [G acc: 0.375]\n",
      "19009 [D loss: (0.547)(R 0.524, F 0.569)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.857] [G acc: 0.250]\n",
      "19010 [D loss: (0.656)(R 0.699, F 0.612)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.246] [G acc: 0.438]\n",
      "19011 [D loss: (0.727)(R 0.771, F 0.682)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.802] [G acc: 0.312]\n",
      "19012 [D loss: (0.860)(R 1.103, F 0.616)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.820] [G acc: 0.250]\n",
      "19013 [D loss: (0.672)(R 0.637, F 0.707)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.785] [G acc: 0.438]\n",
      "19014 [D loss: (0.810)(R 0.667, F 0.953)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.730] [G acc: 0.625]\n",
      "19015 [D loss: (0.711)(R 0.739, F 0.683)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.773] [G acc: 0.562]\n",
      "19016 [D loss: (0.705)(R 0.688, F 0.723)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.788] [G acc: 0.375]\n",
      "19017 [D loss: (0.735)(R 0.830, F 0.640)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.838] [G acc: 0.250]\n",
      "19018 [D loss: (0.674)(R 0.748, F 0.600)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.883] [G acc: 0.312]\n",
      "19019 [D loss: (0.544)(R 0.687, F 0.401)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.389] [G acc: 0.188]\n",
      "19020 [D loss: (0.534)(R 0.632, F 0.436)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.721] [G acc: 0.125]\n",
      "19021 [D loss: (0.539)(R 0.703, F 0.375)] [D acc: (0.656)(0.562, 0.750)] [G loss: 3.257] [G acc: 0.250]\n",
      "19022 [D loss: (0.533)(R 0.526, F 0.539)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.191] [G acc: 0.125]\n",
      "19023 [D loss: (0.619)(R 0.657, F 0.580)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.892] [G acc: 0.125]\n",
      "19024 [D loss: (0.630)(R 0.667, F 0.592)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.042] [G acc: 0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19025 [D loss: (0.699)(R 0.636, F 0.762)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.849] [G acc: 0.062]\n",
      "19026 [D loss: (0.587)(R 0.587, F 0.587)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.880] [G acc: 0.188]\n",
      "19027 [D loss: (0.645)(R 0.682, F 0.608)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.873] [G acc: 0.250]\n",
      "19028 [D loss: (0.611)(R 0.636, F 0.586)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.890] [G acc: 0.125]\n",
      "19029 [D loss: (0.667)(R 0.680, F 0.654)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.910] [G acc: 0.000]\n",
      "19030 [D loss: (0.558)(R 0.562, F 0.555)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.885] [G acc: 0.312]\n",
      "19031 [D loss: (0.625)(R 0.594, F 0.656)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.753] [G acc: 0.375]\n",
      "19032 [D loss: (0.614)(R 0.621, F 0.608)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.915] [G acc: 0.125]\n",
      "19033 [D loss: (0.717)(R 0.744, F 0.690)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.882] [G acc: 0.188]\n",
      "19034 [D loss: (0.634)(R 0.667, F 0.601)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.879] [G acc: 0.250]\n",
      "19035 [D loss: (0.664)(R 0.740, F 0.589)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.809] [G acc: 0.312]\n",
      "19036 [D loss: (0.911)(R 0.763, F 1.060)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.751] [G acc: 0.312]\n",
      "19037 [D loss: (0.661)(R 0.723, F 0.598)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.825] [G acc: 0.250]\n",
      "19038 [D loss: (0.643)(R 0.708, F 0.578)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.829] [G acc: 0.375]\n",
      "19039 [D loss: (0.664)(R 0.624, F 0.703)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.781] [G acc: 0.438]\n",
      "19040 [D loss: (0.755)(R 0.877, F 0.634)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.790] [G acc: 0.188]\n",
      "19041 [D loss: (0.752)(R 0.845, F 0.658)] [D acc: (0.531)(0.562, 0.500)] [G loss: 1.215] [G acc: 0.312]\n",
      "19042 [D loss: (0.606)(R 0.608, F 0.604)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.851] [G acc: 0.250]\n",
      "19043 [D loss: (0.661)(R 0.651, F 0.671)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.754] [G acc: 0.312]\n",
      "19044 [D loss: (0.631)(R 0.618, F 0.645)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.770] [G acc: 0.375]\n",
      "19045 [D loss: (0.745)(R 0.746, F 0.743)] [D acc: (0.406)(0.500, 0.312)] [G loss: 0.771] [G acc: 0.312]\n",
      "19046 [D loss: (0.710)(R 0.700, F 0.721)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.773] [G acc: 0.188]\n",
      "19047 [D loss: (0.969)(R 0.644, F 1.293)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.547] [G acc: 0.750]\n",
      "19048 [D loss: (0.901)(R 0.626, F 1.175)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.601] [G acc: 0.562]\n",
      "19049 [D loss: (0.988)(R 0.706, F 1.270)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.691] [G acc: 0.625]\n",
      "19050 [D loss: (0.636)(R 0.620, F 0.653)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.935] [G acc: 0.125]\n",
      "19051 [D loss: (0.581)(R 0.566, F 0.597)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.809] [G acc: 0.312]\n",
      "19052 [D loss: (0.790)(R 0.912, F 0.668)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.827] [G acc: 0.250]\n",
      "19053 [D loss: (1.205)(R 0.674, F 1.737)] [D acc: (0.406)(0.562, 0.250)] [G loss: 1.409] [G acc: 0.438]\n",
      "19054 [D loss: (0.459)(R 0.678, F 0.239)] [D acc: (0.812)(0.688, 0.938)] [G loss: 2.318] [G acc: 0.125]\n",
      "19055 [D loss: (0.513)(R 0.637, F 0.389)] [D acc: (0.750)(0.750, 0.750)] [G loss: 3.994] [G acc: 0.375]\n",
      "19056 [D loss: (0.582)(R 0.706, F 0.458)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.358] [G acc: 0.125]\n",
      "19057 [D loss: (0.601)(R 0.639, F 0.563)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.837] [G acc: 0.375]\n",
      "19058 [D loss: (0.698)(R 0.786, F 0.611)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.603] [G acc: 0.125]\n",
      "19059 [D loss: (0.670)(R 0.736, F 0.604)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.987] [G acc: 0.312]\n",
      "19060 [D loss: (0.738)(R 0.764, F 0.712)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.924] [G acc: 0.188]\n",
      "19061 [D loss: (0.672)(R 0.682, F 0.662)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.740] [G acc: 0.562]\n",
      "19062 [D loss: (0.682)(R 0.730, F 0.633)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.753] [G acc: 0.438]\n",
      "19063 [D loss: (0.636)(R 0.603, F 0.669)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.797] [G acc: 0.375]\n",
      "19064 [D loss: (0.666)(R 0.651, F 0.680)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.697] [G acc: 0.438]\n",
      "19065 [D loss: (0.665)(R 0.680, F 0.650)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.763] [G acc: 0.250]\n",
      "19066 [D loss: (0.623)(R 0.645, F 0.601)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.852] [G acc: 0.188]\n",
      "19067 [D loss: (0.636)(R 0.638, F 0.635)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.818] [G acc: 0.188]\n",
      "19068 [D loss: (0.670)(R 0.685, F 0.655)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.802] [G acc: 0.312]\n",
      "19069 [D loss: (0.706)(R 0.745, F 0.667)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.817] [G acc: 0.250]\n",
      "19070 [D loss: (0.737)(R 0.769, F 0.706)] [D acc: (0.656)(0.375, 0.938)] [G loss: 0.821] [G acc: 0.125]\n",
      "19071 [D loss: (0.686)(R 0.684, F 0.689)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.816] [G acc: 0.312]\n",
      "19072 [D loss: (0.725)(R 0.747, F 0.702)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.727] [G acc: 0.500]\n",
      "19073 [D loss: (0.710)(R 0.753, F 0.667)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.782] [G acc: 0.375]\n",
      "19074 [D loss: (0.651)(R 0.629, F 0.672)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.765] [G acc: 0.438]\n",
      "19075 [D loss: (0.671)(R 0.665, F 0.678)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.826] [G acc: 0.250]\n",
      "19076 [D loss: (0.642)(R 0.610, F 0.673)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.775] [G acc: 0.438]\n",
      "19077 [D loss: (0.695)(R 0.806, F 0.583)] [D acc: (0.625)(0.312, 0.938)] [G loss: 0.793] [G acc: 0.250]\n",
      "19078 [D loss: (0.711)(R 0.742, F 0.679)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.792] [G acc: 0.188]\n",
      "19079 [D loss: (0.696)(R 0.734, F 0.658)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.819] [G acc: 0.250]\n",
      "19080 [D loss: (0.627)(R 0.618, F 0.637)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.764] [G acc: 0.312]\n",
      "19081 [D loss: (0.587)(R 0.632, F 0.542)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.837] [G acc: 0.250]\n",
      "19082 [D loss: (0.652)(R 0.664, F 0.639)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.734] [G acc: 0.438]\n",
      "19083 [D loss: (0.671)(R 0.703, F 0.640)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.792] [G acc: 0.250]\n",
      "19084 [D loss: (0.669)(R 0.677, F 0.660)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.796] [G acc: 0.375]\n",
      "19085 [D loss: (0.726)(R 0.749, F 0.703)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.688] [G acc: 0.500]\n",
      "19086 [D loss: (0.632)(R 0.622, F 0.642)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.746] [G acc: 0.438]\n",
      "19087 [D loss: (0.642)(R 0.645, F 0.640)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.682] [G acc: 0.438]\n",
      "19088 [D loss: (0.652)(R 0.586, F 0.718)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.770] [G acc: 0.438]\n",
      "19089 [D loss: (1.131)(R 0.700, F 1.561)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.860] [G acc: 0.250]\n",
      "19090 [D loss: (0.666)(R 0.764, F 0.568)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.911] [G acc: 0.188]\n",
      "19091 [D loss: (0.659)(R 0.695, F 0.622)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.663] [G acc: 0.625]\n",
      "19092 [D loss: (0.761)(R 0.727, F 0.796)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.716] [G acc: 0.562]\n",
      "19093 [D loss: (0.700)(R 0.718, F 0.682)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.813] [G acc: 0.250]\n",
      "19094 [D loss: (0.908)(R 1.099, F 0.716)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.694] [G acc: 0.500]\n",
      "19095 [D loss: (0.702)(R 0.650, F 0.754)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.650] [G acc: 0.625]\n",
      "19096 [D loss: (0.692)(R 0.663, F 0.720)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.639] [G acc: 0.750]\n",
      "19097 [D loss: (0.711)(R 0.643, F 0.779)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.703] [G acc: 0.500]\n",
      "19098 [D loss: (0.637)(R 0.666, F 0.609)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.849] [G acc: 0.125]\n",
      "19099 [D loss: (0.670)(R 0.652, F 0.688)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.681] [G acc: 0.500]\n",
      "19100 [D loss: (0.768)(R 0.741, F 0.795)] [D acc: (0.406)(0.500, 0.312)] [G loss: 0.698] [G acc: 0.438]\n",
      "19101 [D loss: (0.717)(R 0.721, F 0.713)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.694] [G acc: 0.500]\n",
      "19102 [D loss: (0.667)(R 0.625, F 0.708)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.690] [G acc: 0.625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19103 [D loss: (0.803)(R 0.631, F 0.975)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.702] [G acc: 0.688]\n",
      "19104 [D loss: (0.703)(R 0.647, F 0.760)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.737] [G acc: 0.438]\n",
      "19105 [D loss: (0.712)(R 0.695, F 0.729)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.685] [G acc: 0.688]\n",
      "19106 [D loss: (0.758)(R 0.743, F 0.774)] [D acc: (0.375)(0.500, 0.250)] [G loss: 0.699] [G acc: 0.500]\n",
      "19107 [D loss: (0.686)(R 0.634, F 0.738)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.646] [G acc: 0.688]\n",
      "19108 [D loss: (0.705)(R 0.716, F 0.693)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.637] [G acc: 0.625]\n",
      "19109 [D loss: (0.694)(R 0.630, F 0.759)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.587] [G acc: 0.812]\n",
      "19110 [D loss: (0.699)(R 0.642, F 0.756)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.696] [G acc: 0.562]\n",
      "19111 [D loss: (0.731)(R 0.670, F 0.792)] [D acc: (0.375)(0.562, 0.188)] [G loss: 0.676] [G acc: 0.625]\n",
      "19112 [D loss: (0.772)(R 0.831, F 0.713)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.649] [G acc: 0.625]\n",
      "19113 [D loss: (0.593)(R 0.654, F 0.533)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.843] [G acc: 0.375]\n",
      "19114 [D loss: (0.467)(R 0.664, F 0.271)] [D acc: (0.688)(0.562, 0.812)] [G loss: 5.104] [G acc: 0.062]\n",
      "19115 [D loss: (0.582)(R 0.584, F 0.579)] [D acc: (0.594)(0.688, 0.500)] [G loss: 1.837] [G acc: 0.438]\n",
      "19116 [D loss: (0.527)(R 0.585, F 0.469)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.059] [G acc: 0.250]\n",
      "19117 [D loss: (0.680)(R 0.577, F 0.784)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.639] [G acc: 0.812]\n",
      "19118 [D loss: (0.692)(R 0.566, F 0.818)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.663] [G acc: 0.625]\n",
      "19119 [D loss: (0.714)(R 0.684, F 0.744)] [D acc: (0.375)(0.562, 0.188)] [G loss: 0.625] [G acc: 0.750]\n",
      "19120 [D loss: (0.667)(R 0.608, F 0.727)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.653] [G acc: 0.625]\n",
      "19121 [D loss: (0.714)(R 0.624, F 0.804)] [D acc: (0.375)(0.625, 0.125)] [G loss: 0.688] [G acc: 0.500]\n",
      "19122 [D loss: (0.657)(R 0.570, F 0.744)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.694] [G acc: 0.625]\n",
      "19123 [D loss: (0.651)(R 0.558, F 0.744)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.604] [G acc: 0.875]\n",
      "19124 [D loss: (0.651)(R 0.571, F 0.730)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.620] [G acc: 0.750]\n",
      "19125 [D loss: (0.739)(R 0.684, F 0.793)] [D acc: (0.406)(0.688, 0.125)] [G loss: 0.543] [G acc: 0.688]\n",
      "19126 [D loss: (0.827)(R 0.597, F 1.057)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.636] [G acc: 0.750]\n",
      "19127 [D loss: (0.633)(R 0.459, F 0.807)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.548] [G acc: 0.625]\n",
      "19128 [D loss: (0.702)(R 0.549, F 0.856)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.653] [G acc: 0.688]\n",
      "19129 [D loss: (0.847)(R 0.556, F 1.138)] [D acc: (0.469)(0.750, 0.188)] [G loss: 1.830] [G acc: 0.375]\n",
      "19130 [D loss: (0.610)(R 0.620, F 0.600)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.879] [G acc: 0.562]\n",
      "19131 [D loss: (0.627)(R 0.655, F 0.600)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.818] [G acc: 0.375]\n",
      "19132 [D loss: (0.625)(R 0.532, F 0.717)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.702] [G acc: 0.625]\n",
      "19133 [D loss: (0.542)(R 0.415, F 0.668)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.832] [G acc: 0.500]\n",
      "19134 [D loss: (0.654)(R 0.536, F 0.771)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.722] [G acc: 0.562]\n",
      "19135 [D loss: (0.585)(R 0.426, F 0.744)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.669] [G acc: 0.562]\n",
      "19136 [D loss: (0.566)(R 0.502, F 0.630)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.737] [G acc: 0.312]\n",
      "19137 [D loss: (0.594)(R 0.475, F 0.713)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.644] [G acc: 0.562]\n",
      "19138 [D loss: (0.618)(R 0.548, F 0.687)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.808] [G acc: 0.250]\n",
      "19139 [D loss: (0.555)(R 0.456, F 0.655)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.624] [G acc: 0.625]\n",
      "19140 [D loss: (0.551)(R 0.409, F 0.693)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.720] [G acc: 0.438]\n",
      "19141 [D loss: (0.618)(R 0.494, F 0.742)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.730] [G acc: 0.375]\n",
      "19142 [D loss: (0.594)(R 0.461, F 0.728)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.855] [G acc: 0.188]\n",
      "19143 [D loss: (0.650)(R 0.567, F 0.733)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.676] [G acc: 0.500]\n",
      "19144 [D loss: (0.483)(R 0.405, F 0.560)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.844] [G acc: 0.125]\n",
      "19145 [D loss: (0.587)(R 0.468, F 0.707)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.704] [G acc: 0.312]\n",
      "19146 [D loss: (0.610)(R 0.582, F 0.637)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.883] [G acc: 0.312]\n",
      "19147 [D loss: (0.413)(R 0.541, F 0.285)] [D acc: (0.844)(0.750, 0.938)] [G loss: 2.074] [G acc: 0.125]\n",
      "19148 [D loss: (0.504)(R 0.448, F 0.561)] [D acc: (0.719)(0.750, 0.688)] [G loss: 4.157] [G acc: 0.375]\n",
      "19149 [D loss: (0.402)(R 0.442, F 0.361)] [D acc: (0.875)(0.812, 0.938)] [G loss: 4.095] [G acc: 0.188]\n",
      "19150 [D loss: (0.588)(R 0.394, F 0.781)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.577] [G acc: 0.562]\n",
      "19151 [D loss: (0.740)(R 0.539, F 0.940)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.814] [G acc: 0.125]\n",
      "19152 [D loss: (0.627)(R 0.589, F 0.664)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.059] [G acc: 0.062]\n",
      "19153 [D loss: (0.532)(R 0.490, F 0.575)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.838] [G acc: 0.188]\n",
      "19154 [D loss: (0.613)(R 0.569, F 0.657)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.708] [G acc: 0.375]\n",
      "19155 [D loss: (0.698)(R 0.542, F 0.854)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.830] [G acc: 0.125]\n",
      "19156 [D loss: (0.615)(R 0.572, F 0.659)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.800] [G acc: 0.250]\n",
      "19157 [D loss: (0.653)(R 0.606, F 0.700)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.856] [G acc: 0.188]\n",
      "19158 [D loss: (0.590)(R 0.616, F 0.563)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.630] [G acc: 0.562]\n",
      "19159 [D loss: (0.656)(R 0.674, F 0.637)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.922] [G acc: 0.125]\n",
      "19160 [D loss: (0.647)(R 0.599, F 0.694)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.933] [G acc: 0.188]\n",
      "19161 [D loss: (0.660)(R 0.635, F 0.685)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.718] [G acc: 0.438]\n",
      "19162 [D loss: (0.591)(R 0.584, F 0.599)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.843] [G acc: 0.188]\n",
      "19163 [D loss: (0.569)(R 0.474, F 0.665)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.854] [G acc: 0.125]\n",
      "19164 [D loss: (0.538)(R 0.501, F 0.575)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.919] [G acc: 0.125]\n",
      "19165 [D loss: (0.626)(R 0.599, F 0.654)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.816] [G acc: 0.250]\n",
      "19166 [D loss: (0.537)(R 0.464, F 0.610)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.883] [G acc: 0.312]\n",
      "19167 [D loss: (0.452)(R 0.447, F 0.458)] [D acc: (0.844)(0.750, 0.938)] [G loss: 0.927] [G acc: 0.125]\n",
      "19168 [D loss: (0.482)(R 0.447, F 0.518)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.973] [G acc: 0.188]\n",
      "19169 [D loss: (0.547)(R 0.404, F 0.689)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.872] [G acc: 0.062]\n",
      "19170 [D loss: (0.518)(R 0.456, F 0.579)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.797] [G acc: 0.312]\n",
      "19171 [D loss: (0.601)(R 0.576, F 0.626)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.919] [G acc: 0.062]\n",
      "19172 [D loss: (0.582)(R 0.562, F 0.601)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.912] [G acc: 0.188]\n",
      "19173 [D loss: (0.459)(R 0.374, F 0.543)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.751] [G acc: 0.438]\n",
      "19174 [D loss: (0.514)(R 0.355, F 0.673)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.850] [G acc: 0.375]\n",
      "19175 [D loss: (0.599)(R 0.639, F 0.559)] [D acc: (0.656)(0.375, 0.938)] [G loss: 0.606] [G acc: 0.688]\n",
      "19176 [D loss: (0.578)(R 0.451, F 0.705)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.957] [G acc: 0.062]\n",
      "19177 [D loss: (0.543)(R 0.505, F 0.582)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.873] [G acc: 0.188]\n",
      "19178 [D loss: (0.506)(R 0.429, F 0.583)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.872] [G acc: 0.125]\n",
      "19179 [D loss: (0.589)(R 0.668, F 0.510)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.728] [G acc: 0.438]\n",
      "19180 [D loss: (0.548)(R 0.553, F 0.542)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.862] [G acc: 0.250]\n",
      "19181 [D loss: (0.728)(R 0.541, F 0.916)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.885] [G acc: 0.250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19182 [D loss: (0.451)(R 0.424, F 0.477)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.672] [G acc: 0.250]\n",
      "19183 [D loss: (0.464)(R 0.470, F 0.457)] [D acc: (0.656)(0.750, 0.562)] [G loss: 7.477] [G acc: 0.188]\n",
      "19184 [D loss: (0.564)(R 0.548, F 0.579)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.219] [G acc: 0.375]\n",
      "19185 [D loss: (0.640)(R 0.721, F 0.558)] [D acc: (0.562)(0.312, 0.812)] [G loss: 0.975] [G acc: 0.250]\n",
      "19186 [D loss: (0.721)(R 0.835, F 0.608)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.651] [G acc: 0.438]\n",
      "19187 [D loss: (0.578)(R 0.662, F 0.495)] [D acc: (0.750)(0.500, 1.000)] [G loss: 1.008] [G acc: 0.125]\n",
      "19188 [D loss: (0.615)(R 0.653, F 0.578)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.920] [G acc: 0.125]\n",
      "19189 [D loss: (0.610)(R 0.496, F 0.725)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.974] [G acc: 0.125]\n",
      "19190 [D loss: (0.621)(R 0.556, F 0.686)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.930] [G acc: 0.125]\n",
      "19191 [D loss: (0.591)(R 0.595, F 0.588)] [D acc: (0.531)(0.375, 0.688)] [G loss: 1.061] [G acc: 0.188]\n",
      "19192 [D loss: (0.502)(R 0.558, F 0.446)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.377] [G acc: 0.000]\n",
      "19193 [D loss: (0.503)(R 0.488, F 0.518)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.643] [G acc: 0.500]\n",
      "19194 [D loss: (0.614)(R 0.649, F 0.579)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.913] [G acc: 0.375]\n",
      "19195 [D loss: (0.617)(R 0.614, F 0.619)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.785] [G acc: 0.312]\n",
      "19196 [D loss: (0.517)(R 0.632, F 0.401)] [D acc: (0.750)(0.500, 1.000)] [G loss: 0.754] [G acc: 0.375]\n",
      "19197 [D loss: (0.664)(R 0.679, F 0.648)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.726] [G acc: 0.500]\n",
      "19198 [D loss: (0.628)(R 0.563, F 0.694)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.907] [G acc: 0.438]\n",
      "19199 [D loss: (0.399)(R 0.536, F 0.262)] [D acc: (0.781)(0.688, 0.875)] [G loss: 3.710] [G acc: 0.125]\n",
      "19200 [D loss: (0.663)(R 0.531, F 0.796)] [D acc: (0.656)(0.625, 0.688)] [G loss: 5.786] [G acc: 0.000]\n",
      "19201 [D loss: (0.404)(R 0.645, F 0.164)] [D acc: (0.781)(0.562, 1.000)] [G loss: 2.221] [G acc: 0.062]\n",
      "19202 [D loss: (0.540)(R 0.751, F 0.329)] [D acc: (0.625)(0.250, 1.000)] [G loss: 0.974] [G acc: 0.250]\n",
      "19203 [D loss: (0.600)(R 0.686, F 0.514)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.920] [G acc: 0.312]\n",
      "19204 [D loss: (0.496)(R 0.553, F 0.438)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.060] [G acc: 0.188]\n",
      "19205 [D loss: (0.518)(R 0.563, F 0.474)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.090] [G acc: 0.062]\n",
      "19206 [D loss: (0.549)(R 0.498, F 0.600)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.870] [G acc: 0.312]\n",
      "19207 [D loss: (0.654)(R 0.680, F 0.628)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.882] [G acc: 0.188]\n",
      "19208 [D loss: (0.600)(R 0.619, F 0.581)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.904] [G acc: 0.250]\n",
      "19209 [D loss: (0.629)(R 0.667, F 0.590)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.929] [G acc: 0.188]\n",
      "19210 [D loss: (0.505)(R 0.468, F 0.542)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.987] [G acc: 0.062]\n",
      "19211 [D loss: (0.618)(R 0.455, F 0.780)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.819] [G acc: 0.250]\n",
      "19212 [D loss: (0.558)(R 0.505, F 0.611)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.804] [G acc: 0.312]\n",
      "19213 [D loss: (0.819)(R 0.651, F 0.987)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.939] [G acc: 0.125]\n",
      "19214 [D loss: (0.609)(R 0.603, F 0.614)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.953] [G acc: 0.188]\n",
      "19215 [D loss: (0.616)(R 0.568, F 0.664)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.813] [G acc: 0.250]\n",
      "19216 [D loss: (0.944)(R 0.792, F 1.096)] [D acc: (0.438)(0.438, 0.438)] [G loss: 1.102] [G acc: 0.188]\n",
      "19217 [D loss: (0.492)(R 0.613, F 0.372)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.103] [G acc: 0.125]\n",
      "19218 [D loss: (0.632)(R 0.508, F 0.755)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.281] [G acc: 0.125]\n",
      "19219 [D loss: (0.518)(R 0.491, F 0.545)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.835] [G acc: 0.312]\n",
      "19220 [D loss: (0.575)(R 0.548, F 0.601)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.532] [G acc: 0.062]\n",
      "19221 [D loss: (0.484)(R 0.594, F 0.374)] [D acc: (0.688)(0.500, 0.875)] [G loss: 1.152] [G acc: 0.375]\n",
      "19222 [D loss: (0.692)(R 0.895, F 0.488)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.931] [G acc: 0.250]\n",
      "19223 [D loss: (0.611)(R 0.675, F 0.547)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.708] [G acc: 0.312]\n",
      "19224 [D loss: (0.506)(R 0.614, F 0.399)] [D acc: (0.688)(0.625, 0.750)] [G loss: 3.085] [G acc: 0.312]\n",
      "19225 [D loss: (0.490)(R 0.517, F 0.464)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.123] [G acc: 0.125]\n",
      "19226 [D loss: (0.683)(R 0.807, F 0.558)] [D acc: (0.594)(0.375, 0.812)] [G loss: 1.842] [G acc: 0.188]\n",
      "19227 [D loss: (0.662)(R 0.791, F 0.534)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.921] [G acc: 0.125]\n",
      "19228 [D loss: (0.626)(R 0.714, F 0.539)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.907] [G acc: 0.250]\n",
      "19229 [D loss: (0.528)(R 0.502, F 0.555)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.943] [G acc: 0.188]\n",
      "19230 [D loss: (0.581)(R 0.534, F 0.627)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.970] [G acc: 0.125]\n",
      "19231 [D loss: (0.677)(R 0.553, F 0.800)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.596] [G acc: 0.812]\n",
      "19232 [D loss: (0.565)(R 0.530, F 0.601)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.720] [G acc: 0.625]\n",
      "19233 [D loss: (0.605)(R 0.654, F 0.557)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.983] [G acc: 0.062]\n",
      "19234 [D loss: (0.602)(R 0.521, F 0.683)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.884] [G acc: 0.188]\n",
      "19235 [D loss: (0.680)(R 0.701, F 0.659)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.877] [G acc: 0.188]\n",
      "19236 [D loss: (0.716)(R 0.719, F 0.713)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.675] [G acc: 0.562]\n",
      "19237 [D loss: (0.603)(R 0.564, F 0.643)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.963] [G acc: 0.125]\n",
      "19238 [D loss: (0.511)(R 0.492, F 0.531)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.131] [G acc: 0.438]\n",
      "19239 [D loss: (0.595)(R 0.728, F 0.463)] [D acc: (0.719)(0.500, 0.938)] [G loss: 0.758] [G acc: 0.438]\n",
      "19240 [D loss: (0.637)(R 0.631, F 0.642)] [D acc: (0.594)(0.500, 0.688)] [G loss: 1.028] [G acc: 0.188]\n",
      "19241 [D loss: (0.686)(R 0.776, F 0.597)] [D acc: (0.562)(0.438, 0.688)] [G loss: 1.040] [G acc: 0.188]\n",
      "19242 [D loss: (0.529)(R 0.571, F 0.487)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.883] [G acc: 0.438]\n",
      "19243 [D loss: (0.653)(R 0.689, F 0.618)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.791] [G acc: 0.375]\n",
      "19244 [D loss: (0.642)(R 0.654, F 0.631)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.956] [G acc: 0.125]\n",
      "19245 [D loss: (0.688)(R 0.744, F 0.631)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.921] [G acc: 0.062]\n",
      "19246 [D loss: (0.667)(R 0.667, F 0.666)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.745] [G acc: 0.500]\n",
      "19247 [D loss: (0.704)(R 0.724, F 0.684)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.886] [G acc: 0.250]\n",
      "19248 [D loss: (0.528)(R 0.574, F 0.482)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.819] [G acc: 0.438]\n",
      "19249 [D loss: (0.694)(R 0.623, F 0.765)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.832] [G acc: 0.312]\n",
      "19250 [D loss: (0.634)(R 0.683, F 0.585)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.653] [G acc: 0.500]\n",
      "19251 [D loss: (0.578)(R 0.734, F 0.422)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.931] [G acc: 0.250]\n",
      "19252 [D loss: (0.757)(R 0.617, F 0.896)] [D acc: (0.531)(0.688, 0.375)] [G loss: 1.483] [G acc: 0.438]\n",
      "19253 [D loss: (0.480)(R 0.791, F 0.168)] [D acc: (0.656)(0.500, 0.812)] [G loss: 2.519] [G acc: 0.125]\n",
      "19254 [D loss: (0.707)(R 0.761, F 0.653)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.905] [G acc: 0.312]\n",
      "19255 [D loss: (0.652)(R 0.830, F 0.475)] [D acc: (0.531)(0.250, 0.812)] [G loss: 1.166] [G acc: 0.125]\n",
      "19256 [D loss: (0.636)(R 0.671, F 0.602)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.959] [G acc: 0.125]\n",
      "19257 [D loss: (0.661)(R 0.750, F 0.573)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.862] [G acc: 0.125]\n",
      "19258 [D loss: (0.614)(R 0.664, F 0.563)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.760] [G acc: 0.562]\n",
      "19259 [D loss: (0.646)(R 0.787, F 0.504)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.849] [G acc: 0.375]\n",
      "19260 [D loss: (0.600)(R 0.544, F 0.656)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.770] [G acc: 0.250]\n",
      "19261 [D loss: (0.742)(R 0.774, F 0.710)] [D acc: (0.375)(0.312, 0.438)] [G loss: 1.227] [G acc: 0.250]\n",
      "19262 [D loss: (0.460)(R 0.698, F 0.223)] [D acc: (0.719)(0.562, 0.875)] [G loss: 3.692] [G acc: 0.188]\n",
      "19263 [D loss: (0.707)(R 0.688, F 0.726)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.851] [G acc: 0.312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19264 [D loss: (0.650)(R 0.595, F 0.704)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.763] [G acc: 0.438]\n",
      "19265 [D loss: (0.750)(R 0.659, F 0.840)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.656] [G acc: 0.562]\n",
      "19266 [D loss: (0.700)(R 0.555, F 0.844)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.791] [G acc: 0.375]\n",
      "19267 [D loss: (0.599)(R 0.596, F 0.602)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.805] [G acc: 0.375]\n",
      "19268 [D loss: (0.604)(R 0.567, F 0.640)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.812] [G acc: 0.375]\n",
      "19269 [D loss: (0.582)(R 0.442, F 0.721)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.840] [G acc: 0.250]\n",
      "19270 [D loss: (0.651)(R 0.674, F 0.628)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.702] [G acc: 0.500]\n",
      "19271 [D loss: (0.743)(R 0.714, F 0.772)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.695] [G acc: 0.500]\n",
      "19272 [D loss: (0.572)(R 0.622, F 0.523)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.093] [G acc: 0.312]\n",
      "19273 [D loss: (0.642)(R 0.661, F 0.624)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.811] [G acc: 0.312]\n",
      "19274 [D loss: (0.575)(R 0.554, F 0.596)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.759] [G acc: 0.500]\n",
      "19275 [D loss: (0.647)(R 0.685, F 0.609)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.677] [G acc: 0.500]\n",
      "19276 [D loss: (0.681)(R 0.500, F 0.862)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.199] [G acc: 0.125]\n",
      "19277 [D loss: (0.521)(R 0.578, F 0.464)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.355] [G acc: 0.125]\n",
      "19278 [D loss: (0.523)(R 0.532, F 0.515)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.948] [G acc: 0.250]\n",
      "19279 [D loss: (0.535)(R 0.527, F 0.542)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.838] [G acc: 0.438]\n",
      "19280 [D loss: (0.759)(R 0.744, F 0.775)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.875] [G acc: 0.125]\n",
      "19281 [D loss: (0.664)(R 0.670, F 0.658)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.899] [G acc: 0.250]\n",
      "19282 [D loss: (0.720)(R 0.821, F 0.620)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.827] [G acc: 0.312]\n",
      "19283 [D loss: (0.684)(R 0.587, F 0.781)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.791] [G acc: 0.312]\n",
      "19284 [D loss: (0.570)(R 0.614, F 0.526)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.912] [G acc: 0.188]\n",
      "19285 [D loss: (0.523)(R 0.554, F 0.492)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.864] [G acc: 0.250]\n",
      "19286 [D loss: (0.583)(R 0.624, F 0.543)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.883] [G acc: 0.312]\n",
      "19287 [D loss: (0.710)(R 0.657, F 0.763)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.772] [G acc: 0.250]\n",
      "19288 [D loss: (0.853)(R 0.779, F 0.927)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.834] [G acc: 0.375]\n",
      "19289 [D loss: (0.475)(R 0.481, F 0.468)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.983] [G acc: 0.188]\n",
      "19290 [D loss: (0.669)(R 0.674, F 0.664)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.865] [G acc: 0.312]\n",
      "19291 [D loss: (0.685)(R 0.469, F 0.901)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.386] [G acc: 0.312]\n",
      "19292 [D loss: (0.847)(R 0.850, F 0.844)] [D acc: (0.500)(0.250, 0.750)] [G loss: 1.303] [G acc: 0.125]\n",
      "19293 [D loss: (0.526)(R 0.653, F 0.400)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.682] [G acc: 0.188]\n",
      "19294 [D loss: (0.582)(R 0.892, F 0.272)] [D acc: (0.688)(0.375, 1.000)] [G loss: 3.756] [G acc: 0.125]\n",
      "19295 [D loss: (0.523)(R 0.588, F 0.458)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.259] [G acc: 0.375]\n",
      "19296 [D loss: (0.882)(R 0.792, F 0.972)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.847] [G acc: 0.188]\n",
      "19297 [D loss: (0.662)(R 0.766, F 0.558)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.001] [G acc: 0.000]\n",
      "19298 [D loss: (0.507)(R 0.508, F 0.505)] [D acc: (0.844)(0.875, 0.812)] [G loss: 0.835] [G acc: 0.062]\n",
      "19299 [D loss: (0.629)(R 0.630, F 0.628)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.819] [G acc: 0.250]\n",
      "19300 [D loss: (0.637)(R 0.708, F 0.566)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.746] [G acc: 0.375]\n",
      "19301 [D loss: (0.579)(R 0.572, F 0.587)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.882] [G acc: 0.125]\n",
      "19302 [D loss: (0.615)(R 0.601, F 0.628)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.929] [G acc: 0.188]\n",
      "19303 [D loss: (0.684)(R 0.721, F 0.647)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.809] [G acc: 0.375]\n",
      "19304 [D loss: (0.637)(R 0.619, F 0.655)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.877] [G acc: 0.375]\n",
      "19305 [D loss: (0.666)(R 0.599, F 0.733)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.986] [G acc: 0.062]\n",
      "19306 [D loss: (0.669)(R 0.651, F 0.686)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.802] [G acc: 0.188]\n",
      "19307 [D loss: (0.996)(R 0.961, F 1.031)] [D acc: (0.750)(0.938, 0.562)] [G loss: 0.802] [G acc: 0.375]\n",
      "19308 [D loss: (0.622)(R 0.485, F 0.760)] [D acc: (0.750)(0.938, 0.562)] [G loss: 0.812] [G acc: 0.250]\n",
      "19309 [D loss: (0.610)(R 0.598, F 0.623)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.734] [G acc: 0.500]\n",
      "19310 [D loss: (0.590)(R 0.523, F 0.656)] [D acc: (0.750)(0.875, 0.625)] [G loss: 1.116] [G acc: 0.312]\n",
      "19311 [D loss: (0.541)(R 0.649, F 0.432)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.244] [G acc: 0.250]\n",
      "19312 [D loss: (0.570)(R 0.721, F 0.419)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.383] [G acc: 0.562]\n",
      "19313 [D loss: (1.105)(R 1.769, F 0.441)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.867] [G acc: 0.312]\n",
      "19314 [D loss: (0.552)(R 0.611, F 0.493)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.928] [G acc: 0.250]\n",
      "19315 [D loss: (0.598)(R 0.537, F 0.658)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.894] [G acc: 0.312]\n",
      "19316 [D loss: (0.627)(R 0.584, F 0.670)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.933] [G acc: 0.250]\n",
      "19317 [D loss: (0.666)(R 0.639, F 0.694)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.791] [G acc: 0.312]\n",
      "19318 [D loss: (0.692)(R 0.666, F 0.719)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.753] [G acc: 0.438]\n",
      "19319 [D loss: (0.621)(R 0.543, F 0.698)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.806] [G acc: 0.250]\n",
      "19320 [D loss: (0.730)(R 0.762, F 0.697)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.743] [G acc: 0.562]\n",
      "19321 [D loss: (0.683)(R 0.685, F 0.681)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.758] [G acc: 0.312]\n",
      "19322 [D loss: (0.649)(R 0.652, F 0.647)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.788] [G acc: 0.375]\n",
      "19323 [D loss: (0.621)(R 0.595, F 0.647)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.841] [G acc: 0.312]\n",
      "19324 [D loss: (0.546)(R 0.620, F 0.471)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.257] [G acc: 0.188]\n",
      "19325 [D loss: (0.605)(R 0.690, F 0.521)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.703] [G acc: 0.438]\n",
      "19326 [D loss: (0.654)(R 0.572, F 0.735)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.832] [G acc: 0.188]\n",
      "19327 [D loss: (0.618)(R 0.552, F 0.685)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.793] [G acc: 0.562]\n",
      "19328 [D loss: (0.538)(R 0.491, F 0.586)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.904] [G acc: 0.250]\n",
      "19329 [D loss: (0.559)(R 0.518, F 0.601)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.723] [G acc: 0.500]\n",
      "19330 [D loss: (0.669)(R 0.664, F 0.673)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.670] [G acc: 0.500]\n",
      "19331 [D loss: (0.583)(R 0.684, F 0.482)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.758] [G acc: 0.438]\n",
      "19332 [D loss: (0.630)(R 0.498, F 0.762)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.767] [G acc: 0.500]\n",
      "19333 [D loss: (0.534)(R 0.495, F 0.573)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.809] [G acc: 0.312]\n",
      "19334 [D loss: (0.618)(R 0.603, F 0.634)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.987] [G acc: 0.125]\n",
      "19335 [D loss: (0.517)(R 0.598, F 0.435)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.212] [G acc: 0.188]\n",
      "19336 [D loss: (0.469)(R 0.613, F 0.325)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.436] [G acc: 0.312]\n",
      "19337 [D loss: (0.469)(R 0.566, F 0.372)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.732] [G acc: 0.250]\n",
      "19338 [D loss: (0.573)(R 0.611, F 0.536)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.902] [G acc: 0.250]\n",
      "19339 [D loss: (0.586)(R 0.618, F 0.554)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.708] [G acc: 0.500]\n",
      "19340 [D loss: (0.636)(R 0.583, F 0.688)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.801] [G acc: 0.250]\n",
      "19341 [D loss: (0.517)(R 0.413, F 0.621)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.762] [G acc: 0.375]\n",
      "19342 [D loss: (0.517)(R 0.371, F 0.662)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.056] [G acc: 0.125]\n",
      "19343 [D loss: (0.708)(R 0.655, F 0.761)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.891] [G acc: 0.312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19344 [D loss: (0.536)(R 0.647, F 0.425)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.026] [G acc: 0.125]\n",
      "19345 [D loss: (0.483)(R 0.434, F 0.532)] [D acc: (0.781)(0.812, 0.750)] [G loss: 2.145] [G acc: 0.062]\n",
      "19346 [D loss: (0.407)(R 0.608, F 0.207)] [D acc: (0.750)(0.625, 0.875)] [G loss: 3.557] [G acc: 0.188]\n",
      "19347 [D loss: (0.552)(R 0.917, F 0.186)] [D acc: (0.875)(0.750, 1.000)] [G loss: 4.755] [G acc: 0.125]\n",
      "19348 [D loss: (0.556)(R 0.572, F 0.541)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.864] [G acc: 0.312]\n",
      "19349 [D loss: (0.567)(R 0.533, F 0.601)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.023] [G acc: 0.125]\n",
      "19350 [D loss: (0.611)(R 0.549, F 0.674)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.618] [G acc: 0.688]\n",
      "19351 [D loss: (0.619)(R 0.564, F 0.675)] [D acc: (0.594)(0.750, 0.438)] [G loss: 1.062] [G acc: 0.188]\n",
      "19352 [D loss: (0.501)(R 0.524, F 0.478)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.541] [G acc: 0.688]\n",
      "19353 [D loss: (0.514)(R 0.486, F 0.542)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.912] [G acc: 0.188]\n",
      "19354 [D loss: (0.573)(R 0.682, F 0.463)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.093] [G acc: 0.125]\n",
      "19355 [D loss: (0.665)(R 0.713, F 0.617)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.015] [G acc: 0.375]\n",
      "19356 [D loss: (0.680)(R 0.535, F 0.825)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.902] [G acc: 0.250]\n",
      "19357 [D loss: (0.616)(R 0.571, F 0.661)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.929] [G acc: 0.250]\n",
      "19358 [D loss: (0.646)(R 0.656, F 0.636)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.974] [G acc: 0.250]\n",
      "19359 [D loss: (0.607)(R 0.601, F 0.614)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.912] [G acc: 0.188]\n",
      "19360 [D loss: (0.600)(R 0.620, F 0.580)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.876] [G acc: 0.312]\n",
      "19361 [D loss: (0.579)(R 0.522, F 0.637)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.018] [G acc: 0.562]\n",
      "19362 [D loss: (0.463)(R 0.519, F 0.408)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.191] [G acc: 0.188]\n",
      "19363 [D loss: (0.456)(R 0.387, F 0.525)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.101] [G acc: 0.062]\n",
      "19364 [D loss: (0.564)(R 0.530, F 0.599)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.808] [G acc: 0.438]\n",
      "19365 [D loss: (0.517)(R 0.548, F 0.485)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.058] [G acc: 0.250]\n",
      "19366 [D loss: (0.718)(R 0.996, F 0.440)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.094] [G acc: 0.188]\n",
      "19367 [D loss: (0.620)(R 0.771, F 0.470)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.125] [G acc: 0.375]\n",
      "19368 [D loss: (0.418)(R 0.420, F 0.415)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.368] [G acc: 0.125]\n",
      "19369 [D loss: (0.333)(R 0.435, F 0.231)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.694] [G acc: 0.188]\n",
      "19370 [D loss: (0.555)(R 0.547, F 0.563)] [D acc: (0.719)(0.625, 0.812)] [G loss: 2.081] [G acc: 0.250]\n",
      "19371 [D loss: (0.730)(R 1.051, F 0.410)] [D acc: (0.688)(0.562, 0.812)] [G loss: 2.147] [G acc: 0.062]\n",
      "19372 [D loss: (0.503)(R 0.512, F 0.494)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.123] [G acc: 0.188]\n",
      "19373 [D loss: (0.470)(R 0.465, F 0.475)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.764] [G acc: 0.375]\n",
      "19374 [D loss: (0.589)(R 0.520, F 0.658)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.703] [G acc: 0.500]\n",
      "19375 [D loss: (0.781)(R 0.657, F 0.904)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.946] [G acc: 0.312]\n",
      "19376 [D loss: (0.628)(R 0.622, F 0.634)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.061] [G acc: 0.125]\n",
      "19377 [D loss: (0.530)(R 0.555, F 0.506)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.048] [G acc: 0.438]\n",
      "19378 [D loss: (0.526)(R 0.417, F 0.635)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.038] [G acc: 0.000]\n",
      "19379 [D loss: (0.589)(R 0.542, F 0.635)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.916] [G acc: 0.125]\n",
      "19380 [D loss: (0.354)(R 0.221, F 0.487)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.690] [G acc: 0.125]\n",
      "19381 [D loss: (0.249)(R 0.377, F 0.122)] [D acc: (0.875)(0.812, 0.938)] [G loss: 3.470] [G acc: 0.062]\n",
      "19382 [D loss: (0.496)(R 0.467, F 0.525)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.059] [G acc: 0.062]\n",
      "19383 [D loss: (0.416)(R 0.338, F 0.494)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.168] [G acc: 0.188]\n",
      "19384 [D loss: (0.494)(R 0.339, F 0.650)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.673] [G acc: 0.500]\n",
      "19385 [D loss: (0.696)(R 0.703, F 0.689)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.797] [G acc: 0.500]\n",
      "19386 [D loss: (0.583)(R 0.433, F 0.734)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.775] [G acc: 0.438]\n",
      "19387 [D loss: (0.606)(R 0.587, F 0.625)] [D acc: (0.562)(0.438, 0.688)] [G loss: 1.483] [G acc: 0.062]\n",
      "19388 [D loss: (0.812)(R 0.666, F 0.958)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.914] [G acc: 0.500]\n",
      "19389 [D loss: (0.543)(R 0.597, F 0.489)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.390] [G acc: 0.125]\n",
      "19390 [D loss: (0.604)(R 0.566, F 0.642)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.297] [G acc: 0.375]\n",
      "19391 [D loss: (0.604)(R 0.500, F 0.707)] [D acc: (0.562)(0.625, 0.500)] [G loss: 3.346] [G acc: 0.438]\n",
      "19392 [D loss: (0.402)(R 0.580, F 0.225)] [D acc: (0.781)(0.625, 0.938)] [G loss: 4.121] [G acc: 0.000]\n",
      "19393 [D loss: (0.642)(R 0.591, F 0.693)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.198] [G acc: 0.125]\n",
      "19394 [D loss: (0.532)(R 0.431, F 0.634)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.862] [G acc: 0.375]\n",
      "19395 [D loss: (0.679)(R 0.413, F 0.945)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.666] [G acc: 0.625]\n",
      "19396 [D loss: (0.758)(R 0.914, F 0.602)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.776] [G acc: 0.375]\n",
      "19397 [D loss: (0.837)(R 0.885, F 0.789)] [D acc: (0.656)(0.812, 0.500)] [G loss: 1.772] [G acc: 0.125]\n",
      "19398 [D loss: (0.515)(R 0.488, F 0.542)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.068] [G acc: 0.375]\n",
      "19399 [D loss: (0.541)(R 0.572, F 0.509)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.167] [G acc: 0.062]\n",
      "19400 [D loss: (0.653)(R 0.598, F 0.709)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.004] [G acc: 0.312]\n",
      "19401 [D loss: (0.637)(R 0.642, F 0.633)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.311] [G acc: 0.438]\n",
      "19402 [D loss: (0.653)(R 0.502, F 0.804)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.346] [G acc: 0.375]\n",
      "19403 [D loss: (0.582)(R 0.633, F 0.531)] [D acc: (0.562)(0.438, 0.688)] [G loss: 1.141] [G acc: 0.250]\n",
      "19404 [D loss: (0.563)(R 0.576, F 0.550)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.179] [G acc: 0.438]\n",
      "19405 [D loss: (0.289)(R 0.375, F 0.203)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.495] [G acc: 0.312]\n",
      "19406 [D loss: (0.541)(R 0.345, F 0.736)] [D acc: (0.688)(0.812, 0.562)] [G loss: 1.438] [G acc: 0.188]\n",
      "19407 [D loss: (0.594)(R 0.660, F 0.529)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.192] [G acc: 0.125]\n",
      "19408 [D loss: (1.064)(R 0.527, F 1.601)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.127] [G acc: 0.000]\n",
      "19409 [D loss: (0.662)(R 0.755, F 0.569)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.875] [G acc: 0.438]\n",
      "19410 [D loss: (0.431)(R 0.517, F 0.345)] [D acc: (0.812)(0.688, 0.938)] [G loss: 2.263] [G acc: 0.188]\n",
      "19411 [D loss: (0.500)(R 0.403, F 0.597)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.866] [G acc: 0.500]\n",
      "19412 [D loss: (0.493)(R 0.565, F 0.421)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.070] [G acc: 0.062]\n",
      "19413 [D loss: (0.501)(R 0.596, F 0.405)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.207] [G acc: 0.062]\n",
      "19414 [D loss: (0.619)(R 0.677, F 0.561)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.244] [G acc: 0.062]\n",
      "19415 [D loss: (0.666)(R 0.746, F 0.587)] [D acc: (0.562)(0.438, 0.688)] [G loss: 1.122] [G acc: 0.125]\n",
      "19416 [D loss: (0.606)(R 0.879, F 0.333)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.341] [G acc: 0.188]\n",
      "19417 [D loss: (0.623)(R 0.735, F 0.511)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.955] [G acc: 0.312]\n",
      "19418 [D loss: (0.446)(R 0.500, F 0.392)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.978] [G acc: 0.375]\n",
      "19419 [D loss: (0.594)(R 0.641, F 0.546)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.826] [G acc: 0.500]\n",
      "19420 [D loss: (0.715)(R 0.398, F 1.033)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.942] [G acc: 0.125]\n",
      "19421 [D loss: (0.655)(R 0.678, F 0.632)] [D acc: (0.688)(0.500, 0.875)] [G loss: 1.193] [G acc: 0.250]\n",
      "19422 [D loss: (0.575)(R 0.605, F 0.546)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.191] [G acc: 0.125]\n",
      "19423 [D loss: (0.566)(R 0.619, F 0.514)] [D acc: (0.688)(0.625, 0.750)] [G loss: 2.331] [G acc: 0.188]\n",
      "19424 [D loss: (0.299)(R 0.550, F 0.048)] [D acc: (0.781)(0.562, 1.000)] [G loss: 3.576] [G acc: 0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19425 [D loss: (0.474)(R 0.543, F 0.405)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.360] [G acc: 0.125]\n",
      "19426 [D loss: (0.734)(R 0.919, F 0.549)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.170] [G acc: 0.125]\n",
      "19427 [D loss: (0.681)(R 0.470, F 0.893)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.919] [G acc: 0.312]\n",
      "19428 [D loss: (0.597)(R 0.415, F 0.779)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.819] [G acc: 0.250]\n",
      "19429 [D loss: (0.637)(R 0.619, F 0.655)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.798] [G acc: 0.438]\n",
      "19430 [D loss: (0.534)(R 0.404, F 0.665)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.836] [G acc: 0.438]\n",
      "19431 [D loss: (0.666)(R 0.937, F 0.396)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.784] [G acc: 0.375]\n",
      "19432 [D loss: (0.759)(R 0.921, F 0.597)] [D acc: (0.594)(0.500, 0.688)] [G loss: 1.157] [G acc: 0.312]\n",
      "19433 [D loss: (0.619)(R 0.649, F 0.589)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.853] [G acc: 0.188]\n",
      "19434 [D loss: (0.683)(R 0.764, F 0.602)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.789] [G acc: 0.438]\n",
      "19435 [D loss: (0.520)(R 0.472, F 0.568)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.932] [G acc: 0.188]\n",
      "19436 [D loss: (0.754)(R 0.589, F 0.918)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.503] [G acc: 0.250]\n",
      "19437 [D loss: (0.457)(R 0.763, F 0.152)] [D acc: (0.750)(0.625, 0.875)] [G loss: 2.121] [G acc: 0.125]\n",
      "19438 [D loss: (0.527)(R 0.559, F 0.495)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.933] [G acc: 0.312]\n",
      "19439 [D loss: (0.630)(R 0.722, F 0.539)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.682] [G acc: 0.500]\n",
      "19440 [D loss: (0.584)(R 0.627, F 0.540)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.984] [G acc: 0.375]\n",
      "19441 [D loss: (0.676)(R 0.646, F 0.706)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.819] [G acc: 0.438]\n",
      "19442 [D loss: (0.524)(R 0.575, F 0.473)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.932] [G acc: 0.250]\n",
      "19443 [D loss: (0.600)(R 0.536, F 0.664)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.870] [G acc: 0.375]\n",
      "19444 [D loss: (0.632)(R 0.490, F 0.775)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.969] [G acc: 0.188]\n",
      "19445 [D loss: (0.762)(R 0.869, F 0.655)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.964] [G acc: 0.250]\n",
      "19446 [D loss: (0.570)(R 0.405, F 0.735)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.267] [G acc: 0.188]\n",
      "19447 [D loss: (0.574)(R 0.774, F 0.375)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.930] [G acc: 0.188]\n",
      "19448 [D loss: (0.359)(R 0.495, F 0.223)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.885] [G acc: 0.250]\n",
      "19449 [D loss: (0.467)(R 0.583, F 0.352)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.241] [G acc: 0.188]\n",
      "19450 [D loss: (0.471)(R 0.493, F 0.449)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.247] [G acc: 0.125]\n",
      "19451 [D loss: (0.583)(R 0.665, F 0.502)] [D acc: (0.719)(0.625, 0.812)] [G loss: 2.183] [G acc: 0.438]\n",
      "19452 [D loss: (0.748)(R 0.700, F 0.795)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.434] [G acc: 0.812]\n",
      "19453 [D loss: (0.853)(R 0.861, F 0.846)] [D acc: (0.594)(0.500, 0.688)] [G loss: 1.052] [G acc: 0.250]\n",
      "19454 [D loss: (0.684)(R 0.701, F 0.667)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.936] [G acc: 0.188]\n",
      "19455 [D loss: (0.509)(R 0.519, F 0.500)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.041] [G acc: 0.312]\n",
      "19456 [D loss: (0.528)(R 0.566, F 0.491)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.709] [G acc: 0.688]\n",
      "19457 [D loss: (0.583)(R 0.629, F 0.536)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.896] [G acc: 0.500]\n",
      "19458 [D loss: (0.827)(R 0.537, F 1.116)] [D acc: (0.531)(0.625, 0.438)] [G loss: 1.163] [G acc: 0.438]\n",
      "19459 [D loss: (0.700)(R 0.652, F 0.747)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.747] [G acc: 0.625]\n",
      "19460 [D loss: (1.370)(R 0.897, F 1.844)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.585] [G acc: 0.688]\n",
      "19461 [D loss: (1.064)(R 0.619, F 1.508)] [D acc: (0.312)(0.375, 0.250)] [G loss: 0.840] [G acc: 0.438]\n",
      "19462 [D loss: (1.081)(R 0.641, F 1.521)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.844] [G acc: 0.375]\n",
      "19463 [D loss: (1.015)(R 0.899, F 1.131)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.749] [G acc: 0.562]\n",
      "19464 [D loss: (1.072)(R 0.771, F 1.372)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.749] [G acc: 0.562]\n",
      "19465 [D loss: (0.752)(R 0.696, F 0.809)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.789] [G acc: 0.438]\n",
      "19466 [D loss: (1.118)(R 0.592, F 1.643)] [D acc: (0.438)(0.750, 0.125)] [G loss: 1.154] [G acc: 0.500]\n",
      "19467 [D loss: (0.524)(R 0.603, F 0.445)] [D acc: (0.656)(0.750, 0.562)] [G loss: 3.832] [G acc: 0.188]\n",
      "19468 [D loss: (1.292)(R 0.796, F 1.788)] [D acc: (0.406)(0.438, 0.375)] [G loss: 2.860] [G acc: 0.438]\n",
      "19469 [D loss: (0.650)(R 0.651, F 0.649)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.170] [G acc: 0.375]\n",
      "19470 [D loss: (0.802)(R 0.825, F 0.778)] [D acc: (0.344)(0.312, 0.375)] [G loss: 0.926] [G acc: 0.438]\n",
      "19471 [D loss: (1.145)(R 0.843, F 1.448)] [D acc: (0.375)(0.500, 0.250)] [G loss: 0.686] [G acc: 0.688]\n",
      "19472 [D loss: (1.097)(R 0.656, F 1.539)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.752] [G acc: 0.562]\n",
      "19473 [D loss: (0.642)(R 0.635, F 0.648)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.802] [G acc: 0.375]\n",
      "19474 [D loss: (0.552)(R 0.606, F 0.499)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.695] [G acc: 0.500]\n",
      "19475 [D loss: (0.697)(R 0.722, F 0.672)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.663] [G acc: 0.562]\n",
      "19476 [D loss: (0.874)(R 0.831, F 0.917)] [D acc: (0.406)(0.500, 0.312)] [G loss: 0.463] [G acc: 0.812]\n",
      "19477 [D loss: (1.165)(R 0.856, F 1.475)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.709] [G acc: 0.688]\n",
      "19478 [D loss: (0.806)(R 0.660, F 0.952)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.580] [G acc: 0.688]\n",
      "19479 [D loss: (0.933)(R 0.799, F 1.067)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.569] [G acc: 0.750]\n",
      "19480 [D loss: (1.144)(R 0.766, F 1.521)] [D acc: (0.438)(0.500, 0.375)] [G loss: 1.227] [G acc: 0.625]\n",
      "19481 [D loss: (0.795)(R 0.627, F 0.964)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.921] [G acc: 0.500]\n",
      "19482 [D loss: (0.871)(R 0.652, F 1.091)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.619] [G acc: 0.625]\n",
      "19483 [D loss: (0.571)(R 0.626, F 0.516)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.873] [G acc: 0.375]\n",
      "19484 [D loss: (0.756)(R 0.698, F 0.814)] [D acc: (0.344)(0.562, 0.125)] [G loss: 0.834] [G acc: 0.625]\n",
      "19485 [D loss: (0.721)(R 0.588, F 0.853)] [D acc: (0.531)(0.938, 0.125)] [G loss: 0.760] [G acc: 0.500]\n",
      "19486 [D loss: (0.711)(R 0.629, F 0.792)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.671] [G acc: 0.625]\n",
      "19487 [D loss: (0.779)(R 0.691, F 0.868)] [D acc: (0.406)(0.625, 0.188)] [G loss: 0.779] [G acc: 0.438]\n",
      "19488 [D loss: (0.662)(R 0.661, F 0.663)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.758] [G acc: 0.438]\n",
      "19489 [D loss: (0.743)(R 0.688, F 0.799)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.784] [G acc: 0.438]\n",
      "19490 [D loss: (0.670)(R 0.557, F 0.783)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.668] [G acc: 0.500]\n",
      "19491 [D loss: (0.655)(R 0.589, F 0.720)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.743] [G acc: 0.438]\n",
      "19492 [D loss: (0.762)(R 0.718, F 0.805)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.605] [G acc: 0.688]\n",
      "19493 [D loss: (0.652)(R 0.581, F 0.724)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.610] [G acc: 0.875]\n",
      "19494 [D loss: (0.670)(R 0.628, F 0.713)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.762] [G acc: 0.625]\n",
      "19495 [D loss: (0.521)(R 0.642, F 0.400)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.975] [G acc: 0.188]\n",
      "19496 [D loss: (0.434)(R 0.521, F 0.347)] [D acc: (0.875)(0.938, 0.812)] [G loss: 2.462] [G acc: 0.562]\n",
      "19497 [D loss: (0.575)(R 0.637, F 0.514)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.831] [G acc: 0.438]\n",
      "19498 [D loss: (0.706)(R 0.686, F 0.725)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.681] [G acc: 0.688]\n",
      "19499 [D loss: (0.661)(R 0.627, F 0.695)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.743] [G acc: 0.312]\n",
      "19500 [D loss: (0.662)(R 0.586, F 0.738)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.838] [G acc: 0.188]\n",
      "19501 [D loss: (0.720)(R 0.678, F 0.762)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.613] [G acc: 0.875]\n",
      "19502 [D loss: (0.695)(R 0.645, F 0.745)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.613] [G acc: 0.688]\n",
      "19503 [D loss: (0.878)(R 0.916, F 0.840)] [D acc: (0.406)(0.688, 0.125)] [G loss: 0.699] [G acc: 0.812]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19504 [D loss: (0.718)(R 0.564, F 0.872)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.714] [G acc: 0.562]\n",
      "19505 [D loss: (0.670)(R 0.559, F 0.781)] [D acc: (0.625)(1.000, 0.250)] [G loss: 0.662] [G acc: 0.688]\n",
      "19506 [D loss: (0.742)(R 0.629, F 0.855)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.673] [G acc: 0.688]\n",
      "19507 [D loss: (0.679)(R 0.609, F 0.749)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.650] [G acc: 0.625]\n",
      "19508 [D loss: (0.688)(R 0.588, F 0.788)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.647] [G acc: 0.812]\n",
      "19509 [D loss: (0.706)(R 0.651, F 0.760)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.696] [G acc: 0.438]\n",
      "19510 [D loss: (0.686)(R 0.610, F 0.762)] [D acc: (0.625)(1.000, 0.250)] [G loss: 0.663] [G acc: 0.562]\n",
      "19511 [D loss: (0.717)(R 0.668, F 0.766)] [D acc: (0.406)(0.688, 0.125)] [G loss: 0.704] [G acc: 0.312]\n",
      "19512 [D loss: (0.631)(R 0.633, F 0.630)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.641] [G acc: 0.625]\n",
      "19513 [D loss: (0.676)(R 0.625, F 0.727)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.687] [G acc: 0.625]\n",
      "19514 [D loss: (0.936)(R 0.654, F 1.218)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.854] [G acc: 0.312]\n",
      "19515 [D loss: (0.637)(R 0.590, F 0.685)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.764] [G acc: 0.375]\n",
      "19516 [D loss: (0.710)(R 0.633, F 0.786)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.730] [G acc: 0.312]\n",
      "19517 [D loss: (0.678)(R 0.609, F 0.747)] [D acc: (0.656)(0.938, 0.375)] [G loss: 0.679] [G acc: 0.625]\n",
      "19518 [D loss: (0.664)(R 0.613, F 0.714)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.757] [G acc: 0.375]\n",
      "19519 [D loss: (0.649)(R 0.611, F 0.688)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.708] [G acc: 0.562]\n",
      "19520 [D loss: (0.663)(R 0.604, F 0.722)] [D acc: (0.656)(0.938, 0.375)] [G loss: 0.664] [G acc: 0.688]\n",
      "19521 [D loss: (0.649)(R 0.629, F 0.669)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.706] [G acc: 0.500]\n",
      "19522 [D loss: (0.703)(R 0.624, F 0.782)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.761] [G acc: 0.438]\n",
      "19523 [D loss: (0.570)(R 0.681, F 0.458)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.014] [G acc: 0.250]\n",
      "19524 [D loss: (0.660)(R 0.612, F 0.709)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.858] [G acc: 0.312]\n",
      "19525 [D loss: (0.720)(R 0.673, F 0.768)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.899] [G acc: 0.188]\n",
      "19526 [D loss: (0.664)(R 0.625, F 0.704)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.744] [G acc: 0.500]\n",
      "19527 [D loss: (0.648)(R 0.644, F 0.651)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.773] [G acc: 0.375]\n",
      "19528 [D loss: (0.691)(R 0.701, F 0.680)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.746] [G acc: 0.375]\n",
      "19529 [D loss: (0.633)(R 0.585, F 0.681)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.763] [G acc: 0.312]\n",
      "19530 [D loss: (0.680)(R 0.647, F 0.713)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.788] [G acc: 0.125]\n",
      "19531 [D loss: (0.677)(R 0.642, F 0.712)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.739] [G acc: 0.375]\n",
      "19532 [D loss: (0.668)(R 0.633, F 0.703)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.722] [G acc: 0.438]\n",
      "19533 [D loss: (0.622)(R 0.616, F 0.628)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.790] [G acc: 0.250]\n",
      "19534 [D loss: (0.680)(R 0.657, F 0.702)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.866] [G acc: 0.188]\n",
      "19535 [D loss: (0.658)(R 0.675, F 0.641)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.764] [G acc: 0.312]\n",
      "19536 [D loss: (0.650)(R 0.702, F 0.599)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.961] [G acc: 0.250]\n",
      "19537 [D loss: (0.458)(R 0.608, F 0.307)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.447] [G acc: 0.312]\n",
      "19538 [D loss: (0.393)(R 0.600, F 0.186)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.374] [G acc: 0.188]\n",
      "19539 [D loss: (0.713)(R 0.702, F 0.725)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.720] [G acc: 0.562]\n",
      "19540 [D loss: (0.600)(R 0.650, F 0.549)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.893] [G acc: 0.250]\n",
      "19541 [D loss: (0.625)(R 0.574, F 0.677)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.722] [G acc: 0.562]\n",
      "19542 [D loss: (0.658)(R 0.645, F 0.672)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.795] [G acc: 0.250]\n",
      "19543 [D loss: (0.685)(R 0.672, F 0.698)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.792] [G acc: 0.250]\n",
      "19544 [D loss: (0.606)(R 0.594, F 0.617)] [D acc: (0.875)(1.000, 0.750)] [G loss: 0.770] [G acc: 0.375]\n",
      "19545 [D loss: (0.648)(R 0.642, F 0.653)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.781] [G acc: 0.312]\n",
      "19546 [D loss: (0.706)(R 0.688, F 0.724)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.756] [G acc: 0.375]\n",
      "19547 [D loss: (0.636)(R 0.606, F 0.666)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.746] [G acc: 0.375]\n",
      "19548 [D loss: (0.642)(R 0.657, F 0.627)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.802] [G acc: 0.188]\n",
      "19549 [D loss: (0.628)(R 0.575, F 0.680)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.849] [G acc: 0.062]\n",
      "19550 [D loss: (0.632)(R 0.615, F 0.648)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.781] [G acc: 0.250]\n",
      "19551 [D loss: (0.607)(R 0.551, F 0.662)] [D acc: (0.656)(0.812, 0.500)] [G loss: 1.126] [G acc: 0.125]\n",
      "19552 [D loss: (0.650)(R 0.710, F 0.591)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.882] [G acc: 0.250]\n",
      "19553 [D loss: (0.665)(R 0.686, F 0.644)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.723] [G acc: 0.375]\n",
      "19554 [D loss: (0.584)(R 0.616, F 0.552)] [D acc: (0.875)(0.875, 0.875)] [G loss: 0.835] [G acc: 0.188]\n",
      "19555 [D loss: (0.616)(R 0.618, F 0.615)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.819] [G acc: 0.375]\n",
      "19556 [D loss: (0.615)(R 0.645, F 0.585)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.927] [G acc: 0.312]\n",
      "19557 [D loss: (0.666)(R 0.684, F 0.648)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.731] [G acc: 0.375]\n",
      "19558 [D loss: (0.555)(R 0.563, F 0.546)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.947] [G acc: 0.188]\n",
      "19559 [D loss: (0.628)(R 0.673, F 0.583)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.817] [G acc: 0.312]\n",
      "19560 [D loss: (0.571)(R 0.632, F 0.510)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.869] [G acc: 0.500]\n",
      "19561 [D loss: (0.583)(R 0.599, F 0.567)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.032] [G acc: 0.188]\n",
      "19562 [D loss: (0.563)(R 0.537, F 0.590)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.918] [G acc: 0.312]\n",
      "19563 [D loss: (0.603)(R 0.611, F 0.595)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.270] [G acc: 0.250]\n",
      "19564 [D loss: (0.625)(R 0.684, F 0.566)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.518] [G acc: 0.688]\n",
      "19565 [D loss: (0.702)(R 0.660, F 0.744)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.949] [G acc: 0.250]\n",
      "19566 [D loss: (0.837)(R 0.743, F 0.930)] [D acc: (0.531)(0.500, 0.562)] [G loss: 1.304] [G acc: 0.250]\n",
      "19567 [D loss: (0.528)(R 0.623, F 0.434)] [D acc: (0.688)(0.750, 0.625)] [G loss: 3.954] [G acc: 0.125]\n",
      "19568 [D loss: (0.673)(R 0.648, F 0.697)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.195] [G acc: 0.375]\n",
      "19569 [D loss: (0.568)(R 0.613, F 0.522)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.176] [G acc: 0.125]\n",
      "19570 [D loss: (0.559)(R 0.628, F 0.490)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.106] [G acc: 0.188]\n",
      "19571 [D loss: (0.577)(R 0.587, F 0.568)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.868] [G acc: 0.312]\n",
      "19572 [D loss: (0.637)(R 0.698, F 0.576)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.882] [G acc: 0.188]\n",
      "19573 [D loss: (0.631)(R 0.655, F 0.608)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.749] [G acc: 0.500]\n",
      "19574 [D loss: (0.968)(R 0.707, F 1.229)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.875] [G acc: 0.250]\n",
      "19575 [D loss: (0.666)(R 0.705, F 0.627)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.894] [G acc: 0.312]\n",
      "19576 [D loss: (0.586)(R 0.587, F 0.585)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.567] [G acc: 0.750]\n",
      "19577 [D loss: (0.677)(R 0.796, F 0.557)] [D acc: (0.500)(0.312, 0.688)] [G loss: 0.949] [G acc: 0.125]\n",
      "19578 [D loss: (0.711)(R 0.748, F 0.674)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.868] [G acc: 0.312]\n",
      "19579 [D loss: (0.729)(R 0.725, F 0.734)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.790] [G acc: 0.375]\n",
      "19580 [D loss: (0.574)(R 0.655, F 0.492)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.862] [G acc: 0.188]\n",
      "19581 [D loss: (0.648)(R 0.684, F 0.612)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.748] [G acc: 0.375]\n",
      "19582 [D loss: (0.535)(R 0.485, F 0.586)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.719] [G acc: 0.688]\n",
      "19583 [D loss: (0.504)(R 0.474, F 0.534)] [D acc: (0.750)(0.875, 0.625)] [G loss: 1.211] [G acc: 0.062]\n",
      "19584 [D loss: (0.667)(R 0.659, F 0.676)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.817] [G acc: 0.375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19585 [D loss: (0.612)(R 0.658, F 0.565)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.954] [G acc: 0.188]\n",
      "19586 [D loss: (0.755)(R 0.888, F 0.622)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.752] [G acc: 0.562]\n",
      "19587 [D loss: (0.694)(R 0.741, F 0.647)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.837] [G acc: 0.375]\n",
      "19588 [D loss: (0.688)(R 0.637, F 0.739)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.758] [G acc: 0.625]\n",
      "19589 [D loss: (0.747)(R 0.757, F 0.737)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.724] [G acc: 0.500]\n",
      "19590 [D loss: (0.674)(R 0.692, F 0.655)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.902] [G acc: 0.188]\n",
      "19591 [D loss: (0.631)(R 0.532, F 0.730)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.809] [G acc: 0.312]\n",
      "19592 [D loss: (0.731)(R 0.685, F 0.777)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.887] [G acc: 0.375]\n",
      "19593 [D loss: (0.571)(R 0.622, F 0.520)] [D acc: (0.594)(0.438, 0.750)] [G loss: 1.421] [G acc: 0.250]\n",
      "19594 [D loss: (1.096)(R 0.674, F 1.519)] [D acc: (0.562)(0.562, 0.562)] [G loss: 4.681] [G acc: 0.250]\n",
      "19595 [D loss: (0.456)(R 0.780, F 0.131)] [D acc: (0.688)(0.500, 0.875)] [G loss: 3.090] [G acc: 0.062]\n",
      "19596 [D loss: (0.644)(R 0.660, F 0.628)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.756] [G acc: 0.250]\n",
      "19597 [D loss: (0.655)(R 0.667, F 0.643)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.790] [G acc: 0.312]\n",
      "19598 [D loss: (0.698)(R 0.748, F 0.647)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.744] [G acc: 0.625]\n",
      "19599 [D loss: (0.644)(R 0.654, F 0.634)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.823] [G acc: 0.188]\n",
      "19600 [D loss: (0.644)(R 0.560, F 0.727)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.738] [G acc: 0.562]\n",
      "19601 [D loss: (0.653)(R 0.615, F 0.691)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.780] [G acc: 0.500]\n",
      "19602 [D loss: (0.657)(R 0.661, F 0.652)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.770] [G acc: 0.375]\n",
      "19603 [D loss: (0.642)(R 0.609, F 0.676)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.658] [G acc: 0.625]\n",
      "19604 [D loss: (0.626)(R 0.610, F 0.643)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.749] [G acc: 0.312]\n",
      "19605 [D loss: (0.727)(R 0.713, F 0.741)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.802] [G acc: 0.312]\n",
      "19606 [D loss: (0.594)(R 0.490, F 0.697)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.796] [G acc: 0.312]\n",
      "19607 [D loss: (0.648)(R 0.537, F 0.760)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.779] [G acc: 0.375]\n",
      "19608 [D loss: (0.611)(R 0.552, F 0.670)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.831] [G acc: 0.250]\n",
      "19609 [D loss: (0.620)(R 0.634, F 0.606)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.863] [G acc: 0.375]\n",
      "19610 [D loss: (0.647)(R 0.620, F 0.674)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.994] [G acc: 0.188]\n",
      "19611 [D loss: (0.587)(R 0.611, F 0.564)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.542] [G acc: 0.750]\n",
      "19612 [D loss: (1.042)(R 0.608, F 1.476)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.932] [G acc: 0.125]\n",
      "19613 [D loss: (0.589)(R 0.554, F 0.623)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.717] [G acc: 0.438]\n",
      "19614 [D loss: (0.971)(R 0.749, F 1.194)] [D acc: (0.406)(0.500, 0.312)] [G loss: 0.861] [G acc: 0.312]\n",
      "19615 [D loss: (0.542)(R 0.599, F 0.484)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.971] [G acc: 0.312]\n",
      "19616 [D loss: (0.629)(R 0.571, F 0.687)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.597] [G acc: 0.562]\n",
      "19617 [D loss: (0.658)(R 0.700, F 0.616)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.806] [G acc: 0.375]\n",
      "19618 [D loss: (0.764)(R 0.705, F 0.822)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.912] [G acc: 0.312]\n",
      "19619 [D loss: (0.641)(R 0.622, F 0.661)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.872] [G acc: 0.375]\n",
      "19620 [D loss: (0.662)(R 0.649, F 0.676)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.812] [G acc: 0.375]\n",
      "19621 [D loss: (0.628)(R 0.601, F 0.655)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.854] [G acc: 0.312]\n",
      "19622 [D loss: (0.638)(R 0.601, F 0.675)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.765] [G acc: 0.375]\n",
      "19623 [D loss: (0.687)(R 0.544, F 0.831)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.867] [G acc: 0.250]\n",
      "19624 [D loss: (0.645)(R 0.637, F 0.653)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.234] [G acc: 0.250]\n",
      "19625 [D loss: (0.569)(R 0.863, F 0.276)] [D acc: (0.719)(0.500, 0.938)] [G loss: 1.361] [G acc: 0.312]\n",
      "19626 [D loss: (0.609)(R 0.666, F 0.552)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.432] [G acc: 0.062]\n",
      "19627 [D loss: (0.642)(R 0.658, F 0.625)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.830] [G acc: 0.312]\n",
      "19628 [D loss: (0.704)(R 0.764, F 0.644)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.744] [G acc: 0.312]\n",
      "19629 [D loss: (0.970)(R 0.661, F 1.278)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.935] [G acc: 0.312]\n",
      "19630 [D loss: (0.608)(R 0.555, F 0.660)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.896] [G acc: 0.312]\n",
      "19631 [D loss: (0.636)(R 0.641, F 0.631)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.920] [G acc: 0.250]\n",
      "19632 [D loss: (0.666)(R 0.593, F 0.740)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.631] [G acc: 0.562]\n",
      "19633 [D loss: (0.650)(R 0.644, F 0.657)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.863] [G acc: 0.250]\n",
      "19634 [D loss: (0.577)(R 0.547, F 0.606)] [D acc: (0.812)(0.938, 0.688)] [G loss: 0.783] [G acc: 0.375]\n",
      "19635 [D loss: (0.622)(R 0.495, F 0.748)] [D acc: (0.594)(0.750, 0.438)] [G loss: 1.323] [G acc: 0.312]\n",
      "19636 [D loss: (0.501)(R 0.691, F 0.311)] [D acc: (0.719)(0.625, 0.812)] [G loss: 2.072] [G acc: 0.188]\n",
      "19637 [D loss: (0.614)(R 0.514, F 0.714)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.905] [G acc: 0.312]\n",
      "19638 [D loss: (0.608)(R 0.561, F 0.655)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.883] [G acc: 0.312]\n",
      "19639 [D loss: (0.545)(R 0.511, F 0.579)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.066] [G acc: 0.125]\n",
      "19640 [D loss: (0.482)(R 0.451, F 0.513)] [D acc: (0.906)(0.875, 0.938)] [G loss: 0.787] [G acc: 0.500]\n",
      "19641 [D loss: (0.687)(R 0.652, F 0.723)] [D acc: (0.594)(0.750, 0.438)] [G loss: 1.161] [G acc: 0.375]\n",
      "19642 [D loss: (0.764)(R 0.685, F 0.843)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.744] [G acc: 0.500]\n",
      "19643 [D loss: (0.606)(R 0.477, F 0.734)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.796] [G acc: 0.438]\n",
      "19644 [D loss: (0.569)(R 0.645, F 0.492)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.980] [G acc: 0.125]\n",
      "19645 [D loss: (0.559)(R 0.568, F 0.549)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.880] [G acc: 0.312]\n",
      "19646 [D loss: (0.633)(R 0.574, F 0.693)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.819] [G acc: 0.250]\n",
      "19647 [D loss: (0.586)(R 0.526, F 0.647)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.915] [G acc: 0.375]\n",
      "19648 [D loss: (0.548)(R 0.546, F 0.549)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.931] [G acc: 0.250]\n",
      "19649 [D loss: (0.635)(R 0.644, F 0.626)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.730] [G acc: 0.438]\n",
      "19650 [D loss: (0.598)(R 0.539, F 0.657)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.826] [G acc: 0.438]\n",
      "19651 [D loss: (0.493)(R 0.443, F 0.543)] [D acc: (0.875)(0.938, 0.812)] [G loss: 0.954] [G acc: 0.250]\n",
      "19652 [D loss: (0.567)(R 0.690, F 0.444)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.634] [G acc: 0.250]\n",
      "19653 [D loss: (0.511)(R 0.652, F 0.370)] [D acc: (0.656)(0.625, 0.688)] [G loss: 6.902] [G acc: 0.250]\n",
      "19654 [D loss: (0.556)(R 0.555, F 0.557)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.958] [G acc: 0.375]\n",
      "19655 [D loss: (0.608)(R 0.619, F 0.598)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.735] [G acc: 0.250]\n",
      "19656 [D loss: (0.594)(R 0.720, F 0.468)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.975] [G acc: 0.375]\n",
      "19657 [D loss: (0.606)(R 0.667, F 0.546)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.894] [G acc: 0.375]\n",
      "19658 [D loss: (0.633)(R 0.668, F 0.598)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.926] [G acc: 0.250]\n",
      "19659 [D loss: (0.563)(R 0.587, F 0.539)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.919] [G acc: 0.250]\n",
      "19660 [D loss: (0.630)(R 0.669, F 0.591)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.996] [G acc: 0.125]\n",
      "19661 [D loss: (0.699)(R 0.670, F 0.728)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.973] [G acc: 0.188]\n",
      "19662 [D loss: (0.647)(R 0.689, F 0.605)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.794] [G acc: 0.438]\n",
      "19663 [D loss: (0.541)(R 0.547, F 0.534)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.199] [G acc: 0.500]\n",
      "19664 [D loss: (0.575)(R 0.618, F 0.532)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.509] [G acc: 0.312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19665 [D loss: (0.434)(R 0.650, F 0.218)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.909] [G acc: 0.250]\n",
      "19666 [D loss: (0.578)(R 0.601, F 0.554)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.949] [G acc: 0.312]\n",
      "19667 [D loss: (0.658)(R 0.654, F 0.661)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.907] [G acc: 0.250]\n",
      "19668 [D loss: (0.740)(R 0.742, F 0.737)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.828] [G acc: 0.438]\n",
      "19669 [D loss: (0.590)(R 0.517, F 0.663)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.695] [G acc: 0.500]\n",
      "19670 [D loss: (0.608)(R 0.619, F 0.596)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.829] [G acc: 0.438]\n",
      "19671 [D loss: (0.624)(R 0.528, F 0.721)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.834] [G acc: 0.250]\n",
      "19672 [D loss: (0.655)(R 0.635, F 0.675)] [D acc: (0.625)(0.750, 0.500)] [G loss: 1.093] [G acc: 0.375]\n",
      "19673 [D loss: (0.456)(R 0.428, F 0.485)] [D acc: (0.875)(0.938, 0.812)] [G loss: 4.014] [G acc: 0.188]\n",
      "19674 [D loss: (0.864)(R 0.538, F 1.190)] [D acc: (0.625)(0.750, 0.500)] [G loss: 7.922] [G acc: 0.312]\n",
      "19675 [D loss: (0.515)(R 0.494, F 0.537)] [D acc: (0.719)(0.750, 0.688)] [G loss: 3.830] [G acc: 0.312]\n",
      "19676 [D loss: (0.534)(R 0.613, F 0.455)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.996] [G acc: 0.375]\n",
      "19677 [D loss: (0.530)(R 0.537, F 0.522)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.230] [G acc: 0.188]\n",
      "19678 [D loss: (0.628)(R 0.599, F 0.657)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.986] [G acc: 0.312]\n",
      "19679 [D loss: (0.655)(R 0.642, F 0.668)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.938] [G acc: 0.375]\n",
      "19680 [D loss: (0.630)(R 0.506, F 0.754)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.953] [G acc: 0.312]\n",
      "19681 [D loss: (0.707)(R 0.582, F 0.833)] [D acc: (0.688)(0.812, 0.562)] [G loss: 1.062] [G acc: 0.312]\n",
      "19682 [D loss: (0.434)(R 0.481, F 0.386)] [D acc: (0.875)(0.938, 0.812)] [G loss: 1.091] [G acc: 0.250]\n",
      "19683 [D loss: (0.577)(R 0.660, F 0.493)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.996] [G acc: 0.188]\n",
      "19684 [D loss: (0.686)(R 0.725, F 0.648)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.988] [G acc: 0.312]\n",
      "19685 [D loss: (0.636)(R 0.575, F 0.696)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.950] [G acc: 0.188]\n",
      "19686 [D loss: (0.449)(R 0.528, F 0.370)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.665] [G acc: 0.062]\n",
      "19687 [D loss: (0.616)(R 0.594, F 0.638)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.884] [G acc: 0.375]\n",
      "19688 [D loss: (0.698)(R 0.694, F 0.703)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.922] [G acc: 0.500]\n",
      "19689 [D loss: (0.488)(R 0.500, F 0.476)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.155] [G acc: 0.188]\n",
      "19690 [D loss: (0.603)(R 0.623, F 0.583)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.908] [G acc: 0.375]\n",
      "19691 [D loss: (0.596)(R 0.438, F 0.754)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.921] [G acc: 0.250]\n",
      "19692 [D loss: (0.544)(R 0.503, F 0.585)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.871] [G acc: 0.500]\n",
      "19693 [D loss: (0.571)(R 0.585, F 0.557)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.997] [G acc: 0.125]\n",
      "19694 [D loss: (0.642)(R 0.681, F 0.602)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.040] [G acc: 0.125]\n",
      "19695 [D loss: (0.551)(R 0.456, F 0.647)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.903] [G acc: 0.250]\n",
      "19696 [D loss: (0.532)(R 0.500, F 0.565)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.781] [G acc: 0.500]\n",
      "19697 [D loss: (0.529)(R 0.495, F 0.564)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.924] [G acc: 0.250]\n",
      "19698 [D loss: (0.768)(R 0.683, F 0.852)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.870] [G acc: 0.312]\n",
      "19699 [D loss: (0.657)(R 0.641, F 0.673)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.597] [G acc: 0.375]\n",
      "19700 [D loss: (0.504)(R 0.546, F 0.462)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.837] [G acc: 0.000]\n",
      "19701 [D loss: (0.495)(R 0.641, F 0.349)] [D acc: (0.656)(0.625, 0.688)] [G loss: 3.175] [G acc: 0.125]\n",
      "19702 [D loss: (0.287)(R 0.447, F 0.127)] [D acc: (0.875)(0.750, 1.000)] [G loss: 2.070] [G acc: 0.188]\n",
      "19703 [D loss: (0.619)(R 0.631, F 0.607)] [D acc: (0.625)(0.562, 0.688)] [G loss: 6.070] [G acc: 0.312]\n",
      "19704 [D loss: (0.613)(R 0.746, F 0.480)] [D acc: (0.656)(0.625, 0.688)] [G loss: 2.214] [G acc: 0.125]\n",
      "19705 [D loss: (0.565)(R 0.482, F 0.648)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.963] [G acc: 0.250]\n",
      "19706 [D loss: (0.579)(R 0.573, F 0.586)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.138] [G acc: 0.125]\n",
      "19707 [D loss: (0.646)(R 0.610, F 0.682)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.856] [G acc: 0.438]\n",
      "19708 [D loss: (0.696)(R 0.775, F 0.617)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.816] [G acc: 0.625]\n",
      "19709 [D loss: (0.676)(R 0.662, F 0.690)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.790] [G acc: 0.438]\n",
      "19710 [D loss: (0.595)(R 0.501, F 0.688)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.689] [G acc: 0.750]\n",
      "19711 [D loss: (0.562)(R 0.410, F 0.713)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.717] [G acc: 0.500]\n",
      "19712 [D loss: (0.587)(R 0.462, F 0.712)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.706] [G acc: 0.438]\n",
      "19713 [D loss: (0.562)(R 0.443, F 0.681)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.841] [G acc: 0.438]\n",
      "19714 [D loss: (0.442)(R 0.456, F 0.429)] [D acc: (0.875)(0.812, 0.938)] [G loss: 0.929] [G acc: 0.375]\n",
      "19715 [D loss: (0.672)(R 0.754, F 0.590)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.634] [G acc: 0.625]\n",
      "19716 [D loss: (0.611)(R 0.559, F 0.663)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.673] [G acc: 0.500]\n",
      "19717 [D loss: (0.464)(R 0.388, F 0.540)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.727] [G acc: 0.500]\n",
      "19718 [D loss: (0.648)(R 0.484, F 0.812)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.795] [G acc: 0.500]\n",
      "19719 [D loss: (0.627)(R 0.525, F 0.728)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.843] [G acc: 0.375]\n",
      "19720 [D loss: (0.585)(R 0.617, F 0.552)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.987] [G acc: 0.375]\n",
      "19721 [D loss: (0.903)(R 1.110, F 0.696)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.553] [G acc: 0.625]\n",
      "19722 [D loss: (0.666)(R 0.591, F 0.742)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.695] [G acc: 0.562]\n",
      "19723 [D loss: (0.829)(R 0.700, F 0.958)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.721] [G acc: 0.562]\n",
      "19724 [D loss: (0.671)(R 0.591, F 0.751)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.885] [G acc: 0.500]\n",
      "19725 [D loss: (0.671)(R 0.705, F 0.638)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.095] [G acc: 0.375]\n",
      "19726 [D loss: (0.397)(R 0.592, F 0.203)] [D acc: (0.812)(0.688, 0.938)] [G loss: 4.529] [G acc: 0.188]\n",
      "19727 [D loss: (1.007)(R 0.664, F 1.350)] [D acc: (0.625)(0.688, 0.562)] [G loss: 3.895] [G acc: 0.375]\n",
      "19728 [D loss: (0.749)(R 0.656, F 0.842)] [D acc: (0.531)(0.688, 0.375)] [G loss: 1.593] [G acc: 0.500]\n",
      "19729 [D loss: (0.631)(R 0.864, F 0.399)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.608] [G acc: 0.625]\n",
      "19730 [D loss: (0.582)(R 0.661, F 0.502)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.068] [G acc: 0.312]\n",
      "19731 [D loss: (0.910)(R 0.524, F 1.295)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.854] [G acc: 0.438]\n",
      "19732 [D loss: (0.638)(R 0.524, F 0.752)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.730] [G acc: 0.500]\n",
      "19733 [D loss: (0.862)(R 0.905, F 0.819)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.746] [G acc: 0.438]\n",
      "19734 [D loss: (0.918)(R 0.819, F 1.016)] [D acc: (0.438)(0.688, 0.188)] [G loss: 1.651] [G acc: 0.000]\n",
      "19735 [D loss: (0.545)(R 0.628, F 0.461)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.795] [G acc: 0.562]\n",
      "19736 [D loss: (0.589)(R 0.529, F 0.649)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.587] [G acc: 0.688]\n",
      "19737 [D loss: (0.798)(R 0.688, F 0.907)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.698] [G acc: 0.688]\n",
      "19738 [D loss: (0.794)(R 0.850, F 0.739)] [D acc: (0.375)(0.438, 0.312)] [G loss: 0.878] [G acc: 0.562]\n",
      "19739 [D loss: (0.709)(R 0.719, F 0.698)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.859] [G acc: 0.438]\n",
      "19740 [D loss: (0.789)(R 0.815, F 0.762)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.841] [G acc: 0.312]\n",
      "19741 [D loss: (0.603)(R 0.615, F 0.592)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.944] [G acc: 0.500]\n",
      "19742 [D loss: (0.760)(R 0.648, F 0.872)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.767] [G acc: 0.688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19743 [D loss: (0.638)(R 0.613, F 0.663)] [D acc: (0.594)(0.750, 0.438)] [G loss: 1.876] [G acc: 0.188]\n",
      "19744 [D loss: (0.548)(R 0.661, F 0.434)] [D acc: (0.781)(0.688, 0.875)] [G loss: 2.123] [G acc: 0.188]\n",
      "19745 [D loss: (0.673)(R 0.774, F 0.571)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.054] [G acc: 0.250]\n",
      "19746 [D loss: (0.640)(R 0.639, F 0.641)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.862] [G acc: 0.375]\n",
      "19747 [D loss: (0.830)(R 0.940, F 0.720)] [D acc: (0.531)(0.750, 0.312)] [G loss: 1.534] [G acc: 0.250]\n",
      "19748 [D loss: (0.619)(R 0.583, F 0.656)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.875] [G acc: 0.375]\n",
      "19749 [D loss: (0.542)(R 0.492, F 0.593)] [D acc: (0.781)(0.938, 0.625)] [G loss: 0.884] [G acc: 0.312]\n",
      "19750 [D loss: (0.652)(R 0.627, F 0.676)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.933] [G acc: 0.188]\n",
      "19751 [D loss: (0.566)(R 0.640, F 0.491)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.010] [G acc: 0.125]\n",
      "19752 [D loss: (0.580)(R 0.612, F 0.548)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.980] [G acc: 0.250]\n",
      "19753 [D loss: (0.531)(R 0.574, F 0.489)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.997] [G acc: 0.062]\n",
      "19754 [D loss: (0.697)(R 0.742, F 0.653)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.953] [G acc: 0.375]\n",
      "19755 [D loss: (0.671)(R 0.726, F 0.615)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.156] [G acc: 0.250]\n",
      "19756 [D loss: (0.754)(R 0.789, F 0.720)] [D acc: (0.406)(0.375, 0.438)] [G loss: 0.907] [G acc: 0.375]\n",
      "19757 [D loss: (0.570)(R 0.645, F 0.496)] [D acc: (0.844)(0.750, 0.938)] [G loss: 0.923] [G acc: 0.375]\n",
      "19758 [D loss: (0.621)(R 0.654, F 0.588)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.914] [G acc: 0.562]\n",
      "19759 [D loss: (0.399)(R 0.572, F 0.226)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.817] [G acc: 0.000]\n",
      "19760 [D loss: (0.661)(R 0.614, F 0.709)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.061] [G acc: 0.250]\n",
      "19761 [D loss: (0.719)(R 0.799, F 0.639)] [D acc: (0.531)(0.500, 0.562)] [G loss: 1.205] [G acc: 0.188]\n",
      "19762 [D loss: (0.495)(R 0.677, F 0.314)] [D acc: (0.750)(0.562, 0.938)] [G loss: 2.832] [G acc: 0.000]\n",
      "19763 [D loss: (0.678)(R 0.514, F 0.841)] [D acc: (0.594)(0.875, 0.312)] [G loss: 4.019] [G acc: 0.250]\n",
      "19764 [D loss: (0.576)(R 0.571, F 0.582)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.942] [G acc: 0.188]\n",
      "19765 [D loss: (0.624)(R 0.688, F 0.559)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.959] [G acc: 0.188]\n",
      "19766 [D loss: (0.612)(R 0.642, F 0.583)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.900] [G acc: 0.250]\n",
      "19767 [D loss: (0.616)(R 0.609, F 0.624)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.825] [G acc: 0.250]\n",
      "19768 [D loss: (0.735)(R 0.820, F 0.649)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.842] [G acc: 0.312]\n",
      "19769 [D loss: (0.642)(R 0.591, F 0.692)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.884] [G acc: 0.375]\n",
      "19770 [D loss: (0.640)(R 0.643, F 0.637)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.834] [G acc: 0.438]\n",
      "19771 [D loss: (0.569)(R 0.548, F 0.590)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.948] [G acc: 0.312]\n",
      "19772 [D loss: (0.629)(R 0.598, F 0.659)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.385] [G acc: 0.375]\n",
      "19773 [D loss: (0.434)(R 0.477, F 0.391)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.045] [G acc: 0.062]\n",
      "19774 [D loss: (0.693)(R 0.786, F 0.599)] [D acc: (0.594)(0.500, 0.688)] [G loss: 1.299] [G acc: 0.062]\n",
      "19775 [D loss: (0.713)(R 0.928, F 0.498)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.666] [G acc: 0.438]\n",
      "19776 [D loss: (0.662)(R 0.601, F 0.723)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.828] [G acc: 0.250]\n",
      "19777 [D loss: (0.758)(R 0.685, F 0.830)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.894] [G acc: 0.312]\n",
      "19778 [D loss: (0.615)(R 0.738, F 0.493)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.017] [G acc: 0.188]\n",
      "19779 [D loss: (0.582)(R 0.576, F 0.587)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.788] [G acc: 0.375]\n",
      "19780 [D loss: (0.631)(R 0.515, F 0.747)] [D acc: (0.719)(0.875, 0.562)] [G loss: 1.178] [G acc: 0.312]\n",
      "19781 [D loss: (0.528)(R 0.659, F 0.396)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.541] [G acc: 0.000]\n",
      "19782 [D loss: (0.677)(R 0.748, F 0.607)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.999] [G acc: 0.312]\n",
      "19783 [D loss: (0.511)(R 0.563, F 0.459)] [D acc: (0.875)(0.750, 1.000)] [G loss: 0.781] [G acc: 0.500]\n",
      "19784 [D loss: (0.640)(R 0.682, F 0.597)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.301] [G acc: 0.375]\n",
      "19785 [D loss: (0.788)(R 0.673, F 0.903)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.878] [G acc: 0.250]\n",
      "19786 [D loss: (0.647)(R 0.515, F 0.779)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.911] [G acc: 0.125]\n",
      "19787 [D loss: (0.930)(R 0.668, F 1.193)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.837] [G acc: 0.312]\n",
      "19788 [D loss: (0.673)(R 0.821, F 0.524)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.996] [G acc: 0.188]\n",
      "19789 [D loss: (0.693)(R 0.775, F 0.611)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.516] [G acc: 0.562]\n",
      "19790 [D loss: (0.684)(R 0.609, F 0.760)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.769] [G acc: 0.375]\n",
      "19791 [D loss: (0.758)(R 0.780, F 0.736)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.907] [G acc: 0.500]\n",
      "19792 [D loss: (0.491)(R 0.641, F 0.341)] [D acc: (0.844)(0.812, 0.875)] [G loss: 2.749] [G acc: 0.125]\n",
      "19793 [D loss: (0.537)(R 0.674, F 0.400)] [D acc: (0.750)(0.750, 0.750)] [G loss: 3.556] [G acc: 0.312]\n",
      "19794 [D loss: (0.515)(R 0.536, F 0.494)] [D acc: (0.906)(0.875, 0.938)] [G loss: 2.145] [G acc: 0.250]\n",
      "19795 [D loss: (0.586)(R 0.604, F 0.568)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.317] [G acc: 0.250]\n",
      "19796 [D loss: (0.801)(R 0.653, F 0.948)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.855] [G acc: 0.188]\n",
      "19797 [D loss: (1.627)(R 0.649, F 2.605)] [D acc: (0.438)(0.688, 0.188)] [G loss: 0.652] [G acc: 0.500]\n",
      "19798 [D loss: (0.676)(R 0.674, F 0.677)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.189] [G acc: 0.250]\n",
      "19799 [D loss: (0.605)(R 0.675, F 0.534)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.168] [G acc: 0.062]\n",
      "19800 [D loss: (0.673)(R 0.725, F 0.622)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.963] [G acc: 0.125]\n",
      "19801 [D loss: (0.575)(R 0.566, F 0.584)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.179] [G acc: 0.312]\n",
      "19802 [D loss: (0.571)(R 0.604, F 0.538)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.132] [G acc: 0.188]\n",
      "19803 [D loss: (0.726)(R 0.771, F 0.681)] [D acc: (0.562)(0.375, 0.750)] [G loss: 1.151] [G acc: 0.125]\n",
      "19804 [D loss: (0.437)(R 0.610, F 0.265)] [D acc: (0.812)(0.625, 1.000)] [G loss: 1.149] [G acc: 0.250]\n",
      "19805 [D loss: (0.758)(R 0.980, F 0.536)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.001] [G acc: 0.312]\n",
      "19806 [D loss: (0.543)(R 0.704, F 0.382)] [D acc: (0.719)(0.438, 1.000)] [G loss: 1.691] [G acc: 0.438]\n",
      "19807 [D loss: (0.632)(R 0.616, F 0.647)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.117] [G acc: 0.188]\n",
      "19808 [D loss: (0.658)(R 0.670, F 0.646)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.684] [G acc: 0.625]\n",
      "19809 [D loss: (0.624)(R 0.537, F 0.711)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.764] [G acc: 0.438]\n",
      "19810 [D loss: (0.811)(R 0.917, F 0.704)] [D acc: (0.500)(0.438, 0.562)] [G loss: 1.119] [G acc: 0.375]\n",
      "19811 [D loss: (0.605)(R 0.615, F 0.595)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.770] [G acc: 0.562]\n",
      "19812 [D loss: (0.570)(R 0.537, F 0.603)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.908] [G acc: 0.250]\n",
      "19813 [D loss: (0.590)(R 0.549, F 0.630)] [D acc: (0.719)(0.875, 0.562)] [G loss: 1.193] [G acc: 0.375]\n",
      "19814 [D loss: (0.599)(R 0.600, F 0.599)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.210] [G acc: 0.062]\n",
      "19815 [D loss: (0.518)(R 0.652, F 0.383)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.043] [G acc: 0.375]\n",
      "19816 [D loss: (0.520)(R 0.607, F 0.434)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.023] [G acc: 0.188]\n",
      "19817 [D loss: (0.525)(R 0.556, F 0.494)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.917] [G acc: 0.125]\n",
      "19818 [D loss: (0.581)(R 0.668, F 0.493)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.991] [G acc: 0.062]\n",
      "19819 [D loss: (0.585)(R 0.629, F 0.541)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.934] [G acc: 0.188]\n",
      "19820 [D loss: (0.490)(R 0.620, F 0.360)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.504] [G acc: 0.062]\n",
      "19821 [D loss: (0.558)(R 0.594, F 0.521)] [D acc: (0.688)(0.688, 0.688)] [G loss: 2.101] [G acc: 0.438]\n",
      "19822 [D loss: (0.555)(R 0.731, F 0.379)] [D acc: (0.781)(0.562, 1.000)] [G loss: 1.876] [G acc: 0.125]\n",
      "19823 [D loss: (0.639)(R 0.641, F 0.637)] [D acc: (0.625)(0.688, 0.562)] [G loss: 4.797] [G acc: 0.188]\n",
      "19824 [D loss: (0.541)(R 0.600, F 0.481)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.910] [G acc: 0.375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19825 [D loss: (0.548)(R 0.533, F 0.563)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.991] [G acc: 0.188]\n",
      "19826 [D loss: (0.500)(R 0.569, F 0.432)] [D acc: (0.844)(0.750, 0.938)] [G loss: 0.885] [G acc: 0.312]\n",
      "19827 [D loss: (0.566)(R 0.633, F 0.500)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.204] [G acc: 0.062]\n",
      "19828 [D loss: (0.916)(R 0.554, F 1.277)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.996] [G acc: 0.188]\n",
      "19829 [D loss: (0.552)(R 0.633, F 0.471)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.159] [G acc: 0.188]\n",
      "19830 [D loss: (0.485)(R 0.523, F 0.447)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.093] [G acc: 0.125]\n",
      "19831 [D loss: (0.523)(R 0.495, F 0.551)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.084] [G acc: 0.250]\n",
      "19832 [D loss: (0.579)(R 0.608, F 0.550)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.018] [G acc: 0.062]\n",
      "19833 [D loss: (0.647)(R 0.673, F 0.622)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.055] [G acc: 0.062]\n",
      "19834 [D loss: (0.592)(R 0.586, F 0.598)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.975] [G acc: 0.188]\n",
      "19835 [D loss: (0.572)(R 0.573, F 0.571)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.647] [G acc: 0.625]\n",
      "19836 [D loss: (0.630)(R 0.687, F 0.573)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.012] [G acc: 0.062]\n",
      "19837 [D loss: (0.559)(R 0.602, F 0.517)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.041] [G acc: 0.188]\n",
      "19838 [D loss: (0.542)(R 0.562, F 0.522)] [D acc: (0.844)(0.875, 0.812)] [G loss: 0.937] [G acc: 0.250]\n",
      "19839 [D loss: (0.590)(R 0.573, F 0.607)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.193] [G acc: 0.250]\n",
      "19840 [D loss: (0.482)(R 0.562, F 0.402)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.125] [G acc: 0.125]\n",
      "19841 [D loss: (0.602)(R 0.716, F 0.487)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.056] [G acc: 0.125]\n",
      "19842 [D loss: (0.649)(R 0.779, F 0.520)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.962] [G acc: 0.250]\n",
      "19843 [D loss: (0.542)(R 0.559, F 0.526)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.063] [G acc: 0.125]\n",
      "19844 [D loss: (0.536)(R 0.606, F 0.466)] [D acc: (0.906)(0.812, 1.000)] [G loss: 1.088] [G acc: 0.062]\n",
      "19845 [D loss: (0.470)(R 0.488, F 0.453)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.670] [G acc: 0.625]\n",
      "19846 [D loss: (0.466)(R 0.415, F 0.516)] [D acc: (0.875)(0.938, 0.812)] [G loss: 0.943] [G acc: 0.312]\n",
      "19847 [D loss: (0.642)(R 0.530, F 0.753)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.969] [G acc: 0.250]\n",
      "19848 [D loss: (0.556)(R 0.389, F 0.722)] [D acc: (0.688)(0.875, 0.500)] [G loss: 1.718] [G acc: 0.250]\n",
      "19849 [D loss: (0.418)(R 0.701, F 0.136)] [D acc: (0.844)(0.688, 1.000)] [G loss: 4.196] [G acc: 0.188]\n",
      "19850 [D loss: (0.696)(R 0.697, F 0.696)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.047] [G acc: 0.125]\n",
      "19851 [D loss: (0.558)(R 0.591, F 0.526)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.096] [G acc: 0.125]\n",
      "19852 [D loss: (0.578)(R 0.661, F 0.495)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.946] [G acc: 0.312]\n",
      "19853 [D loss: (0.615)(R 0.629, F 0.601)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.889] [G acc: 0.375]\n",
      "19854 [D loss: (0.674)(R 0.618, F 0.731)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.837] [G acc: 0.312]\n",
      "19855 [D loss: (0.592)(R 0.624, F 0.560)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.949] [G acc: 0.375]\n",
      "19856 [D loss: (0.626)(R 0.680, F 0.573)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.050] [G acc: 0.312]\n",
      "19857 [D loss: (0.639)(R 0.843, F 0.435)] [D acc: (0.625)(0.500, 0.750)] [G loss: 2.111] [G acc: 0.188]\n",
      "19858 [D loss: (0.547)(R 0.516, F 0.578)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.139] [G acc: 0.188]\n",
      "19859 [D loss: (0.671)(R 0.681, F 0.660)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.809] [G acc: 0.375]\n",
      "19860 [D loss: (0.616)(R 0.596, F 0.637)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.950] [G acc: 0.188]\n",
      "19861 [D loss: (0.910)(R 0.551, F 1.270)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.750] [G acc: 0.500]\n",
      "19862 [D loss: (0.601)(R 0.605, F 0.596)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.923] [G acc: 0.375]\n",
      "19863 [D loss: (0.553)(R 0.551, F 0.555)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.194] [G acc: 0.188]\n",
      "19864 [D loss: (0.660)(R 0.610, F 0.710)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.692] [G acc: 0.375]\n",
      "19865 [D loss: (0.669)(R 0.536, F 0.802)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.789] [G acc: 0.562]\n",
      "19866 [D loss: (0.601)(R 0.561, F 0.642)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.995] [G acc: 0.062]\n",
      "19867 [D loss: (0.724)(R 0.806, F 0.642)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.056] [G acc: 0.375]\n",
      "19868 [D loss: (0.662)(R 0.800, F 0.524)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.966] [G acc: 0.438]\n",
      "19869 [D loss: (0.574)(R 0.624, F 0.525)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.006] [G acc: 0.250]\n",
      "19870 [D loss: (0.668)(R 0.760, F 0.576)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.039] [G acc: 0.000]\n",
      "19871 [D loss: (0.601)(R 0.596, F 0.606)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.680] [G acc: 0.500]\n",
      "19872 [D loss: (0.571)(R 0.505, F 0.638)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.886] [G acc: 0.250]\n",
      "19873 [D loss: (0.713)(R 0.565, F 0.861)] [D acc: (0.562)(0.688, 0.438)] [G loss: 1.138] [G acc: 0.188]\n",
      "19874 [D loss: (0.322)(R 0.620, F 0.024)] [D acc: (0.812)(0.625, 1.000)] [G loss: 8.605] [G acc: 0.062]\n",
      "19875 [D loss: (0.564)(R 0.717, F 0.410)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.313] [G acc: 0.062]\n",
      "19876 [D loss: (0.526)(R 0.560, F 0.493)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.373] [G acc: 0.000]\n",
      "19877 [D loss: (0.484)(R 0.491, F 0.478)] [D acc: (0.875)(0.875, 0.875)] [G loss: 0.872] [G acc: 0.312]\n",
      "19878 [D loss: (0.508)(R 0.497, F 0.519)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.134] [G acc: 0.125]\n",
      "19879 [D loss: (0.561)(R 0.537, F 0.585)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.461] [G acc: 0.125]\n",
      "19880 [D loss: (0.594)(R 0.615, F 0.574)] [D acc: (0.594)(0.688, 0.500)] [G loss: 1.090] [G acc: 0.500]\n",
      "19881 [D loss: (0.576)(R 0.651, F 0.501)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.073] [G acc: 0.062]\n",
      "19882 [D loss: (0.410)(R 0.399, F 0.421)] [D acc: (0.938)(0.875, 1.000)] [G loss: 1.150] [G acc: 0.125]\n",
      "19883 [D loss: (0.527)(R 0.549, F 0.506)] [D acc: (0.844)(0.875, 0.812)] [G loss: 3.088] [G acc: 0.125]\n",
      "19884 [D loss: (1.059)(R 0.461, F 1.656)] [D acc: (0.688)(0.812, 0.562)] [G loss: 2.018] [G acc: 0.438]\n",
      "19885 [D loss: (0.575)(R 0.701, F 0.449)] [D acc: (0.750)(0.625, 0.875)] [G loss: 2.123] [G acc: 0.125]\n",
      "19886 [D loss: (0.732)(R 0.737, F 0.727)] [D acc: (0.562)(0.625, 0.500)] [G loss: 1.723] [G acc: 0.312]\n",
      "19887 [D loss: (0.519)(R 0.897, F 0.140)] [D acc: (0.719)(0.438, 1.000)] [G loss: 6.098] [G acc: 0.000]\n",
      "19888 [D loss: (0.501)(R 0.668, F 0.334)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.323] [G acc: 0.312]\n",
      "19889 [D loss: (0.534)(R 0.554, F 0.514)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.058] [G acc: 0.125]\n",
      "19890 [D loss: (0.798)(R 0.802, F 0.795)] [D acc: (0.375)(0.375, 0.375)] [G loss: 0.714] [G acc: 0.562]\n",
      "19891 [D loss: (0.630)(R 0.516, F 0.744)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.771] [G acc: 0.438]\n",
      "19892 [D loss: (0.634)(R 0.679, F 0.588)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.963] [G acc: 0.188]\n",
      "19893 [D loss: (0.929)(R 0.606, F 1.252)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.854] [G acc: 0.312]\n",
      "19894 [D loss: (0.664)(R 0.743, F 0.584)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.933] [G acc: 0.375]\n",
      "19895 [D loss: (0.506)(R 0.381, F 0.632)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.152] [G acc: 0.312]\n",
      "19896 [D loss: (0.459)(R 0.726, F 0.192)] [D acc: (0.781)(0.562, 1.000)] [G loss: 2.296] [G acc: 0.000]\n",
      "19897 [D loss: (0.647)(R 0.662, F 0.632)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.748] [G acc: 0.438]\n",
      "19898 [D loss: (0.594)(R 0.584, F 0.604)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.860] [G acc: 0.250]\n",
      "19899 [D loss: (0.739)(R 0.526, F 0.951)] [D acc: (0.688)(0.812, 0.562)] [G loss: 1.386] [G acc: 0.250]\n",
      "19900 [D loss: (0.520)(R 0.696, F 0.343)] [D acc: (0.719)(0.625, 0.812)] [G loss: 2.665] [G acc: 0.125]\n",
      "19901 [D loss: (0.550)(R 0.678, F 0.423)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.750] [G acc: 0.062]\n",
      "19902 [D loss: (0.494)(R 0.625, F 0.364)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.672] [G acc: 0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19903 [D loss: (0.511)(R 0.585, F 0.437)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.075] [G acc: 0.188]\n",
      "19904 [D loss: (0.584)(R 0.694, F 0.474)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.912] [G acc: 0.250]\n",
      "19905 [D loss: (0.460)(R 0.541, F 0.379)] [D acc: (0.875)(0.750, 1.000)] [G loss: 0.917] [G acc: 0.375]\n",
      "19906 [D loss: (0.571)(R 0.646, F 0.495)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.028] [G acc: 0.312]\n",
      "19907 [D loss: (0.601)(R 0.536, F 0.665)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.995] [G acc: 0.188]\n",
      "19908 [D loss: (0.690)(R 0.731, F 0.650)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.037] [G acc: 0.062]\n",
      "19909 [D loss: (0.552)(R 0.632, F 0.472)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.978] [G acc: 0.125]\n",
      "19910 [D loss: (0.596)(R 0.669, F 0.523)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.054] [G acc: 0.125]\n",
      "19911 [D loss: (0.660)(R 0.699, F 0.621)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.263] [G acc: 0.188]\n",
      "19912 [D loss: (0.413)(R 0.512, F 0.315)] [D acc: (0.812)(0.625, 1.000)] [G loss: 1.422] [G acc: 0.062]\n",
      "19913 [D loss: (0.481)(R 0.537, F 0.425)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.148] [G acc: 0.188]\n",
      "19914 [D loss: (0.501)(R 0.506, F 0.496)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.905] [G acc: 0.312]\n",
      "19915 [D loss: (0.788)(R 0.707, F 0.869)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.838] [G acc: 0.562]\n",
      "19916 [D loss: (0.485)(R 0.544, F 0.425)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.241] [G acc: 0.312]\n",
      "19917 [D loss: (0.534)(R 0.514, F 0.554)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.066] [G acc: 0.062]\n",
      "19918 [D loss: (0.589)(R 0.453, F 0.724)] [D acc: (0.750)(0.875, 0.625)] [G loss: 1.398] [G acc: 0.125]\n",
      "19919 [D loss: (0.544)(R 0.544, F 0.544)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.154] [G acc: 0.188]\n",
      "19920 [D loss: (0.556)(R 0.547, F 0.565)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.406] [G acc: 0.062]\n",
      "19921 [D loss: (0.300)(R 0.467, F 0.134)] [D acc: (0.906)(0.812, 1.000)] [G loss: 1.195] [G acc: 0.250]\n",
      "19922 [D loss: (0.506)(R 0.605, F 0.408)] [D acc: (0.781)(0.625, 0.938)] [G loss: 2.340] [G acc: 0.062]\n",
      "19923 [D loss: (0.573)(R 0.672, F 0.473)] [D acc: (0.562)(0.625, 0.500)] [G loss: 3.167] [G acc: 0.438]\n",
      "19924 [D loss: (0.876)(R 0.547, F 1.204)] [D acc: (0.656)(0.750, 0.562)] [G loss: 5.264] [G acc: 0.125]\n",
      "19925 [D loss: (0.485)(R 0.567, F 0.404)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.494] [G acc: 0.000]\n",
      "19926 [D loss: (0.640)(R 0.832, F 0.448)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.950] [G acc: 0.250]\n",
      "19927 [D loss: (0.514)(R 0.511, F 0.517)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.987] [G acc: 0.312]\n",
      "19928 [D loss: (0.472)(R 0.547, F 0.398)] [D acc: (0.844)(0.688, 1.000)] [G loss: 1.046] [G acc: 0.188]\n",
      "19929 [D loss: (0.507)(R 0.446, F 0.568)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.222] [G acc: 0.125]\n",
      "19930 [D loss: (0.364)(R 0.293, F 0.435)] [D acc: (0.906)(1.000, 0.812)] [G loss: 1.373] [G acc: 0.125]\n",
      "19931 [D loss: (0.533)(R 0.600, F 0.466)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.783] [G acc: 0.188]\n",
      "19932 [D loss: (0.520)(R 0.500, F 0.539)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.134] [G acc: 0.000]\n",
      "19933 [D loss: (0.464)(R 0.473, F 0.454)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.015] [G acc: 0.188]\n",
      "19934 [D loss: (0.597)(R 0.754, F 0.439)] [D acc: (0.875)(0.750, 1.000)] [G loss: 0.937] [G acc: 0.312]\n",
      "19935 [D loss: (0.590)(R 0.423, F 0.757)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.165] [G acc: 0.312]\n",
      "19936 [D loss: (0.517)(R 0.613, F 0.422)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.243] [G acc: 0.125]\n",
      "19937 [D loss: (0.523)(R 0.464, F 0.583)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.020] [G acc: 0.188]\n",
      "19938 [D loss: (0.499)(R 0.493, F 0.505)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.035] [G acc: 0.250]\n",
      "19939 [D loss: (0.556)(R 0.614, F 0.497)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.997] [G acc: 0.188]\n",
      "19940 [D loss: (0.505)(R 0.477, F 0.533)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.144] [G acc: 0.375]\n",
      "19941 [D loss: (0.497)(R 0.616, F 0.379)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.980] [G acc: 0.375]\n",
      "19942 [D loss: (0.518)(R 0.542, F 0.495)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.052] [G acc: 0.188]\n",
      "19943 [D loss: (0.578)(R 0.557, F 0.599)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.296] [G acc: 0.500]\n",
      "19944 [D loss: (0.381)(R 0.685, F 0.077)] [D acc: (0.781)(0.562, 1.000)] [G loss: 5.805] [G acc: 0.000]\n",
      "19945 [D loss: (0.671)(R 0.583, F 0.759)] [D acc: (0.656)(0.625, 0.688)] [G loss: 3.043] [G acc: 0.312]\n",
      "19946 [D loss: (0.527)(R 0.640, F 0.414)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.556] [G acc: 0.125]\n",
      "19947 [D loss: (0.609)(R 0.488, F 0.731)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.441] [G acc: 0.125]\n",
      "19948 [D loss: (0.470)(R 0.443, F 0.497)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.084] [G acc: 0.188]\n",
      "19949 [D loss: (0.403)(R 0.460, F 0.345)] [D acc: (0.906)(0.812, 1.000)] [G loss: 1.194] [G acc: 0.125]\n",
      "19950 [D loss: (0.507)(R 0.491, F 0.522)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.053] [G acc: 0.250]\n",
      "19951 [D loss: (0.547)(R 0.640, F 0.453)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.075] [G acc: 0.188]\n",
      "19952 [D loss: (0.527)(R 0.569, F 0.485)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.325] [G acc: 0.188]\n",
      "19953 [D loss: (0.489)(R 0.493, F 0.485)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.116] [G acc: 0.250]\n",
      "19954 [D loss: (0.575)(R 0.432, F 0.719)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.973] [G acc: 0.562]\n",
      "19955 [D loss: (0.698)(R 0.729, F 0.668)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.387] [G acc: 0.125]\n",
      "19956 [D loss: (0.541)(R 0.417, F 0.665)] [D acc: (0.688)(0.812, 0.562)] [G loss: 1.173] [G acc: 0.188]\n",
      "19957 [D loss: (0.758)(R 0.876, F 0.641)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.880] [G acc: 0.500]\n",
      "19958 [D loss: (0.574)(R 0.562, F 0.585)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.952] [G acc: 0.312]\n",
      "19959 [D loss: (0.612)(R 0.607, F 0.616)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.838] [G acc: 0.625]\n",
      "19960 [D loss: (0.591)(R 0.561, F 0.622)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.827] [G acc: 0.438]\n",
      "19961 [D loss: (0.801)(R 0.678, F 0.925)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.946] [G acc: 0.312]\n",
      "19962 [D loss: (1.281)(R 0.726, F 1.836)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.768] [G acc: 0.438]\n",
      "19963 [D loss: (0.718)(R 0.608, F 0.827)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.976] [G acc: 0.375]\n",
      "19964 [D loss: (0.548)(R 0.646, F 0.449)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.050] [G acc: 0.375]\n",
      "19965 [D loss: (0.691)(R 0.621, F 0.761)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.300] [G acc: 0.562]\n",
      "19966 [D loss: (0.465)(R 0.538, F 0.391)] [D acc: (0.750)(0.688, 0.812)] [G loss: 2.375] [G acc: 0.188]\n",
      "19967 [D loss: (0.657)(R 0.822, F 0.492)] [D acc: (0.562)(0.312, 0.812)] [G loss: 3.104] [G acc: 0.125]\n",
      "19968 [D loss: (0.545)(R 0.684, F 0.407)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.065] [G acc: 0.562]\n",
      "19969 [D loss: (0.658)(R 0.565, F 0.751)] [D acc: (0.594)(0.688, 0.500)] [G loss: 1.047] [G acc: 0.250]\n",
      "19970 [D loss: (0.689)(R 0.737, F 0.642)] [D acc: (0.562)(0.438, 0.688)] [G loss: 1.317] [G acc: 0.188]\n",
      "19971 [D loss: (0.529)(R 0.558, F 0.500)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.821] [G acc: 0.375]\n",
      "19972 [D loss: (0.649)(R 0.700, F 0.599)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.097] [G acc: 0.438]\n",
      "19973 [D loss: (0.951)(R 0.794, F 1.108)] [D acc: (0.594)(0.688, 0.500)] [G loss: 1.038] [G acc: 0.375]\n",
      "19974 [D loss: (0.700)(R 0.795, F 0.606)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.714] [G acc: 0.500]\n",
      "19975 [D loss: (0.731)(R 0.849, F 0.613)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.892] [G acc: 0.312]\n",
      "19976 [D loss: (0.623)(R 0.460, F 0.786)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.891] [G acc: 0.250]\n",
      "19977 [D loss: (1.131)(R 0.617, F 1.645)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.921] [G acc: 0.625]\n",
      "19978 [D loss: (0.391)(R 0.707, F 0.076)] [D acc: (0.781)(0.562, 1.000)] [G loss: 3.595] [G acc: 0.125]\n",
      "19979 [D loss: (0.391)(R 0.496, F 0.287)] [D acc: (0.812)(0.812, 0.812)] [G loss: 3.695] [G acc: 0.250]\n",
      "19980 [D loss: (0.473)(R 0.562, F 0.385)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.202] [G acc: 0.188]\n",
      "19981 [D loss: (0.579)(R 0.648, F 0.509)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.113] [G acc: 0.250]\n",
      "19982 [D loss: (0.610)(R 0.688, F 0.533)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.991] [G acc: 0.375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19983 [D loss: (0.642)(R 0.708, F 0.576)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.282] [G acc: 0.188]\n",
      "19984 [D loss: (0.626)(R 0.587, F 0.665)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.886] [G acc: 0.250]\n",
      "19985 [D loss: (0.565)(R 0.549, F 0.582)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.977] [G acc: 0.312]\n",
      "19986 [D loss: (0.790)(R 0.881, F 0.699)] [D acc: (0.594)(0.500, 0.688)] [G loss: 1.163] [G acc: 0.062]\n",
      "19987 [D loss: (0.671)(R 0.707, F 0.636)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.997] [G acc: 0.062]\n",
      "19988 [D loss: (0.568)(R 0.609, F 0.526)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.068] [G acc: 0.250]\n",
      "19989 [D loss: (0.460)(R 0.473, F 0.448)] [D acc: (0.906)(0.875, 0.938)] [G loss: 1.404] [G acc: 0.500]\n",
      "19990 [D loss: (0.878)(R 0.561, F 1.196)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.991] [G acc: 0.250]\n",
      "19991 [D loss: (0.579)(R 0.593, F 0.565)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.952] [G acc: 0.250]\n",
      "19992 [D loss: (0.683)(R 0.562, F 0.803)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.900] [G acc: 0.188]\n",
      "19993 [D loss: (0.504)(R 0.419, F 0.589)] [D acc: (0.875)(0.938, 0.812)] [G loss: 0.827] [G acc: 0.250]\n",
      "19994 [D loss: (0.596)(R 0.657, F 0.535)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.798] [G acc: 0.438]\n",
      "19995 [D loss: (0.615)(R 0.760, F 0.471)] [D acc: (0.594)(0.438, 0.750)] [G loss: 1.322] [G acc: 0.125]\n",
      "19996 [D loss: (0.515)(R 0.602, F 0.428)] [D acc: (0.875)(0.750, 1.000)] [G loss: 1.763] [G acc: 0.000]\n",
      "19997 [D loss: (0.615)(R 0.661, F 0.569)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.955] [G acc: 0.188]\n",
      "19998 [D loss: (0.775)(R 0.761, F 0.789)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.933] [G acc: 0.125]\n",
      "19999 [D loss: (0.597)(R 0.847, F 0.346)] [D acc: (0.594)(0.438, 0.750)] [G loss: 1.084] [G acc: 0.188]\n",
      "20000 [D loss: (0.521)(R 0.545, F 0.497)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.782] [G acc: 0.312]\n",
      "20001 [D loss: (0.564)(R 0.596, F 0.532)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.844] [G acc: 0.438]\n",
      "20002 [D loss: (0.743)(R 0.657, F 0.828)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.584] [G acc: 0.625]\n",
      "20003 [D loss: (0.710)(R 0.666, F 0.755)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.520] [G acc: 0.625]\n",
      "20004 [D loss: (0.780)(R 0.709, F 0.852)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.668] [G acc: 0.562]\n",
      "20005 [D loss: (0.615)(R 0.634, F 0.596)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.204] [G acc: 0.500]\n",
      "20006 [D loss: (0.499)(R 0.760, F 0.238)] [D acc: (0.656)(0.438, 0.875)] [G loss: 3.120] [G acc: 0.000]\n",
      "20007 [D loss: (0.623)(R 0.713, F 0.532)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.564] [G acc: 0.188]\n",
      "20008 [D loss: (0.548)(R 0.660, F 0.436)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.637] [G acc: 0.125]\n",
      "20009 [D loss: (0.674)(R 0.665, F 0.683)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.884] [G acc: 0.312]\n",
      "20010 [D loss: (0.569)(R 0.693, F 0.446)] [D acc: (0.719)(0.500, 0.938)] [G loss: 0.986] [G acc: 0.312]\n",
      "20011 [D loss: (0.550)(R 0.648, F 0.452)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.390] [G acc: 0.250]\n",
      "20012 [D loss: (0.662)(R 0.678, F 0.647)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.281] [G acc: 0.125]\n",
      "20013 [D loss: (0.512)(R 0.650, F 0.374)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.584] [G acc: 0.188]\n",
      "20014 [D loss: (0.546)(R 0.681, F 0.411)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.151] [G acc: 0.375]\n",
      "20015 [D loss: (0.542)(R 0.582, F 0.502)] [D acc: (0.844)(0.750, 0.938)] [G loss: 0.966] [G acc: 0.250]\n",
      "20016 [D loss: (0.567)(R 0.575, F 0.558)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.997] [G acc: 0.188]\n",
      "20017 [D loss: (0.528)(R 0.603, F 0.452)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.168] [G acc: 0.250]\n",
      "20018 [D loss: (0.695)(R 0.837, F 0.554)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.901] [G acc: 0.250]\n",
      "20019 [D loss: (0.574)(R 0.505, F 0.642)] [D acc: (0.750)(0.875, 0.625)] [G loss: 1.229] [G acc: 0.125]\n",
      "20020 [D loss: (0.651)(R 0.798, F 0.505)] [D acc: (0.625)(0.438, 0.812)] [G loss: 1.039] [G acc: 0.188]\n",
      "20021 [D loss: (0.572)(R 0.608, F 0.537)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.810] [G acc: 0.312]\n",
      "20022 [D loss: (0.657)(R 0.638, F 0.676)] [D acc: (0.500)(0.562, 0.438)] [G loss: 5.558] [G acc: 0.375]\n",
      "20023 [D loss: (0.552)(R 0.624, F 0.481)] [D acc: (0.594)(0.688, 0.500)] [G loss: 4.222] [G acc: 0.438]\n",
      "20024 [D loss: (0.749)(R 0.648, F 0.850)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.869] [G acc: 0.250]\n",
      "20025 [D loss: (0.544)(R 0.546, F 0.542)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.864] [G acc: 0.375]\n",
      "20026 [D loss: (0.655)(R 0.803, F 0.508)] [D acc: (0.562)(0.500, 0.625)] [G loss: 1.023] [G acc: 0.312]\n",
      "20027 [D loss: (0.659)(R 0.701, F 0.617)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.995] [G acc: 0.312]\n",
      "20028 [D loss: (0.630)(R 0.691, F 0.570)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.044] [G acc: 0.250]\n",
      "20029 [D loss: (0.607)(R 0.690, F 0.523)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.116] [G acc: 0.125]\n",
      "20030 [D loss: (0.472)(R 0.539, F 0.406)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.262] [G acc: 0.062]\n",
      "20031 [D loss: (0.647)(R 0.591, F 0.704)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.878] [G acc: 0.312]\n",
      "20032 [D loss: (0.608)(R 0.647, F 0.568)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.931] [G acc: 0.188]\n",
      "20033 [D loss: (0.504)(R 0.675, F 0.333)] [D acc: (0.781)(0.562, 1.000)] [G loss: 1.140] [G acc: 0.125]\n",
      "20034 [D loss: (0.712)(R 0.742, F 0.682)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.903] [G acc: 0.188]\n",
      "20035 [D loss: (0.688)(R 0.709, F 0.667)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.737] [G acc: 0.562]\n",
      "20036 [D loss: (0.798)(R 0.854, F 0.741)] [D acc: (0.375)(0.438, 0.312)] [G loss: 0.703] [G acc: 0.438]\n",
      "20037 [D loss: (0.685)(R 0.630, F 0.739)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.924] [G acc: 0.125]\n",
      "20038 [D loss: (0.654)(R 0.569, F 0.739)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.672] [G acc: 0.500]\n",
      "20039 [D loss: (0.622)(R 0.626, F 0.618)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.945] [G acc: 0.188]\n",
      "20040 [D loss: (0.679)(R 0.653, F 0.705)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.847] [G acc: 0.438]\n",
      "20041 [D loss: (0.581)(R 0.740, F 0.421)] [D acc: (0.719)(0.500, 0.938)] [G loss: 0.853] [G acc: 0.312]\n",
      "20042 [D loss: (0.604)(R 0.589, F 0.619)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.671] [G acc: 0.625]\n",
      "20043 [D loss: (0.726)(R 0.610, F 0.842)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.915] [G acc: 0.312]\n",
      "20044 [D loss: (0.462)(R 0.595, F 0.330)] [D acc: (0.719)(0.625, 0.812)] [G loss: 2.087] [G acc: 0.062]\n",
      "20045 [D loss: (0.608)(R 0.705, F 0.510)] [D acc: (0.562)(0.625, 0.500)] [G loss: 3.747] [G acc: 0.188]\n",
      "20046 [D loss: (0.368)(R 0.479, F 0.257)] [D acc: (0.906)(0.812, 1.000)] [G loss: 2.280] [G acc: 0.188]\n",
      "20047 [D loss: (0.809)(R 0.643, F 0.975)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.990] [G acc: 0.125]\n",
      "20048 [D loss: (0.664)(R 0.760, F 0.568)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.935] [G acc: 0.188]\n",
      "20049 [D loss: (0.557)(R 0.469, F 0.646)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.931] [G acc: 0.062]\n",
      "20050 [D loss: (0.762)(R 0.823, F 0.701)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.834] [G acc: 0.312]\n",
      "20051 [D loss: (0.676)(R 0.703, F 0.648)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.805] [G acc: 0.438]\n",
      "20052 [D loss: (0.652)(R 0.698, F 0.607)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.790] [G acc: 0.375]\n",
      "20053 [D loss: (0.645)(R 0.625, F 0.665)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.791] [G acc: 0.312]\n",
      "20054 [D loss: (0.634)(R 0.616, F 0.652)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.882] [G acc: 0.250]\n",
      "20055 [D loss: (0.617)(R 0.586, F 0.648)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.675] [G acc: 0.562]\n",
      "20056 [D loss: (0.666)(R 0.677, F 0.655)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.614] [G acc: 0.750]\n",
      "20057 [D loss: (0.641)(R 0.636, F 0.646)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.619] [G acc: 0.688]\n",
      "20058 [D loss: (0.666)(R 0.756, F 0.576)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.878] [G acc: 0.188]\n",
      "20059 [D loss: (0.671)(R 0.742, F 0.600)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.834] [G acc: 0.312]\n",
      "20060 [D loss: (0.742)(R 0.658, F 0.826)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.992] [G acc: 0.438]\n",
      "20061 [D loss: (0.665)(R 0.505, F 0.824)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.768] [G acc: 0.375]\n",
      "20062 [D loss: (0.584)(R 0.515, F 0.653)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.695] [G acc: 0.438]\n",
      "20063 [D loss: (0.603)(R 0.609, F 0.598)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.857] [G acc: 0.312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20064 [D loss: (0.681)(R 0.669, F 0.693)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.754] [G acc: 0.500]\n",
      "20065 [D loss: (0.689)(R 0.594, F 0.784)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.747] [G acc: 0.562]\n",
      "20066 [D loss: (0.607)(R 0.775, F 0.439)] [D acc: (0.594)(0.312, 0.875)] [G loss: 1.294] [G acc: 0.375]\n",
      "20067 [D loss: (0.723)(R 0.606, F 0.841)] [D acc: (0.625)(0.625, 0.625)] [G loss: 4.800] [G acc: 0.125]\n",
      "20068 [D loss: (0.372)(R 0.576, F 0.168)] [D acc: (0.812)(0.688, 0.938)] [G loss: 3.245] [G acc: 0.000]\n",
      "20069 [D loss: (0.724)(R 0.725, F 0.722)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.703] [G acc: 0.438]\n",
      "20070 [D loss: (0.608)(R 0.595, F 0.621)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.220] [G acc: 0.250]\n",
      "20071 [D loss: (0.672)(R 0.701, F 0.642)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.946] [G acc: 0.250]\n",
      "20072 [D loss: (0.556)(R 0.604, F 0.508)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.985] [G acc: 0.312]\n",
      "20073 [D loss: (0.593)(R 0.715, F 0.470)] [D acc: (0.719)(0.500, 0.938)] [G loss: 0.854] [G acc: 0.312]\n",
      "20074 [D loss: (0.563)(R 0.582, F 0.545)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.873] [G acc: 0.062]\n",
      "20075 [D loss: (0.565)(R 0.550, F 0.581)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.792] [G acc: 0.188]\n",
      "20076 [D loss: (0.702)(R 0.681, F 0.723)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.906] [G acc: 0.125]\n",
      "20077 [D loss: (0.739)(R 0.721, F 0.758)] [D acc: (0.375)(0.375, 0.375)] [G loss: 0.870] [G acc: 0.000]\n",
      "20078 [D loss: (0.684)(R 0.644, F 0.725)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.649] [G acc: 0.625]\n",
      "20079 [D loss: (0.655)(R 0.624, F 0.686)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.776] [G acc: 0.312]\n",
      "20080 [D loss: (0.612)(R 0.528, F 0.696)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.946] [G acc: 0.188]\n",
      "20081 [D loss: (0.569)(R 0.686, F 0.453)] [D acc: (0.656)(0.438, 0.875)] [G loss: 1.068] [G acc: 0.188]\n",
      "20082 [D loss: (0.520)(R 0.738, F 0.302)] [D acc: (0.750)(0.625, 0.875)] [G loss: 2.186] [G acc: 0.188]\n",
      "20083 [D loss: (0.415)(R 0.622, F 0.208)] [D acc: (0.781)(0.625, 0.938)] [G loss: 2.403] [G acc: 0.062]\n",
      "20084 [D loss: (0.506)(R 0.412, F 0.601)] [D acc: (0.844)(0.875, 0.812)] [G loss: 0.768] [G acc: 0.375]\n",
      "20085 [D loss: (0.581)(R 0.614, F 0.547)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.809] [G acc: 0.375]\n",
      "20086 [D loss: (0.579)(R 0.635, F 0.524)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.939] [G acc: 0.375]\n",
      "20087 [D loss: (0.557)(R 0.561, F 0.553)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.973] [G acc: 0.062]\n",
      "20088 [D loss: (0.561)(R 0.534, F 0.588)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.871] [G acc: 0.188]\n",
      "20089 [D loss: (0.574)(R 0.572, F 0.576)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.824] [G acc: 0.312]\n",
      "20090 [D loss: (0.607)(R 0.567, F 0.647)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.432] [G acc: 0.812]\n",
      "20091 [D loss: (0.507)(R 0.476, F 0.537)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.876] [G acc: 0.125]\n",
      "20092 [D loss: (0.568)(R 0.473, F 0.663)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.821] [G acc: 0.250]\n",
      "20093 [D loss: (0.656)(R 0.477, F 0.836)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.891] [G acc: 0.500]\n",
      "20094 [D loss: (0.610)(R 0.638, F 0.582)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.937] [G acc: 0.188]\n",
      "20095 [D loss: (0.505)(R 0.375, F 0.635)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.959] [G acc: 0.125]\n",
      "20096 [D loss: (0.592)(R 0.588, F 0.597)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.923] [G acc: 0.125]\n",
      "20097 [D loss: (0.613)(R 0.620, F 0.607)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.849] [G acc: 0.250]\n",
      "20098 [D loss: (0.664)(R 0.712, F 0.616)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.962] [G acc: 0.188]\n",
      "20099 [D loss: (1.034)(R 0.753, F 1.314)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.779] [G acc: 0.375]\n",
      "20100 [D loss: (0.617)(R 0.641, F 0.592)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.848] [G acc: 0.500]\n",
      "20101 [D loss: (0.419)(R 0.426, F 0.413)] [D acc: (0.906)(0.875, 0.938)] [G loss: 1.266] [G acc: 0.125]\n",
      "20102 [D loss: (0.600)(R 0.597, F 0.602)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.906] [G acc: 0.188]\n",
      "20103 [D loss: (0.628)(R 0.650, F 0.607)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.940] [G acc: 0.125]\n",
      "20104 [D loss: (0.594)(R 0.555, F 0.632)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.994] [G acc: 0.062]\n",
      "20105 [D loss: (0.575)(R 0.536, F 0.614)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.996] [G acc: 0.312]\n",
      "20106 [D loss: (0.425)(R 0.465, F 0.385)] [D acc: (0.781)(0.625, 0.938)] [G loss: 2.844] [G acc: 0.188]\n",
      "20107 [D loss: (0.553)(R 0.526, F 0.580)] [D acc: (0.781)(0.625, 0.938)] [G loss: 4.720] [G acc: 0.250]\n",
      "20108 [D loss: (0.528)(R 0.541, F 0.515)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.933] [G acc: 0.000]\n",
      "20109 [D loss: (0.512)(R 0.497, F 0.526)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.687] [G acc: 0.500]\n",
      "20110 [D loss: (0.379)(R 0.332, F 0.426)] [D acc: (0.938)(0.938, 0.938)] [G loss: 1.138] [G acc: 0.125]\n",
      "20111 [D loss: (0.492)(R 0.486, F 0.499)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.102] [G acc: 0.062]\n",
      "20112 [D loss: (0.582)(R 0.684, F 0.480)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.003] [G acc: 0.188]\n",
      "20113 [D loss: (0.512)(R 0.480, F 0.544)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.020] [G acc: 0.188]\n",
      "20114 [D loss: (0.442)(R 0.427, F 0.457)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.109] [G acc: 0.062]\n",
      "20115 [D loss: (0.438)(R 0.422, F 0.455)] [D acc: (0.938)(0.875, 1.000)] [G loss: 0.963] [G acc: 0.125]\n",
      "20116 [D loss: (0.583)(R 0.602, F 0.564)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.079] [G acc: 0.188]\n",
      "20117 [D loss: (0.473)(R 0.372, F 0.573)] [D acc: (0.906)(0.875, 0.938)] [G loss: 0.954] [G acc: 0.125]\n",
      "20118 [D loss: (0.498)(R 0.526, F 0.469)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.796] [G acc: 0.438]\n",
      "20119 [D loss: (0.522)(R 0.486, F 0.559)] [D acc: (0.844)(0.812, 0.875)] [G loss: 3.491] [G acc: 0.375]\n",
      "20120 [D loss: (0.318)(R 0.525, F 0.112)] [D acc: (0.875)(0.812, 0.938)] [G loss: 7.687] [G acc: 0.062]\n",
      "20121 [D loss: (0.466)(R 0.562, F 0.370)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.713] [G acc: 0.000]\n",
      "20122 [D loss: (0.589)(R 0.712, F 0.465)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.110] [G acc: 0.062]\n",
      "20123 [D loss: (0.454)(R 0.446, F 0.463)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.079] [G acc: 0.188]\n",
      "20124 [D loss: (0.358)(R 0.358, F 0.359)] [D acc: (0.938)(0.938, 0.938)] [G loss: 0.436] [G acc: 0.688]\n",
      "20125 [D loss: (0.444)(R 0.443, F 0.446)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.125] [G acc: 0.188]\n",
      "20126 [D loss: (0.445)(R 0.465, F 0.426)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.892] [G acc: 0.312]\n",
      "20127 [D loss: (0.407)(R 0.450, F 0.364)] [D acc: (0.875)(0.750, 1.000)] [G loss: 1.604] [G acc: 0.125]\n",
      "20128 [D loss: (0.245)(R 0.305, F 0.185)] [D acc: (0.969)(0.938, 1.000)] [G loss: 4.408] [G acc: 0.062]\n",
      "20129 [D loss: (0.324)(R 0.438, F 0.210)] [D acc: (0.906)(0.812, 1.000)] [G loss: 1.449] [G acc: 0.125]\n",
      "20130 [D loss: (0.351)(R 0.451, F 0.251)] [D acc: (0.938)(0.875, 1.000)] [G loss: 1.669] [G acc: 0.062]\n",
      "20131 [D loss: (1.236)(R 2.073, F 0.399)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.270] [G acc: 0.062]\n",
      "20132 [D loss: (0.542)(R 0.604, F 0.479)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.138] [G acc: 0.188]\n",
      "20133 [D loss: (0.358)(R 0.231, F 0.485)] [D acc: (0.875)(1.000, 0.750)] [G loss: 1.350] [G acc: 0.125]\n",
      "20134 [D loss: (0.357)(R 0.167, F 0.547)] [D acc: (0.844)(1.000, 0.688)] [G loss: 0.616] [G acc: 0.625]\n",
      "20135 [D loss: (0.419)(R 0.336, F 0.502)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.461] [G acc: 0.188]\n",
      "20136 [D loss: (0.560)(R 0.479, F 0.641)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.492] [G acc: 0.125]\n",
      "20137 [D loss: (0.542)(R 0.481, F 0.602)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.508] [G acc: 0.875]\n",
      "20138 [D loss: (0.340)(R 0.265, F 0.414)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.269] [G acc: 0.250]\n",
      "20139 [D loss: (0.317)(R 0.358, F 0.275)] [D acc: (0.875)(0.812, 0.938)] [G loss: 2.252] [G acc: 0.250]\n",
      "20140 [D loss: (0.348)(R 0.403, F 0.293)] [D acc: (0.938)(0.938, 0.938)] [G loss: 0.944] [G acc: 0.312]\n",
      "20141 [D loss: (0.620)(R 0.532, F 0.708)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.439] [G acc: 0.312]\n",
      "20142 [D loss: (0.448)(R 0.588, F 0.308)] [D acc: (0.750)(0.688, 0.812)] [G loss: 2.071] [G acc: 0.062]\n",
      "20143 [D loss: (0.546)(R 0.750, F 0.341)] [D acc: (0.719)(0.500, 0.938)] [G loss: 0.984] [G acc: 0.375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20144 [D loss: (0.747)(R 0.864, F 0.630)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.333] [G acc: 0.250]\n",
      "20145 [D loss: (0.473)(R 0.460, F 0.487)] [D acc: (0.781)(0.750, 0.812)] [G loss: 2.409] [G acc: 0.000]\n",
      "20146 [D loss: (0.315)(R 0.346, F 0.284)] [D acc: (0.938)(0.875, 1.000)] [G loss: 1.289] [G acc: 0.188]\n",
      "20147 [D loss: (1.009)(R 0.552, F 1.467)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.694] [G acc: 0.062]\n",
      "20148 [D loss: (0.343)(R 0.447, F 0.239)] [D acc: (0.906)(0.875, 0.938)] [G loss: 1.478] [G acc: 0.062]\n",
      "20149 [D loss: (0.413)(R 0.359, F 0.467)] [D acc: (0.906)(0.938, 0.875)] [G loss: 2.468] [G acc: 0.125]\n",
      "20150 [D loss: (0.313)(R 0.403, F 0.224)] [D acc: (0.938)(0.938, 0.938)] [G loss: 1.121] [G acc: 0.250]\n",
      "20151 [D loss: (0.544)(R 0.555, F 0.532)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.406] [G acc: 0.125]\n",
      "20152 [D loss: (0.464)(R 0.476, F 0.451)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.406] [G acc: 0.125]\n",
      "20153 [D loss: (0.585)(R 0.609, F 0.561)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.205] [G acc: 0.000]\n",
      "20154 [D loss: (0.418)(R 0.317, F 0.519)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.840] [G acc: 0.188]\n",
      "20155 [D loss: (0.397)(R 0.486, F 0.307)] [D acc: (0.906)(0.875, 0.938)] [G loss: 3.012] [G acc: 0.125]\n",
      "20156 [D loss: (0.557)(R 0.588, F 0.526)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.464] [G acc: 0.812]\n",
      "20157 [D loss: (0.515)(R 0.590, F 0.440)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.365] [G acc: 0.250]\n",
      "20158 [D loss: (0.391)(R 0.377, F 0.406)] [D acc: (0.875)(0.938, 0.812)] [G loss: 2.814] [G acc: 0.125]\n",
      "20159 [D loss: (0.470)(R 0.720, F 0.220)] [D acc: (0.781)(0.688, 0.875)] [G loss: 5.361] [G acc: 0.000]\n",
      "20160 [D loss: (0.478)(R 0.455, F 0.501)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.603] [G acc: 0.688]\n",
      "20161 [D loss: (0.520)(R 0.425, F 0.616)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.769] [G acc: 0.500]\n",
      "20162 [D loss: (0.955)(R 0.583, F 1.326)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.258] [G acc: 0.250]\n",
      "20163 [D loss: (0.508)(R 0.717, F 0.300)] [D acc: (0.781)(0.562, 1.000)] [G loss: 1.784] [G acc: 0.125]\n",
      "20164 [D loss: (0.584)(R 0.281, F 0.887)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.447] [G acc: 0.750]\n",
      "20165 [D loss: (0.534)(R 0.576, F 0.492)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.238] [G acc: 0.250]\n",
      "20166 [D loss: (0.933)(R 0.492, F 1.373)] [D acc: (0.688)(0.812, 0.562)] [G loss: 1.749] [G acc: 0.562]\n",
      "20167 [D loss: (0.596)(R 0.747, F 0.444)] [D acc: (0.688)(0.500, 0.875)] [G loss: 1.972] [G acc: 0.188]\n",
      "20168 [D loss: (0.438)(R 0.457, F 0.419)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.329] [G acc: 0.438]\n",
      "20169 [D loss: (0.400)(R 0.429, F 0.371)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.813] [G acc: 0.125]\n",
      "20170 [D loss: (0.423)(R 0.359, F 0.487)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.524] [G acc: 0.000]\n",
      "20171 [D loss: (0.784)(R 0.601, F 0.968)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.603] [G acc: 0.688]\n",
      "20172 [D loss: (1.723)(R 0.490, F 2.956)] [D acc: (0.625)(0.812, 0.438)] [G loss: 1.027] [G acc: 0.250]\n",
      "20173 [D loss: (0.496)(R 0.824, F 0.169)] [D acc: (0.781)(0.562, 1.000)] [G loss: 1.366] [G acc: 0.188]\n",
      "20174 [D loss: (0.485)(R 0.466, F 0.504)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.301] [G acc: 0.062]\n",
      "20175 [D loss: (0.526)(R 0.375, F 0.677)] [D acc: (0.781)(0.938, 0.625)] [G loss: 1.195] [G acc: 0.250]\n",
      "20176 [D loss: (0.591)(R 0.781, F 0.401)] [D acc: (0.875)(0.812, 0.938)] [G loss: 0.919] [G acc: 0.375]\n",
      "20177 [D loss: (0.438)(R 0.416, F 0.460)] [D acc: (0.844)(0.875, 0.812)] [G loss: 0.738] [G acc: 0.625]\n",
      "20178 [D loss: (0.639)(R 0.396, F 0.882)] [D acc: (0.688)(0.875, 0.500)] [G loss: 1.008] [G acc: 0.438]\n",
      "20179 [D loss: (0.540)(R 0.894, F 0.185)] [D acc: (0.781)(0.625, 0.938)] [G loss: 4.058] [G acc: 0.000]\n",
      "20180 [D loss: (1.017)(R 0.401, F 1.633)] [D acc: (0.688)(0.875, 0.500)] [G loss: 2.055] [G acc: 0.500]\n",
      "20181 [D loss: (0.563)(R 0.704, F 0.422)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.988] [G acc: 0.375]\n",
      "20182 [D loss: (0.681)(R 0.734, F 0.629)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.980] [G acc: 0.375]\n",
      "20183 [D loss: (0.675)(R 0.467, F 0.883)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.969] [G acc: 0.250]\n",
      "20184 [D loss: (1.182)(R 0.528, F 1.836)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.683] [G acc: 0.500]\n",
      "20185 [D loss: (0.878)(R 0.532, F 1.224)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.775] [G acc: 0.562]\n",
      "20186 [D loss: (0.612)(R 0.473, F 0.750)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.622] [G acc: 0.688]\n",
      "20187 [D loss: (0.674)(R 0.680, F 0.668)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.918] [G acc: 0.438]\n",
      "20188 [D loss: (0.712)(R 0.599, F 0.826)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.673] [G acc: 0.562]\n",
      "20189 [D loss: (0.837)(R 0.511, F 1.163)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.748] [G acc: 0.500]\n",
      "20190 [D loss: (0.737)(R 0.641, F 0.834)] [D acc: (0.594)(0.750, 0.438)] [G loss: 1.011] [G acc: 0.312]\n",
      "20191 [D loss: (0.758)(R 0.535, F 0.982)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.027] [G acc: 0.250]\n",
      "20192 [D loss: (0.934)(R 1.242, F 0.626)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.862] [G acc: 0.375]\n",
      "20193 [D loss: (0.689)(R 0.601, F 0.777)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.042] [G acc: 0.500]\n",
      "20194 [D loss: (0.651)(R 0.501, F 0.801)] [D acc: (0.594)(0.750, 0.438)] [G loss: 1.828] [G acc: 0.250]\n",
      "20195 [D loss: (0.357)(R 0.568, F 0.146)] [D acc: (0.844)(0.688, 1.000)] [G loss: 7.131] [G acc: 0.125]\n",
      "20196 [D loss: (0.418)(R 0.489, F 0.347)] [D acc: (0.812)(0.875, 0.750)] [G loss: 2.386] [G acc: 0.562]\n",
      "20197 [D loss: (0.473)(R 0.575, F 0.371)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.316] [G acc: 0.125]\n",
      "20198 [D loss: (0.502)(R 0.437, F 0.567)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.453] [G acc: 0.438]\n",
      "20199 [D loss: (0.619)(R 0.453, F 0.786)] [D acc: (0.688)(0.812, 0.562)] [G loss: 1.321] [G acc: 0.188]\n",
      "20200 [D loss: (0.558)(R 0.537, F 0.579)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.714] [G acc: 0.438]\n",
      "20201 [D loss: (0.657)(R 0.748, F 0.567)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.520] [G acc: 0.062]\n",
      "20202 [D loss: (0.692)(R 0.681, F 0.703)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.969] [G acc: 0.188]\n",
      "20203 [D loss: (0.633)(R 0.655, F 0.610)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.978] [G acc: 0.312]\n",
      "20204 [D loss: (0.577)(R 0.514, F 0.640)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.820] [G acc: 0.375]\n",
      "20205 [D loss: (0.785)(R 0.527, F 1.044)] [D acc: (0.625)(0.750, 0.500)] [G loss: 1.043] [G acc: 0.375]\n",
      "20206 [D loss: (0.461)(R 0.704, F 0.217)] [D acc: (0.812)(0.625, 1.000)] [G loss: 1.478] [G acc: 0.062]\n",
      "20207 [D loss: (0.485)(R 0.521, F 0.450)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.009] [G acc: 0.188]\n",
      "20208 [D loss: (0.705)(R 0.687, F 0.724)] [D acc: (0.531)(0.688, 0.375)] [G loss: 1.016] [G acc: 0.188]\n",
      "20209 [D loss: (0.548)(R 0.507, F 0.589)] [D acc: (0.844)(0.938, 0.750)] [G loss: 0.756] [G acc: 0.562]\n",
      "20210 [D loss: (0.933)(R 0.766, F 1.100)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.879] [G acc: 0.188]\n",
      "20211 [D loss: (0.431)(R 0.550, F 0.313)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.197] [G acc: 0.250]\n",
      "20212 [D loss: (0.541)(R 0.561, F 0.521)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.017] [G acc: 0.125]\n",
      "20213 [D loss: (0.646)(R 0.583, F 0.710)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.709] [G acc: 0.562]\n",
      "20214 [D loss: (0.638)(R 0.694, F 0.582)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.037] [G acc: 0.438]\n",
      "20215 [D loss: (1.559)(R 2.564, F 0.554)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.703] [G acc: 0.125]\n",
      "20216 [D loss: (0.524)(R 0.569, F 0.480)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.082] [G acc: 0.125]\n",
      "20217 [D loss: (0.429)(R 0.400, F 0.459)] [D acc: (0.875)(0.938, 0.812)] [G loss: 1.018] [G acc: 0.250]\n",
      "20218 [D loss: (0.610)(R 0.651, F 0.568)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.592] [G acc: 0.562]\n",
      "20219 [D loss: (0.465)(R 0.459, F 0.471)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.942] [G acc: 0.188]\n",
      "20220 [D loss: (0.488)(R 0.602, F 0.374)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.995] [G acc: 0.062]\n",
      "20221 [D loss: (0.645)(R 0.647, F 0.642)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.087] [G acc: 0.188]\n",
      "20222 [D loss: (0.558)(R 0.571, F 0.545)] [D acc: (0.688)(0.688, 0.688)] [G loss: 2.262] [G acc: 0.125]\n",
      "20223 [D loss: (0.394)(R 0.673, F 0.115)] [D acc: (0.750)(0.500, 1.000)] [G loss: 4.343] [G acc: 0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20224 [D loss: (0.454)(R 0.552, F 0.357)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.163] [G acc: 0.125]\n",
      "20225 [D loss: (0.531)(R 0.729, F 0.333)] [D acc: (0.844)(0.688, 1.000)] [G loss: 0.875] [G acc: 0.375]\n",
      "20226 [D loss: (0.481)(R 0.536, F 0.427)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.179] [G acc: 0.125]\n",
      "20227 [D loss: (0.573)(R 0.355, F 0.791)] [D acc: (0.906)(0.938, 0.875)] [G loss: 1.147] [G acc: 0.062]\n",
      "20228 [D loss: (0.476)(R 0.602, F 0.351)] [D acc: (0.875)(0.750, 1.000)] [G loss: 1.022] [G acc: 0.125]\n",
      "20229 [D loss: (0.437)(R 0.385, F 0.490)] [D acc: (0.906)(0.875, 0.938)] [G loss: 1.376] [G acc: 0.062]\n",
      "20230 [D loss: (0.401)(R 0.433, F 0.368)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.071] [G acc: 0.250]\n",
      "20231 [D loss: (0.566)(R 0.711, F 0.421)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.092] [G acc: 0.062]\n",
      "20232 [D loss: (0.500)(R 0.432, F 0.569)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.146] [G acc: 0.125]\n",
      "20233 [D loss: (0.616)(R 0.878, F 0.354)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.311] [G acc: 0.188]\n",
      "20234 [D loss: (0.424)(R 0.498, F 0.350)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.558] [G acc: 0.062]\n",
      "20235 [D loss: (0.336)(R 0.270, F 0.402)] [D acc: (0.906)(1.000, 0.812)] [G loss: 0.773] [G acc: 0.375]\n",
      "20236 [D loss: (0.539)(R 0.550, F 0.529)] [D acc: (0.781)(0.750, 0.812)] [G loss: 2.787] [G acc: 0.125]\n",
      "20237 [D loss: (0.309)(R 0.381, F 0.236)] [D acc: (0.875)(0.875, 0.875)] [G loss: 3.169] [G acc: 0.062]\n",
      "20238 [D loss: (0.402)(R 0.504, F 0.300)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.543] [G acc: 0.000]\n",
      "20239 [D loss: (0.404)(R 0.433, F 0.375)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.006] [G acc: 0.500]\n",
      "20240 [D loss: (0.404)(R 0.471, F 0.338)] [D acc: (0.875)(0.750, 1.000)] [G loss: 1.363] [G acc: 0.062]\n",
      "20241 [D loss: (0.492)(R 0.536, F 0.448)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.360] [G acc: 0.125]\n",
      "20242 [D loss: (0.518)(R 0.515, F 0.521)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.008] [G acc: 0.438]\n",
      "20243 [D loss: (0.369)(R 0.308, F 0.430)] [D acc: (0.875)(0.938, 0.812)] [G loss: 1.318] [G acc: 0.062]\n",
      "20244 [D loss: (0.505)(R 0.504, F 0.506)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.305] [G acc: 0.000]\n",
      "20245 [D loss: (0.435)(R 0.436, F 0.433)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.408] [G acc: 0.125]\n",
      "20246 [D loss: (0.487)(R 0.486, F 0.488)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.951] [G acc: 0.500]\n",
      "20247 [D loss: (0.431)(R 0.378, F 0.484)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.327] [G acc: 0.125]\n",
      "20248 [D loss: (0.564)(R 0.707, F 0.420)] [D acc: (0.656)(0.562, 0.750)] [G loss: 2.426] [G acc: 0.375]\n",
      "20249 [D loss: (0.413)(R 0.574, F 0.251)] [D acc: (0.812)(0.688, 0.938)] [G loss: 6.660] [G acc: 0.062]\n",
      "20250 [D loss: (0.473)(R 0.412, F 0.534)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.407] [G acc: 0.188]\n",
      "20251 [D loss: (0.672)(R 0.712, F 0.632)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.192] [G acc: 0.312]\n",
      "20252 [D loss: (0.781)(R 0.836, F 0.725)] [D acc: (0.531)(0.375, 0.688)] [G loss: 1.317] [G acc: 0.188]\n",
      "20253 [D loss: (0.611)(R 0.454, F 0.768)] [D acc: (0.562)(0.688, 0.438)] [G loss: 1.562] [G acc: 0.125]\n",
      "20254 [D loss: (0.855)(R 0.444, F 1.266)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.902] [G acc: 0.375]\n",
      "20255 [D loss: (0.897)(R 0.500, F 1.294)] [D acc: (0.688)(0.812, 0.562)] [G loss: 1.557] [G acc: 0.000]\n",
      "20256 [D loss: (0.527)(R 0.755, F 0.300)] [D acc: (0.688)(0.500, 0.875)] [G loss: 1.569] [G acc: 0.250]\n",
      "20257 [D loss: (0.481)(R 0.602, F 0.359)] [D acc: (0.812)(0.625, 1.000)] [G loss: 0.499] [G acc: 0.688]\n",
      "20258 [D loss: (1.055)(R 1.382, F 0.727)] [D acc: (0.562)(0.562, 0.562)] [G loss: 1.470] [G acc: 0.125]\n",
      "20259 [D loss: (0.542)(R 0.658, F 0.427)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.243] [G acc: 0.188]\n",
      "20260 [D loss: (0.396)(R 0.522, F 0.270)] [D acc: (0.844)(0.688, 1.000)] [G loss: 1.662] [G acc: 0.250]\n",
      "20261 [D loss: (0.446)(R 0.353, F 0.538)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.886] [G acc: 0.375]\n",
      "20262 [D loss: (0.327)(R 0.403, F 0.251)] [D acc: (0.906)(0.938, 0.875)] [G loss: 2.536] [G acc: 0.250]\n",
      "20263 [D loss: (0.549)(R 0.501, F 0.597)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.750] [G acc: 0.062]\n",
      "20264 [D loss: (0.672)(R 0.610, F 0.734)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.303] [G acc: 0.188]\n",
      "20265 [D loss: (0.715)(R 0.470, F 0.960)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.413] [G acc: 0.125]\n",
      "20266 [D loss: (0.530)(R 0.526, F 0.534)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.021] [G acc: 0.188]\n",
      "20267 [D loss: (0.528)(R 0.581, F 0.476)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.048] [G acc: 0.562]\n",
      "20268 [D loss: (0.715)(R 0.856, F 0.573)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.702] [G acc: 0.312]\n",
      "20269 [D loss: (0.479)(R 0.593, F 0.366)] [D acc: (0.719)(0.688, 0.750)] [G loss: 4.336] [G acc: 0.062]\n",
      "20270 [D loss: (0.563)(R 0.555, F 0.571)] [D acc: (0.719)(0.688, 0.750)] [G loss: 2.842] [G acc: 0.312]\n",
      "20271 [D loss: (0.502)(R 0.450, F 0.553)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.758] [G acc: 0.688]\n",
      "20272 [D loss: (0.575)(R 0.452, F 0.699)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.372] [G acc: 0.062]\n",
      "20273 [D loss: (0.484)(R 0.558, F 0.411)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.456] [G acc: 0.062]\n",
      "20274 [D loss: (0.419)(R 0.448, F 0.391)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.868] [G acc: 0.562]\n",
      "20275 [D loss: (0.617)(R 0.649, F 0.586)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.031] [G acc: 0.188]\n",
      "20276 [D loss: (0.444)(R 0.408, F 0.480)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.242] [G acc: 0.062]\n",
      "20277 [D loss: (0.471)(R 0.444, F 0.499)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.253] [G acc: 0.062]\n",
      "20278 [D loss: (0.735)(R 0.766, F 0.704)] [D acc: (0.562)(0.500, 0.625)] [G loss: 1.809] [G acc: 0.188]\n",
      "20279 [D loss: (0.414)(R 0.580, F 0.248)] [D acc: (0.812)(0.750, 0.875)] [G loss: 2.979] [G acc: 0.125]\n",
      "20280 [D loss: (0.662)(R 0.755, F 0.568)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.275] [G acc: 0.312]\n",
      "20281 [D loss: (0.657)(R 0.582, F 0.733)] [D acc: (0.500)(0.562, 0.438)] [G loss: 1.107] [G acc: 0.188]\n",
      "20282 [D loss: (0.626)(R 0.604, F 0.648)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.009] [G acc: 0.188]\n",
      "20283 [D loss: (0.604)(R 0.646, F 0.562)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.107] [G acc: 0.250]\n",
      "20284 [D loss: (0.559)(R 0.741, F 0.378)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.619] [G acc: 0.125]\n",
      "20285 [D loss: (0.495)(R 0.270, F 0.720)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.902] [G acc: 0.312]\n",
      "20286 [D loss: (0.553)(R 0.510, F 0.597)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.122] [G acc: 0.062]\n",
      "20287 [D loss: (0.768)(R 0.900, F 0.637)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.948] [G acc: 0.250]\n",
      "20288 [D loss: (0.459)(R 0.473, F 0.445)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.080] [G acc: 0.188]\n",
      "20289 [D loss: (0.571)(R 0.485, F 0.657)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.156] [G acc: 0.000]\n",
      "20290 [D loss: (0.556)(R 0.611, F 0.502)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.968] [G acc: 0.250]\n",
      "20291 [D loss: (0.579)(R 0.609, F 0.549)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.589] [G acc: 0.562]\n",
      "20292 [D loss: (0.505)(R 0.441, F 0.570)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.051] [G acc: 0.250]\n",
      "20293 [D loss: (0.363)(R 0.529, F 0.197)] [D acc: (0.812)(0.625, 1.000)] [G loss: 1.397] [G acc: 0.062]\n",
      "20294 [D loss: (0.714)(R 0.757, F 0.671)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.733] [G acc: 0.500]\n",
      "20295 [D loss: (0.442)(R 0.344, F 0.540)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.048] [G acc: 0.250]\n",
      "20296 [D loss: (0.555)(R 0.607, F 0.503)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.085] [G acc: 0.188]\n",
      "20297 [D loss: (0.471)(R 0.341, F 0.601)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.935] [G acc: 0.438]\n",
      "20298 [D loss: (0.518)(R 0.436, F 0.600)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.925] [G acc: 0.250]\n",
      "20299 [D loss: (0.463)(R 0.392, F 0.533)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.876] [G acc: 0.438]\n",
      "20300 [D loss: (0.591)(R 0.482, F 0.700)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.859] [G acc: 0.438]\n",
      "20301 [D loss: (0.424)(R 0.333, F 0.516)] [D acc: (0.750)(0.875, 0.625)] [G loss: 1.583] [G acc: 0.312]\n",
      "20302 [D loss: (0.311)(R 0.463, F 0.159)] [D acc: (0.844)(0.750, 0.938)] [G loss: 6.148] [G acc: 0.062]\n",
      "20303 [D loss: (0.482)(R 0.362, F 0.601)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.165] [G acc: 0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20304 [D loss: (0.633)(R 0.746, F 0.521)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.703] [G acc: 0.438]\n",
      "20305 [D loss: (0.442)(R 0.277, F 0.606)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.055] [G acc: 0.188]\n",
      "20306 [D loss: (0.517)(R 0.511, F 0.523)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.981] [G acc: 0.375]\n",
      "20307 [D loss: (0.429)(R 0.621, F 0.238)] [D acc: (0.781)(0.562, 1.000)] [G loss: 1.429] [G acc: 0.062]\n",
      "20308 [D loss: (0.341)(R 0.283, F 0.399)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.447] [G acc: 0.250]\n",
      "20309 [D loss: (0.480)(R 0.537, F 0.424)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.100] [G acc: 0.188]\n",
      "20310 [D loss: (0.503)(R 0.486, F 0.519)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.170] [G acc: 0.188]\n",
      "20311 [D loss: (0.347)(R 0.337, F 0.357)] [D acc: (0.906)(0.812, 1.000)] [G loss: 1.366] [G acc: 0.375]\n",
      "20312 [D loss: (0.707)(R 0.986, F 0.427)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.268] [G acc: 0.312]\n",
      "20313 [D loss: (0.329)(R 0.429, F 0.228)] [D acc: (0.844)(0.688, 1.000)] [G loss: 1.244] [G acc: 0.250]\n",
      "20314 [D loss: (0.630)(R 0.493, F 0.767)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.174] [G acc: 0.312]\n",
      "20315 [D loss: (0.519)(R 0.431, F 0.607)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.064] [G acc: 0.188]\n",
      "20316 [D loss: (0.465)(R 0.324, F 0.605)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.045] [G acc: 0.125]\n",
      "20317 [D loss: (0.606)(R 0.562, F 0.650)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.157] [G acc: 0.188]\n",
      "20318 [D loss: (0.496)(R 0.389, F 0.603)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.171] [G acc: 0.062]\n",
      "20319 [D loss: (0.466)(R 0.504, F 0.429)] [D acc: (0.781)(0.688, 0.875)] [G loss: 2.081] [G acc: 0.062]\n",
      "20320 [D loss: (0.445)(R 0.555, F 0.336)] [D acc: (0.844)(0.688, 1.000)] [G loss: 1.085] [G acc: 0.062]\n",
      "20321 [D loss: (0.501)(R 0.709, F 0.293)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.132] [G acc: 0.188]\n",
      "20322 [D loss: (0.462)(R 0.622, F 0.302)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.285] [G acc: 0.188]\n",
      "20323 [D loss: (0.311)(R 0.364, F 0.258)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.918] [G acc: 0.188]\n",
      "20324 [D loss: (0.648)(R 0.583, F 0.713)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.089] [G acc: 0.188]\n",
      "20325 [D loss: (0.461)(R 0.362, F 0.561)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.692] [G acc: 0.250]\n",
      "20326 [D loss: (0.437)(R 0.567, F 0.307)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.671] [G acc: 0.125]\n",
      "20327 [D loss: (0.470)(R 0.431, F 0.509)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.173] [G acc: 0.188]\n",
      "20328 [D loss: (0.468)(R 0.510, F 0.427)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.437] [G acc: 0.062]\n",
      "20329 [D loss: (0.452)(R 0.402, F 0.502)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.128] [G acc: 0.125]\n",
      "20330 [D loss: (0.494)(R 0.517, F 0.472)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.038] [G acc: 0.125]\n",
      "20331 [D loss: (0.471)(R 0.482, F 0.460)] [D acc: (0.844)(0.688, 1.000)] [G loss: 1.499] [G acc: 0.125]\n",
      "20332 [D loss: (0.626)(R 0.496, F 0.757)] [D acc: (0.531)(0.562, 0.500)] [G loss: 1.087] [G acc: 0.188]\n",
      "20333 [D loss: (0.496)(R 0.441, F 0.552)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.255] [G acc: 0.125]\n",
      "20334 [D loss: (0.439)(R 0.440, F 0.439)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.050] [G acc: 0.188]\n",
      "20335 [D loss: (0.462)(R 0.408, F 0.515)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.939] [G acc: 0.375]\n",
      "20336 [D loss: (0.600)(R 0.658, F 0.542)] [D acc: (0.844)(0.875, 0.812)] [G loss: 0.699] [G acc: 0.562]\n",
      "20337 [D loss: (0.459)(R 0.436, F 0.481)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.151] [G acc: 0.188]\n",
      "20338 [D loss: (0.481)(R 0.406, F 0.556)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.124] [G acc: 0.188]\n",
      "20339 [D loss: (0.291)(R 0.302, F 0.280)] [D acc: (0.938)(0.875, 1.000)] [G loss: 1.901] [G acc: 0.062]\n",
      "20340 [D loss: (0.476)(R 0.437, F 0.515)] [D acc: (0.844)(0.938, 0.750)] [G loss: 1.086] [G acc: 0.125]\n",
      "20341 [D loss: (0.695)(R 0.528, F 0.862)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.241] [G acc: 0.188]\n",
      "20342 [D loss: (0.434)(R 0.327, F 0.541)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.890] [G acc: 0.438]\n",
      "20343 [D loss: (0.461)(R 0.570, F 0.353)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.415] [G acc: 0.188]\n",
      "20344 [D loss: (0.635)(R 0.542, F 0.728)] [D acc: (0.750)(0.688, 0.812)] [G loss: 6.855] [G acc: 0.062]\n",
      "20345 [D loss: (0.579)(R 0.569, F 0.588)] [D acc: (0.812)(0.750, 0.875)] [G loss: 2.444] [G acc: 0.125]\n",
      "20346 [D loss: (0.477)(R 0.394, F 0.559)] [D acc: (0.656)(0.688, 0.625)] [G loss: 2.575] [G acc: 0.125]\n",
      "20347 [D loss: (0.521)(R 0.584, F 0.457)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.136] [G acc: 0.188]\n",
      "20348 [D loss: (0.522)(R 0.356, F 0.688)] [D acc: (0.781)(0.875, 0.688)] [G loss: 9.904] [G acc: 0.188]\n",
      "20349 [D loss: (0.379)(R 0.351, F 0.408)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.290] [G acc: 0.125]\n",
      "20350 [D loss: (0.385)(R 0.225, F 0.544)] [D acc: (0.906)(1.000, 0.812)] [G loss: 1.155] [G acc: 0.188]\n",
      "20351 [D loss: (0.477)(R 0.358, F 0.596)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.975] [G acc: 0.250]\n",
      "20352 [D loss: (0.521)(R 0.555, F 0.486)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.171] [G acc: 0.062]\n",
      "20353 [D loss: (0.573)(R 0.616, F 0.530)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.401] [G acc: 0.125]\n",
      "20354 [D loss: (0.573)(R 0.551, F 0.595)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.304] [G acc: 0.125]\n",
      "20355 [D loss: (0.484)(R 0.532, F 0.436)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.273] [G acc: 0.062]\n",
      "20356 [D loss: (0.569)(R 0.491, F 0.648)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.371] [G acc: 0.188]\n",
      "20357 [D loss: (0.438)(R 0.420, F 0.456)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.154] [G acc: 0.250]\n",
      "20358 [D loss: (0.474)(R 0.484, F 0.465)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.605] [G acc: 0.500]\n",
      "20359 [D loss: (0.388)(R 0.449, F 0.328)] [D acc: (0.906)(0.875, 0.938)] [G loss: 1.906] [G acc: 0.125]\n",
      "20360 [D loss: (0.396)(R 0.368, F 0.424)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.078] [G acc: 0.250]\n",
      "20361 [D loss: (0.458)(R 0.448, F 0.467)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.906] [G acc: 0.375]\n",
      "20362 [D loss: (0.487)(R 0.548, F 0.426)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.395] [G acc: 0.062]\n",
      "20363 [D loss: (0.570)(R 0.689, F 0.450)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.289] [G acc: 0.250]\n",
      "20364 [D loss: (0.616)(R 0.587, F 0.645)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.005] [G acc: 0.188]\n",
      "20365 [D loss: (0.540)(R 0.766, F 0.313)] [D acc: (0.812)(0.625, 1.000)] [G loss: 0.931] [G acc: 0.250]\n",
      "20366 [D loss: (0.408)(R 0.420, F 0.395)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.990] [G acc: 0.250]\n",
      "20367 [D loss: (0.530)(R 0.453, F 0.608)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.043] [G acc: 0.188]\n",
      "20368 [D loss: (0.534)(R 0.488, F 0.581)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.921] [G acc: 0.312]\n",
      "20369 [D loss: (0.587)(R 0.528, F 0.646)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.357] [G acc: 0.250]\n",
      "20370 [D loss: (0.503)(R 0.365, F 0.641)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.121] [G acc: 0.312]\n",
      "20371 [D loss: (0.468)(R 0.515, F 0.420)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.586] [G acc: 0.125]\n",
      "20372 [D loss: (0.559)(R 0.347, F 0.771)] [D acc: (0.688)(0.812, 0.562)] [G loss: 2.728] [G acc: 0.375]\n",
      "20373 [D loss: (0.571)(R 0.557, F 0.586)] [D acc: (0.656)(0.688, 0.625)] [G loss: 3.577] [G acc: 0.188]\n",
      "20374 [D loss: (0.449)(R 0.346, F 0.553)] [D acc: (0.781)(0.875, 0.688)] [G loss: 4.786] [G acc: 0.250]\n",
      "20375 [D loss: (0.451)(R 0.564, F 0.338)] [D acc: (0.781)(0.750, 0.812)] [G loss: 2.240] [G acc: 0.188]\n",
      "20376 [D loss: (0.516)(R 0.566, F 0.466)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.280] [G acc: 0.312]\n",
      "20377 [D loss: (0.650)(R 0.652, F 0.648)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.898] [G acc: 0.250]\n",
      "20378 [D loss: (0.495)(R 0.356, F 0.635)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.828] [G acc: 0.562]\n",
      "20379 [D loss: (0.573)(R 0.581, F 0.565)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.019] [G acc: 0.375]\n",
      "20380 [D loss: (0.598)(R 0.426, F 0.769)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.477] [G acc: 0.875]\n",
      "20381 [D loss: (0.478)(R 0.359, F 0.597)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.910] [G acc: 0.312]\n",
      "20382 [D loss: (0.690)(R 0.483, F 0.896)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.499] [G acc: 0.812]\n",
      "20383 [D loss: (0.545)(R 0.464, F 0.626)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.046] [G acc: 0.375]\n",
      "20384 [D loss: (0.830)(R 0.786, F 0.874)] [D acc: (0.594)(0.688, 0.500)] [G loss: 1.082] [G acc: 0.250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20385 [D loss: (0.651)(R 0.604, F 0.697)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.489] [G acc: 0.688]\n",
      "20386 [D loss: (0.571)(R 0.526, F 0.616)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.870] [G acc: 0.312]\n",
      "20387 [D loss: (1.103)(R 0.330, F 1.876)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.805] [G acc: 0.500]\n",
      "20388 [D loss: (0.851)(R 0.881, F 0.820)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.664] [G acc: 0.562]\n",
      "20389 [D loss: (0.993)(R 0.666, F 1.320)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.642] [G acc: 0.562]\n",
      "20390 [D loss: (0.749)(R 0.477, F 1.022)] [D acc: (0.594)(0.750, 0.438)] [G loss: 1.009] [G acc: 0.312]\n",
      "20391 [D loss: (0.603)(R 0.623, F 0.583)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.905] [G acc: 0.250]\n",
      "20392 [D loss: (0.713)(R 0.537, F 0.888)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.760] [G acc: 0.438]\n",
      "20393 [D loss: (0.647)(R 0.503, F 0.791)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.676] [G acc: 0.562]\n",
      "20394 [D loss: (0.636)(R 0.495, F 0.777)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.740] [G acc: 0.625]\n",
      "20395 [D loss: (0.603)(R 0.669, F 0.537)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.905] [G acc: 0.312]\n",
      "20396 [D loss: (0.798)(R 0.547, F 1.049)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.610] [G acc: 0.750]\n",
      "20397 [D loss: (0.936)(R 0.586, F 1.285)] [D acc: (0.562)(0.688, 0.438)] [G loss: 1.082] [G acc: 0.312]\n",
      "20398 [D loss: (0.526)(R 0.487, F 0.564)] [D acc: (0.688)(0.812, 0.562)] [G loss: 1.761] [G acc: 0.438]\n",
      "20399 [D loss: (1.266)(R 0.657, F 1.876)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.402] [G acc: 0.250]\n",
      "20400 [D loss: (0.539)(R 0.488, F 0.590)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.319] [G acc: 0.312]\n",
      "20401 [D loss: (0.870)(R 0.662, F 1.077)] [D acc: (0.469)(0.562, 0.375)] [G loss: 1.112] [G acc: 0.188]\n",
      "20402 [D loss: (0.872)(R 0.701, F 1.043)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.853] [G acc: 0.438]\n",
      "20403 [D loss: (0.705)(R 0.718, F 0.692)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.538] [G acc: 0.688]\n",
      "20404 [D loss: (0.779)(R 0.489, F 1.069)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.699] [G acc: 0.500]\n",
      "20405 [D loss: (0.746)(R 0.624, F 0.868)] [D acc: (0.406)(0.500, 0.312)] [G loss: 0.757] [G acc: 0.375]\n",
      "20406 [D loss: (0.729)(R 0.737, F 0.720)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.673] [G acc: 0.625]\n",
      "20407 [D loss: (0.754)(R 0.676, F 0.832)] [D acc: (0.406)(0.375, 0.438)] [G loss: 0.755] [G acc: 0.438]\n",
      "20408 [D loss: (0.662)(R 0.668, F 0.656)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.712] [G acc: 0.500]\n",
      "20409 [D loss: (0.859)(R 0.777, F 0.940)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.898] [G acc: 0.375]\n",
      "20410 [D loss: (0.711)(R 0.731, F 0.690)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.824] [G acc: 0.312]\n",
      "20411 [D loss: (0.819)(R 0.643, F 0.994)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.794] [G acc: 0.438]\n",
      "20412 [D loss: (0.649)(R 0.591, F 0.706)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.006] [G acc: 0.312]\n",
      "20413 [D loss: (0.781)(R 0.712, F 0.849)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.865] [G acc: 0.438]\n",
      "20414 [D loss: (0.656)(R 0.678, F 0.634)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.683] [G acc: 0.250]\n",
      "20415 [D loss: (0.347)(R 0.514, F 0.179)] [D acc: (0.844)(0.750, 0.938)] [G loss: 4.703] [G acc: 0.000]\n",
      "20416 [D loss: (0.574)(R 0.562, F 0.587)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.673] [G acc: 0.312]\n",
      "20417 [D loss: (0.678)(R 0.723, F 0.633)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.962] [G acc: 0.125]\n",
      "20418 [D loss: (0.565)(R 0.587, F 0.544)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.312] [G acc: 0.438]\n",
      "20419 [D loss: (0.725)(R 0.643, F 0.806)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.879] [G acc: 0.312]\n",
      "20420 [D loss: (0.730)(R 0.576, F 0.883)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.632] [G acc: 0.562]\n",
      "20421 [D loss: (0.728)(R 0.647, F 0.809)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.665] [G acc: 0.625]\n",
      "20422 [D loss: (0.763)(R 0.693, F 0.833)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.828] [G acc: 0.375]\n",
      "20423 [D loss: (0.809)(R 0.563, F 1.055)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.320] [G acc: 0.688]\n",
      "20424 [D loss: (0.706)(R 0.518, F 0.894)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.499] [G acc: 0.375]\n",
      "20425 [D loss: (0.502)(R 0.626, F 0.377)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.096] [G acc: 0.125]\n",
      "20426 [D loss: (0.697)(R 0.877, F 0.518)] [D acc: (0.531)(0.312, 0.750)] [G loss: 1.005] [G acc: 0.188]\n",
      "20427 [D loss: (0.627)(R 0.531, F 0.722)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.885] [G acc: 0.250]\n",
      "20428 [D loss: (0.623)(R 0.603, F 0.644)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.944] [G acc: 0.250]\n",
      "20429 [D loss: (0.498)(R 0.686, F 0.309)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.970] [G acc: 0.438]\n",
      "20430 [D loss: (0.532)(R 0.538, F 0.526)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.447] [G acc: 0.125]\n",
      "20431 [D loss: (0.564)(R 0.594, F 0.535)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.800] [G acc: 0.312]\n",
      "20432 [D loss: (0.610)(R 0.733, F 0.488)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.026] [G acc: 0.188]\n",
      "20433 [D loss: (0.607)(R 0.574, F 0.641)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.102] [G acc: 0.312]\n",
      "20434 [D loss: (0.563)(R 0.591, F 0.535)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.095] [G acc: 0.125]\n",
      "20435 [D loss: (0.486)(R 0.592, F 0.380)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.570] [G acc: 0.188]\n",
      "20436 [D loss: (0.445)(R 0.698, F 0.192)] [D acc: (0.688)(0.438, 0.938)] [G loss: 3.221] [G acc: 0.125]\n",
      "20437 [D loss: (0.463)(R 0.549, F 0.376)] [D acc: (0.781)(0.750, 0.812)] [G loss: 3.799] [G acc: 0.125]\n",
      "20438 [D loss: (0.514)(R 0.573, F 0.456)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.734] [G acc: 0.188]\n",
      "20439 [D loss: (0.513)(R 0.509, F 0.516)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.991] [G acc: 0.125]\n",
      "20440 [D loss: (0.625)(R 0.632, F 0.618)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.484] [G acc: 0.812]\n",
      "20441 [D loss: (0.418)(R 0.378, F 0.457)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.752] [G acc: 0.500]\n",
      "20442 [D loss: (0.607)(R 0.641, F 0.574)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.934] [G acc: 0.375]\n",
      "20443 [D loss: (0.521)(R 0.514, F 0.527)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.050] [G acc: 0.062]\n",
      "20444 [D loss: (0.576)(R 0.461, F 0.691)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.311] [G acc: 0.875]\n",
      "20445 [D loss: (0.595)(R 0.408, F 0.783)] [D acc: (0.875)(1.000, 0.750)] [G loss: 0.931] [G acc: 0.312]\n",
      "20446 [D loss: (0.649)(R 0.626, F 0.672)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.023] [G acc: 0.062]\n",
      "20447 [D loss: (0.478)(R 0.489, F 0.466)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.964] [G acc: 0.312]\n",
      "20448 [D loss: (0.640)(R 0.588, F 0.692)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.765] [G acc: 0.375]\n",
      "20449 [D loss: (0.506)(R 0.509, F 0.503)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.905] [G acc: 0.188]\n",
      "20450 [D loss: (0.946)(R 0.858, F 1.034)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.084] [G acc: 0.375]\n",
      "20451 [D loss: (0.610)(R 0.659, F 0.562)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.892] [G acc: 0.312]\n",
      "20452 [D loss: (0.473)(R 0.528, F 0.418)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.991] [G acc: 0.375]\n",
      "20453 [D loss: (0.825)(R 0.591, F 1.059)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.103] [G acc: 0.438]\n",
      "20454 [D loss: (0.493)(R 0.589, F 0.396)] [D acc: (0.750)(0.688, 0.812)] [G loss: 2.857] [G acc: 0.438]\n",
      "20455 [D loss: (0.510)(R 0.544, F 0.476)] [D acc: (0.812)(0.875, 0.750)] [G loss: 5.388] [G acc: 0.438]\n",
      "20456 [D loss: (0.779)(R 0.498, F 1.059)] [D acc: (0.719)(0.812, 0.625)] [G loss: 4.608] [G acc: 0.250]\n",
      "20457 [D loss: (0.367)(R 0.494, F 0.240)] [D acc: (0.906)(0.875, 0.938)] [G loss: 2.388] [G acc: 0.250]\n",
      "20458 [D loss: (1.168)(R 0.498, F 1.838)] [D acc: (0.656)(0.812, 0.500)] [G loss: 1.904] [G acc: 0.250]\n",
      "20459 [D loss: (0.398)(R 0.570, F 0.227)] [D acc: (0.844)(0.812, 0.875)] [G loss: 4.794] [G acc: 0.188]\n",
      "20460 [D loss: (1.931)(R 0.695, F 3.166)] [D acc: (0.625)(0.688, 0.562)] [G loss: 3.570] [G acc: 0.125]\n",
      "20461 [D loss: (0.473)(R 0.728, F 0.218)] [D acc: (0.812)(0.625, 1.000)] [G loss: 1.369] [G acc: 0.312]\n",
      "20462 [D loss: (0.441)(R 0.636, F 0.245)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.410] [G acc: 0.438]\n",
      "20463 [D loss: (0.759)(R 1.210, F 0.308)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.737] [G acc: 0.625]\n",
      "20464 [D loss: (0.606)(R 0.771, F 0.441)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.912] [G acc: 0.125]\n",
      "20465 [D loss: (0.649)(R 0.661, F 0.638)] [D acc: (0.562)(0.500, 0.625)] [G loss: 1.269] [G acc: 0.125]\n",
      "20466 [D loss: (0.535)(R 0.586, F 0.483)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.113] [G acc: 0.250]\n",
      "20467 [D loss: (0.483)(R 0.568, F 0.397)] [D acc: (0.906)(0.812, 1.000)] [G loss: 1.366] [G acc: 0.250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20468 [D loss: (0.619)(R 0.577, F 0.662)] [D acc: (0.625)(0.750, 0.500)] [G loss: 1.609] [G acc: 0.438]\n",
      "20469 [D loss: (0.765)(R 1.095, F 0.434)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.688] [G acc: 0.062]\n",
      "20470 [D loss: (0.453)(R 0.559, F 0.347)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.697] [G acc: 0.125]\n",
      "20471 [D loss: (0.506)(R 0.685, F 0.326)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.294] [G acc: 0.188]\n",
      "20472 [D loss: (0.525)(R 0.574, F 0.475)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.111] [G acc: 0.062]\n",
      "20473 [D loss: (0.625)(R 0.559, F 0.690)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.939] [G acc: 0.438]\n",
      "20474 [D loss: (0.441)(R 0.435, F 0.448)] [D acc: (0.875)(0.875, 0.875)] [G loss: 0.847] [G acc: 0.312]\n",
      "20475 [D loss: (0.624)(R 0.436, F 0.812)] [D acc: (0.875)(0.938, 0.812)] [G loss: 0.895] [G acc: 0.312]\n",
      "20476 [D loss: (0.649)(R 0.732, F 0.566)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.916] [G acc: 0.375]\n",
      "20477 [D loss: (0.651)(R 0.483, F 0.819)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.570] [G acc: 0.562]\n",
      "20478 [D loss: (0.930)(R 0.621, F 1.240)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.049] [G acc: 0.188]\n",
      "20479 [D loss: (1.865)(R 3.247, F 0.483)] [D acc: (0.562)(0.438, 0.688)] [G loss: 2.751] [G acc: 0.125]\n",
      "20480 [D loss: (0.382)(R 0.610, F 0.153)] [D acc: (0.844)(0.750, 0.938)] [G loss: 6.506] [G acc: 0.125]\n",
      "20481 [D loss: (0.586)(R 0.649, F 0.524)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.906] [G acc: 0.250]\n",
      "20482 [D loss: (0.423)(R 0.617, F 0.229)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.107] [G acc: 0.250]\n",
      "20483 [D loss: (0.390)(R 0.577, F 0.204)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.308] [G acc: 0.000]\n",
      "20484 [D loss: (0.418)(R 0.534, F 0.302)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.925] [G acc: 0.312]\n",
      "20485 [D loss: (0.436)(R 0.633, F 0.240)] [D acc: (0.812)(0.625, 1.000)] [G loss: 1.131] [G acc: 0.312]\n",
      "20486 [D loss: (0.626)(R 0.699, F 0.554)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.331] [G acc: 0.250]\n",
      "20487 [D loss: (1.203)(R 1.645, F 0.762)] [D acc: (0.781)(0.938, 0.625)] [G loss: 0.920] [G acc: 0.188]\n",
      "20488 [D loss: (0.574)(R 0.490, F 0.657)] [D acc: (0.688)(0.812, 0.562)] [G loss: 1.333] [G acc: 0.250]\n",
      "20489 [D loss: (0.728)(R 0.678, F 0.777)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.321] [G acc: 0.250]\n",
      "20490 [D loss: (0.578)(R 0.573, F 0.583)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.224] [G acc: 0.125]\n",
      "20491 [D loss: (0.659)(R 0.684, F 0.635)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.800] [G acc: 0.438]\n",
      "20492 [D loss: (0.620)(R 0.491, F 0.750)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.633] [G acc: 0.750]\n",
      "20493 [D loss: (0.473)(R 0.445, F 0.502)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.789] [G acc: 0.312]\n",
      "20494 [D loss: (0.544)(R 0.471, F 0.616)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.029] [G acc: 0.250]\n",
      "20495 [D loss: (0.496)(R 0.465, F 0.528)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.106] [G acc: 0.312]\n",
      "20496 [D loss: (0.508)(R 0.693, F 0.323)] [D acc: (0.719)(0.500, 0.938)] [G loss: 0.887] [G acc: 0.438]\n",
      "20497 [D loss: (0.800)(R 1.024, F 0.577)] [D acc: (0.594)(0.438, 0.750)] [G loss: 1.033] [G acc: 0.188]\n",
      "20498 [D loss: (0.717)(R 0.690, F 0.744)] [D acc: (0.531)(0.562, 0.500)] [G loss: 1.040] [G acc: 0.188]\n",
      "20499 [D loss: (0.680)(R 0.528, F 0.831)] [D acc: (0.625)(0.750, 0.500)] [G loss: 1.065] [G acc: 0.312]\n",
      "20500 [D loss: (0.506)(R 0.537, F 0.475)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.065] [G acc: 0.062]\n",
      "20501 [D loss: (0.561)(R 0.521, F 0.600)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.955] [G acc: 0.125]\n",
      "20502 [D loss: (0.658)(R 0.635, F 0.682)] [D acc: (0.500)(0.562, 0.438)] [G loss: 1.004] [G acc: 0.250]\n",
      "20503 [D loss: (0.542)(R 0.586, F 0.497)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.171] [G acc: 0.125]\n",
      "20504 [D loss: (0.941)(R 0.679, F 1.204)] [D acc: (0.406)(0.562, 0.250)] [G loss: 1.470] [G acc: 0.250]\n",
      "20505 [D loss: (0.691)(R 0.802, F 0.580)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.419] [G acc: 0.125]\n",
      "20506 [D loss: (0.622)(R 0.625, F 0.618)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.969] [G acc: 0.250]\n",
      "20507 [D loss: (0.641)(R 0.741, F 0.540)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.168] [G acc: 0.375]\n",
      "20508 [D loss: (0.434)(R 0.540, F 0.328)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.644] [G acc: 0.062]\n",
      "20509 [D loss: (1.072)(R 1.598, F 0.546)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.962] [G acc: 0.188]\n",
      "20510 [D loss: (0.511)(R 0.529, F 0.493)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.643] [G acc: 0.625]\n",
      "20511 [D loss: (0.645)(R 0.562, F 0.729)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.800] [G acc: 0.312]\n",
      "20512 [D loss: (0.683)(R 0.700, F 0.667)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.914] [G acc: 0.312]\n",
      "20513 [D loss: (0.660)(R 0.521, F 0.798)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.928] [G acc: 0.438]\n",
      "20514 [D loss: (0.573)(R 0.690, F 0.457)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.988] [G acc: 0.500]\n",
      "20515 [D loss: (0.869)(R 0.669, F 1.068)] [D acc: (0.406)(0.625, 0.188)] [G loss: 0.668] [G acc: 0.688]\n",
      "20516 [D loss: (0.406)(R 0.586, F 0.226)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.351] [G acc: 0.312]\n",
      "20517 [D loss: (0.698)(R 0.748, F 0.647)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.383] [G acc: 0.125]\n",
      "20518 [D loss: (0.779)(R 0.602, F 0.956)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.865] [G acc: 0.250]\n",
      "20519 [D loss: (0.737)(R 0.505, F 0.969)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.727] [G acc: 0.500]\n",
      "20520 [D loss: (0.734)(R 0.799, F 0.670)] [D acc: (0.406)(0.312, 0.500)] [G loss: 0.787] [G acc: 0.438]\n",
      "20521 [D loss: (0.563)(R 0.474, F 0.651)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.955] [G acc: 0.188]\n",
      "20522 [D loss: (0.869)(R 0.828, F 0.910)] [D acc: (0.406)(0.625, 0.188)] [G loss: 0.796] [G acc: 0.375]\n",
      "20523 [D loss: (0.735)(R 0.678, F 0.791)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.576] [G acc: 0.625]\n",
      "20524 [D loss: (0.680)(R 0.533, F 0.828)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.840] [G acc: 0.438]\n",
      "20525 [D loss: (0.755)(R 0.729, F 0.782)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.785] [G acc: 0.375]\n",
      "20526 [D loss: (0.487)(R 0.610, F 0.364)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.880] [G acc: 0.438]\n",
      "20527 [D loss: (0.773)(R 0.824, F 0.721)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.791] [G acc: 0.438]\n",
      "20528 [D loss: (0.896)(R 0.936, F 0.857)] [D acc: (0.281)(0.312, 0.250)] [G loss: 0.590] [G acc: 0.500]\n",
      "20529 [D loss: (0.828)(R 0.693, F 0.963)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.674] [G acc: 0.562]\n",
      "20530 [D loss: (0.675)(R 0.659, F 0.692)] [D acc: (0.531)(0.500, 0.562)] [G loss: 1.138] [G acc: 0.562]\n",
      "20531 [D loss: (0.493)(R 0.824, F 0.162)] [D acc: (0.688)(0.438, 0.938)] [G loss: 6.507] [G acc: 0.125]\n",
      "20532 [D loss: (0.865)(R 0.724, F 1.006)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.758] [G acc: 0.438]\n",
      "20533 [D loss: (0.722)(R 0.778, F 0.666)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.077] [G acc: 0.250]\n",
      "20534 [D loss: (0.657)(R 0.718, F 0.597)] [D acc: (0.500)(0.375, 0.625)] [G loss: 1.114] [G acc: 0.250]\n",
      "20535 [D loss: (0.692)(R 0.704, F 0.680)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.745] [G acc: 0.250]\n",
      "20536 [D loss: (0.612)(R 0.717, F 0.506)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.905] [G acc: 0.250]\n",
      "20537 [D loss: (0.785)(R 0.749, F 0.822)] [D acc: (0.406)(0.500, 0.312)] [G loss: 0.736] [G acc: 0.438]\n",
      "20538 [D loss: (0.727)(R 0.696, F 0.759)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.847] [G acc: 0.375]\n",
      "20539 [D loss: (0.532)(R 0.602, F 0.462)] [D acc: (0.812)(0.625, 1.000)] [G loss: 0.742] [G acc: 0.438]\n",
      "20540 [D loss: (0.603)(R 0.657, F 0.549)] [D acc: (0.688)(0.438, 0.938)] [G loss: 0.907] [G acc: 0.250]\n",
      "20541 [D loss: (0.712)(R 0.661, F 0.764)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.782] [G acc: 0.438]\n",
      "20542 [D loss: (0.687)(R 0.728, F 0.646)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.675] [G acc: 0.438]\n",
      "20543 [D loss: (0.689)(R 0.770, F 0.608)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.723] [G acc: 0.438]\n",
      "20544 [D loss: (0.614)(R 0.699, F 0.528)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.168] [G acc: 0.188]\n",
      "20545 [D loss: (0.735)(R 0.752, F 0.718)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.840] [G acc: 0.312]\n",
      "20546 [D loss: (0.599)(R 0.764, F 0.434)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.400] [G acc: 0.250]\n",
      "20547 [D loss: (0.518)(R 0.688, F 0.348)] [D acc: (0.594)(0.500, 0.688)] [G loss: 1.643] [G acc: 0.188]\n",
      "20548 [D loss: (0.528)(R 0.652, F 0.403)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.747] [G acc: 0.188]\n",
      "20549 [D loss: (0.731)(R 0.768, F 0.694)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.797] [G acc: 0.375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20550 [D loss: (0.690)(R 0.796, F 0.584)] [D acc: (0.562)(0.312, 0.812)] [G loss: 0.915] [G acc: 0.125]\n",
      "20551 [D loss: (0.599)(R 0.599, F 0.599)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.834] [G acc: 0.188]\n",
      "20552 [D loss: (0.653)(R 0.669, F 0.637)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.868] [G acc: 0.125]\n",
      "20553 [D loss: (0.565)(R 0.544, F 0.586)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.006] [G acc: 0.125]\n",
      "20554 [D loss: (0.606)(R 0.577, F 0.636)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.872] [G acc: 0.375]\n",
      "20555 [D loss: (0.606)(R 0.635, F 0.578)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.804] [G acc: 0.250]\n",
      "20556 [D loss: (0.588)(R 0.539, F 0.638)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.756] [G acc: 0.375]\n",
      "20557 [D loss: (0.540)(R 0.623, F 0.457)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.806] [G acc: 0.250]\n",
      "20558 [D loss: (0.655)(R 0.689, F 0.621)] [D acc: (0.531)(0.375, 0.688)] [G loss: 1.054] [G acc: 0.250]\n",
      "20559 [D loss: (0.589)(R 0.711, F 0.467)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.938] [G acc: 0.125]\n",
      "20560 [D loss: (0.533)(R 0.652, F 0.413)] [D acc: (0.688)(0.500, 0.875)] [G loss: 1.119] [G acc: 0.188]\n",
      "20561 [D loss: (0.556)(R 0.527, F 0.584)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.841] [G acc: 0.250]\n",
      "20562 [D loss: (0.323)(R 0.560, F 0.086)] [D acc: (0.812)(0.625, 1.000)] [G loss: 8.414] [G acc: 0.062]\n",
      "20563 [D loss: (0.382)(R 0.544, F 0.221)] [D acc: (0.812)(0.688, 0.938)] [G loss: 3.502] [G acc: 0.125]\n",
      "20564 [D loss: (0.518)(R 0.502, F 0.534)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.952] [G acc: 0.125]\n",
      "20565 [D loss: (0.633)(R 0.676, F 0.590)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.035] [G acc: 0.250]\n",
      "20566 [D loss: (0.481)(R 0.453, F 0.509)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.998] [G acc: 0.000]\n",
      "20567 [D loss: (0.493)(R 0.523, F 0.463)] [D acc: (0.875)(0.812, 0.938)] [G loss: 0.974] [G acc: 0.188]\n",
      "20568 [D loss: (0.541)(R 0.617, F 0.466)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.046] [G acc: 0.375]\n",
      "20569 [D loss: (0.408)(R 0.496, F 0.319)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.074] [G acc: 0.062]\n",
      "20570 [D loss: (0.670)(R 0.703, F 0.636)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.039] [G acc: 0.250]\n",
      "20571 [D loss: (0.578)(R 0.587, F 0.568)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.139] [G acc: 0.250]\n",
      "20572 [D loss: (0.483)(R 0.516, F 0.450)] [D acc: (0.875)(0.812, 0.938)] [G loss: 0.797] [G acc: 0.312]\n",
      "20573 [D loss: (0.523)(R 0.518, F 0.528)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.014] [G acc: 0.125]\n",
      "20574 [D loss: (0.567)(R 0.498, F 0.637)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.787] [G acc: 0.312]\n",
      "20575 [D loss: (0.543)(R 0.599, F 0.487)] [D acc: (0.625)(0.438, 0.812)] [G loss: 1.062] [G acc: 0.062]\n",
      "20576 [D loss: (0.451)(R 0.473, F 0.430)] [D acc: (0.875)(0.750, 1.000)] [G loss: 1.291] [G acc: 0.125]\n",
      "20577 [D loss: (0.400)(R 0.432, F 0.369)] [D acc: (0.844)(0.875, 0.812)] [G loss: 3.532] [G acc: 0.188]\n",
      "20578 [D loss: (0.529)(R 0.616, F 0.442)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.278] [G acc: 0.375]\n",
      "20579 [D loss: (0.627)(R 0.803, F 0.452)] [D acc: (0.625)(0.438, 0.812)] [G loss: 3.454] [G acc: 0.125]\n",
      "20580 [D loss: (0.344)(R 0.416, F 0.272)] [D acc: (0.875)(0.875, 0.875)] [G loss: 4.085] [G acc: 0.188]\n",
      "20581 [D loss: (0.420)(R 0.547, F 0.292)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.583] [G acc: 0.250]\n",
      "20582 [D loss: (0.367)(R 0.491, F 0.244)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.843] [G acc: 0.125]\n",
      "20583 [D loss: (0.568)(R 0.509, F 0.627)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.832] [G acc: 0.375]\n",
      "20584 [D loss: (0.430)(R 0.295, F 0.564)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.057] [G acc: 0.125]\n",
      "20585 [D loss: (0.600)(R 0.525, F 0.676)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.891] [G acc: 0.375]\n",
      "20586 [D loss: (0.488)(R 0.391, F 0.585)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.436] [G acc: 0.188]\n",
      "20587 [D loss: (0.736)(R 1.304, F 0.168)] [D acc: (0.812)(0.688, 0.938)] [G loss: 4.476] [G acc: 0.000]\n",
      "20588 [D loss: (0.462)(R 0.336, F 0.588)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.796] [G acc: 0.438]\n",
      "20589 [D loss: (0.570)(R 0.613, F 0.526)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.105] [G acc: 0.062]\n",
      "20590 [D loss: (0.604)(R 0.670, F 0.539)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.791] [G acc: 0.312]\n",
      "20591 [D loss: (0.425)(R 0.259, F 0.592)] [D acc: (0.875)(1.000, 0.750)] [G loss: 1.153] [G acc: 0.125]\n",
      "20592 [D loss: (0.503)(R 0.451, F 0.555)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.214] [G acc: 0.188]\n",
      "20593 [D loss: (0.533)(R 0.513, F 0.553)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.422] [G acc: 0.062]\n",
      "20594 [D loss: (0.459)(R 0.462, F 0.455)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.043] [G acc: 0.188]\n",
      "20595 [D loss: (0.519)(R 0.454, F 0.584)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.926] [G acc: 0.188]\n",
      "20596 [D loss: (0.554)(R 0.536, F 0.572)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.371] [G acc: 0.125]\n",
      "20597 [D loss: (0.470)(R 0.553, F 0.387)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.699] [G acc: 0.250]\n",
      "20598 [D loss: (0.478)(R 0.466, F 0.489)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.280] [G acc: 0.188]\n",
      "20599 [D loss: (0.690)(R 0.759, F 0.621)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.722] [G acc: 0.562]\n",
      "20600 [D loss: (0.504)(R 0.560, F 0.447)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.867] [G acc: 0.500]\n",
      "20601 [D loss: (0.471)(R 0.386, F 0.556)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.999] [G acc: 0.188]\n",
      "20602 [D loss: (0.610)(R 0.640, F 0.581)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.965] [G acc: 0.125]\n",
      "20603 [D loss: (0.480)(R 0.611, F 0.349)] [D acc: (0.750)(0.625, 0.875)] [G loss: 2.566] [G acc: 0.500]\n",
      "20604 [D loss: (0.403)(R 0.495, F 0.311)] [D acc: (0.719)(0.625, 0.812)] [G loss: 4.926] [G acc: 0.125]\n",
      "20605 [D loss: (0.525)(R 0.435, F 0.615)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.290] [G acc: 0.312]\n",
      "20606 [D loss: (0.735)(R 0.350, F 1.121)] [D acc: (0.719)(1.000, 0.438)] [G loss: 2.023] [G acc: 0.062]\n",
      "20607 [D loss: (0.425)(R 0.537, F 0.313)] [D acc: (0.688)(0.500, 0.875)] [G loss: 4.549] [G acc: 0.125]\n",
      "20608 [D loss: (0.459)(R 0.493, F 0.424)] [D acc: (0.688)(0.688, 0.688)] [G loss: 4.393] [G acc: 0.250]\n",
      "20609 [D loss: (0.480)(R 0.377, F 0.583)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.446] [G acc: 0.125]\n",
      "20610 [D loss: (0.434)(R 0.345, F 0.522)] [D acc: (0.906)(0.938, 0.875)] [G loss: 0.886] [G acc: 0.250]\n",
      "20611 [D loss: (0.525)(R 0.606, F 0.444)] [D acc: (0.719)(0.500, 0.938)] [G loss: 1.164] [G acc: 0.062]\n",
      "20612 [D loss: (0.504)(R 0.518, F 0.490)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.532] [G acc: 0.062]\n",
      "20613 [D loss: (0.595)(R 0.814, F 0.376)] [D acc: (0.656)(0.438, 0.875)] [G loss: 1.477] [G acc: 0.250]\n",
      "20614 [D loss: (0.804)(R 0.644, F 0.965)] [D acc: (0.562)(0.688, 0.438)] [G loss: 1.090] [G acc: 0.312]\n",
      "20615 [D loss: (0.787)(R 0.446, F 1.128)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.733] [G acc: 0.500]\n",
      "20616 [D loss: (0.503)(R 0.547, F 0.460)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.954] [G acc: 0.500]\n",
      "20617 [D loss: (1.893)(R 3.311, F 0.475)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.710] [G acc: 0.062]\n",
      "20618 [D loss: (0.570)(R 0.633, F 0.508)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.267] [G acc: 0.250]\n",
      "20619 [D loss: (0.699)(R 0.551, F 0.846)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.734] [G acc: 0.500]\n",
      "20620 [D loss: (0.613)(R 0.511, F 0.716)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.206] [G acc: 0.375]\n",
      "20621 [D loss: (0.565)(R 0.713, F 0.417)] [D acc: (0.719)(0.500, 0.938)] [G loss: 0.559] [G acc: 0.625]\n",
      "20622 [D loss: (0.595)(R 0.578, F 0.612)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.076] [G acc: 0.375]\n",
      "20623 [D loss: (0.756)(R 0.629, F 0.882)] [D acc: (0.531)(0.625, 0.438)] [G loss: 1.128] [G acc: 0.562]\n",
      "20624 [D loss: (0.339)(R 0.264, F 0.414)] [D acc: (0.844)(0.938, 0.750)] [G loss: 1.306] [G acc: 0.188]\n",
      "20625 [D loss: (0.471)(R 0.441, F 0.501)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.966] [G acc: 0.438]\n",
      "20626 [D loss: (0.689)(R 0.539, F 0.839)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.815] [G acc: 0.375]\n",
      "20627 [D loss: (0.648)(R 0.549, F 0.746)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.671] [G acc: 0.500]\n",
      "20628 [D loss: (0.711)(R 0.677, F 0.746)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.966] [G acc: 0.312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20629 [D loss: (0.672)(R 0.685, F 0.659)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.643] [G acc: 0.625]\n",
      "20630 [D loss: (0.659)(R 0.420, F 0.899)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.950] [G acc: 0.312]\n",
      "20631 [D loss: (0.857)(R 0.877, F 0.837)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.789] [G acc: 0.250]\n",
      "20632 [D loss: (0.727)(R 0.495, F 0.959)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.670] [G acc: 0.562]\n",
      "20633 [D loss: (0.639)(R 0.426, F 0.852)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.926] [G acc: 0.375]\n",
      "20634 [D loss: (0.958)(R 0.576, F 1.341)] [D acc: (0.469)(0.625, 0.312)] [G loss: 1.297] [G acc: 0.438]\n",
      "20635 [D loss: (0.923)(R 0.791, F 1.055)] [D acc: (0.531)(0.312, 0.750)] [G loss: 1.327] [G acc: 0.062]\n",
      "20636 [D loss: (0.735)(R 0.920, F 0.551)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.704] [G acc: 0.438]\n",
      "20637 [D loss: (0.664)(R 0.795, F 0.532)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.338] [G acc: 0.312]\n",
      "20638 [D loss: (0.391)(R 0.625, F 0.157)] [D acc: (0.719)(0.438, 1.000)] [G loss: 2.212] [G acc: 0.125]\n",
      "20639 [D loss: (0.588)(R 0.675, F 0.501)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.907] [G acc: 0.312]\n",
      "20640 [D loss: (0.605)(R 0.530, F 0.680)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.177] [G acc: 0.250]\n",
      "20641 [D loss: (0.576)(R 0.560, F 0.592)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.072] [G acc: 0.125]\n",
      "20642 [D loss: (0.750)(R 0.876, F 0.623)] [D acc: (0.531)(0.188, 0.875)] [G loss: 1.060] [G acc: 0.250]\n",
      "20643 [D loss: (0.698)(R 0.675, F 0.721)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.837] [G acc: 0.375]\n",
      "20644 [D loss: (0.590)(R 0.541, F 0.639)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.707] [G acc: 0.438]\n",
      "20645 [D loss: (0.569)(R 0.599, F 0.539)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.923] [G acc: 0.188]\n",
      "20646 [D loss: (0.679)(R 0.707, F 0.652)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.848] [G acc: 0.250]\n",
      "20647 [D loss: (0.623)(R 0.585, F 0.661)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.870] [G acc: 0.250]\n",
      "20648 [D loss: (0.866)(R 0.728, F 1.004)] [D acc: (0.406)(0.375, 0.438)] [G loss: 0.845] [G acc: 0.375]\n",
      "20649 [D loss: (0.666)(R 0.880, F 0.453)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.830] [G acc: 0.250]\n",
      "20650 [D loss: (0.953)(R 0.584, F 1.321)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.793] [G acc: 0.250]\n",
      "20651 [D loss: (0.733)(R 0.711, F 0.756)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.950] [G acc: 0.000]\n",
      "20652 [D loss: (0.773)(R 0.739, F 0.808)] [D acc: (0.531)(0.250, 0.812)] [G loss: 1.120] [G acc: 0.125]\n",
      "20653 [D loss: (0.528)(R 0.585, F 0.471)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.244] [G acc: 0.062]\n",
      "20654 [D loss: (0.527)(R 0.435, F 0.619)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.748] [G acc: 0.312]\n",
      "20655 [D loss: (0.675)(R 0.623, F 0.727)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.870] [G acc: 0.125]\n",
      "20656 [D loss: (0.639)(R 0.650, F 0.628)] [D acc: (0.562)(0.375, 0.750)] [G loss: 1.111] [G acc: 0.062]\n",
      "20657 [D loss: (0.620)(R 0.648, F 0.593)] [D acc: (0.719)(0.500, 0.938)] [G loss: 0.798] [G acc: 0.312]\n",
      "20658 [D loss: (0.768)(R 0.459, F 1.077)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.809] [G acc: 0.250]\n",
      "20659 [D loss: (0.900)(R 0.678, F 1.121)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.766] [G acc: 0.312]\n",
      "20660 [D loss: (0.691)(R 0.680, F 0.703)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.844] [G acc: 0.250]\n",
      "20661 [D loss: (0.694)(R 0.679, F 0.709)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.698] [G acc: 0.375]\n",
      "20662 [D loss: (0.556)(R 0.646, F 0.465)] [D acc: (0.688)(0.438, 0.938)] [G loss: 0.839] [G acc: 0.250]\n",
      "20663 [D loss: (0.649)(R 0.604, F 0.694)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.563] [G acc: 0.562]\n",
      "20664 [D loss: (1.360)(R 0.601, F 2.118)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.727] [G acc: 0.312]\n",
      "20665 [D loss: (0.537)(R 0.592, F 0.483)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.808] [G acc: 0.375]\n",
      "20666 [D loss: (1.226)(R 0.894, F 1.557)] [D acc: (0.438)(0.375, 0.500)] [G loss: 1.097] [G acc: 0.312]\n",
      "20667 [D loss: (0.343)(R 0.483, F 0.203)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.251] [G acc: 0.062]\n",
      "20668 [D loss: (0.503)(R 0.510, F 0.497)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.799] [G acc: 0.250]\n",
      "20669 [D loss: (0.599)(R 0.615, F 0.584)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.634] [G acc: 0.250]\n",
      "20670 [D loss: (0.495)(R 0.578, F 0.411)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.865] [G acc: 0.312]\n",
      "20671 [D loss: (0.561)(R 0.586, F 0.537)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.970] [G acc: 0.188]\n",
      "20672 [D loss: (0.686)(R 0.624, F 0.748)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.708] [G acc: 0.375]\n",
      "20673 [D loss: (0.539)(R 0.531, F 0.548)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.872] [G acc: 0.312]\n",
      "20674 [D loss: (0.690)(R 0.613, F 0.767)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.983] [G acc: 0.375]\n",
      "20675 [D loss: (0.506)(R 0.659, F 0.352)] [D acc: (0.719)(0.500, 0.938)] [G loss: 2.034] [G acc: 0.125]\n",
      "20676 [D loss: (0.638)(R 0.879, F 0.397)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.886] [G acc: 0.438]\n",
      "20677 [D loss: (0.700)(R 0.664, F 0.735)] [D acc: (0.562)(0.438, 0.688)] [G loss: 1.094] [G acc: 0.125]\n",
      "20678 [D loss: (0.557)(R 0.465, F 0.648)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.797] [G acc: 0.188]\n",
      "20679 [D loss: (0.857)(R 0.563, F 1.150)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.883] [G acc: 0.188]\n",
      "20680 [D loss: (0.529)(R 0.493, F 0.565)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.626] [G acc: 0.562]\n",
      "20681 [D loss: (0.477)(R 0.489, F 0.464)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.650] [G acc: 0.500]\n",
      "20682 [D loss: (0.612)(R 0.756, F 0.468)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.324] [G acc: 0.188]\n",
      "20683 [D loss: (0.593)(R 0.525, F 0.661)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.286] [G acc: 0.188]\n",
      "20684 [D loss: (0.534)(R 0.538, F 0.529)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.910] [G acc: 0.125]\n",
      "20685 [D loss: (0.540)(R 0.514, F 0.566)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.950] [G acc: 0.188]\n",
      "20686 [D loss: (0.530)(R 0.407, F 0.652)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.899] [G acc: 0.250]\n",
      "20687 [D loss: (0.600)(R 0.610, F 0.590)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.028] [G acc: 0.188]\n",
      "20688 [D loss: (0.536)(R 0.479, F 0.592)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.822] [G acc: 0.250]\n",
      "20689 [D loss: (0.464)(R 0.450, F 0.478)] [D acc: (0.875)(0.875, 0.875)] [G loss: 0.942] [G acc: 0.125]\n",
      "20690 [D loss: (0.456)(R 0.544, F 0.368)] [D acc: (0.844)(0.750, 0.938)] [G loss: 0.941] [G acc: 0.188]\n",
      "20691 [D loss: (0.552)(R 0.436, F 0.667)] [D acc: (0.688)(0.812, 0.562)] [G loss: 1.947] [G acc: 0.000]\n",
      "20692 [D loss: (0.396)(R 0.542, F 0.249)] [D acc: (0.750)(0.688, 0.812)] [G loss: 7.595] [G acc: 0.062]\n",
      "20693 [D loss: (0.418)(R 0.498, F 0.339)] [D acc: (0.938)(0.875, 1.000)] [G loss: 0.770] [G acc: 0.438]\n",
      "20694 [D loss: (0.481)(R 0.449, F 0.513)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.392] [G acc: 0.125]\n",
      "20695 [D loss: (0.515)(R 0.577, F 0.453)] [D acc: (0.656)(0.562, 0.750)] [G loss: 5.587] [G acc: 0.125]\n",
      "20696 [D loss: (0.379)(R 0.484, F 0.275)] [D acc: (0.844)(0.812, 0.875)] [G loss: 2.138] [G acc: 0.188]\n",
      "20697 [D loss: (0.353)(R 0.276, F 0.429)] [D acc: (0.969)(1.000, 0.938)] [G loss: 1.029] [G acc: 0.375]\n",
      "20698 [D loss: (0.502)(R 0.474, F 0.530)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.685] [G acc: 0.188]\n",
      "20699 [D loss: (0.545)(R 0.569, F 0.522)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.116] [G acc: 0.062]\n",
      "20700 [D loss: (0.444)(R 0.326, F 0.562)] [D acc: (0.844)(0.875, 0.812)] [G loss: 0.922] [G acc: 0.250]\n",
      "20701 [D loss: (0.524)(R 0.466, F 0.582)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.835] [G acc: 0.438]\n",
      "20702 [D loss: (0.555)(R 0.305, F 0.804)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.095] [G acc: 0.125]\n",
      "20703 [D loss: (0.514)(R 0.559, F 0.468)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.100] [G acc: 0.125]\n",
      "20704 [D loss: (0.401)(R 0.348, F 0.454)] [D acc: (0.969)(0.938, 1.000)] [G loss: 1.023] [G acc: 0.125]\n",
      "20705 [D loss: (0.492)(R 0.423, F 0.560)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.040] [G acc: 0.062]\n",
      "20706 [D loss: (0.398)(R 0.372, F 0.424)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.122] [G acc: 0.125]\n",
      "20707 [D loss: (0.529)(R 0.522, F 0.536)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.120] [G acc: 0.125]\n",
      "20708 [D loss: (0.549)(R 0.500, F 0.598)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.117] [G acc: 0.250]\n",
      "20709 [D loss: (0.817)(R 0.479, F 1.154)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.910] [G acc: 0.500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20710 [D loss: (0.405)(R 0.503, F 0.306)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.761] [G acc: 0.125]\n",
      "20711 [D loss: (0.407)(R 0.490, F 0.325)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.485] [G acc: 0.062]\n",
      "20712 [D loss: (0.640)(R 0.525, F 0.756)] [D acc: (0.594)(0.750, 0.438)] [G loss: 1.588] [G acc: 0.062]\n",
      "20713 [D loss: (0.729)(R 1.145, F 0.313)] [D acc: (0.688)(0.500, 0.875)] [G loss: 1.738] [G acc: 0.000]\n",
      "20714 [D loss: (0.440)(R 0.411, F 0.469)] [D acc: (0.875)(0.938, 0.812)] [G loss: 1.323] [G acc: 0.062]\n",
      "20715 [D loss: (0.465)(R 0.433, F 0.497)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.073] [G acc: 0.188]\n",
      "20716 [D loss: (0.576)(R 0.625, F 0.526)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.968] [G acc: 0.312]\n",
      "20717 [D loss: (0.502)(R 0.521, F 0.483)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.913] [G acc: 0.312]\n",
      "20718 [D loss: (0.595)(R 0.718, F 0.472)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.229] [G acc: 0.062]\n",
      "20719 [D loss: (0.501)(R 0.497, F 0.506)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.210] [G acc: 0.062]\n",
      "20720 [D loss: (0.503)(R 0.463, F 0.544)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.296] [G acc: 0.125]\n",
      "20721 [D loss: (0.394)(R 0.291, F 0.498)] [D acc: (0.906)(0.938, 0.875)] [G loss: 1.080] [G acc: 0.250]\n",
      "20722 [D loss: (0.445)(R 0.388, F 0.503)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.038] [G acc: 0.188]\n",
      "20723 [D loss: (0.415)(R 0.375, F 0.456)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.164] [G acc: 0.125]\n",
      "20724 [D loss: (0.602)(R 0.611, F 0.592)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.174] [G acc: 0.250]\n",
      "20725 [D loss: (0.446)(R 0.501, F 0.391)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.197] [G acc: 0.062]\n",
      "20726 [D loss: (0.499)(R 0.471, F 0.527)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.104] [G acc: 0.062]\n",
      "20727 [D loss: (0.409)(R 0.277, F 0.540)] [D acc: (0.844)(0.938, 0.750)] [G loss: 1.052] [G acc: 0.125]\n",
      "20728 [D loss: (0.364)(R 0.342, F 0.387)] [D acc: (0.969)(0.938, 1.000)] [G loss: 1.165] [G acc: 0.188]\n",
      "20729 [D loss: (0.532)(R 0.552, F 0.512)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.340] [G acc: 0.000]\n",
      "20730 [D loss: (0.534)(R 0.523, F 0.544)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.149] [G acc: 0.188]\n",
      "20731 [D loss: (0.495)(R 0.509, F 0.482)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.126] [G acc: 0.312]\n",
      "20732 [D loss: (0.478)(R 0.475, F 0.481)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.016] [G acc: 0.250]\n",
      "20733 [D loss: (0.568)(R 0.564, F 0.572)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.988] [G acc: 0.250]\n",
      "20734 [D loss: (0.486)(R 0.447, F 0.524)] [D acc: (0.844)(0.812, 0.875)] [G loss: 2.627] [G acc: 0.250]\n",
      "20735 [D loss: (0.367)(R 0.558, F 0.175)] [D acc: (0.781)(0.688, 0.875)] [G loss: 10.666] [G acc: 0.062]\n",
      "20736 [D loss: (0.414)(R 0.606, F 0.223)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.119] [G acc: 0.125]\n",
      "20737 [D loss: (0.320)(R 0.263, F 0.377)] [D acc: (0.875)(0.938, 0.812)] [G loss: 1.583] [G acc: 0.188]\n",
      "20738 [D loss: (0.575)(R 0.558, F 0.593)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.955] [G acc: 0.312]\n",
      "20739 [D loss: (0.466)(R 0.371, F 0.560)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.073] [G acc: 0.000]\n",
      "20740 [D loss: (0.650)(R 0.723, F 0.578)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.757] [G acc: 0.500]\n",
      "20741 [D loss: (0.652)(R 0.595, F 0.710)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.987] [G acc: 0.312]\n",
      "20742 [D loss: (0.447)(R 0.275, F 0.619)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.901] [G acc: 0.438]\n",
      "20743 [D loss: (0.554)(R 0.337, F 0.771)] [D acc: (0.750)(0.938, 0.562)] [G loss: 0.878] [G acc: 0.375]\n",
      "20744 [D loss: (0.648)(R 0.533, F 0.764)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.088] [G acc: 0.312]\n",
      "20745 [D loss: (0.529)(R 0.459, F 0.598)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.399] [G acc: 0.062]\n",
      "20746 [D loss: (0.503)(R 0.496, F 0.511)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.831] [G acc: 0.438]\n",
      "20747 [D loss: (0.385)(R 0.193, F 0.578)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.874] [G acc: 0.375]\n",
      "20748 [D loss: (0.662)(R 0.582, F 0.742)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.128] [G acc: 0.250]\n",
      "20749 [D loss: (0.741)(R 0.988, F 0.495)] [D acc: (0.531)(0.250, 0.812)] [G loss: 0.877] [G acc: 0.312]\n",
      "20750 [D loss: (0.679)(R 0.493, F 0.866)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.676] [G acc: 0.625]\n",
      "20751 [D loss: (0.723)(R 0.538, F 0.907)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.699] [G acc: 0.625]\n",
      "20752 [D loss: (0.713)(R 0.401, F 1.025)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.795] [G acc: 0.438]\n",
      "20753 [D loss: (0.584)(R 0.354, F 0.814)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.867] [G acc: 0.250]\n",
      "20754 [D loss: (0.885)(R 0.734, F 1.037)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.667] [G acc: 0.625]\n",
      "20755 [D loss: (0.738)(R 0.651, F 0.825)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.743] [G acc: 0.625]\n",
      "20756 [D loss: (0.755)(R 0.668, F 0.843)] [D acc: (0.562)(0.562, 0.562)] [G loss: 2.696] [G acc: 0.188]\n",
      "20757 [D loss: (1.137)(R 0.508, F 1.765)] [D acc: (0.688)(0.688, 0.688)] [G loss: 5.175] [G acc: 0.250]\n",
      "20758 [D loss: (0.961)(R 0.727, F 1.196)] [D acc: (0.562)(0.500, 0.625)] [G loss: 1.849] [G acc: 0.250]\n",
      "20759 [D loss: (0.444)(R 0.634, F 0.255)] [D acc: (0.719)(0.625, 0.812)] [G loss: 5.514] [G acc: 0.188]\n",
      "20760 [D loss: (0.462)(R 0.428, F 0.495)] [D acc: (0.719)(0.812, 0.625)] [G loss: 2.230] [G acc: 0.500]\n",
      "20761 [D loss: (0.963)(R 0.595, F 1.332)] [D acc: (0.500)(0.562, 0.438)] [G loss: 1.123] [G acc: 0.500]\n",
      "20762 [D loss: (1.145)(R 0.557, F 1.732)] [D acc: (0.500)(0.750, 0.250)] [G loss: 1.069] [G acc: 0.500]\n",
      "20763 [D loss: (0.777)(R 0.501, F 1.053)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.818] [G acc: 0.375]\n",
      "20764 [D loss: (0.738)(R 0.620, F 0.855)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.958] [G acc: 0.375]\n",
      "20765 [D loss: (0.740)(R 0.639, F 0.841)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.903] [G acc: 0.375]\n",
      "20766 [D loss: (0.553)(R 0.621, F 0.485)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.397] [G acc: 0.250]\n",
      "20767 [D loss: (0.584)(R 0.580, F 0.589)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.189] [G acc: 0.562]\n",
      "20768 [D loss: (0.748)(R 0.607, F 0.889)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.713] [G acc: 0.500]\n",
      "20769 [D loss: (0.661)(R 0.709, F 0.614)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.138] [G acc: 0.375]\n",
      "20770 [D loss: (0.714)(R 0.635, F 0.793)] [D acc: (0.531)(0.750, 0.312)] [G loss: 1.113] [G acc: 0.250]\n",
      "20771 [D loss: (0.543)(R 0.535, F 0.551)] [D acc: (0.719)(0.750, 0.688)] [G loss: 2.548] [G acc: 0.125]\n",
      "20772 [D loss: (0.688)(R 0.602, F 0.775)] [D acc: (0.562)(0.625, 0.500)] [G loss: 2.131] [G acc: 0.438]\n",
      "20773 [D loss: (0.521)(R 0.805, F 0.237)] [D acc: (0.719)(0.500, 0.938)] [G loss: 2.265] [G acc: 0.250]\n",
      "20774 [D loss: (0.637)(R 0.553, F 0.720)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.676] [G acc: 0.750]\n",
      "20775 [D loss: (0.676)(R 0.710, F 0.643)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.870] [G acc: 0.250]\n",
      "20776 [D loss: (0.668)(R 0.784, F 0.551)] [D acc: (0.625)(0.312, 0.938)] [G loss: 0.657] [G acc: 0.500]\n",
      "20777 [D loss: (0.719)(R 0.857, F 0.580)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.929] [G acc: 0.062]\n",
      "20778 [D loss: (0.693)(R 0.619, F 0.768)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.557] [G acc: 0.562]\n",
      "20779 [D loss: (0.709)(R 0.738, F 0.680)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.783] [G acc: 0.250]\n",
      "20780 [D loss: (0.907)(R 1.069, F 0.745)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.824] [G acc: 0.250]\n",
      "20781 [D loss: (0.683)(R 0.610, F 0.756)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.724] [G acc: 0.562]\n",
      "20782 [D loss: (0.555)(R 0.473, F 0.637)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.948] [G acc: 0.188]\n",
      "20783 [D loss: (0.625)(R 0.658, F 0.592)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.811] [G acc: 0.250]\n",
      "20784 [D loss: (0.584)(R 0.556, F 0.612)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.955] [G acc: 0.375]\n",
      "20785 [D loss: (0.368)(R 0.527, F 0.208)] [D acc: (0.875)(0.750, 1.000)] [G loss: 1.897] [G acc: 0.000]\n",
      "20786 [D loss: (0.572)(R 0.548, F 0.596)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.980] [G acc: 0.000]\n",
      "20787 [D loss: (0.582)(R 0.458, F 0.705)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.026] [G acc: 0.500]\n",
      "20788 [D loss: (0.610)(R 0.660, F 0.560)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.832] [G acc: 0.188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20789 [D loss: (0.720)(R 0.665, F 0.775)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.686] [G acc: 0.562]\n",
      "20790 [D loss: (0.596)(R 0.669, F 0.523)] [D acc: (0.688)(0.500, 0.875)] [G loss: 1.082] [G acc: 0.062]\n",
      "20791 [D loss: (0.613)(R 0.596, F 0.630)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.426] [G acc: 0.500]\n",
      "20792 [D loss: (0.673)(R 0.588, F 0.758)] [D acc: (0.625)(0.625, 0.625)] [G loss: 4.396] [G acc: 0.312]\n",
      "20793 [D loss: (0.354)(R 0.551, F 0.157)] [D acc: (0.844)(0.688, 1.000)] [G loss: 1.596] [G acc: 0.062]\n",
      "20794 [D loss: (0.494)(R 0.485, F 0.503)] [D acc: (0.656)(0.625, 0.688)] [G loss: 2.048] [G acc: 0.062]\n",
      "20795 [D loss: (0.522)(R 0.618, F 0.426)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.373] [G acc: 0.125]\n",
      "20796 [D loss: (0.539)(R 0.482, F 0.595)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.966] [G acc: 0.062]\n",
      "20797 [D loss: (0.563)(R 0.471, F 0.656)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.921] [G acc: 0.125]\n",
      "20798 [D loss: (0.614)(R 0.685, F 0.542)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.718] [G acc: 0.500]\n",
      "20799 [D loss: (0.572)(R 0.518, F 0.626)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.944] [G acc: 0.125]\n",
      "20800 [D loss: (0.623)(R 0.745, F 0.501)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.995] [G acc: 0.188]\n",
      "20801 [D loss: (0.643)(R 0.699, F 0.588)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.194] [G acc: 0.188]\n",
      "20802 [D loss: (0.380)(R 0.430, F 0.329)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.408] [G acc: 0.125]\n",
      "20803 [D loss: (0.480)(R 0.443, F 0.517)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.951] [G acc: 0.375]\n",
      "20804 [D loss: (0.448)(R 0.479, F 0.416)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.504] [G acc: 0.125]\n",
      "20805 [D loss: (0.382)(R 0.552, F 0.212)] [D acc: (0.844)(0.688, 1.000)] [G loss: 0.979] [G acc: 0.312]\n",
      "20806 [D loss: (0.581)(R 0.677, F 0.486)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.919] [G acc: 0.375]\n",
      "20807 [D loss: (0.605)(R 0.492, F 0.718)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.692] [G acc: 0.562]\n",
      "20808 [D loss: (0.496)(R 0.453, F 0.538)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.050] [G acc: 0.250]\n",
      "20809 [D loss: (0.665)(R 0.747, F 0.583)] [D acc: (0.531)(0.375, 0.688)] [G loss: 1.314] [G acc: 0.188]\n",
      "20810 [D loss: (0.519)(R 0.677, F 0.360)] [D acc: (0.625)(0.500, 0.750)] [G loss: 5.096] [G acc: 0.250]\n",
      "20811 [D loss: (0.404)(R 0.512, F 0.295)] [D acc: (0.781)(0.688, 0.875)] [G loss: 3.780] [G acc: 0.188]\n",
      "20812 [D loss: (0.501)(R 0.583, F 0.419)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.903] [G acc: 0.125]\n",
      "20813 [D loss: (0.549)(R 0.476, F 0.622)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.866] [G acc: 0.312]\n",
      "20814 [D loss: (0.516)(R 0.475, F 0.557)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.945] [G acc: 0.188]\n",
      "20815 [D loss: (0.532)(R 0.572, F 0.493)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.989] [G acc: 0.250]\n",
      "20816 [D loss: (0.559)(R 0.474, F 0.645)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.020] [G acc: 0.125]\n",
      "20817 [D loss: (0.604)(R 0.635, F 0.573)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.854] [G acc: 0.500]\n",
      "20818 [D loss: (0.540)(R 0.573, F 0.508)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.926] [G acc: 0.188]\n",
      "20819 [D loss: (0.620)(R 0.554, F 0.686)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.966] [G acc: 0.125]\n",
      "20820 [D loss: (0.568)(R 0.642, F 0.494)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.929] [G acc: 0.125]\n",
      "20821 [D loss: (0.502)(R 0.447, F 0.557)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.997] [G acc: 0.188]\n",
      "20822 [D loss: (0.660)(R 0.554, F 0.765)] [D acc: (0.594)(0.688, 0.500)] [G loss: 1.048] [G acc: 0.125]\n",
      "20823 [D loss: (0.553)(R 0.664, F 0.443)] [D acc: (0.812)(0.625, 1.000)] [G loss: 1.070] [G acc: 0.062]\n",
      "20824 [D loss: (0.580)(R 0.505, F 0.655)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.001] [G acc: 0.188]\n",
      "20825 [D loss: (0.680)(R 0.687, F 0.674)] [D acc: (0.562)(0.562, 0.562)] [G loss: 1.016] [G acc: 0.062]\n",
      "20826 [D loss: (0.554)(R 0.591, F 0.518)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.999] [G acc: 0.125]\n",
      "20827 [D loss: (0.565)(R 0.606, F 0.524)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.237] [G acc: 0.188]\n",
      "20828 [D loss: (0.493)(R 0.515, F 0.470)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.010] [G acc: 0.062]\n",
      "20829 [D loss: (0.523)(R 0.552, F 0.494)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.020] [G acc: 0.250]\n",
      "20830 [D loss: (0.499)(R 0.521, F 0.478)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.271] [G acc: 0.125]\n",
      "20831 [D loss: (0.553)(R 0.524, F 0.582)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.160] [G acc: 0.062]\n",
      "20832 [D loss: (0.551)(R 0.593, F 0.510)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.045] [G acc: 0.125]\n",
      "20833 [D loss: (0.430)(R 0.518, F 0.342)] [D acc: (0.844)(0.688, 1.000)] [G loss: 1.247] [G acc: 0.125]\n",
      "20834 [D loss: (0.506)(R 0.542, F 0.470)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.258] [G acc: 0.062]\n",
      "20835 [D loss: (0.605)(R 0.651, F 0.560)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.124] [G acc: 0.188]\n",
      "20836 [D loss: (0.504)(R 0.523, F 0.486)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.022] [G acc: 0.062]\n",
      "20837 [D loss: (0.512)(R 0.459, F 0.565)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.282] [G acc: 0.188]\n",
      "20838 [D loss: (0.652)(R 0.508, F 0.797)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.737] [G acc: 0.500]\n",
      "20839 [D loss: (0.533)(R 0.497, F 0.570)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.127] [G acc: 0.312]\n",
      "20840 [D loss: (0.735)(R 0.578, F 0.892)] [D acc: (0.625)(0.750, 0.500)] [G loss: 2.883] [G acc: 0.125]\n",
      "20841 [D loss: (0.305)(R 0.577, F 0.032)] [D acc: (0.844)(0.688, 1.000)] [G loss: 8.671] [G acc: 0.000]\n",
      "20842 [D loss: (0.563)(R 0.839, F 0.286)] [D acc: (0.625)(0.438, 0.812)] [G loss: 1.012] [G acc: 0.188]\n",
      "20843 [D loss: (0.478)(R 0.535, F 0.421)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.220] [G acc: 0.125]\n",
      "20844 [D loss: (0.385)(R 0.369, F 0.401)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.636] [G acc: 0.375]\n",
      "20845 [D loss: (0.609)(R 0.567, F 0.651)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.642] [G acc: 0.125]\n",
      "20846 [D loss: (0.517)(R 0.398, F 0.636)] [D acc: (0.812)(0.938, 0.688)] [G loss: 1.298] [G acc: 0.125]\n",
      "20847 [D loss: (0.600)(R 0.538, F 0.662)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.235] [G acc: 0.062]\n",
      "20848 [D loss: (0.444)(R 0.385, F 0.503)] [D acc: (0.906)(0.938, 0.875)] [G loss: 0.978] [G acc: 0.062]\n",
      "20849 [D loss: (0.547)(R 0.497, F 0.597)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.739] [G acc: 0.625]\n",
      "20850 [D loss: (0.544)(R 0.547, F 0.541)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.583] [G acc: 0.688]\n",
      "20851 [D loss: (0.476)(R 0.375, F 0.578)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.938] [G acc: 0.188]\n",
      "20852 [D loss: (0.572)(R 0.570, F 0.573)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.773] [G acc: 0.375]\n",
      "20853 [D loss: (0.565)(R 0.479, F 0.652)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.688] [G acc: 0.562]\n",
      "20854 [D loss: (0.540)(R 0.545, F 0.534)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.536] [G acc: 0.812]\n",
      "20855 [D loss: (0.525)(R 0.583, F 0.467)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.156] [G acc: 0.125]\n",
      "20856 [D loss: (0.705)(R 0.784, F 0.626)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.964] [G acc: 0.250]\n",
      "20857 [D loss: (0.726)(R 0.832, F 0.620)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.947] [G acc: 0.188]\n",
      "20858 [D loss: (0.818)(R 0.640, F 0.996)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.438] [G acc: 0.938]\n",
      "20859 [D loss: (0.539)(R 0.435, F 0.644)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.828] [G acc: 0.500]\n",
      "20860 [D loss: (0.759)(R 0.566, F 0.951)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.879] [G acc: 0.312]\n",
      "20861 [D loss: (0.746)(R 0.803, F 0.689)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.812] [G acc: 0.438]\n",
      "20862 [D loss: (0.597)(R 0.686, F 0.509)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.946] [G acc: 0.438]\n",
      "20863 [D loss: (0.396)(R 0.691, F 0.102)] [D acc: (0.750)(0.562, 0.938)] [G loss: 8.290] [G acc: 0.188]\n",
      "20864 [D loss: (0.733)(R 0.727, F 0.738)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.515] [G acc: 0.812]\n",
      "20865 [D loss: (0.624)(R 0.712, F 0.535)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.069] [G acc: 0.125]\n",
      "20866 [D loss: (0.610)(R 0.633, F 0.586)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.668] [G acc: 0.688]\n",
      "20867 [D loss: (0.885)(R 0.861, F 0.910)] [D acc: (0.281)(0.312, 0.250)] [G loss: 0.748] [G acc: 0.375]\n",
      "20868 [D loss: (0.823)(R 1.007, F 0.639)] [D acc: (0.469)(0.312, 0.625)] [G loss: 1.559] [G acc: 0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20869 [D loss: (0.534)(R 0.493, F 0.576)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.864] [G acc: 0.375]\n",
      "20870 [D loss: (0.792)(R 0.783, F 0.801)] [D acc: (0.469)(0.562, 0.375)] [G loss: 1.096] [G acc: 0.312]\n",
      "20871 [D loss: (0.594)(R 0.773, F 0.415)] [D acc: (0.562)(0.375, 0.750)] [G loss: 2.635] [G acc: 0.125]\n",
      "20872 [D loss: (0.772)(R 0.740, F 0.805)] [D acc: (0.531)(0.375, 0.688)] [G loss: 4.330] [G acc: 0.125]\n",
      "20873 [D loss: (0.459)(R 0.533, F 0.384)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.126] [G acc: 0.312]\n",
      "20874 [D loss: (0.436)(R 0.551, F 0.320)] [D acc: (0.750)(0.625, 0.875)] [G loss: 2.180] [G acc: 0.000]\n",
      "20875 [D loss: (0.605)(R 0.710, F 0.501)] [D acc: (0.562)(0.500, 0.625)] [G loss: 2.244] [G acc: 0.250]\n",
      "20876 [D loss: (0.695)(R 0.785, F 0.606)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.694] [G acc: 0.625]\n",
      "20877 [D loss: (0.687)(R 0.648, F 0.725)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.066] [G acc: 0.188]\n",
      "20878 [D loss: (0.578)(R 0.537, F 0.619)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.726] [G acc: 0.500]\n",
      "20879 [D loss: (0.629)(R 0.600, F 0.657)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.789] [G acc: 0.375]\n",
      "20880 [D loss: (0.719)(R 0.603, F 0.836)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.889] [G acc: 0.188]\n",
      "20881 [D loss: (0.577)(R 0.527, F 0.626)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.757] [G acc: 0.375]\n",
      "20882 [D loss: (0.674)(R 0.564, F 0.785)] [D acc: (0.562)(0.750, 0.375)] [G loss: 1.014] [G acc: 0.125]\n",
      "20883 [D loss: (0.671)(R 0.622, F 0.721)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.681] [G acc: 0.562]\n",
      "20884 [D loss: (0.683)(R 0.594, F 0.771)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.486] [G acc: 0.812]\n",
      "20885 [D loss: (0.734)(R 0.830, F 0.637)] [D acc: (0.438)(0.312, 0.562)] [G loss: 0.765] [G acc: 0.562]\n",
      "20886 [D loss: (0.812)(R 0.867, F 0.757)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.399] [G acc: 0.750]\n",
      "20887 [D loss: (0.707)(R 0.623, F 0.791)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.891] [G acc: 0.500]\n",
      "20888 [D loss: (0.636)(R 0.599, F 0.674)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.871] [G acc: 0.312]\n",
      "20889 [D loss: (1.015)(R 0.572, F 1.457)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.136] [G acc: 0.125]\n",
      "20890 [D loss: (0.624)(R 0.693, F 0.554)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.949] [G acc: 0.312]\n",
      "20891 [D loss: (0.696)(R 0.630, F 0.761)] [D acc: (0.531)(0.625, 0.438)] [G loss: 1.096] [G acc: 0.062]\n",
      "20892 [D loss: (0.604)(R 0.633, F 0.574)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.858] [G acc: 0.250]\n",
      "20893 [D loss: (0.830)(R 0.895, F 0.766)] [D acc: (0.375)(0.375, 0.375)] [G loss: 0.839] [G acc: 0.312]\n",
      "20894 [D loss: (0.712)(R 0.775, F 0.648)] [D acc: (0.406)(0.250, 0.562)] [G loss: 0.802] [G acc: 0.438]\n",
      "20895 [D loss: (0.640)(R 0.608, F 0.672)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.614] [G acc: 0.688]\n",
      "20896 [D loss: (0.575)(R 0.620, F 0.530)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.741] [G acc: 0.500]\n",
      "20897 [D loss: (0.603)(R 0.714, F 0.493)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.889] [G acc: 0.312]\n",
      "20898 [D loss: (0.702)(R 0.663, F 0.741)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.753] [G acc: 0.500]\n",
      "20899 [D loss: (0.859)(R 0.681, F 1.037)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.927] [G acc: 0.312]\n",
      "20900 [D loss: (0.508)(R 0.757, F 0.260)] [D acc: (0.719)(0.438, 1.000)] [G loss: 1.345] [G acc: 0.000]\n",
      "20901 [D loss: (0.585)(R 0.473, F 0.696)] [D acc: (0.719)(0.812, 0.625)] [G loss: 2.178] [G acc: 0.125]\n",
      "20902 [D loss: (0.397)(R 0.657, F 0.137)] [D acc: (0.781)(0.625, 0.938)] [G loss: 8.744] [G acc: 0.062]\n",
      "20903 [D loss: (0.517)(R 0.577, F 0.456)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.887] [G acc: 0.188]\n",
      "20904 [D loss: (0.545)(R 0.670, F 0.420)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.686] [G acc: 0.500]\n",
      "20905 [D loss: (0.557)(R 0.639, F 0.474)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.485] [G acc: 0.812]\n",
      "20906 [D loss: (0.532)(R 0.553, F 0.512)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.039] [G acc: 0.312]\n",
      "20907 [D loss: (0.469)(R 0.577, F 0.361)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.202] [G acc: 0.250]\n",
      "20908 [D loss: (0.635)(R 0.448, F 0.822)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.559] [G acc: 0.688]\n",
      "20909 [D loss: (0.779)(R 0.701, F 0.857)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.807] [G acc: 0.562]\n",
      "20910 [D loss: (0.704)(R 0.661, F 0.746)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.675] [G acc: 0.562]\n",
      "20911 [D loss: (0.666)(R 0.590, F 0.741)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.728] [G acc: 0.312]\n",
      "20912 [D loss: (1.387)(R 0.678, F 2.095)] [D acc: (0.562)(0.562, 0.562)] [G loss: 1.343] [G acc: 0.125]\n",
      "20913 [D loss: (0.594)(R 0.613, F 0.575)] [D acc: (0.688)(0.562, 0.812)] [G loss: 3.535] [G acc: 0.062]\n",
      "20914 [D loss: (1.119)(R 0.786, F 1.452)] [D acc: (0.688)(0.562, 0.812)] [G loss: 3.099] [G acc: 0.438]\n",
      "20915 [D loss: (0.552)(R 0.525, F 0.578)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.852] [G acc: 0.375]\n",
      "20916 [D loss: (0.714)(R 0.619, F 0.808)] [D acc: (0.469)(0.562, 0.375)] [G loss: 1.021] [G acc: 0.375]\n",
      "20917 [D loss: (0.688)(R 0.761, F 0.614)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.775] [G acc: 0.375]\n",
      "20918 [D loss: (0.659)(R 0.613, F 0.705)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.697] [G acc: 0.438]\n",
      "20919 [D loss: (0.549)(R 0.560, F 0.537)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.068] [G acc: 0.250]\n",
      "20920 [D loss: (0.482)(R 0.500, F 0.463)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.069] [G acc: 0.188]\n",
      "20921 [D loss: (0.553)(R 0.623, F 0.483)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.897] [G acc: 0.250]\n",
      "20922 [D loss: (0.704)(R 0.698, F 0.710)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.965] [G acc: 0.125]\n",
      "20923 [D loss: (0.685)(R 0.654, F 0.716)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.516] [G acc: 0.750]\n",
      "20924 [D loss: (0.617)(R 0.502, F 0.732)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.837] [G acc: 0.375]\n",
      "20925 [D loss: (0.658)(R 0.617, F 0.699)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.526] [G acc: 0.688]\n",
      "20926 [D loss: (0.710)(R 0.591, F 0.829)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.233] [G acc: 0.062]\n",
      "20927 [D loss: (0.604)(R 0.662, F 0.546)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.978] [G acc: 0.438]\n",
      "20928 [D loss: (0.512)(R 0.694, F 0.330)] [D acc: (0.625)(0.438, 0.812)] [G loss: 1.363] [G acc: 0.125]\n",
      "20929 [D loss: (0.530)(R 0.516, F 0.544)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.986] [G acc: 0.188]\n",
      "20930 [D loss: (0.592)(R 0.664, F 0.520)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.377] [G acc: 0.875]\n",
      "20931 [D loss: (0.528)(R 0.424, F 0.632)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.692] [G acc: 0.438]\n",
      "20932 [D loss: (0.614)(R 0.632, F 0.596)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.815] [G acc: 0.312]\n",
      "20933 [D loss: (0.708)(R 0.526, F 0.889)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.810] [G acc: 0.250]\n",
      "20934 [D loss: (0.628)(R 0.606, F 0.650)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.851] [G acc: 0.250]\n",
      "20935 [D loss: (0.598)(R 0.663, F 0.532)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.767] [G acc: 0.375]\n",
      "20936 [D loss: (0.725)(R 0.723, F 0.727)] [D acc: (0.500)(0.438, 0.562)] [G loss: 1.073] [G acc: 0.188]\n",
      "20937 [D loss: (0.510)(R 0.556, F 0.465)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.308] [G acc: 0.438]\n",
      "20938 [D loss: (0.503)(R 0.456, F 0.550)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.867] [G acc: 0.125]\n",
      "20939 [D loss: (0.748)(R 0.769, F 0.727)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.768] [G acc: 0.438]\n",
      "20940 [D loss: (0.617)(R 0.653, F 0.582)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.390] [G acc: 0.750]\n",
      "20941 [D loss: (1.041)(R 1.163, F 0.918)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.810] [G acc: 0.438]\n",
      "20942 [D loss: (0.701)(R 0.469, F 0.933)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.801] [G acc: 0.312]\n",
      "20943 [D loss: (0.567)(R 0.527, F 0.608)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.886] [G acc: 0.125]\n",
      "20944 [D loss: (0.611)(R 0.552, F 0.671)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.799] [G acc: 0.438]\n",
      "20945 [D loss: (0.659)(R 0.636, F 0.682)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.735] [G acc: 0.375]\n",
      "20946 [D loss: (0.581)(R 0.479, F 0.682)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.934] [G acc: 0.125]\n",
      "20947 [D loss: (0.933)(R 0.813, F 1.053)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.848] [G acc: 0.375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20948 [D loss: (0.879)(R 0.489, F 1.269)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.619] [G acc: 0.125]\n",
      "20949 [D loss: (0.397)(R 0.667, F 0.127)] [D acc: (0.781)(0.562, 1.000)] [G loss: 8.920] [G acc: 0.000]\n",
      "20950 [D loss: (0.354)(R 0.581, F 0.127)] [D acc: (0.844)(0.688, 1.000)] [G loss: 2.451] [G acc: 0.188]\n",
      "20951 [D loss: (0.526)(R 0.400, F 0.653)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.539] [G acc: 0.312]\n",
      "20952 [D loss: (0.896)(R 0.513, F 1.280)] [D acc: (0.594)(0.812, 0.375)] [G loss: 1.006] [G acc: 0.125]\n",
      "20953 [D loss: (1.513)(R 0.501, F 2.526)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.975] [G acc: 0.312]\n",
      "20954 [D loss: (0.707)(R 0.608, F 0.806)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.434] [G acc: 0.062]\n",
      "20955 [D loss: (0.484)(R 0.682, F 0.286)] [D acc: (0.750)(0.500, 1.000)] [G loss: 1.331] [G acc: 0.250]\n",
      "20956 [D loss: (0.760)(R 0.734, F 0.786)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.864] [G acc: 0.188]\n",
      "20957 [D loss: (0.559)(R 0.498, F 0.620)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.193] [G acc: 0.062]\n",
      "20958 [D loss: (0.430)(R 0.529, F 0.332)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.692] [G acc: 0.062]\n",
      "20959 [D loss: (0.438)(R 0.413, F 0.463)] [D acc: (0.875)(0.875, 0.875)] [G loss: 2.798] [G acc: 0.312]\n",
      "20960 [D loss: (0.512)(R 0.540, F 0.485)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.952] [G acc: 0.438]\n",
      "20961 [D loss: (0.716)(R 0.542, F 0.890)] [D acc: (0.875)(0.812, 0.938)] [G loss: 0.977] [G acc: 0.375]\n",
      "20962 [D loss: (0.499)(R 0.486, F 0.512)] [D acc: (0.812)(0.875, 0.750)] [G loss: 2.687] [G acc: 0.062]\n",
      "20963 [D loss: (1.257)(R 0.734, F 1.780)] [D acc: (0.562)(0.625, 0.500)] [G loss: 5.114] [G acc: 0.062]\n",
      "20964 [D loss: (0.514)(R 0.445, F 0.583)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.206] [G acc: 0.250]\n",
      "20965 [D loss: (0.453)(R 0.479, F 0.427)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.537] [G acc: 0.188]\n",
      "20966 [D loss: (0.472)(R 0.504, F 0.441)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.218] [G acc: 0.312]\n",
      "20967 [D loss: (0.590)(R 0.670, F 0.511)] [D acc: (0.594)(0.500, 0.688)] [G loss: 1.112] [G acc: 0.062]\n",
      "20968 [D loss: (0.683)(R 0.920, F 0.446)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.914] [G acc: 0.125]\n",
      "20969 [D loss: (0.548)(R 0.557, F 0.539)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.920] [G acc: 0.250]\n",
      "20970 [D loss: (0.679)(R 0.471, F 0.887)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.784] [G acc: 0.688]\n",
      "20971 [D loss: (0.535)(R 0.464, F 0.606)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.744] [G acc: 0.438]\n",
      "20972 [D loss: (0.938)(R 0.775, F 1.102)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.765] [G acc: 0.312]\n",
      "20973 [D loss: (0.501)(R 0.526, F 0.476)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.440] [G acc: 0.312]\n",
      "20974 [D loss: (0.436)(R 0.550, F 0.322)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.580] [G acc: 0.062]\n",
      "20975 [D loss: (0.492)(R 0.401, F 0.582)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.933] [G acc: 0.062]\n",
      "20976 [D loss: (0.333)(R 0.532, F 0.135)] [D acc: (0.875)(0.750, 1.000)] [G loss: 11.455] [G acc: 0.125]\n",
      "20977 [D loss: (0.390)(R 0.414, F 0.366)] [D acc: (0.906)(0.812, 1.000)] [G loss: 1.538] [G acc: 0.188]\n",
      "20978 [D loss: (0.456)(R 0.458, F 0.454)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.762] [G acc: 0.125]\n",
      "20979 [D loss: (0.544)(R 0.649, F 0.440)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.986] [G acc: 0.250]\n",
      "20980 [D loss: (0.464)(R 0.488, F 0.439)] [D acc: (0.875)(0.812, 0.938)] [G loss: 0.981] [G acc: 0.188]\n",
      "20981 [D loss: (0.581)(R 0.458, F 0.704)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.179] [G acc: 0.125]\n",
      "20982 [D loss: (0.396)(R 0.327, F 0.466)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.419] [G acc: 0.125]\n",
      "20983 [D loss: (0.396)(R 0.627, F 0.165)] [D acc: (0.844)(0.750, 0.938)] [G loss: 3.137] [G acc: 0.062]\n",
      "20984 [D loss: (0.445)(R 0.599, F 0.291)] [D acc: (0.812)(0.688, 0.938)] [G loss: 3.714] [G acc: 0.188]\n",
      "20985 [D loss: (0.532)(R 0.491, F 0.572)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.002] [G acc: 0.188]\n",
      "20986 [D loss: (1.456)(R 2.465, F 0.446)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.237] [G acc: 0.062]\n",
      "20987 [D loss: (0.447)(R 0.458, F 0.435)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.245] [G acc: 0.125]\n",
      "20988 [D loss: (0.450)(R 0.464, F 0.436)] [D acc: (0.875)(0.812, 0.938)] [G loss: 0.948] [G acc: 0.125]\n",
      "20989 [D loss: (0.409)(R 0.417, F 0.401)] [D acc: (0.906)(0.875, 0.938)] [G loss: 1.203] [G acc: 0.062]\n",
      "20990 [D loss: (0.474)(R 0.447, F 0.501)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.131] [G acc: 0.250]\n",
      "20991 [D loss: (0.428)(R 0.422, F 0.433)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.224] [G acc: 0.062]\n",
      "20992 [D loss: (0.493)(R 0.614, F 0.372)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.187] [G acc: 0.312]\n",
      "20993 [D loss: (0.417)(R 0.395, F 0.440)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.313] [G acc: 0.000]\n",
      "20994 [D loss: (0.375)(R 0.261, F 0.488)] [D acc: (0.938)(0.938, 0.938)] [G loss: 1.820] [G acc: 0.125]\n",
      "20995 [D loss: (0.270)(R 0.284, F 0.257)] [D acc: (0.938)(0.938, 0.938)] [G loss: 1.134] [G acc: 0.250]\n",
      "20996 [D loss: (0.340)(R 0.292, F 0.389)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.299] [G acc: 0.062]\n",
      "20997 [D loss: (0.494)(R 0.646, F 0.342)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.956] [G acc: 0.000]\n",
      "20998 [D loss: (0.344)(R 0.311, F 0.377)] [D acc: (0.938)(0.938, 0.938)] [G loss: 1.342] [G acc: 0.062]\n",
      "20999 [D loss: (0.445)(R 0.588, F 0.301)] [D acc: (0.844)(0.688, 1.000)] [G loss: 1.857] [G acc: 0.125]\n",
      "21000 [D loss: (0.470)(R 0.673, F 0.266)] [D acc: (0.719)(0.500, 0.938)] [G loss: 1.471] [G acc: 0.188]\n",
      "21001 [D loss: (0.367)(R 0.521, F 0.212)] [D acc: (0.844)(0.750, 0.938)] [G loss: 3.626] [G acc: 0.062]\n",
      "21002 [D loss: (0.395)(R 0.413, F 0.377)] [D acc: (0.906)(0.812, 1.000)] [G loss: 1.002] [G acc: 0.312]\n",
      "21003 [D loss: (0.511)(R 0.643, F 0.379)] [D acc: (0.844)(0.688, 1.000)] [G loss: 1.347] [G acc: 0.125]\n",
      "21004 [D loss: (0.519)(R 0.507, F 0.531)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.434] [G acc: 0.000]\n",
      "21005 [D loss: (0.371)(R 0.374, F 0.368)] [D acc: (0.906)(0.812, 1.000)] [G loss: 1.520] [G acc: 0.125]\n",
      "21006 [D loss: (0.328)(R 0.299, F 0.356)] [D acc: (0.906)(0.812, 1.000)] [G loss: 1.187] [G acc: 0.125]\n",
      "21007 [D loss: (0.409)(R 0.372, F 0.447)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.232] [G acc: 0.250]\n",
      "21008 [D loss: (0.308)(R 0.161, F 0.455)] [D acc: (0.875)(0.938, 0.812)] [G loss: 1.360] [G acc: 0.125]\n",
      "21009 [D loss: (0.365)(R 0.489, F 0.241)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.843] [G acc: 0.062]\n",
      "21010 [D loss: (0.534)(R 0.600, F 0.469)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.281] [G acc: 0.125]\n",
      "21011 [D loss: (0.426)(R 0.420, F 0.431)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.384] [G acc: 0.125]\n",
      "21012 [D loss: (0.438)(R 0.329, F 0.547)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.228] [G acc: 0.250]\n",
      "21013 [D loss: (0.315)(R 0.191, F 0.439)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.462] [G acc: 0.062]\n",
      "21014 [D loss: (0.745)(R 0.459, F 1.031)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.985] [G acc: 0.125]\n",
      "21015 [D loss: (0.269)(R 0.408, F 0.129)] [D acc: (0.844)(0.812, 0.875)] [G loss: 7.303] [G acc: 0.188]\n",
      "21016 [D loss: (0.423)(R 0.400, F 0.446)] [D acc: (0.781)(0.750, 0.812)] [G loss: 6.766] [G acc: 0.188]\n",
      "21017 [D loss: (0.439)(R 0.703, F 0.175)] [D acc: (0.844)(0.750, 0.938)] [G loss: 5.532] [G acc: 0.000]\n",
      "21018 [D loss: (0.234)(R 0.241, F 0.226)] [D acc: (0.938)(0.938, 0.938)] [G loss: 1.752] [G acc: 0.062]\n",
      "21019 [D loss: (0.390)(R 0.383, F 0.396)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.509] [G acc: 0.188]\n",
      "21020 [D loss: (0.358)(R 0.440, F 0.277)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.718] [G acc: 0.000]\n",
      "21021 [D loss: (0.429)(R 0.420, F 0.437)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.412] [G acc: 0.125]\n",
      "21022 [D loss: (0.458)(R 0.321, F 0.596)] [D acc: (0.781)(0.875, 0.688)] [G loss: 2.126] [G acc: 0.062]\n",
      "21023 [D loss: (0.297)(R 0.240, F 0.355)] [D acc: (0.969)(0.938, 1.000)] [G loss: 1.748] [G acc: 0.062]\n",
      "21024 [D loss: (0.315)(R 0.270, F 0.359)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.657] [G acc: 0.000]\n",
      "21025 [D loss: (0.311)(R 0.234, F 0.388)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.691] [G acc: 0.125]\n",
      "21026 [D loss: (0.364)(R 0.304, F 0.423)] [D acc: (0.875)(0.938, 0.812)] [G loss: 2.025] [G acc: 0.188]\n",
      "21027 [D loss: (0.570)(R 0.630, F 0.509)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.824] [G acc: 0.188]\n",
      "21028 [D loss: (0.502)(R 0.519, F 0.485)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.480] [G acc: 0.125]\n",
      "21029 [D loss: (0.536)(R 0.499, F 0.572)] [D acc: (0.812)(0.812, 0.812)] [G loss: 2.376] [G acc: 0.062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21030 [D loss: (0.184)(R 0.256, F 0.112)] [D acc: (0.906)(0.812, 1.000)] [G loss: 4.894] [G acc: 0.125]\n",
      "21031 [D loss: (0.483)(R 0.355, F 0.611)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.621] [G acc: 0.250]\n",
      "21032 [D loss: (0.396)(R 0.571, F 0.221)] [D acc: (0.875)(0.750, 1.000)] [G loss: 1.535] [G acc: 0.125]\n",
      "21033 [D loss: (0.490)(R 0.712, F 0.267)] [D acc: (0.812)(0.625, 1.000)] [G loss: 1.743] [G acc: 0.062]\n",
      "21034 [D loss: (0.395)(R 0.274, F 0.515)] [D acc: (0.906)(0.938, 0.875)] [G loss: 1.419] [G acc: 0.250]\n",
      "21035 [D loss: (0.319)(R 0.438, F 0.199)] [D acc: (0.875)(0.812, 0.938)] [G loss: 2.439] [G acc: 0.125]\n",
      "21036 [D loss: (0.509)(R 0.475, F 0.542)] [D acc: (0.781)(0.750, 0.812)] [G loss: 2.215] [G acc: 0.125]\n",
      "21037 [D loss: (0.372)(R 0.364, F 0.381)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.459] [G acc: 0.125]\n",
      "21038 [D loss: (0.471)(R 0.545, F 0.397)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.463] [G acc: 0.062]\n",
      "21039 [D loss: (0.600)(R 0.597, F 0.604)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.333] [G acc: 0.000]\n",
      "21040 [D loss: (0.606)(R 0.702, F 0.509)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.065] [G acc: 0.188]\n",
      "21041 [D loss: (0.455)(R 0.422, F 0.488)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.825] [G acc: 0.375]\n",
      "21042 [D loss: (0.472)(R 0.420, F 0.523)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.119] [G acc: 0.188]\n",
      "21043 [D loss: (0.724)(R 0.670, F 0.778)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.158] [G acc: 0.125]\n",
      "21044 [D loss: (0.569)(R 0.624, F 0.514)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.315] [G acc: 0.188]\n",
      "21045 [D loss: (0.235)(R 0.145, F 0.325)] [D acc: (0.906)(0.938, 0.875)] [G loss: 3.221] [G acc: 0.188]\n",
      "21046 [D loss: (0.425)(R 0.689, F 0.162)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.781] [G acc: 0.250]\n",
      "21047 [D loss: (0.342)(R 0.507, F 0.178)] [D acc: (0.906)(0.812, 1.000)] [G loss: 1.774] [G acc: 0.188]\n",
      "21048 [D loss: (0.526)(R 0.439, F 0.613)] [D acc: (0.719)(0.750, 0.688)] [G loss: 4.233] [G acc: 0.062]\n",
      "21049 [D loss: (0.361)(R 0.649, F 0.072)] [D acc: (0.781)(0.562, 1.000)] [G loss: 4.583] [G acc: 0.125]\n",
      "21050 [D loss: (0.360)(R 0.274, F 0.446)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.388] [G acc: 0.062]\n",
      "21051 [D loss: (0.696)(R 0.819, F 0.572)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.256] [G acc: 0.188]\n",
      "21052 [D loss: (0.431)(R 0.317, F 0.544)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.051] [G acc: 0.250]\n",
      "21053 [D loss: (0.599)(R 0.777, F 0.420)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.062] [G acc: 0.188]\n",
      "21054 [D loss: (0.884)(R 0.341, F 1.427)] [D acc: (0.750)(0.875, 0.625)] [G loss: 1.027] [G acc: 0.312]\n",
      "21055 [D loss: (0.487)(R 0.369, F 0.604)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.506] [G acc: 0.062]\n",
      "21056 [D loss: (0.530)(R 0.378, F 0.682)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.015] [G acc: 0.188]\n",
      "21057 [D loss: (0.548)(R 0.568, F 0.529)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.145] [G acc: 0.062]\n",
      "21058 [D loss: (0.404)(R 0.500, F 0.308)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.426] [G acc: 0.188]\n",
      "21059 [D loss: (0.257)(R 0.287, F 0.226)] [D acc: (0.938)(0.875, 1.000)] [G loss: 3.078] [G acc: 0.000]\n",
      "21060 [D loss: (0.663)(R 0.869, F 0.456)] [D acc: (0.625)(0.500, 0.750)] [G loss: 2.836] [G acc: 0.188]\n",
      "21061 [D loss: (0.228)(R 0.325, F 0.132)] [D acc: (0.906)(0.812, 1.000)] [G loss: 1.197] [G acc: 0.188]\n",
      "21062 [D loss: (0.414)(R 0.371, F 0.457)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.061] [G acc: 0.375]\n",
      "21063 [D loss: (0.800)(R 0.557, F 1.044)] [D acc: (0.562)(0.750, 0.375)] [G loss: 1.234] [G acc: 0.188]\n",
      "21064 [D loss: (0.576)(R 0.517, F 0.634)] [D acc: (0.688)(0.812, 0.562)] [G loss: 1.613] [G acc: 0.438]\n",
      "21065 [D loss: (0.458)(R 0.368, F 0.548)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.144] [G acc: 0.188]\n",
      "21066 [D loss: (0.529)(R 0.532, F 0.526)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.908] [G acc: 0.188]\n",
      "21067 [D loss: (0.492)(R 0.370, F 0.613)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.231] [G acc: 0.438]\n",
      "21068 [D loss: (0.493)(R 0.471, F 0.514)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.121] [G acc: 0.125]\n",
      "21069 [D loss: (0.557)(R 0.457, F 0.657)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.505] [G acc: 0.250]\n",
      "21070 [D loss: (0.461)(R 0.554, F 0.368)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.446] [G acc: 0.000]\n",
      "21071 [D loss: (0.392)(R 0.353, F 0.432)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.115] [G acc: 0.188]\n",
      "21072 [D loss: (0.452)(R 0.489, F 0.415)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.231] [G acc: 0.250]\n",
      "21073 [D loss: (0.650)(R 0.469, F 0.832)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.572] [G acc: 0.312]\n",
      "21074 [D loss: (0.552)(R 0.634, F 0.471)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.009] [G acc: 0.188]\n",
      "21075 [D loss: (0.773)(R 0.659, F 0.888)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.511] [G acc: 0.688]\n",
      "21076 [D loss: (1.125)(R 0.519, F 1.732)] [D acc: (0.500)(0.625, 0.375)] [G loss: 1.675] [G acc: 0.312]\n",
      "21077 [D loss: (0.441)(R 0.557, F 0.325)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.796] [G acc: 0.125]\n",
      "21078 [D loss: (0.744)(R 0.389, F 1.100)] [D acc: (0.594)(0.688, 0.500)] [G loss: 1.171] [G acc: 0.250]\n",
      "21079 [D loss: (0.552)(R 0.594, F 0.511)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.574] [G acc: 0.000]\n",
      "21080 [D loss: (1.541)(R 0.719, F 2.363)] [D acc: (0.562)(0.625, 0.500)] [G loss: 1.054] [G acc: 0.688]\n",
      "21081 [D loss: (0.684)(R 0.718, F 0.649)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.188] [G acc: 0.312]\n",
      "21082 [D loss: (1.428)(R 1.145, F 1.711)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.456] [G acc: 0.688]\n",
      "21083 [D loss: (1.140)(R 0.816, F 1.464)] [D acc: (0.469)(0.438, 0.500)] [G loss: 1.463] [G acc: 0.250]\n",
      "21084 [D loss: (2.209)(R 0.718, F 3.700)] [D acc: (0.469)(0.562, 0.375)] [G loss: 1.410] [G acc: 0.438]\n",
      "21085 [D loss: (0.623)(R 0.739, F 0.506)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.558] [G acc: 0.312]\n",
      "21086 [D loss: (1.203)(R 0.844, F 1.562)] [D acc: (0.625)(0.500, 0.750)] [G loss: 2.419] [G acc: 0.438]\n",
      "21087 [D loss: (1.642)(R 0.625, F 2.660)] [D acc: (0.562)(0.625, 0.500)] [G loss: 1.161] [G acc: 0.500]\n",
      "21088 [D loss: (4.746)(R 1.196, F 8.296)] [D acc: (0.344)(0.375, 0.312)] [G loss: 1.415] [G acc: 0.312]\n",
      "21089 [D loss: (1.786)(R 0.597, F 2.975)] [D acc: (0.594)(0.562, 0.625)] [G loss: 2.498] [G acc: 0.562]\n",
      "21090 [D loss: (2.248)(R 0.746, F 3.750)] [D acc: (0.406)(0.438, 0.375)] [G loss: 1.223] [G acc: 0.562]\n",
      "21091 [D loss: (2.954)(R 0.804, F 5.103)] [D acc: (0.500)(0.500, 0.500)] [G loss: 1.757] [G acc: 0.500]\n",
      "21092 [D loss: (1.236)(R 0.926, F 1.545)] [D acc: (0.531)(0.500, 0.562)] [G loss: 3.096] [G acc: 0.188]\n",
      "21093 [D loss: (2.839)(R 0.757, F 4.921)] [D acc: (0.375)(0.438, 0.312)] [G loss: 0.822] [G acc: 0.375]\n",
      "21094 [D loss: (2.480)(R 0.732, F 4.229)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.997] [G acc: 0.562]\n",
      "21095 [D loss: (1.304)(R 0.715, F 1.893)] [D acc: (0.562)(0.500, 0.625)] [G loss: 1.255] [G acc: 0.250]\n",
      "21096 [D loss: (1.739)(R 0.806, F 2.672)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.823] [G acc: 0.500]\n",
      "21097 [D loss: (1.228)(R 0.929, F 1.528)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.610] [G acc: 0.625]\n",
      "21098 [D loss: (0.941)(R 0.944, F 0.938)] [D acc: (0.375)(0.312, 0.438)] [G loss: 0.957] [G acc: 0.125]\n",
      "21099 [D loss: (1.526)(R 1.174, F 1.879)] [D acc: (0.312)(0.312, 0.312)] [G loss: 1.625] [G acc: 0.312]\n",
      "21100 [D loss: (1.422)(R 0.731, F 2.112)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.637] [G acc: 0.562]\n",
      "21101 [D loss: (1.508)(R 0.841, F 2.175)] [D acc: (0.312)(0.375, 0.250)] [G loss: 0.993] [G acc: 0.312]\n",
      "21102 [D loss: (0.975)(R 0.685, F 1.265)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.721] [G acc: 0.375]\n",
      "21103 [D loss: (0.948)(R 0.623, F 1.272)] [D acc: (0.406)(0.625, 0.188)] [G loss: 0.892] [G acc: 0.500]\n",
      "21104 [D loss: (0.664)(R 0.816, F 0.512)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.817] [G acc: 0.438]\n",
      "21105 [D loss: (0.685)(R 0.794, F 0.576)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.786] [G acc: 0.500]\n",
      "21106 [D loss: (0.916)(R 0.944, F 0.889)] [D acc: (0.406)(0.375, 0.438)] [G loss: 0.827] [G acc: 0.250]\n",
      "21107 [D loss: (0.868)(R 0.692, F 1.044)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.982] [G acc: 0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21108 [D loss: (0.810)(R 0.730, F 0.890)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.632] [G acc: 0.562]\n",
      "21109 [D loss: (1.268)(R 0.723, F 1.812)] [D acc: (0.375)(0.375, 0.375)] [G loss: 1.476] [G acc: 0.500]\n",
      "21110 [D loss: (0.680)(R 0.643, F 0.717)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.900] [G acc: 0.375]\n",
      "21111 [D loss: (0.931)(R 0.905, F 0.958)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.911] [G acc: 0.375]\n",
      "21112 [D loss: (0.863)(R 0.743, F 0.983)] [D acc: (0.375)(0.438, 0.312)] [G loss: 0.691] [G acc: 0.375]\n",
      "21113 [D loss: (0.663)(R 0.676, F 0.651)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.578] [G acc: 0.625]\n",
      "21114 [D loss: (0.987)(R 0.625, F 1.349)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.502] [G acc: 0.625]\n",
      "21115 [D loss: (1.127)(R 0.997, F 1.256)] [D acc: (0.281)(0.125, 0.438)] [G loss: 1.279] [G acc: 0.125]\n",
      "21116 [D loss: (0.656)(R 0.724, F 0.589)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.876] [G acc: 0.250]\n",
      "21117 [D loss: (0.766)(R 0.719, F 0.814)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.686] [G acc: 0.438]\n",
      "21118 [D loss: (1.141)(R 0.758, F 1.524)] [D acc: (0.375)(0.312, 0.438)] [G loss: 0.561] [G acc: 0.562]\n",
      "21119 [D loss: (0.848)(R 0.678, F 1.018)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.553] [G acc: 0.625]\n",
      "21120 [D loss: (0.992)(R 0.665, F 1.320)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.738] [G acc: 0.375]\n",
      "21121 [D loss: (0.916)(R 0.849, F 0.983)] [D acc: (0.406)(0.375, 0.438)] [G loss: 0.345] [G acc: 0.812]\n",
      "21122 [D loss: (0.677)(R 0.712, F 0.641)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.635] [G acc: 0.562]\n",
      "21123 [D loss: (1.056)(R 0.870, F 1.241)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.481] [G acc: 0.688]\n",
      "21124 [D loss: (0.772)(R 0.653, F 0.892)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.585] [G acc: 0.562]\n",
      "21125 [D loss: (1.192)(R 0.632, F 1.752)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.726] [G acc: 0.500]\n",
      "21126 [D loss: (0.633)(R 0.660, F 0.606)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.146] [G acc: 0.312]\n",
      "21127 [D loss: (0.655)(R 0.772, F 0.538)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.942] [G acc: 0.438]\n",
      "21128 [D loss: (0.663)(R 0.642, F 0.684)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.699] [G acc: 0.562]\n",
      "21129 [D loss: (0.744)(R 0.686, F 0.801)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.832] [G acc: 0.250]\n",
      "21130 [D loss: (0.788)(R 0.787, F 0.789)] [D acc: (0.375)(0.375, 0.375)] [G loss: 0.773] [G acc: 0.250]\n",
      "21131 [D loss: (0.778)(R 0.698, F 0.858)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.000] [G acc: 0.438]\n",
      "21132 [D loss: (0.482)(R 0.695, F 0.269)] [D acc: (0.719)(0.562, 0.875)] [G loss: 4.044] [G acc: 0.125]\n",
      "21133 [D loss: (0.593)(R 0.660, F 0.526)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.936] [G acc: 0.000]\n",
      "21134 [D loss: (0.551)(R 0.739, F 0.363)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.349] [G acc: 0.375]\n",
      "21135 [D loss: (0.622)(R 0.712, F 0.532)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.798] [G acc: 0.375]\n",
      "21136 [D loss: (0.716)(R 0.757, F 0.675)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.913] [G acc: 0.250]\n",
      "21137 [D loss: (0.673)(R 0.616, F 0.730)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.541] [G acc: 0.750]\n",
      "21138 [D loss: (0.785)(R 0.769, F 0.801)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.809] [G acc: 0.562]\n",
      "21139 [D loss: (0.678)(R 0.605, F 0.751)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.702] [G acc: 0.500]\n",
      "21140 [D loss: (0.692)(R 0.824, F 0.559)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.772] [G acc: 0.375]\n",
      "21141 [D loss: (0.666)(R 0.635, F 0.697)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.689] [G acc: 0.500]\n",
      "21142 [D loss: (0.694)(R 0.597, F 0.791)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.800] [G acc: 0.500]\n",
      "21143 [D loss: (0.586)(R 0.693, F 0.478)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.667] [G acc: 0.562]\n",
      "21144 [D loss: (0.433)(R 0.533, F 0.333)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.563] [G acc: 0.688]\n",
      "21145 [D loss: (0.674)(R 0.782, F 0.566)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.632] [G acc: 0.625]\n",
      "21146 [D loss: (0.611)(R 0.650, F 0.572)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.674] [G acc: 0.562]\n",
      "21147 [D loss: (0.736)(R 0.674, F 0.799)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.754] [G acc: 0.312]\n",
      "21148 [D loss: (0.623)(R 0.500, F 0.746)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.699] [G acc: 0.375]\n",
      "21149 [D loss: (0.656)(R 0.575, F 0.737)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.709] [G acc: 0.438]\n",
      "21150 [D loss: (0.694)(R 0.645, F 0.743)] [D acc: (0.500)(0.500, 0.500)] [G loss: 1.824] [G acc: 0.125]\n",
      "21151 [D loss: (0.419)(R 0.609, F 0.229)] [D acc: (0.844)(0.812, 0.875)] [G loss: 4.769] [G acc: 0.438]\n",
      "21152 [D loss: (0.545)(R 0.695, F 0.396)] [D acc: (0.562)(0.500, 0.625)] [G loss: 4.294] [G acc: 0.375]\n",
      "21153 [D loss: (0.530)(R 0.622, F 0.437)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.833] [G acc: 0.375]\n",
      "21154 [D loss: (0.822)(R 0.954, F 0.691)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.614] [G acc: 0.625]\n",
      "21155 [D loss: (0.669)(R 0.627, F 0.710)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.753] [G acc: 0.438]\n",
      "21156 [D loss: (0.628)(R 0.563, F 0.694)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.694] [G acc: 0.562]\n",
      "21157 [D loss: (0.688)(R 0.659, F 0.717)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.693] [G acc: 0.500]\n",
      "21158 [D loss: (0.632)(R 0.564, F 0.701)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.732] [G acc: 0.375]\n",
      "21159 [D loss: (0.646)(R 0.626, F 0.666)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.697] [G acc: 0.375]\n",
      "21160 [D loss: (0.679)(R 0.667, F 0.691)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.712] [G acc: 0.375]\n",
      "21161 [D loss: (0.663)(R 0.613, F 0.713)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.862] [G acc: 0.188]\n",
      "21162 [D loss: (0.668)(R 0.657, F 0.679)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.969] [G acc: 0.000]\n",
      "21163 [D loss: (0.633)(R 0.659, F 0.607)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.944] [G acc: 0.188]\n",
      "21164 [D loss: (0.643)(R 0.556, F 0.729)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.824] [G acc: 0.375]\n",
      "21165 [D loss: (0.663)(R 0.572, F 0.753)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.825] [G acc: 0.125]\n",
      "21166 [D loss: (0.639)(R 0.657, F 0.620)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.820] [G acc: 0.250]\n",
      "21167 [D loss: (0.747)(R 0.736, F 0.759)] [D acc: (0.344)(0.375, 0.312)] [G loss: 0.718] [G acc: 0.438]\n",
      "21168 [D loss: (0.625)(R 0.574, F 0.676)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.881] [G acc: 0.125]\n",
      "21169 [D loss: (0.715)(R 0.771, F 0.659)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.761] [G acc: 0.250]\n",
      "21170 [D loss: (0.648)(R 0.653, F 0.643)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.849] [G acc: 0.125]\n",
      "21171 [D loss: (0.691)(R 0.750, F 0.633)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.806] [G acc: 0.125]\n",
      "21172 [D loss: (0.772)(R 0.934, F 0.610)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.859] [G acc: 0.062]\n",
      "21173 [D loss: (0.601)(R 0.582, F 0.620)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.807] [G acc: 0.188]\n",
      "21174 [D loss: (0.652)(R 0.599, F 0.706)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.762] [G acc: 0.438]\n",
      "21175 [D loss: (0.696)(R 0.741, F 0.652)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.856] [G acc: 0.250]\n",
      "21176 [D loss: (0.657)(R 0.679, F 0.636)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.904] [G acc: 0.000]\n",
      "21177 [D loss: (0.623)(R 0.687, F 0.560)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.773] [G acc: 0.312]\n",
      "21178 [D loss: (0.595)(R 0.579, F 0.612)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.860] [G acc: 0.188]\n",
      "21179 [D loss: (0.571)(R 0.546, F 0.596)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.879] [G acc: 0.312]\n",
      "21180 [D loss: (0.597)(R 0.716, F 0.479)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.860] [G acc: 0.250]\n",
      "21181 [D loss: (0.635)(R 0.693, F 0.578)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.857] [G acc: 0.125]\n",
      "21182 [D loss: (0.642)(R 0.661, F 0.623)] [D acc: (0.594)(0.438, 0.750)] [G loss: 1.022] [G acc: 0.250]\n",
      "21183 [D loss: (0.407)(R 0.625, F 0.188)] [D acc: (0.781)(0.688, 0.875)] [G loss: 8.190] [G acc: 0.125]\n",
      "21184 [D loss: (0.652)(R 0.625, F 0.679)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.991] [G acc: 0.312]\n",
      "21185 [D loss: (0.738)(R 0.736, F 0.740)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.858] [G acc: 0.312]\n",
      "21186 [D loss: (0.643)(R 0.757, F 0.528)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.997] [G acc: 0.125]\n",
      "21187 [D loss: (0.687)(R 0.670, F 0.705)] [D acc: (0.562)(0.625, 0.500)] [G loss: 1.033] [G acc: 0.000]\n",
      "21188 [D loss: (0.499)(R 0.641, F 0.357)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.816] [G acc: 0.188]\n",
      "21189 [D loss: (0.707)(R 0.947, F 0.467)] [D acc: (0.406)(0.312, 0.500)] [G loss: 5.213] [G acc: 0.375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21190 [D loss: (0.589)(R 0.546, F 0.633)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.722] [G acc: 0.438]\n",
      "21191 [D loss: (0.527)(R 0.465, F 0.589)] [D acc: (0.875)(0.875, 0.875)] [G loss: 0.822] [G acc: 0.188]\n",
      "21192 [D loss: (0.660)(R 0.643, F 0.677)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.827] [G acc: 0.312]\n",
      "21193 [D loss: (0.684)(R 0.666, F 0.701)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.865] [G acc: 0.375]\n",
      "21194 [D loss: (0.537)(R 0.568, F 0.506)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.829] [G acc: 0.312]\n",
      "21195 [D loss: (0.647)(R 0.670, F 0.624)] [D acc: (0.562)(0.438, 0.688)] [G loss: 1.014] [G acc: 0.188]\n",
      "21196 [D loss: (0.573)(R 0.593, F 0.552)] [D acc: (0.875)(0.812, 0.938)] [G loss: 0.852] [G acc: 0.188]\n",
      "21197 [D loss: (0.594)(R 0.711, F 0.477)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.889] [G acc: 0.062]\n",
      "21198 [D loss: (0.489)(R 0.593, F 0.384)] [D acc: (0.875)(0.812, 0.938)] [G loss: 0.816] [G acc: 0.188]\n",
      "21199 [D loss: (0.590)(R 0.610, F 0.570)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.832] [G acc: 0.250]\n",
      "21200 [D loss: (0.591)(R 0.644, F 0.539)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.915] [G acc: 0.375]\n",
      "21201 [D loss: (0.568)(R 0.698, F 0.438)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.153] [G acc: 0.250]\n",
      "21202 [D loss: (0.631)(R 0.625, F 0.636)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.923] [G acc: 0.188]\n",
      "21203 [D loss: (0.659)(R 0.686, F 0.631)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.912] [G acc: 0.125]\n",
      "21204 [D loss: (0.654)(R 0.604, F 0.705)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.736] [G acc: 0.438]\n",
      "21205 [D loss: (0.534)(R 0.574, F 0.495)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.695] [G acc: 0.250]\n",
      "21206 [D loss: (0.351)(R 0.428, F 0.275)] [D acc: (0.875)(0.875, 0.875)] [G loss: 3.563] [G acc: 0.125]\n",
      "21207 [D loss: (0.526)(R 0.568, F 0.484)] [D acc: (0.656)(0.625, 0.688)] [G loss: 3.068] [G acc: 0.250]\n",
      "21208 [D loss: (0.481)(R 0.593, F 0.368)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.989] [G acc: 0.250]\n",
      "21209 [D loss: (0.569)(R 0.633, F 0.505)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.099] [G acc: 0.188]\n",
      "21210 [D loss: (0.568)(R 0.488, F 0.647)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.866] [G acc: 0.312]\n",
      "21211 [D loss: (0.572)(R 0.520, F 0.625)] [D acc: (0.844)(0.875, 0.812)] [G loss: 0.885] [G acc: 0.250]\n",
      "21212 [D loss: (0.660)(R 0.594, F 0.725)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.989] [G acc: 0.250]\n",
      "21213 [D loss: (0.580)(R 0.501, F 0.658)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.851] [G acc: 0.312]\n",
      "21214 [D loss: (0.838)(R 0.977, F 0.698)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.802] [G acc: 0.312]\n",
      "21215 [D loss: (0.573)(R 0.459, F 0.687)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.726] [G acc: 0.438]\n",
      "21216 [D loss: (0.761)(R 0.813, F 0.709)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.863] [G acc: 0.188]\n",
      "21217 [D loss: (0.611)(R 0.591, F 0.631)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.969] [G acc: 0.312]\n",
      "21218 [D loss: (0.442)(R 0.559, F 0.325)] [D acc: (0.812)(0.625, 1.000)] [G loss: 1.172] [G acc: 0.125]\n",
      "21219 [D loss: (0.635)(R 0.614, F 0.656)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.043] [G acc: 0.188]\n",
      "21220 [D loss: (0.619)(R 0.660, F 0.578)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.752] [G acc: 0.438]\n",
      "21221 [D loss: (0.630)(R 0.657, F 0.603)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.839] [G acc: 0.438]\n",
      "21222 [D loss: (0.450)(R 0.389, F 0.511)] [D acc: (0.875)(0.938, 0.812)] [G loss: 0.941] [G acc: 0.312]\n",
      "21223 [D loss: (0.589)(R 0.468, F 0.709)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.699] [G acc: 0.625]\n",
      "21224 [D loss: (0.520)(R 0.511, F 0.530)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.073] [G acc: 0.188]\n",
      "21225 [D loss: (0.517)(R 0.494, F 0.539)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.033] [G acc: 0.500]\n",
      "21226 [D loss: (0.494)(R 0.469, F 0.519)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.242] [G acc: 0.375]\n",
      "21227 [D loss: (0.811)(R 0.860, F 0.762)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.811] [G acc: 0.375]\n",
      "21228 [D loss: (0.530)(R 0.471, F 0.589)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.653] [G acc: 0.625]\n",
      "21229 [D loss: (0.604)(R 0.505, F 0.703)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.854] [G acc: 0.312]\n",
      "21230 [D loss: (0.547)(R 0.493, F 0.602)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.693] [G acc: 0.500]\n",
      "21231 [D loss: (0.558)(R 0.447, F 0.668)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.695] [G acc: 0.750]\n",
      "21232 [D loss: (0.635)(R 0.494, F 0.776)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.804] [G acc: 0.500]\n",
      "21233 [D loss: (0.593)(R 0.403, F 0.782)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.874] [G acc: 0.250]\n",
      "21234 [D loss: (0.580)(R 0.550, F 0.611)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.890] [G acc: 0.438]\n",
      "21235 [D loss: (0.557)(R 0.468, F 0.646)] [D acc: (0.781)(0.812, 0.750)] [G loss: 2.223] [G acc: 0.250]\n",
      "21236 [D loss: (0.676)(R 0.665, F 0.688)] [D acc: (0.625)(0.688, 0.562)] [G loss: 3.662] [G acc: 0.562]\n",
      "21237 [D loss: (0.407)(R 0.352, F 0.462)] [D acc: (0.750)(0.938, 0.562)] [G loss: 2.428] [G acc: 0.438]\n",
      "21238 [D loss: (0.753)(R 0.682, F 0.824)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.940] [G acc: 0.500]\n",
      "21239 [D loss: (0.703)(R 0.547, F 0.859)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.670] [G acc: 0.438]\n",
      "21240 [D loss: (0.696)(R 0.559, F 0.833)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.817] [G acc: 0.375]\n",
      "21241 [D loss: (0.672)(R 0.602, F 0.742)] [D acc: (0.625)(0.750, 0.500)] [G loss: 1.564] [G acc: 0.500]\n",
      "21242 [D loss: (0.464)(R 0.588, F 0.340)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.968] [G acc: 0.375]\n",
      "21243 [D loss: (0.513)(R 0.563, F 0.462)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.990] [G acc: 0.500]\n",
      "21244 [D loss: (0.612)(R 0.442, F 0.781)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.885] [G acc: 0.250]\n",
      "21245 [D loss: (0.499)(R 0.460, F 0.539)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.904] [G acc: 0.375]\n",
      "21246 [D loss: (0.561)(R 0.604, F 0.517)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.443] [G acc: 0.938]\n",
      "21247 [D loss: (0.620)(R 0.629, F 0.610)] [D acc: (0.625)(0.562, 0.688)] [G loss: 2.324] [G acc: 0.188]\n",
      "21248 [D loss: (0.380)(R 0.614, F 0.147)] [D acc: (0.688)(0.500, 0.875)] [G loss: 7.023] [G acc: 0.188]\n",
      "21249 [D loss: (0.427)(R 0.432, F 0.422)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.790] [G acc: 0.250]\n",
      "21250 [D loss: (0.566)(R 0.495, F 0.637)] [D acc: (0.625)(0.750, 0.500)] [G loss: 1.062] [G acc: 0.188]\n",
      "21251 [D loss: (0.544)(R 0.502, F 0.586)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.215] [G acc: 0.438]\n",
      "21252 [D loss: (0.625)(R 0.641, F 0.609)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.594] [G acc: 0.688]\n",
      "21253 [D loss: (0.851)(R 0.530, F 1.172)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.152] [G acc: 0.188]\n",
      "21254 [D loss: (0.537)(R 0.494, F 0.581)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.761] [G acc: 0.312]\n",
      "21255 [D loss: (0.499)(R 0.491, F 0.506)] [D acc: (0.844)(0.938, 0.750)] [G loss: 1.678] [G acc: 0.250]\n",
      "21256 [D loss: (0.401)(R 0.444, F 0.358)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.291] [G acc: 0.250]\n",
      "21257 [D loss: (1.173)(R 1.380, F 0.966)] [D acc: (0.344)(0.562, 0.125)] [G loss: 1.002] [G acc: 0.438]\n",
      "21258 [D loss: (0.348)(R 0.430, F 0.267)] [D acc: (0.906)(0.938, 0.875)] [G loss: 1.198] [G acc: 0.312]\n",
      "21259 [D loss: (0.522)(R 0.492, F 0.552)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.439] [G acc: 0.875]\n",
      "21260 [D loss: (0.535)(R 0.422, F 0.648)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.824] [G acc: 0.500]\n",
      "21261 [D loss: (0.593)(R 0.520, F 0.665)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.471] [G acc: 0.750]\n",
      "21262 [D loss: (0.730)(R 0.486, F 0.974)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.630] [G acc: 0.625]\n",
      "21263 [D loss: (0.703)(R 0.545, F 0.861)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.565] [G acc: 0.750]\n",
      "21264 [D loss: (0.794)(R 0.514, F 1.074)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.580] [G acc: 0.812]\n",
      "21265 [D loss: (0.690)(R 0.612, F 0.769)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.891] [G acc: 0.438]\n",
      "21266 [D loss: (0.432)(R 0.481, F 0.382)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.637] [G acc: 0.562]\n",
      "21267 [D loss: (0.397)(R 0.551, F 0.243)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.748] [G acc: 0.250]\n",
      "21268 [D loss: (0.985)(R 0.719, F 1.251)] [D acc: (0.594)(0.688, 0.500)] [G loss: 2.762] [G acc: 0.562]\n",
      "21269 [D loss: (0.661)(R 0.462, F 0.859)] [D acc: (0.688)(0.938, 0.438)] [G loss: 0.692] [G acc: 0.688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21270 [D loss: (0.589)(R 0.321, F 0.858)] [D acc: (0.594)(0.875, 0.312)] [G loss: 1.582] [G acc: 0.438]\n",
      "21271 [D loss: (0.465)(R 0.693, F 0.237)] [D acc: (0.812)(0.625, 1.000)] [G loss: 2.970] [G acc: 0.250]\n",
      "21272 [D loss: (0.649)(R 0.521, F 0.777)] [D acc: (0.562)(0.750, 0.375)] [G loss: 1.200] [G acc: 0.500]\n",
      "21273 [D loss: (0.787)(R 1.014, F 0.561)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.739] [G acc: 0.562]\n",
      "21274 [D loss: (0.612)(R 0.462, F 0.761)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.699] [G acc: 0.500]\n",
      "21275 [D loss: (0.576)(R 0.546, F 0.606)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.826] [G acc: 0.688]\n",
      "21276 [D loss: (0.589)(R 0.461, F 0.716)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.429] [G acc: 0.750]\n",
      "21277 [D loss: (0.720)(R 0.556, F 0.884)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.652] [G acc: 0.500]\n",
      "21278 [D loss: (0.692)(R 0.714, F 0.670)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.776] [G acc: 0.375]\n",
      "21279 [D loss: (0.543)(R 0.492, F 0.593)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.714] [G acc: 0.562]\n",
      "21280 [D loss: (0.725)(R 0.475, F 0.975)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.792] [G acc: 0.438]\n",
      "21281 [D loss: (0.608)(R 0.599, F 0.617)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.890] [G acc: 0.375]\n",
      "21282 [D loss: (0.761)(R 0.655, F 0.868)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.620] [G acc: 0.625]\n",
      "21283 [D loss: (0.763)(R 0.646, F 0.880)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.478] [G acc: 0.750]\n",
      "21284 [D loss: (0.791)(R 0.634, F 0.947)] [D acc: (0.375)(0.500, 0.250)] [G loss: 0.603] [G acc: 0.562]\n",
      "21285 [D loss: (0.624)(R 0.576, F 0.672)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.500] [G acc: 0.688]\n",
      "21286 [D loss: (0.928)(R 0.531, F 1.325)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.742] [G acc: 0.438]\n",
      "21287 [D loss: (0.529)(R 0.517, F 0.542)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.916] [G acc: 0.438]\n",
      "21288 [D loss: (0.691)(R 0.571, F 0.812)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.910] [G acc: 0.500]\n",
      "21289 [D loss: (0.697)(R 0.680, F 0.715)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.675] [G acc: 0.562]\n",
      "21290 [D loss: (0.625)(R 0.436, F 0.813)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.923] [G acc: 0.562]\n",
      "21291 [D loss: (0.488)(R 0.556, F 0.421)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.948] [G acc: 0.438]\n",
      "21292 [D loss: (0.834)(R 0.654, F 1.014)] [D acc: (0.531)(0.500, 0.562)] [G loss: 1.696] [G acc: 0.375]\n",
      "21293 [D loss: (0.462)(R 0.719, F 0.205)] [D acc: (0.812)(0.625, 1.000)] [G loss: 1.523] [G acc: 0.312]\n",
      "21294 [D loss: (0.551)(R 0.703, F 0.399)] [D acc: (0.656)(0.438, 0.875)] [G loss: 1.133] [G acc: 0.250]\n",
      "21295 [D loss: (0.441)(R 0.579, F 0.303)] [D acc: (0.844)(0.688, 1.000)] [G loss: 3.189] [G acc: 0.062]\n",
      "21296 [D loss: (0.661)(R 1.037, F 0.284)] [D acc: (0.625)(0.500, 0.750)] [G loss: 3.202] [G acc: 0.438]\n",
      "21297 [D loss: (0.730)(R 0.605, F 0.856)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.523] [G acc: 0.500]\n",
      "21298 [D loss: (0.701)(R 0.621, F 0.781)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.492] [G acc: 0.625]\n",
      "21299 [D loss: (1.064)(R 0.525, F 1.602)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.822] [G acc: 0.250]\n",
      "21300 [D loss: (0.696)(R 0.647, F 0.744)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.801] [G acc: 0.188]\n",
      "21301 [D loss: (0.416)(R 0.394, F 0.439)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.067] [G acc: 0.125]\n",
      "21302 [D loss: (0.607)(R 0.647, F 0.567)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.664] [G acc: 0.438]\n",
      "21303 [D loss: (0.656)(R 0.559, F 0.753)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.934] [G acc: 0.125]\n",
      "21304 [D loss: (0.732)(R 0.725, F 0.738)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.756] [G acc: 0.312]\n",
      "21305 [D loss: (0.736)(R 0.447, F 1.025)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.767] [G acc: 0.250]\n",
      "21306 [D loss: (0.674)(R 0.622, F 0.725)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.199] [G acc: 0.188]\n",
      "21307 [D loss: (0.437)(R 0.486, F 0.387)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.475] [G acc: 0.125]\n",
      "21308 [D loss: (0.475)(R 0.516, F 0.434)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.006] [G acc: 0.250]\n",
      "21309 [D loss: (1.005)(R 0.665, F 1.346)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.865] [G acc: 0.125]\n",
      "21310 [D loss: (0.640)(R 0.578, F 0.702)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.833] [G acc: 0.188]\n",
      "21311 [D loss: (0.625)(R 0.676, F 0.574)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.963] [G acc: 0.188]\n",
      "21312 [D loss: (0.750)(R 0.680, F 0.820)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.903] [G acc: 0.375]\n",
      "21313 [D loss: (0.400)(R 0.436, F 0.363)] [D acc: (0.906)(0.875, 0.938)] [G loss: 2.807] [G acc: 0.062]\n",
      "21314 [D loss: (0.474)(R 0.491, F 0.457)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.004] [G acc: 0.250]\n",
      "21315 [D loss: (0.535)(R 0.583, F 0.486)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.523] [G acc: 0.125]\n",
      "21316 [D loss: (0.656)(R 0.698, F 0.615)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.822] [G acc: 0.312]\n",
      "21317 [D loss: (0.564)(R 0.548, F 0.581)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.804] [G acc: 0.312]\n",
      "21318 [D loss: (0.465)(R 0.401, F 0.530)] [D acc: (0.906)(0.875, 0.938)] [G loss: 0.735] [G acc: 0.375]\n",
      "21319 [D loss: (0.580)(R 0.436, F 0.724)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.939] [G acc: 0.250]\n",
      "21320 [D loss: (0.806)(R 0.632, F 0.979)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.987] [G acc: 0.000]\n",
      "21321 [D loss: (0.756)(R 0.559, F 0.953)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.197] [G acc: 0.125]\n",
      "21322 [D loss: (0.415)(R 0.456, F 0.374)] [D acc: (0.969)(0.938, 1.000)] [G loss: 1.644] [G acc: 0.000]\n",
      "21323 [D loss: (0.526)(R 0.584, F 0.468)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.091] [G acc: 0.125]\n",
      "21324 [D loss: (0.712)(R 0.960, F 0.464)] [D acc: (0.656)(0.375, 0.938)] [G loss: 1.141] [G acc: 0.125]\n",
      "21325 [D loss: (0.662)(R 0.642, F 0.682)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.074] [G acc: 0.000]\n",
      "21326 [D loss: (0.471)(R 0.487, F 0.455)] [D acc: (0.875)(0.750, 1.000)] [G loss: 1.161] [G acc: 0.000]\n",
      "21327 [D loss: (0.504)(R 0.548, F 0.460)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.011] [G acc: 0.125]\n",
      "21328 [D loss: (0.516)(R 0.598, F 0.433)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.941] [G acc: 0.188]\n",
      "21329 [D loss: (0.645)(R 0.524, F 0.767)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.022] [G acc: 0.188]\n",
      "21330 [D loss: (0.447)(R 0.425, F 0.468)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.035] [G acc: 0.250]\n",
      "21331 [D loss: (0.524)(R 0.538, F 0.510)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.160] [G acc: 0.312]\n",
      "21332 [D loss: (1.127)(R 0.536, F 1.719)] [D acc: (0.656)(0.750, 0.562)] [G loss: 4.140] [G acc: 0.250]\n",
      "21333 [D loss: (0.445)(R 0.604, F 0.286)] [D acc: (0.719)(0.625, 0.812)] [G loss: 2.244] [G acc: 0.000]\n",
      "21334 [D loss: (0.505)(R 0.568, F 0.442)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.353] [G acc: 0.062]\n",
      "21335 [D loss: (0.648)(R 0.507, F 0.788)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.296] [G acc: 0.125]\n",
      "21336 [D loss: (0.619)(R 0.558, F 0.680)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.365] [G acc: 0.375]\n",
      "21337 [D loss: (0.381)(R 0.702, F 0.061)] [D acc: (0.781)(0.562, 1.000)] [G loss: 3.712] [G acc: 0.062]\n",
      "21338 [D loss: (0.626)(R 0.502, F 0.751)] [D acc: (0.719)(0.750, 0.688)] [G loss: 2.035] [G acc: 0.312]\n",
      "21339 [D loss: (0.531)(R 0.735, F 0.327)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.005] [G acc: 0.375]\n",
      "21340 [D loss: (0.572)(R 0.563, F 0.581)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.233] [G acc: 0.312]\n",
      "21341 [D loss: (0.441)(R 0.447, F 0.436)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.452] [G acc: 0.125]\n",
      "21342 [D loss: (0.467)(R 0.382, F 0.551)] [D acc: (0.875)(0.938, 0.812)] [G loss: 1.689] [G acc: 0.125]\n",
      "21343 [D loss: (0.425)(R 0.478, F 0.373)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.290] [G acc: 0.125]\n",
      "21344 [D loss: (0.501)(R 0.571, F 0.430)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.333] [G acc: 0.062]\n",
      "21345 [D loss: (0.640)(R 0.807, F 0.473)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.579] [G acc: 0.062]\n",
      "21346 [D loss: (0.428)(R 0.364, F 0.491)] [D acc: (0.906)(0.938, 0.875)] [G loss: 0.938] [G acc: 0.375]\n",
      "21347 [D loss: (0.404)(R 0.439, F 0.369)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.809] [G acc: 0.312]\n",
      "21348 [D loss: (0.523)(R 0.458, F 0.588)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.191] [G acc: 0.125]\n",
      "21349 [D loss: (0.598)(R 0.591, F 0.606)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.973] [G acc: 0.312]\n",
      "21350 [D loss: (0.523)(R 0.647, F 0.400)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.999] [G acc: 0.188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21351 [D loss: (0.556)(R 0.538, F 0.574)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.412] [G acc: 0.750]\n",
      "21352 [D loss: (0.455)(R 0.434, F 0.476)] [D acc: (0.719)(0.812, 0.625)] [G loss: 2.095] [G acc: 0.188]\n",
      "21353 [D loss: (0.509)(R 0.701, F 0.317)] [D acc: (0.781)(0.688, 0.875)] [G loss: 4.865] [G acc: 0.375]\n",
      "21354 [D loss: (0.471)(R 0.453, F 0.489)] [D acc: (0.781)(0.812, 0.750)] [G loss: 5.212] [G acc: 0.250]\n",
      "21355 [D loss: (0.557)(R 0.579, F 0.535)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.362] [G acc: 0.125]\n",
      "21356 [D loss: (0.472)(R 0.370, F 0.573)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.405] [G acc: 0.062]\n",
      "21357 [D loss: (0.497)(R 0.335, F 0.659)] [D acc: (0.750)(0.875, 0.625)] [G loss: 1.286] [G acc: 0.188]\n",
      "21358 [D loss: (0.471)(R 0.475, F 0.466)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.799] [G acc: 0.438]\n",
      "21359 [D loss: (0.327)(R 0.390, F 0.263)] [D acc: (0.875)(0.750, 1.000)] [G loss: 1.251] [G acc: 0.125]\n",
      "21360 [D loss: (0.577)(R 0.465, F 0.689)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.857] [G acc: 0.375]\n",
      "21361 [D loss: (0.573)(R 0.413, F 0.733)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.829] [G acc: 0.375]\n",
      "21362 [D loss: (0.560)(R 0.595, F 0.524)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.495] [G acc: 0.625]\n",
      "21363 [D loss: (0.485)(R 0.298, F 0.672)] [D acc: (0.750)(1.000, 0.500)] [G loss: 1.096] [G acc: 0.125]\n",
      "21364 [D loss: (0.751)(R 0.689, F 0.813)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.831] [G acc: 0.375]\n",
      "21365 [D loss: (0.527)(R 0.494, F 0.560)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.726] [G acc: 0.438]\n",
      "21366 [D loss: (0.524)(R 0.402, F 0.645)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.727] [G acc: 0.500]\n",
      "21367 [D loss: (0.687)(R 0.562, F 0.812)] [D acc: (0.719)(0.812, 0.625)] [G loss: 2.557] [G acc: 0.062]\n",
      "21368 [D loss: (0.412)(R 0.456, F 0.368)] [D acc: (0.781)(0.812, 0.750)] [G loss: 2.544] [G acc: 0.062]\n",
      "21369 [D loss: (0.480)(R 0.525, F 0.436)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.565] [G acc: 0.188]\n",
      "21370 [D loss: (0.306)(R 0.307, F 0.305)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.580] [G acc: 0.500]\n",
      "21371 [D loss: (0.508)(R 0.386, F 0.629)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.396] [G acc: 0.500]\n",
      "21372 [D loss: (0.549)(R 0.435, F 0.662)] [D acc: (0.844)(0.875, 0.812)] [G loss: 2.632] [G acc: 0.188]\n",
      "21373 [D loss: (0.596)(R 0.522, F 0.670)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.826] [G acc: 0.562]\n",
      "21374 [D loss: (0.435)(R 0.339, F 0.530)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.250] [G acc: 0.188]\n",
      "21375 [D loss: (0.492)(R 0.406, F 0.577)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.666] [G acc: 0.625]\n",
      "21376 [D loss: (0.535)(R 0.617, F 0.454)] [D acc: (0.594)(0.500, 0.688)] [G loss: 2.306] [G acc: 0.125]\n",
      "21377 [D loss: (0.577)(R 0.440, F 0.714)] [D acc: (0.625)(0.750, 0.500)] [G loss: 1.020] [G acc: 0.688]\n",
      "21378 [D loss: (0.513)(R 0.435, F 0.592)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.716] [G acc: 0.188]\n",
      "21379 [D loss: (0.637)(R 0.388, F 0.886)] [D acc: (0.750)(0.812, 0.688)] [G loss: 2.099] [G acc: 0.125]\n",
      "21380 [D loss: (0.553)(R 0.946, F 0.160)] [D acc: (0.719)(0.562, 0.875)] [G loss: 6.117] [G acc: 0.188]\n",
      "21381 [D loss: (0.639)(R 0.472, F 0.807)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.532] [G acc: 0.312]\n",
      "21382 [D loss: (0.616)(R 0.941, F 0.290)] [D acc: (0.562)(0.312, 0.812)] [G loss: 2.305] [G acc: 0.312]\n",
      "21383 [D loss: (0.505)(R 0.369, F 0.641)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.969] [G acc: 0.438]\n",
      "21384 [D loss: (0.577)(R 0.473, F 0.682)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.451] [G acc: 0.188]\n",
      "21385 [D loss: (0.714)(R 0.742, F 0.685)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.969] [G acc: 0.438]\n",
      "21386 [D loss: (0.543)(R 0.387, F 0.700)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.839] [G acc: 0.312]\n",
      "21387 [D loss: (1.557)(R 2.519, F 0.594)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.604] [G acc: 0.625]\n",
      "21388 [D loss: (0.642)(R 0.630, F 0.654)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.563] [G acc: 0.188]\n",
      "21389 [D loss: (0.679)(R 0.645, F 0.712)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.242] [G acc: 0.125]\n",
      "21390 [D loss: (0.611)(R 0.686, F 0.535)] [D acc: (0.656)(0.438, 0.875)] [G loss: 1.080] [G acc: 0.250]\n",
      "21391 [D loss: (0.298)(R 0.204, F 0.392)] [D acc: (0.938)(0.875, 1.000)] [G loss: 1.224] [G acc: 0.438]\n",
      "21392 [D loss: (0.437)(R 0.560, F 0.314)] [D acc: (0.750)(0.562, 0.938)] [G loss: 2.114] [G acc: 0.000]\n",
      "21393 [D loss: (0.958)(R 0.828, F 1.088)] [D acc: (0.375)(0.438, 0.312)] [G loss: 1.363] [G acc: 0.125]\n",
      "21394 [D loss: (0.509)(R 0.625, F 0.393)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.173] [G acc: 0.062]\n",
      "21395 [D loss: (0.635)(R 0.635, F 0.636)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.925] [G acc: 0.250]\n",
      "21396 [D loss: (0.515)(R 0.477, F 0.552)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.037] [G acc: 0.250]\n",
      "21397 [D loss: (0.866)(R 1.165, F 0.568)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.976] [G acc: 0.375]\n",
      "21398 [D loss: (0.641)(R 0.633, F 0.649)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.856] [G acc: 0.188]\n",
      "21399 [D loss: (0.589)(R 0.615, F 0.563)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.811] [G acc: 0.375]\n",
      "21400 [D loss: (0.652)(R 0.521, F 0.784)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.746] [G acc: 0.375]\n",
      "21401 [D loss: (0.569)(R 0.613, F 0.525)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.030] [G acc: 0.125]\n",
      "21402 [D loss: (0.712)(R 0.766, F 0.658)] [D acc: (0.500)(0.500, 0.500)] [G loss: 1.514] [G acc: 0.062]\n",
      "21403 [D loss: (0.498)(R 0.648, F 0.348)] [D acc: (0.719)(0.500, 0.938)] [G loss: 1.685] [G acc: 0.125]\n",
      "21404 [D loss: (0.451)(R 0.726, F 0.175)] [D acc: (0.656)(0.312, 1.000)] [G loss: 1.934] [G acc: 0.125]\n",
      "21405 [D loss: (0.496)(R 0.558, F 0.434)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.286] [G acc: 0.000]\n",
      "21406 [D loss: (0.545)(R 0.616, F 0.473)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.912] [G acc: 0.312]\n",
      "21407 [D loss: (0.757)(R 0.652, F 0.862)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.995] [G acc: 0.188]\n",
      "21408 [D loss: (0.447)(R 0.446, F 0.447)] [D acc: (0.906)(0.875, 0.938)] [G loss: 0.855] [G acc: 0.312]\n",
      "21409 [D loss: (0.656)(R 0.717, F 0.596)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.865] [G acc: 0.250]\n",
      "21410 [D loss: (0.558)(R 0.505, F 0.612)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.752] [G acc: 0.438]\n",
      "21411 [D loss: (0.695)(R 0.731, F 0.658)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.933] [G acc: 0.125]\n",
      "21412 [D loss: (0.680)(R 0.720, F 0.640)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.861] [G acc: 0.125]\n",
      "21413 [D loss: (0.947)(R 0.911, F 0.982)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.799] [G acc: 0.375]\n",
      "21414 [D loss: (0.671)(R 0.645, F 0.697)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.972] [G acc: 0.125]\n",
      "21415 [D loss: (0.485)(R 0.325, F 0.644)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.689] [G acc: 0.500]\n",
      "21416 [D loss: (0.664)(R 0.595, F 0.733)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.652] [G acc: 0.438]\n",
      "21417 [D loss: (0.490)(R 0.384, F 0.596)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.651] [G acc: 0.438]\n",
      "21418 [D loss: (0.886)(R 0.643, F 1.129)] [D acc: (0.375)(0.438, 0.312)] [G loss: 1.312] [G acc: 0.312]\n",
      "21419 [D loss: (0.545)(R 0.737, F 0.353)] [D acc: (0.594)(0.312, 0.875)] [G loss: 3.818] [G acc: 0.375]\n",
      "21420 [D loss: (0.722)(R 0.574, F 0.871)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.425] [G acc: 0.250]\n",
      "21421 [D loss: (0.658)(R 0.717, F 0.598)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.860] [G acc: 0.250]\n",
      "21422 [D loss: (0.622)(R 0.641, F 0.603)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.904] [G acc: 0.312]\n",
      "21423 [D loss: (0.511)(R 0.377, F 0.645)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.199] [G acc: 0.188]\n",
      "21424 [D loss: (0.511)(R 0.555, F 0.467)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.237] [G acc: 0.375]\n",
      "21425 [D loss: (0.421)(R 0.526, F 0.315)] [D acc: (0.719)(0.500, 0.938)] [G loss: 2.839] [G acc: 0.000]\n",
      "21426 [D loss: (0.665)(R 0.773, F 0.557)] [D acc: (0.656)(0.375, 0.938)] [G loss: 1.927] [G acc: 0.250]\n",
      "21427 [D loss: (0.414)(R 0.510, F 0.319)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.077] [G acc: 0.312]\n",
      "21428 [D loss: (0.998)(R 0.852, F 1.144)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.687] [G acc: 0.438]\n",
      "21429 [D loss: (0.651)(R 0.555, F 0.747)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.903] [G acc: 0.312]\n",
      "21430 [D loss: (0.703)(R 0.499, F 0.906)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.754] [G acc: 0.438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21431 [D loss: (0.660)(R 0.787, F 0.533)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.108] [G acc: 0.375]\n",
      "21432 [D loss: (0.584)(R 0.483, F 0.686)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.968] [G acc: 0.688]\n",
      "21433 [D loss: (0.492)(R 0.601, F 0.382)] [D acc: (0.750)(0.625, 0.875)] [G loss: 2.155] [G acc: 0.250]\n",
      "21434 [D loss: (0.703)(R 0.599, F 0.807)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.124] [G acc: 0.188]\n",
      "21435 [D loss: (0.501)(R 0.737, F 0.266)] [D acc: (0.688)(0.438, 0.938)] [G loss: 1.519] [G acc: 0.000]\n",
      "21436 [D loss: (0.509)(R 0.570, F 0.448)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.960] [G acc: 0.062]\n",
      "21437 [D loss: (0.755)(R 0.829, F 0.682)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.010] [G acc: 0.438]\n",
      "21438 [D loss: (0.491)(R 0.360, F 0.622)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.844] [G acc: 0.125]\n",
      "21439 [D loss: (0.730)(R 0.732, F 0.727)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.881] [G acc: 0.438]\n",
      "21440 [D loss: (0.528)(R 0.519, F 0.537)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.409] [G acc: 0.062]\n",
      "21441 [D loss: (0.512)(R 0.499, F 0.524)] [D acc: (0.656)(0.688, 0.625)] [G loss: 2.404] [G acc: 0.312]\n",
      "21442 [D loss: (0.414)(R 0.653, F 0.175)] [D acc: (0.844)(0.688, 1.000)] [G loss: 6.317] [G acc: 0.062]\n",
      "21443 [D loss: (0.636)(R 0.714, F 0.559)] [D acc: (0.562)(0.438, 0.688)] [G loss: 1.036] [G acc: 0.062]\n",
      "21444 [D loss: (0.695)(R 0.863, F 0.526)] [D acc: (0.625)(0.438, 0.812)] [G loss: 1.898] [G acc: 0.125]\n",
      "21445 [D loss: (0.454)(R 0.519, F 0.388)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.801] [G acc: 0.125]\n",
      "21446 [D loss: (0.545)(R 0.536, F 0.554)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.848] [G acc: 0.125]\n",
      "21447 [D loss: (0.456)(R 0.396, F 0.517)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.007] [G acc: 0.125]\n",
      "21448 [D loss: (0.566)(R 0.615, F 0.518)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.912] [G acc: 0.062]\n",
      "21449 [D loss: (0.543)(R 0.559, F 0.527)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.717] [G acc: 0.438]\n",
      "21450 [D loss: (0.527)(R 0.555, F 0.499)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.856] [G acc: 0.125]\n",
      "21451 [D loss: (0.526)(R 0.473, F 0.580)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.960] [G acc: 0.125]\n",
      "21452 [D loss: (0.664)(R 0.675, F 0.654)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.904] [G acc: 0.000]\n",
      "21453 [D loss: (0.497)(R 0.457, F 0.537)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.954] [G acc: 0.125]\n",
      "21454 [D loss: (0.474)(R 0.414, F 0.535)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.943] [G acc: 0.250]\n",
      "21455 [D loss: (0.556)(R 0.525, F 0.587)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.937] [G acc: 0.125]\n",
      "21456 [D loss: (0.594)(R 0.516, F 0.672)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.782] [G acc: 0.375]\n",
      "21457 [D loss: (0.596)(R 0.647, F 0.545)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.027] [G acc: 0.188]\n",
      "21458 [D loss: (0.547)(R 0.476, F 0.617)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.678] [G acc: 0.500]\n",
      "21459 [D loss: (0.527)(R 0.467, F 0.588)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.103] [G acc: 0.125]\n",
      "21460 [D loss: (0.547)(R 0.549, F 0.545)] [D acc: (0.594)(0.438, 0.750)] [G loss: 1.036] [G acc: 0.188]\n",
      "21461 [D loss: (0.572)(R 0.528, F 0.617)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.481] [G acc: 0.688]\n",
      "21462 [D loss: (0.526)(R 0.471, F 0.581)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.087] [G acc: 0.250]\n",
      "21463 [D loss: (0.553)(R 0.734, F 0.372)] [D acc: (0.594)(0.375, 0.812)] [G loss: 1.122] [G acc: 0.188]\n",
      "21464 [D loss: (0.560)(R 0.878, F 0.242)] [D acc: (0.562)(0.250, 0.875)] [G loss: 2.947] [G acc: 0.438]\n",
      "21465 [D loss: (1.424)(R 0.448, F 2.400)] [D acc: (0.594)(0.812, 0.375)] [G loss: 2.231] [G acc: 0.312]\n",
      "21466 [D loss: (0.617)(R 0.598, F 0.636)] [D acc: (0.562)(0.500, 0.625)] [G loss: 1.315] [G acc: 0.062]\n",
      "21467 [D loss: (0.701)(R 0.793, F 0.609)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.035] [G acc: 0.188]\n",
      "21468 [D loss: (0.995)(R 0.681, F 1.309)] [D acc: (0.438)(0.562, 0.312)] [G loss: 1.380] [G acc: 0.375]\n",
      "21469 [D loss: (0.487)(R 0.605, F 0.368)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.990] [G acc: 0.188]\n",
      "21470 [D loss: (0.626)(R 0.639, F 0.612)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.089] [G acc: 0.250]\n",
      "21471 [D loss: (0.540)(R 0.639, F 0.440)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.854] [G acc: 0.250]\n",
      "21472 [D loss: (0.555)(R 0.627, F 0.484)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.727] [G acc: 0.500]\n",
      "21473 [D loss: (0.740)(R 0.711, F 0.770)] [D acc: (0.594)(0.625, 0.562)] [G loss: 2.046] [G acc: 0.250]\n",
      "21474 [D loss: (0.403)(R 0.561, F 0.246)] [D acc: (0.719)(0.562, 0.875)] [G loss: 3.068] [G acc: 0.250]\n",
      "21475 [D loss: (0.639)(R 0.694, F 0.584)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.416] [G acc: 0.125]\n",
      "21476 [D loss: (0.585)(R 0.534, F 0.636)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.927] [G acc: 0.312]\n",
      "21477 [D loss: (0.382)(R 0.583, F 0.181)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.633] [G acc: 0.188]\n",
      "21478 [D loss: (0.404)(R 0.550, F 0.258)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.411] [G acc: 0.188]\n",
      "21479 [D loss: (0.517)(R 0.776, F 0.258)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.762] [G acc: 0.375]\n",
      "21480 [D loss: (0.482)(R 0.527, F 0.437)] [D acc: (0.875)(0.750, 1.000)] [G loss: 1.110] [G acc: 0.188]\n",
      "21481 [D loss: (0.559)(R 0.488, F 0.630)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.853] [G acc: 0.375]\n",
      "21482 [D loss: (0.613)(R 0.644, F 0.582)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.190] [G acc: 0.312]\n",
      "21483 [D loss: (0.562)(R 0.617, F 0.508)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.495] [G acc: 0.750]\n",
      "21484 [D loss: (0.483)(R 0.416, F 0.550)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.509] [G acc: 0.438]\n",
      "21485 [D loss: (0.610)(R 0.468, F 0.753)] [D acc: (0.688)(0.812, 0.562)] [G loss: 5.268] [G acc: 0.438]\n",
      "21486 [D loss: (0.261)(R 0.403, F 0.120)] [D acc: (0.906)(0.812, 1.000)] [G loss: 1.538] [G acc: 0.125]\n",
      "21487 [D loss: (0.652)(R 0.670, F 0.634)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.543] [G acc: 0.750]\n",
      "21488 [D loss: (0.715)(R 0.583, F 0.847)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.454] [G acc: 0.688]\n",
      "21489 [D loss: (0.669)(R 0.653, F 0.686)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.923] [G acc: 0.125]\n",
      "21490 [D loss: (0.804)(R 0.869, F 0.738)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.645] [G acc: 0.750]\n",
      "21491 [D loss: (0.765)(R 0.647, F 0.882)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.833] [G acc: 0.438]\n",
      "21492 [D loss: (0.876)(R 0.676, F 1.077)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.900] [G acc: 0.438]\n",
      "21493 [D loss: (0.544)(R 0.698, F 0.390)] [D acc: (0.688)(0.625, 0.750)] [G loss: 2.499] [G acc: 0.438]\n",
      "21494 [D loss: (0.746)(R 0.448, F 1.045)] [D acc: (0.656)(0.812, 0.500)] [G loss: 5.600] [G acc: 0.312]\n",
      "21495 [D loss: (0.812)(R 0.535, F 1.088)] [D acc: (0.625)(0.750, 0.500)] [G loss: 2.007] [G acc: 0.688]\n",
      "21496 [D loss: (1.075)(R 0.612, F 1.538)] [D acc: (0.688)(0.688, 0.688)] [G loss: 5.384] [G acc: 0.625]\n",
      "21497 [D loss: (0.675)(R 0.605, F 0.744)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.678] [G acc: 0.562]\n",
      "21498 [D loss: (0.782)(R 0.582, F 0.982)] [D acc: (0.594)(0.750, 0.438)] [G loss: 1.106] [G acc: 0.500]\n",
      "21499 [D loss: (0.670)(R 0.813, F 0.527)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.591] [G acc: 0.562]\n",
      "21500 [D loss: (0.719)(R 0.683, F 0.756)] [D acc: (0.562)(0.562, 0.562)] [G loss: 1.158] [G acc: 0.562]\n",
      "21501 [D loss: (0.976)(R 1.079, F 0.874)] [D acc: (0.469)(0.438, 0.500)] [G loss: 1.268] [G acc: 0.438]\n",
      "21502 [D loss: (0.790)(R 0.473, F 1.107)] [D acc: (0.625)(0.812, 0.438)] [G loss: 2.179] [G acc: 0.562]\n",
      "21503 [D loss: (0.587)(R 0.581, F 0.592)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.224] [G acc: 0.438]\n",
      "21504 [D loss: (0.696)(R 0.708, F 0.684)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.909] [G acc: 0.438]\n",
      "21505 [D loss: (0.633)(R 0.591, F 0.674)] [D acc: (0.656)(0.625, 0.688)] [G loss: 3.074] [G acc: 0.250]\n",
      "21506 [D loss: (0.717)(R 0.627, F 0.808)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.685] [G acc: 0.688]\n",
      "21507 [D loss: (0.640)(R 0.663, F 0.617)] [D acc: (0.688)(0.688, 0.688)] [G loss: 2.562] [G acc: 0.625]\n",
      "21508 [D loss: (0.562)(R 0.639, F 0.485)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.487] [G acc: 0.438]\n",
      "21509 [D loss: (0.631)(R 0.653, F 0.609)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.373] [G acc: 0.438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21510 [D loss: (0.600)(R 0.643, F 0.558)] [D acc: (0.562)(0.562, 0.562)] [G loss: 1.453] [G acc: 0.438]\n",
      "21511 [D loss: (0.665)(R 0.542, F 0.787)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.985] [G acc: 0.375]\n",
      "21512 [D loss: (0.643)(R 0.687, F 0.598)] [D acc: (0.750)(0.875, 0.625)] [G loss: 1.224] [G acc: 0.188]\n",
      "21513 [D loss: (0.655)(R 0.637, F 0.673)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.450] [G acc: 0.500]\n",
      "21514 [D loss: (0.523)(R 0.668, F 0.377)] [D acc: (0.750)(0.688, 0.812)] [G loss: 2.855] [G acc: 0.250]\n",
      "21515 [D loss: (0.675)(R 0.516, F 0.833)] [D acc: (0.719)(0.750, 0.688)] [G loss: 4.766] [G acc: 0.438]\n",
      "21516 [D loss: (0.568)(R 0.656, F 0.480)] [D acc: (0.656)(0.688, 0.625)] [G loss: 3.873] [G acc: 0.500]\n",
      "21517 [D loss: (0.534)(R 0.707, F 0.362)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.971] [G acc: 0.312]\n",
      "21518 [D loss: (0.619)(R 0.536, F 0.701)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.896] [G acc: 0.438]\n",
      "21519 [D loss: (0.706)(R 0.657, F 0.756)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.672] [G acc: 0.625]\n",
      "21520 [D loss: (0.795)(R 0.774, F 0.815)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.767] [G acc: 0.375]\n",
      "21521 [D loss: (0.749)(R 0.703, F 0.794)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.651] [G acc: 0.500]\n",
      "21522 [D loss: (0.813)(R 0.717, F 0.908)] [D acc: (0.438)(0.750, 0.125)] [G loss: 0.801] [G acc: 0.375]\n",
      "21523 [D loss: (0.687)(R 0.558, F 0.816)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.586] [G acc: 0.625]\n",
      "21524 [D loss: (0.709)(R 0.606, F 0.812)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.731] [G acc: 0.312]\n",
      "21525 [D loss: (0.677)(R 0.540, F 0.815)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.685] [G acc: 0.438]\n",
      "21526 [D loss: (0.657)(R 0.522, F 0.793)] [D acc: (0.656)(1.000, 0.312)] [G loss: 0.671] [G acc: 0.438]\n",
      "21527 [D loss: (0.631)(R 0.520, F 0.741)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.606] [G acc: 0.750]\n",
      "21528 [D loss: (0.662)(R 0.614, F 0.711)] [D acc: (0.625)(0.750, 0.500)] [G loss: 1.359] [G acc: 0.188]\n",
      "21529 [D loss: (0.552)(R 0.533, F 0.571)] [D acc: (0.750)(0.875, 0.625)] [G loss: 1.384] [G acc: 0.250]\n",
      "21530 [D loss: (0.693)(R 0.601, F 0.786)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.718] [G acc: 0.438]\n",
      "21531 [D loss: (0.647)(R 0.613, F 0.681)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.672] [G acc: 0.438]\n",
      "21532 [D loss: (0.841)(R 0.772, F 0.911)] [D acc: (0.375)(0.562, 0.188)] [G loss: 0.732] [G acc: 0.438]\n",
      "21533 [D loss: (0.647)(R 0.547, F 0.748)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.682] [G acc: 0.438]\n",
      "21534 [D loss: (0.682)(R 0.614, F 0.749)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.833] [G acc: 0.250]\n",
      "21535 [D loss: (0.636)(R 0.619, F 0.654)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.789] [G acc: 0.125]\n",
      "21536 [D loss: (0.693)(R 0.636, F 0.749)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.721] [G acc: 0.312]\n",
      "21537 [D loss: (0.665)(R 0.597, F 0.732)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.910] [G acc: 0.188]\n",
      "21538 [D loss: (0.624)(R 0.561, F 0.687)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.711] [G acc: 0.375]\n",
      "21539 [D loss: (0.707)(R 0.563, F 0.850)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.613] [G acc: 0.562]\n",
      "21540 [D loss: (0.673)(R 0.561, F 0.786)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.790] [G acc: 0.312]\n",
      "21541 [D loss: (0.725)(R 0.692, F 0.757)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.764] [G acc: 0.438]\n",
      "21542 [D loss: (0.644)(R 0.569, F 0.719)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.856] [G acc: 0.188]\n",
      "21543 [D loss: (0.653)(R 0.657, F 0.649)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.970] [G acc: 0.125]\n",
      "21544 [D loss: (0.709)(R 0.679, F 0.739)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.747] [G acc: 0.375]\n",
      "21545 [D loss: (0.717)(R 0.670, F 0.764)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.733] [G acc: 0.188]\n",
      "21546 [D loss: (0.652)(R 0.590, F 0.714)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.677] [G acc: 0.375]\n",
      "21547 [D loss: (0.646)(R 0.610, F 0.683)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.731] [G acc: 0.312]\n",
      "21548 [D loss: (0.640)(R 0.591, F 0.688)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.780] [G acc: 0.250]\n",
      "21549 [D loss: (0.644)(R 0.610, F 0.678)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.736] [G acc: 0.312]\n",
      "21550 [D loss: (0.763)(R 0.827, F 0.699)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.659] [G acc: 0.562]\n",
      "21551 [D loss: (0.656)(R 0.571, F 0.740)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.611] [G acc: 0.500]\n",
      "21552 [D loss: (0.680)(R 0.624, F 0.737)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.630] [G acc: 0.625]\n",
      "21553 [D loss: (0.717)(R 0.662, F 0.772)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.770] [G acc: 0.188]\n",
      "21554 [D loss: (0.644)(R 0.570, F 0.718)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.578] [G acc: 0.750]\n",
      "21555 [D loss: (0.600)(R 0.459, F 0.741)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.666] [G acc: 0.500]\n",
      "21556 [D loss: (0.616)(R 0.568, F 0.663)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.558] [G acc: 0.812]\n",
      "21557 [D loss: (0.684)(R 0.607, F 0.761)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.946] [G acc: 0.250]\n",
      "21558 [D loss: (0.412)(R 0.529, F 0.295)] [D acc: (0.844)(0.812, 0.875)] [G loss: 5.331] [G acc: 0.062]\n",
      "21559 [D loss: (0.624)(R 0.676, F 0.572)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.906] [G acc: 0.312]\n",
      "21560 [D loss: (0.486)(R 0.584, F 0.389)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.753] [G acc: 0.250]\n",
      "21561 [D loss: (0.455)(R 0.522, F 0.387)] [D acc: (0.938)(0.938, 0.938)] [G loss: 0.718] [G acc: 0.250]\n",
      "21562 [D loss: (0.457)(R 0.503, F 0.411)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.097] [G acc: 0.188]\n",
      "21563 [D loss: (0.639)(R 0.641, F 0.638)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.696] [G acc: 0.438]\n",
      "21564 [D loss: (0.620)(R 0.492, F 0.748)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.727] [G acc: 0.438]\n",
      "21565 [D loss: (0.623)(R 0.622, F 0.623)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.378] [G acc: 0.250]\n",
      "21566 [D loss: (0.663)(R 0.663, F 0.663)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.650] [G acc: 0.500]\n",
      "21567 [D loss: (0.686)(R 0.584, F 0.788)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.772] [G acc: 0.312]\n",
      "21568 [D loss: (0.594)(R 0.649, F 0.539)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.741] [G acc: 0.312]\n",
      "21569 [D loss: (0.700)(R 0.704, F 0.696)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.741] [G acc: 0.438]\n",
      "21570 [D loss: (0.672)(R 0.698, F 0.646)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.699] [G acc: 0.312]\n",
      "21571 [D loss: (0.621)(R 0.562, F 0.681)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.650] [G acc: 0.500]\n",
      "21572 [D loss: (0.721)(R 0.733, F 0.708)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.638] [G acc: 0.562]\n",
      "21573 [D loss: (0.612)(R 0.499, F 0.725)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.701] [G acc: 0.500]\n",
      "21574 [D loss: (0.640)(R 0.541, F 0.740)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.744] [G acc: 0.438]\n",
      "21575 [D loss: (0.673)(R 0.675, F 0.670)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.794] [G acc: 0.375]\n",
      "21576 [D loss: (0.572)(R 0.573, F 0.570)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.978] [G acc: 0.125]\n",
      "21577 [D loss: (0.637)(R 0.611, F 0.664)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.770] [G acc: 0.188]\n",
      "21578 [D loss: (0.559)(R 0.573, F 0.545)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.138] [G acc: 0.188]\n",
      "21579 [D loss: (0.571)(R 0.604, F 0.538)] [D acc: (0.594)(0.562, 0.625)] [G loss: 2.175] [G acc: 0.375]\n",
      "21580 [D loss: (0.421)(R 0.540, F 0.302)] [D acc: (0.781)(0.688, 0.875)] [G loss: 4.196] [G acc: 0.062]\n",
      "21581 [D loss: (0.486)(R 0.568, F 0.404)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.990] [G acc: 0.125]\n",
      "21582 [D loss: (0.691)(R 0.618, F 0.764)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.769] [G acc: 0.250]\n",
      "21583 [D loss: (0.639)(R 0.579, F 0.698)] [D acc: (0.562)(0.562, 0.562)] [G loss: 1.687] [G acc: 0.375]\n",
      "21584 [D loss: (0.614)(R 0.506, F 0.722)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.736] [G acc: 0.312]\n",
      "21585 [D loss: (0.588)(R 0.545, F 0.631)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.831] [G acc: 0.500]\n",
      "21586 [D loss: (0.637)(R 0.523, F 0.750)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.870] [G acc: 0.312]\n",
      "21587 [D loss: (0.486)(R 0.606, F 0.365)] [D acc: (0.688)(0.562, 0.812)] [G loss: 2.167] [G acc: 0.125]\n",
      "21588 [D loss: (0.627)(R 0.596, F 0.657)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.767] [G acc: 0.312]\n",
      "21589 [D loss: (0.663)(R 0.533, F 0.792)] [D acc: (0.531)(0.625, 0.438)] [G loss: 1.787] [G acc: 0.312]\n",
      "21590 [D loss: (0.733)(R 0.658, F 0.808)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.635] [G acc: 0.500]\n",
      "21591 [D loss: (0.639)(R 0.582, F 0.697)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.750] [G acc: 0.312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21592 [D loss: (0.633)(R 0.568, F 0.697)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.879] [G acc: 0.188]\n",
      "21593 [D loss: (0.592)(R 0.798, F 0.386)] [D acc: (0.562)(0.188, 0.938)] [G loss: 1.309] [G acc: 0.062]\n",
      "21594 [D loss: (0.769)(R 0.842, F 0.696)] [D acc: (0.562)(0.312, 0.812)] [G loss: 0.808] [G acc: 0.125]\n",
      "21595 [D loss: (0.592)(R 0.557, F 0.628)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.708] [G acc: 0.312]\n",
      "21596 [D loss: (0.703)(R 0.647, F 0.760)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.693] [G acc: 0.312]\n",
      "21597 [D loss: (0.760)(R 0.629, F 0.891)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.752] [G acc: 0.438]\n",
      "21598 [D loss: (0.713)(R 0.572, F 0.853)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.800] [G acc: 0.188]\n",
      "21599 [D loss: (0.768)(R 0.673, F 0.864)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.719] [G acc: 0.375]\n",
      "21600 [D loss: (0.706)(R 0.616, F 0.797)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.684] [G acc: 0.375]\n",
      "21601 [D loss: (0.705)(R 0.508, F 0.901)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.596] [G acc: 0.562]\n",
      "21602 [D loss: (0.624)(R 0.585, F 0.663)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.999] [G acc: 0.188]\n",
      "21603 [D loss: (0.892)(R 0.612, F 1.173)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.748] [G acc: 0.312]\n",
      "21604 [D loss: (0.856)(R 0.722, F 0.990)] [D acc: (0.344)(0.375, 0.312)] [G loss: 1.149] [G acc: 0.312]\n",
      "21605 [D loss: (0.388)(R 0.648, F 0.129)] [D acc: (0.688)(0.438, 0.938)] [G loss: 8.900] [G acc: 0.062]\n",
      "21606 [D loss: (0.603)(R 0.561, F 0.644)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.762] [G acc: 0.312]\n",
      "21607 [D loss: (0.688)(R 0.703, F 0.674)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.772] [G acc: 0.312]\n",
      "21608 [D loss: (0.681)(R 0.648, F 0.713)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.752] [G acc: 0.312]\n",
      "21609 [D loss: (0.717)(R 0.734, F 0.701)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.790] [G acc: 0.125]\n",
      "21610 [D loss: (0.628)(R 0.604, F 0.653)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.900] [G acc: 0.062]\n",
      "21611 [D loss: (0.645)(R 0.656, F 0.633)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.929] [G acc: 0.312]\n",
      "21612 [D loss: (0.741)(R 0.699, F 0.782)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.827] [G acc: 0.188]\n",
      "21613 [D loss: (0.640)(R 0.667, F 0.613)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.790] [G acc: 0.188]\n",
      "21614 [D loss: (0.598)(R 0.577, F 0.620)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.783] [G acc: 0.188]\n",
      "21615 [D loss: (0.608)(R 0.560, F 0.655)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.743] [G acc: 0.188]\n",
      "21616 [D loss: (0.599)(R 0.551, F 0.647)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.830] [G acc: 0.375]\n",
      "21617 [D loss: (0.635)(R 0.591, F 0.678)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.941] [G acc: 0.062]\n",
      "21618 [D loss: (0.562)(R 0.601, F 0.522)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.743] [G acc: 0.250]\n",
      "21619 [D loss: (0.658)(R 0.617, F 0.700)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.805] [G acc: 0.250]\n",
      "21620 [D loss: (0.645)(R 0.578, F 0.713)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.922] [G acc: 0.000]\n",
      "21621 [D loss: (0.676)(R 0.680, F 0.671)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.902] [G acc: 0.125]\n",
      "21622 [D loss: (0.807)(R 0.446, F 1.168)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.939] [G acc: 0.188]\n",
      "21623 [D loss: (0.506)(R 0.553, F 0.459)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.950] [G acc: 0.062]\n",
      "21624 [D loss: (0.604)(R 0.541, F 0.666)] [D acc: (0.750)(0.812, 0.688)] [G loss: 2.506] [G acc: 0.125]\n",
      "21625 [D loss: (0.483)(R 0.689, F 0.277)] [D acc: (0.688)(0.375, 1.000)] [G loss: 3.522] [G acc: 0.062]\n",
      "21626 [D loss: (0.609)(R 0.595, F 0.623)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.838] [G acc: 0.188]\n",
      "21627 [D loss: (0.481)(R 0.433, F 0.529)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.858] [G acc: 0.125]\n",
      "21628 [D loss: (0.542)(R 0.553, F 0.532)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.814] [G acc: 0.125]\n",
      "21629 [D loss: (0.585)(R 0.608, F 0.562)] [D acc: (0.844)(0.688, 1.000)] [G loss: 0.801] [G acc: 0.250]\n",
      "21630 [D loss: (0.537)(R 0.495, F 0.580)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.681] [G acc: 0.500]\n",
      "21631 [D loss: (0.533)(R 0.461, F 0.605)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.720] [G acc: 0.500]\n",
      "21632 [D loss: (0.700)(R 0.707, F 0.693)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.560] [G acc: 0.500]\n",
      "21633 [D loss: (0.432)(R 0.305, F 0.560)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.768] [G acc: 0.312]\n",
      "21634 [D loss: (0.697)(R 0.620, F 0.775)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.700] [G acc: 0.375]\n",
      "21635 [D loss: (0.713)(R 0.538, F 0.888)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.885] [G acc: 0.000]\n",
      "21636 [D loss: (0.517)(R 0.460, F 0.574)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.480] [G acc: 0.625]\n",
      "21637 [D loss: (0.640)(R 0.603, F 0.678)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.062] [G acc: 0.438]\n",
      "21638 [D loss: (0.349)(R 0.502, F 0.196)] [D acc: (0.812)(0.688, 0.938)] [G loss: 2.071] [G acc: 0.000]\n",
      "21639 [D loss: (0.564)(R 0.419, F 0.708)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.204] [G acc: 0.188]\n",
      "21640 [D loss: (0.519)(R 0.481, F 0.558)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.903] [G acc: 0.000]\n",
      "21641 [D loss: (0.548)(R 0.467, F 0.630)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.854] [G acc: 0.250]\n",
      "21642 [D loss: (0.571)(R 0.478, F 0.664)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.799] [G acc: 0.375]\n",
      "21643 [D loss: (0.467)(R 0.354, F 0.580)] [D acc: (0.844)(0.875, 0.812)] [G loss: 0.709] [G acc: 0.500]\n",
      "21644 [D loss: (0.505)(R 0.540, F 0.469)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.792] [G acc: 0.312]\n",
      "21645 [D loss: (0.518)(R 0.505, F 0.531)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.912] [G acc: 0.438]\n",
      "21646 [D loss: (0.314)(R 0.514, F 0.114)] [D acc: (0.750)(0.625, 0.875)] [G loss: 6.721] [G acc: 0.250]\n",
      "21647 [D loss: (0.420)(R 0.550, F 0.290)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.865] [G acc: 0.312]\n",
      "21648 [D loss: (0.543)(R 0.629, F 0.456)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.084] [G acc: 0.438]\n",
      "21649 [D loss: (0.474)(R 0.434, F 0.515)] [D acc: (0.844)(0.750, 0.938)] [G loss: 0.783] [G acc: 0.250]\n",
      "21650 [D loss: (0.581)(R 0.570, F 0.593)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.956] [G acc: 0.000]\n",
      "21651 [D loss: (0.520)(R 0.374, F 0.666)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.897] [G acc: 0.125]\n",
      "21652 [D loss: (0.646)(R 0.660, F 0.632)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.916] [G acc: 0.062]\n",
      "21653 [D loss: (0.479)(R 0.380, F 0.578)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.995] [G acc: 0.062]\n",
      "21654 [D loss: (0.525)(R 0.512, F 0.537)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.939] [G acc: 0.188]\n",
      "21655 [D loss: (0.446)(R 0.252, F 0.639)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.874] [G acc: 0.312]\n",
      "21656 [D loss: (0.579)(R 0.565, F 0.593)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.873] [G acc: 0.188]\n",
      "21657 [D loss: (0.525)(R 0.504, F 0.545)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.902] [G acc: 0.188]\n",
      "21658 [D loss: (0.594)(R 0.400, F 0.788)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.009] [G acc: 0.125]\n",
      "21659 [D loss: (0.478)(R 0.433, F 0.523)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.647] [G acc: 0.500]\n",
      "21660 [D loss: (0.472)(R 0.418, F 0.526)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.946] [G acc: 0.125]\n",
      "21661 [D loss: (0.496)(R 0.450, F 0.542)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.877] [G acc: 0.312]\n",
      "21662 [D loss: (0.540)(R 0.521, F 0.559)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.882] [G acc: 0.312]\n",
      "21663 [D loss: (0.532)(R 0.420, F 0.645)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.536] [G acc: 0.062]\n",
      "21664 [D loss: (0.507)(R 0.519, F 0.495)] [D acc: (0.656)(0.562, 0.750)] [G loss: 2.562] [G acc: 0.250]\n",
      "21665 [D loss: (0.240)(R 0.279, F 0.202)] [D acc: (0.875)(0.875, 0.875)] [G loss: 7.886] [G acc: 0.062]\n",
      "21666 [D loss: (0.525)(R 0.644, F 0.406)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.098] [G acc: 0.188]\n",
      "21667 [D loss: (0.445)(R 0.445, F 0.445)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.077] [G acc: 0.438]\n",
      "21668 [D loss: (0.651)(R 0.606, F 0.695)] [D acc: (0.594)(0.500, 0.688)] [G loss: 1.556] [G acc: 0.188]\n",
      "21669 [D loss: (0.683)(R 0.844, F 0.522)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.089] [G acc: 0.062]\n",
      "21670 [D loss: (0.422)(R 0.442, F 0.401)] [D acc: (0.844)(0.750, 0.938)] [G loss: 0.663] [G acc: 0.625]\n",
      "21671 [D loss: (0.552)(R 0.413, F 0.690)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.018] [G acc: 0.188]\n",
      "21672 [D loss: (0.763)(R 0.623, F 0.903)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.960] [G acc: 0.375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21673 [D loss: (0.580)(R 0.603, F 0.556)] [D acc: (0.594)(0.500, 0.688)] [G loss: 1.120] [G acc: 0.250]\n",
      "21674 [D loss: (0.689)(R 0.391, F 0.986)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.512] [G acc: 0.250]\n",
      "21675 [D loss: (0.326)(R 0.406, F 0.246)] [D acc: (0.875)(0.812, 0.938)] [G loss: 2.602] [G acc: 0.000]\n",
      "21676 [D loss: (0.556)(R 0.530, F 0.582)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.161] [G acc: 0.125]\n",
      "21677 [D loss: (0.404)(R 0.366, F 0.442)] [D acc: (0.906)(0.875, 0.938)] [G loss: 1.492] [G acc: 0.062]\n",
      "21678 [D loss: (0.557)(R 0.623, F 0.490)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.937] [G acc: 0.125]\n",
      "21679 [D loss: (0.908)(R 1.289, F 0.527)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.052] [G acc: 0.188]\n",
      "21680 [D loss: (0.715)(R 0.767, F 0.664)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.015] [G acc: 0.125]\n",
      "21681 [D loss: (0.591)(R 0.600, F 0.582)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.871] [G acc: 0.250]\n",
      "21682 [D loss: (0.595)(R 0.499, F 0.690)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.903] [G acc: 0.312]\n",
      "21683 [D loss: (0.698)(R 0.778, F 0.618)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.842] [G acc: 0.500]\n",
      "21684 [D loss: (0.492)(R 0.457, F 0.527)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.189] [G acc: 0.125]\n",
      "21685 [D loss: (0.614)(R 0.319, F 0.909)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.359] [G acc: 0.438]\n",
      "21686 [D loss: (0.873)(R 0.464, F 1.281)] [D acc: (0.656)(0.688, 0.625)] [G loss: 6.525] [G acc: 0.250]\n",
      "21687 [D loss: (0.411)(R 0.523, F 0.299)] [D acc: (0.844)(0.688, 1.000)] [G loss: 6.225] [G acc: 0.125]\n",
      "21688 [D loss: (0.400)(R 0.543, F 0.257)] [D acc: (0.750)(0.625, 0.875)] [G loss: 2.145] [G acc: 0.438]\n",
      "21689 [D loss: (0.513)(R 0.619, F 0.407)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.592] [G acc: 0.250]\n",
      "21690 [D loss: (0.561)(R 0.602, F 0.519)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.902] [G acc: 0.250]\n",
      "21691 [D loss: (0.712)(R 0.762, F 0.662)] [D acc: (0.469)(0.250, 0.688)] [G loss: 1.095] [G acc: 0.000]\n",
      "21692 [D loss: (0.414)(R 0.434, F 0.394)] [D acc: (0.844)(0.750, 0.938)] [G loss: 0.994] [G acc: 0.125]\n",
      "21693 [D loss: (0.381)(R 0.427, F 0.335)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.239] [G acc: 0.062]\n",
      "21694 [D loss: (0.591)(R 0.687, F 0.495)] [D acc: (0.656)(0.375, 0.938)] [G loss: 1.196] [G acc: 0.062]\n",
      "21695 [D loss: (0.662)(R 0.583, F 0.741)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.216] [G acc: 0.062]\n",
      "21696 [D loss: (0.402)(R 0.458, F 0.345)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.317] [G acc: 0.188]\n",
      "21697 [D loss: (0.510)(R 0.624, F 0.397)] [D acc: (0.781)(0.562, 1.000)] [G loss: 1.023] [G acc: 0.250]\n",
      "21698 [D loss: (0.608)(R 0.647, F 0.569)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.727] [G acc: 0.438]\n",
      "21699 [D loss: (0.588)(R 0.480, F 0.696)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.052] [G acc: 0.250]\n",
      "21700 [D loss: (0.606)(R 0.670, F 0.542)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.036] [G acc: 0.188]\n",
      "21701 [D loss: (0.729)(R 0.764, F 0.693)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.005] [G acc: 0.188]\n",
      "21702 [D loss: (0.566)(R 0.514, F 0.619)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.029] [G acc: 0.062]\n",
      "21703 [D loss: (0.548)(R 0.611, F 0.485)] [D acc: (0.625)(0.375, 0.875)] [G loss: 1.355] [G acc: 0.375]\n",
      "21704 [D loss: (0.522)(R 0.673, F 0.371)] [D acc: (0.656)(0.500, 0.812)] [G loss: 6.285] [G acc: 0.188]\n",
      "21705 [D loss: (0.743)(R 0.716, F 0.771)] [D acc: (0.781)(0.688, 0.875)] [G loss: 6.700] [G acc: 0.188]\n",
      "21706 [D loss: (0.472)(R 0.481, F 0.464)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.243] [G acc: 0.438]\n",
      "21707 [D loss: (0.527)(R 0.580, F 0.475)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.224] [G acc: 0.188]\n",
      "21708 [D loss: (0.516)(R 0.515, F 0.516)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.219] [G acc: 0.000]\n",
      "21709 [D loss: (0.797)(R 0.680, F 0.914)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.654] [G acc: 0.500]\n",
      "21710 [D loss: (0.500)(R 0.553, F 0.447)] [D acc: (0.781)(0.562, 1.000)] [G loss: 1.227] [G acc: 0.312]\n",
      "21711 [D loss: (0.534)(R 0.529, F 0.539)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.943] [G acc: 0.188]\n",
      "21712 [D loss: (0.345)(R 0.173, F 0.518)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.983] [G acc: 0.062]\n",
      "21713 [D loss: (0.603)(R 0.554, F 0.653)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.807] [G acc: 0.375]\n",
      "21714 [D loss: (0.855)(R 1.313, F 0.397)] [D acc: (0.656)(0.375, 0.938)] [G loss: 0.954] [G acc: 0.250]\n",
      "21715 [D loss: (0.533)(R 0.657, F 0.410)] [D acc: (0.688)(0.500, 0.875)] [G loss: 1.323] [G acc: 0.000]\n",
      "21716 [D loss: (0.477)(R 0.451, F 0.503)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.942] [G acc: 0.250]\n",
      "21717 [D loss: (0.554)(R 0.484, F 0.624)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.082] [G acc: 0.125]\n",
      "21718 [D loss: (0.533)(R 0.563, F 0.503)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.213] [G acc: 0.188]\n",
      "21719 [D loss: (0.547)(R 0.606, F 0.488)] [D acc: (0.656)(0.438, 0.875)] [G loss: 1.321] [G acc: 0.125]\n",
      "21720 [D loss: (0.460)(R 0.669, F 0.251)] [D acc: (0.719)(0.438, 1.000)] [G loss: 1.443] [G acc: 0.000]\n",
      "21721 [D loss: (0.617)(R 0.690, F 0.544)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.935] [G acc: 0.312]\n",
      "21722 [D loss: (0.664)(R 0.781, F 0.548)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.718] [G acc: 0.812]\n",
      "21723 [D loss: (0.503)(R 0.475, F 0.531)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.784] [G acc: 0.375]\n",
      "21724 [D loss: (0.527)(R 0.473, F 0.581)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.660] [G acc: 0.562]\n",
      "21725 [D loss: (0.552)(R 0.435, F 0.669)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.990] [G acc: 0.312]\n",
      "21726 [D loss: (0.671)(R 0.730, F 0.613)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.994] [G acc: 0.188]\n",
      "21727 [D loss: (0.584)(R 0.590, F 0.578)] [D acc: (0.594)(0.500, 0.688)] [G loss: 1.181] [G acc: 0.250]\n",
      "21728 [D loss: (0.557)(R 0.354, F 0.759)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.428] [G acc: 0.688]\n",
      "21729 [D loss: (0.593)(R 0.615, F 0.570)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.898] [G acc: 0.188]\n",
      "21730 [D loss: (0.452)(R 0.660, F 0.245)] [D acc: (0.719)(0.438, 1.000)] [G loss: 1.677] [G acc: 0.125]\n",
      "21731 [D loss: (0.457)(R 0.609, F 0.305)] [D acc: (0.812)(0.688, 0.938)] [G loss: 2.213] [G acc: 0.062]\n",
      "21732 [D loss: (0.257)(R 0.474, F 0.041)] [D acc: (0.812)(0.625, 1.000)] [G loss: 10.822] [G acc: 0.125]\n",
      "21733 [D loss: (0.275)(R 0.470, F 0.080)] [D acc: (0.844)(0.688, 1.000)] [G loss: 7.967] [G acc: 0.125]\n",
      "21734 [D loss: (0.590)(R 0.595, F 0.585)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.580] [G acc: 0.188]\n",
      "21735 [D loss: (0.698)(R 0.877, F 0.519)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.757] [G acc: 0.438]\n",
      "21736 [D loss: (0.502)(R 0.434, F 0.570)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.087] [G acc: 0.125]\n",
      "21737 [D loss: (0.593)(R 0.516, F 0.670)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.930] [G acc: 0.312]\n",
      "21738 [D loss: (0.765)(R 0.825, F 0.705)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.750] [G acc: 0.375]\n",
      "21739 [D loss: (0.537)(R 0.493, F 0.581)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.224] [G acc: 0.250]\n",
      "21740 [D loss: (0.579)(R 0.562, F 0.595)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.975] [G acc: 0.188]\n",
      "21741 [D loss: (0.989)(R 1.068, F 0.910)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.890] [G acc: 0.250]\n",
      "21742 [D loss: (0.550)(R 0.531, F 0.569)] [D acc: (0.844)(0.688, 1.000)] [G loss: 1.344] [G acc: 0.562]\n",
      "21743 [D loss: (0.763)(R 0.550, F 0.977)] [D acc: (0.594)(0.625, 0.562)] [G loss: 2.373] [G acc: 0.125]\n",
      "21744 [D loss: (0.454)(R 0.569, F 0.338)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.854] [G acc: 0.125]\n",
      "21745 [D loss: (0.606)(R 0.607, F 0.604)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.421] [G acc: 0.125]\n",
      "21746 [D loss: (0.614)(R 0.577, F 0.650)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.506] [G acc: 0.688]\n",
      "21747 [D loss: (0.906)(R 0.374, F 1.439)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.915] [G acc: 0.188]\n",
      "21748 [D loss: (0.603)(R 0.614, F 0.592)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.128] [G acc: 0.125]\n",
      "21749 [D loss: (0.645)(R 0.574, F 0.717)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.907] [G acc: 0.062]\n",
      "21750 [D loss: (0.612)(R 0.668, F 0.556)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.868] [G acc: 0.188]\n",
      "21751 [D loss: (0.511)(R 0.513, F 0.510)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.001] [G acc: 0.312]\n",
      "21752 [D loss: (0.453)(R 0.513, F 0.392)] [D acc: (0.781)(0.812, 0.750)] [G loss: 2.700] [G acc: 0.062]\n",
      "21753 [D loss: (0.535)(R 0.563, F 0.506)] [D acc: (0.688)(0.438, 0.938)] [G loss: 1.009] [G acc: 0.250]\n",
      "21754 [D loss: (0.546)(R 0.507, F 0.585)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.000] [G acc: 0.062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21755 [D loss: (0.932)(R 1.131, F 0.733)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.999] [G acc: 0.062]\n",
      "21756 [D loss: (0.522)(R 0.443, F 0.601)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.920] [G acc: 0.188]\n",
      "21757 [D loss: (0.625)(R 0.544, F 0.706)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.168] [G acc: 0.500]\n",
      "21758 [D loss: (0.719)(R 0.514, F 0.925)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.836] [G acc: 0.312]\n",
      "21759 [D loss: (0.527)(R 0.459, F 0.596)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.980] [G acc: 0.188]\n",
      "21760 [D loss: (0.707)(R 0.612, F 0.802)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.921] [G acc: 0.250]\n",
      "21761 [D loss: (0.520)(R 0.500, F 0.541)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.033] [G acc: 0.375]\n",
      "21762 [D loss: (0.585)(R 0.513, F 0.658)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.937] [G acc: 0.250]\n",
      "21763 [D loss: (0.593)(R 0.544, F 0.641)] [D acc: (0.594)(0.500, 0.688)] [G loss: 1.074] [G acc: 0.312]\n",
      "21764 [D loss: (0.359)(R 0.426, F 0.292)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.138] [G acc: 0.188]\n",
      "21765 [D loss: (0.474)(R 0.528, F 0.420)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.069] [G acc: 0.250]\n",
      "21766 [D loss: (0.500)(R 0.454, F 0.545)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.936] [G acc: 0.625]\n",
      "21767 [D loss: (0.435)(R 0.474, F 0.396)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.635] [G acc: 0.188]\n",
      "21768 [D loss: (0.532)(R 0.501, F 0.563)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.694] [G acc: 0.500]\n",
      "21769 [D loss: (0.368)(R 0.551, F 0.185)] [D acc: (0.781)(0.750, 0.812)] [G loss: 7.229] [G acc: 0.062]\n",
      "21770 [D loss: (0.366)(R 0.532, F 0.201)] [D acc: (0.781)(0.625, 0.938)] [G loss: 2.774] [G acc: 0.125]\n",
      "21771 [D loss: (0.747)(R 1.077, F 0.418)] [D acc: (0.656)(0.500, 0.812)] [G loss: 4.467] [G acc: 0.188]\n",
      "21772 [D loss: (0.738)(R 0.863, F 0.613)] [D acc: (0.469)(0.438, 0.500)] [G loss: 1.271] [G acc: 0.188]\n",
      "21773 [D loss: (0.516)(R 0.431, F 0.602)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.895] [G acc: 0.188]\n",
      "21774 [D loss: (0.590)(R 0.576, F 0.605)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.925] [G acc: 0.375]\n",
      "21775 [D loss: (0.525)(R 0.391, F 0.660)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.849] [G acc: 0.250]\n",
      "21776 [D loss: (0.527)(R 0.540, F 0.513)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.926] [G acc: 0.438]\n",
      "21777 [D loss: (0.446)(R 0.394, F 0.498)] [D acc: (0.906)(0.812, 1.000)] [G loss: 0.834] [G acc: 0.438]\n",
      "21778 [D loss: (0.490)(R 0.474, F 0.506)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.930] [G acc: 0.312]\n",
      "21779 [D loss: (0.543)(R 0.519, F 0.566)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.777] [G acc: 0.438]\n",
      "21780 [D loss: (0.534)(R 0.379, F 0.688)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.983] [G acc: 0.125]\n",
      "21781 [D loss: (0.532)(R 0.497, F 0.567)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.948] [G acc: 0.250]\n",
      "21782 [D loss: (0.562)(R 0.532, F 0.591)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.799] [G acc: 0.375]\n",
      "21783 [D loss: (0.535)(R 0.469, F 0.601)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.950] [G acc: 0.188]\n",
      "21784 [D loss: (0.699)(R 0.779, F 0.619)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.866] [G acc: 0.312]\n",
      "21785 [D loss: (0.557)(R 0.382, F 0.731)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.911] [G acc: 0.312]\n",
      "21786 [D loss: (0.541)(R 0.586, F 0.496)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.112] [G acc: 0.188]\n",
      "21787 [D loss: (0.547)(R 0.467, F 0.628)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.854] [G acc: 0.500]\n",
      "21788 [D loss: (0.453)(R 0.390, F 0.516)] [D acc: (0.844)(0.875, 0.812)] [G loss: 0.719] [G acc: 0.500]\n",
      "21789 [D loss: (0.563)(R 0.483, F 0.643)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.118] [G acc: 0.188]\n",
      "21790 [D loss: (0.551)(R 0.525, F 0.576)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.091] [G acc: 0.312]\n",
      "21791 [D loss: (0.495)(R 0.435, F 0.555)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.891] [G acc: 0.375]\n",
      "21792 [D loss: (0.436)(R 0.347, F 0.524)] [D acc: (0.844)(0.875, 0.812)] [G loss: 0.943] [G acc: 0.375]\n",
      "21793 [D loss: (0.630)(R 0.693, F 0.567)] [D acc: (0.594)(0.500, 0.688)] [G loss: 1.427] [G acc: 0.188]\n",
      "21794 [D loss: (0.366)(R 0.306, F 0.426)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.444] [G acc: 0.188]\n",
      "21795 [D loss: (0.458)(R 0.395, F 0.520)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.243] [G acc: 0.188]\n",
      "21796 [D loss: (0.581)(R 0.657, F 0.505)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.245] [G acc: 0.188]\n",
      "21797 [D loss: (0.547)(R 0.601, F 0.494)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.119] [G acc: 0.188]\n",
      "21798 [D loss: (0.486)(R 0.602, F 0.370)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.363] [G acc: 0.250]\n",
      "21799 [D loss: (0.680)(R 0.633, F 0.726)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.808] [G acc: 0.562]\n",
      "21800 [D loss: (0.676)(R 0.592, F 0.761)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.724] [G acc: 0.125]\n",
      "21801 [D loss: (0.699)(R 0.531, F 0.866)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.084] [G acc: 0.250]\n",
      "21802 [D loss: (1.088)(R 0.531, F 1.644)] [D acc: (0.625)(0.750, 0.500)] [G loss: 1.286] [G acc: 0.312]\n",
      "21803 [D loss: (0.660)(R 0.861, F 0.460)] [D acc: (0.500)(0.375, 0.625)] [G loss: 1.340] [G acc: 0.312]\n",
      "21804 [D loss: (0.548)(R 0.528, F 0.567)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.875] [G acc: 0.250]\n",
      "21805 [D loss: (0.412)(R 0.361, F 0.462)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.764] [G acc: 0.125]\n",
      "21806 [D loss: (0.609)(R 0.707, F 0.510)] [D acc: (0.594)(0.500, 0.688)] [G loss: 2.050] [G acc: 0.062]\n",
      "21807 [D loss: (0.459)(R 0.520, F 0.398)] [D acc: (0.844)(0.875, 0.812)] [G loss: 6.764] [G acc: 0.188]\n",
      "21808 [D loss: (0.362)(R 0.407, F 0.318)] [D acc: (0.844)(0.938, 0.750)] [G loss: 3.080] [G acc: 0.312]\n",
      "21809 [D loss: (0.656)(R 0.675, F 0.636)] [D acc: (0.562)(0.625, 0.500)] [G loss: 1.251] [G acc: 0.250]\n",
      "21810 [D loss: (0.535)(R 0.557, F 0.513)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.010] [G acc: 0.562]\n",
      "21811 [D loss: (0.464)(R 0.303, F 0.625)] [D acc: (0.875)(0.938, 0.812)] [G loss: 1.206] [G acc: 0.312]\n",
      "21812 [D loss: (0.525)(R 0.484, F 0.565)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.142] [G acc: 0.250]\n",
      "21813 [D loss: (0.613)(R 0.633, F 0.592)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.284] [G acc: 0.250]\n",
      "21814 [D loss: (0.414)(R 0.434, F 0.393)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.226] [G acc: 0.312]\n",
      "21815 [D loss: (0.573)(R 0.574, F 0.573)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.430] [G acc: 0.438]\n",
      "21816 [D loss: (0.732)(R 0.651, F 0.812)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.767] [G acc: 0.625]\n",
      "21817 [D loss: (0.491)(R 0.413, F 0.570)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.926] [G acc: 0.375]\n",
      "21818 [D loss: (0.592)(R 0.417, F 0.767)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.937] [G acc: 0.312]\n",
      "21819 [D loss: (0.900)(R 0.885, F 0.914)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.243] [G acc: 0.250]\n",
      "21820 [D loss: (0.638)(R 0.712, F 0.565)] [D acc: (0.594)(0.438, 0.750)] [G loss: 1.123] [G acc: 0.188]\n",
      "21821 [D loss: (0.571)(R 0.715, F 0.427)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.757] [G acc: 0.188]\n",
      "21822 [D loss: (0.499)(R 0.506, F 0.491)] [D acc: (0.688)(0.812, 0.562)] [G loss: 4.375] [G acc: 0.312]\n",
      "21823 [D loss: (0.679)(R 0.670, F 0.687)] [D acc: (0.531)(0.625, 0.438)] [G loss: 5.340] [G acc: 0.188]\n",
      "21824 [D loss: (0.424)(R 0.416, F 0.433)] [D acc: (0.938)(0.938, 0.938)] [G loss: 1.724] [G acc: 0.312]\n",
      "21825 [D loss: (0.556)(R 0.537, F 0.574)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.880] [G acc: 0.562]\n",
      "21826 [D loss: (0.780)(R 0.792, F 0.769)] [D acc: (0.594)(0.688, 0.500)] [G loss: 1.392] [G acc: 0.188]\n",
      "21827 [D loss: (0.873)(R 0.634, F 1.112)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.052] [G acc: 0.188]\n",
      "21828 [D loss: (0.804)(R 0.677, F 0.931)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.182] [G acc: 0.062]\n",
      "21829 [D loss: (0.475)(R 0.487, F 0.463)] [D acc: (0.812)(0.875, 0.750)] [G loss: 2.332] [G acc: 0.188]\n",
      "21830 [D loss: (0.473)(R 0.525, F 0.421)] [D acc: (0.781)(0.750, 0.812)] [G loss: 3.851] [G acc: 0.250]\n",
      "21831 [D loss: (0.547)(R 0.467, F 0.627)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.709] [G acc: 0.562]\n",
      "21832 [D loss: (0.754)(R 0.955, F 0.553)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.185] [G acc: 0.312]\n",
      "21833 [D loss: (0.794)(R 0.796, F 0.792)] [D acc: (0.438)(0.562, 0.312)] [G loss: 2.103] [G acc: 0.188]\n",
      "21834 [D loss: (0.374)(R 0.485, F 0.262)] [D acc: (0.844)(0.812, 0.875)] [G loss: 2.227] [G acc: 0.188]\n",
      "21835 [D loss: (0.512)(R 0.628, F 0.395)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.884] [G acc: 0.375]\n",
      "21836 [D loss: (0.468)(R 0.485, F 0.451)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.803] [G acc: 0.438]\n",
      "21837 [D loss: (0.606)(R 0.627, F 0.586)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.874] [G acc: 0.500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21838 [D loss: (0.548)(R 0.506, F 0.590)] [D acc: (0.875)(0.875, 0.875)] [G loss: 0.982] [G acc: 0.375]\n",
      "21839 [D loss: (0.753)(R 0.644, F 0.861)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.923] [G acc: 0.500]\n",
      "21840 [D loss: (0.564)(R 0.699, F 0.428)] [D acc: (0.562)(0.438, 0.688)] [G loss: 1.045] [G acc: 0.250]\n",
      "21841 [D loss: (0.587)(R 0.531, F 0.642)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.797] [G acc: 0.312]\n",
      "21842 [D loss: (0.667)(R 0.714, F 0.619)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.933] [G acc: 0.312]\n",
      "21843 [D loss: (0.559)(R 0.568, F 0.550)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.990] [G acc: 0.188]\n",
      "21844 [D loss: (0.581)(R 0.551, F 0.611)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.210] [G acc: 0.375]\n",
      "21845 [D loss: (1.019)(R 1.518, F 0.520)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.744] [G acc: 0.500]\n",
      "21846 [D loss: (0.694)(R 0.495, F 0.893)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.860] [G acc: 0.500]\n",
      "21847 [D loss: (0.663)(R 0.518, F 0.808)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.859] [G acc: 0.500]\n",
      "21848 [D loss: (0.671)(R 0.607, F 0.734)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.750] [G acc: 0.375]\n",
      "21849 [D loss: (0.681)(R 0.569, F 0.793)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.664] [G acc: 0.562]\n",
      "21850 [D loss: (0.746)(R 0.580, F 0.911)] [D acc: (0.594)(0.750, 0.438)] [G loss: 1.114] [G acc: 0.062]\n",
      "21851 [D loss: (0.561)(R 0.589, F 0.534)] [D acc: (0.781)(0.750, 0.812)] [G loss: 2.165] [G acc: 0.188]\n",
      "21852 [D loss: (1.110)(R 0.625, F 1.594)] [D acc: (0.469)(0.500, 0.438)] [G loss: 7.285] [G acc: 0.250]\n",
      "21853 [D loss: (0.562)(R 0.654, F 0.470)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.953] [G acc: 0.312]\n",
      "21854 [D loss: (0.550)(R 0.559, F 0.541)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.828] [G acc: 0.062]\n",
      "21855 [D loss: (0.531)(R 0.516, F 0.547)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.013] [G acc: 0.062]\n",
      "21856 [D loss: (0.613)(R 0.432, F 0.794)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.760] [G acc: 0.438]\n",
      "21857 [D loss: (0.701)(R 0.614, F 0.789)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.617] [G acc: 0.812]\n",
      "21858 [D loss: (0.696)(R 0.560, F 0.831)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.805] [G acc: 0.188]\n",
      "21859 [D loss: (0.648)(R 0.621, F 0.674)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.847] [G acc: 0.375]\n",
      "21860 [D loss: (0.638)(R 0.604, F 0.672)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.705] [G acc: 0.562]\n",
      "21861 [D loss: (0.761)(R 0.816, F 0.706)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.674] [G acc: 0.625]\n",
      "21862 [D loss: (0.603)(R 0.536, F 0.670)] [D acc: (0.594)(0.688, 0.500)] [G loss: 1.319] [G acc: 0.625]\n",
      "21863 [D loss: (0.885)(R 0.565, F 1.204)] [D acc: (0.688)(0.688, 0.688)] [G loss: 2.986] [G acc: 0.438]\n",
      "21864 [D loss: (0.424)(R 0.748, F 0.099)] [D acc: (0.781)(0.562, 1.000)] [G loss: 1.001] [G acc: 0.688]\n",
      "21865 [D loss: (0.482)(R 0.576, F 0.389)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.864] [G acc: 0.375]\n",
      "21866 [D loss: (0.715)(R 0.523, F 0.906)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.751] [G acc: 0.500]\n",
      "21867 [D loss: (0.796)(R 0.645, F 0.947)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.555] [G acc: 0.750]\n",
      "21868 [D loss: (0.692)(R 0.522, F 0.862)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.933] [G acc: 0.500]\n",
      "21869 [D loss: (0.860)(R 0.984, F 0.736)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.650] [G acc: 0.562]\n",
      "21870 [D loss: (0.787)(R 0.702, F 0.872)] [D acc: (0.375)(0.500, 0.250)] [G loss: 0.720] [G acc: 0.500]\n",
      "21871 [D loss: (0.801)(R 0.861, F 0.740)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.835] [G acc: 0.438]\n",
      "21872 [D loss: (0.559)(R 0.485, F 0.632)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.885] [G acc: 0.375]\n",
      "21873 [D loss: (0.685)(R 0.510, F 0.860)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.630] [G acc: 0.625]\n",
      "21874 [D loss: (0.692)(R 0.606, F 0.778)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.714] [G acc: 0.625]\n",
      "21875 [D loss: (1.037)(R 0.646, F 1.428)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.657] [G acc: 0.562]\n",
      "21876 [D loss: (0.611)(R 0.551, F 0.671)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.892] [G acc: 0.500]\n",
      "21877 [D loss: (0.461)(R 0.564, F 0.358)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.911] [G acc: 0.375]\n",
      "21878 [D loss: (0.736)(R 0.670, F 0.802)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.500] [G acc: 0.812]\n",
      "21879 [D loss: (0.760)(R 0.577, F 0.943)] [D acc: (0.406)(0.562, 0.250)] [G loss: 0.765] [G acc: 0.500]\n",
      "21880 [D loss: (0.551)(R 0.546, F 0.556)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.841] [G acc: 0.312]\n",
      "21881 [D loss: (0.480)(R 0.558, F 0.402)] [D acc: (0.688)(0.750, 0.625)] [G loss: 7.963] [G acc: 0.062]\n",
      "21882 [D loss: (0.678)(R 0.666, F 0.690)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.742] [G acc: 0.375]\n",
      "21883 [D loss: (0.738)(R 0.572, F 0.905)] [D acc: (0.562)(0.688, 0.438)] [G loss: 1.047] [G acc: 0.438]\n",
      "21884 [D loss: (0.492)(R 0.441, F 0.542)] [D acc: (0.844)(0.938, 0.750)] [G loss: 0.864] [G acc: 0.375]\n",
      "21885 [D loss: (0.659)(R 0.580, F 0.738)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.839] [G acc: 0.562]\n",
      "21886 [D loss: (0.669)(R 0.764, F 0.574)] [D acc: (0.531)(0.375, 0.688)] [G loss: 1.255] [G acc: 0.312]\n",
      "21887 [D loss: (0.934)(R 1.047, F 0.822)] [D acc: (0.406)(0.375, 0.438)] [G loss: 1.394] [G acc: 0.312]\n",
      "21888 [D loss: (0.559)(R 0.540, F 0.577)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.243] [G acc: 0.438]\n",
      "21889 [D loss: (0.653)(R 0.639, F 0.668)] [D acc: (0.531)(0.562, 0.500)] [G loss: 2.982] [G acc: 0.438]\n",
      "21890 [D loss: (0.498)(R 0.597, F 0.399)] [D acc: (0.719)(0.625, 0.812)] [G loss: 2.325] [G acc: 0.250]\n",
      "21891 [D loss: (0.727)(R 0.612, F 0.841)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.628] [G acc: 0.562]\n",
      "21892 [D loss: (0.602)(R 0.515, F 0.688)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.898] [G acc: 0.250]\n",
      "21893 [D loss: (0.793)(R 0.902, F 0.685)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.623] [G acc: 0.625]\n",
      "21894 [D loss: (0.792)(R 0.653, F 0.932)] [D acc: (0.375)(0.438, 0.312)] [G loss: 0.765] [G acc: 0.438]\n",
      "21895 [D loss: (0.693)(R 0.728, F 0.659)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.731] [G acc: 0.438]\n",
      "21896 [D loss: (0.797)(R 0.529, F 1.065)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.690] [G acc: 0.562]\n",
      "21897 [D loss: (0.722)(R 0.737, F 0.706)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.751] [G acc: 0.250]\n",
      "21898 [D loss: (0.522)(R 0.507, F 0.537)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.870] [G acc: 0.500]\n",
      "21899 [D loss: (0.676)(R 0.734, F 0.617)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.090] [G acc: 0.312]\n",
      "21900 [D loss: (0.734)(R 0.534, F 0.935)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.865] [G acc: 0.500]\n",
      "21901 [D loss: (0.631)(R 0.526, F 0.736)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.830] [G acc: 0.312]\n",
      "21902 [D loss: (0.770)(R 0.959, F 0.581)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.803] [G acc: 0.250]\n",
      "21903 [D loss: (0.683)(R 0.746, F 0.619)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.787] [G acc: 0.312]\n",
      "21904 [D loss: (0.721)(R 0.679, F 0.763)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.822] [G acc: 0.125]\n",
      "21905 [D loss: (0.660)(R 0.684, F 0.637)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.720] [G acc: 0.562]\n",
      "21906 [D loss: (0.658)(R 0.687, F 0.629)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.837] [G acc: 0.500]\n",
      "21907 [D loss: (0.453)(R 0.619, F 0.287)] [D acc: (0.719)(0.625, 0.812)] [G loss: 2.742] [G acc: 0.125]\n",
      "21908 [D loss: (0.899)(R 0.619, F 1.179)] [D acc: (0.625)(0.688, 0.562)] [G loss: 7.588] [G acc: 0.375]\n",
      "21909 [D loss: (0.519)(R 0.568, F 0.470)] [D acc: (0.625)(0.625, 0.625)] [G loss: 7.052] [G acc: 0.250]\n",
      "21910 [D loss: (0.581)(R 0.732, F 0.431)] [D acc: (0.562)(0.375, 0.750)] [G loss: 1.716] [G acc: 0.375]\n",
      "21911 [D loss: (0.640)(R 0.729, F 0.550)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.572] [G acc: 0.688]\n",
      "21912 [D loss: (0.555)(R 0.561, F 0.550)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.868] [G acc: 0.250]\n",
      "21913 [D loss: (0.591)(R 0.586, F 0.596)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.852] [G acc: 0.062]\n",
      "21914 [D loss: (0.654)(R 0.682, F 0.625)] [D acc: (0.625)(0.562, 0.688)] [G loss: 2.753] [G acc: 0.500]\n",
      "21915 [D loss: (0.663)(R 0.678, F 0.648)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.911] [G acc: 0.562]\n",
      "21916 [D loss: (0.625)(R 0.524, F 0.725)] [D acc: (0.688)(0.875, 0.500)] [G loss: 1.248] [G acc: 0.375]\n",
      "21917 [D loss: (0.379)(R 0.388, F 0.370)] [D acc: (0.844)(0.938, 0.750)] [G loss: 1.328] [G acc: 0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21918 [D loss: (0.666)(R 0.715, F 0.617)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.631] [G acc: 0.562]\n",
      "21919 [D loss: (0.635)(R 0.535, F 0.735)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.767] [G acc: 0.438]\n",
      "21920 [D loss: (0.714)(R 0.653, F 0.776)] [D acc: (0.469)(0.562, 0.375)] [G loss: 1.057] [G acc: 0.312]\n",
      "21921 [D loss: (0.521)(R 0.611, F 0.431)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.642] [G acc: 0.125]\n",
      "21922 [D loss: (0.581)(R 0.703, F 0.460)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.080] [G acc: 0.375]\n",
      "21923 [D loss: (0.569)(R 0.539, F 0.599)] [D acc: (0.625)(0.750, 0.500)] [G loss: 1.140] [G acc: 0.312]\n",
      "21924 [D loss: (0.545)(R 0.568, F 0.522)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.835] [G acc: 0.438]\n",
      "21925 [D loss: (0.486)(R 0.543, F 0.430)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.901] [G acc: 0.312]\n",
      "21926 [D loss: (0.633)(R 0.574, F 0.691)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.836] [G acc: 0.312]\n",
      "21927 [D loss: (0.783)(R 0.627, F 0.939)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.897] [G acc: 0.500]\n",
      "21928 [D loss: (0.607)(R 0.784, F 0.429)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.142] [G acc: 0.062]\n",
      "21929 [D loss: (0.675)(R 0.592, F 0.757)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.789] [G acc: 0.312]\n",
      "21930 [D loss: (0.597)(R 0.607, F 0.588)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.942] [G acc: 0.188]\n",
      "21931 [D loss: (0.719)(R 0.539, F 0.899)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.804] [G acc: 0.188]\n",
      "21932 [D loss: (0.622)(R 0.529, F 0.714)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.785] [G acc: 0.438]\n",
      "21933 [D loss: (0.628)(R 0.590, F 0.666)] [D acc: (0.594)(0.688, 0.500)] [G loss: 1.016] [G acc: 0.562]\n",
      "21934 [D loss: (0.473)(R 0.595, F 0.350)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.762] [G acc: 0.188]\n",
      "21935 [D loss: (0.771)(R 0.658, F 0.884)] [D acc: (0.438)(0.562, 0.312)] [G loss: 1.227] [G acc: 0.438]\n",
      "21936 [D loss: (0.559)(R 0.816, F 0.302)] [D acc: (0.750)(0.688, 0.812)] [G loss: 3.461] [G acc: 0.125]\n",
      "21937 [D loss: (0.518)(R 0.631, F 0.404)] [D acc: (0.656)(0.625, 0.688)] [G loss: 4.300] [G acc: 0.375]\n",
      "21938 [D loss: (0.684)(R 0.701, F 0.667)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.749] [G acc: 0.500]\n",
      "21939 [D loss: (0.609)(R 0.552, F 0.665)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.684] [G acc: 0.562]\n",
      "21940 [D loss: (0.632)(R 0.649, F 0.616)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.905] [G acc: 0.312]\n",
      "21941 [D loss: (0.597)(R 0.552, F 0.642)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.910] [G acc: 0.562]\n",
      "21942 [D loss: (0.775)(R 0.682, F 0.867)] [D acc: (0.562)(0.625, 0.500)] [G loss: 1.252] [G acc: 0.250]\n",
      "21943 [D loss: (0.653)(R 0.591, F 0.715)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.950] [G acc: 0.188]\n",
      "21944 [D loss: (0.646)(R 0.579, F 0.712)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.686] [G acc: 0.438]\n",
      "21945 [D loss: (0.674)(R 0.586, F 0.761)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.752] [G acc: 0.438]\n",
      "21946 [D loss: (0.699)(R 0.586, F 0.813)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.646] [G acc: 0.688]\n",
      "21947 [D loss: (0.683)(R 0.688, F 0.679)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.925] [G acc: 0.375]\n",
      "21948 [D loss: (0.692)(R 0.658, F 0.726)] [D acc: (0.562)(0.688, 0.438)] [G loss: 1.095] [G acc: 0.312]\n",
      "21949 [D loss: (0.621)(R 0.571, F 0.671)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.785] [G acc: 0.312]\n",
      "21950 [D loss: (0.648)(R 0.606, F 0.690)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.982] [G acc: 0.312]\n",
      "21951 [D loss: (0.610)(R 0.564, F 0.655)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.769] [G acc: 0.438]\n",
      "21952 [D loss: (0.659)(R 0.600, F 0.718)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.717] [G acc: 0.438]\n",
      "21953 [D loss: (0.594)(R 0.585, F 0.602)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.789] [G acc: 0.375]\n",
      "21954 [D loss: (0.533)(R 0.508, F 0.557)] [D acc: (0.844)(0.875, 0.812)] [G loss: 0.867] [G acc: 0.375]\n",
      "21955 [D loss: (0.671)(R 0.618, F 0.724)] [D acc: (0.531)(0.625, 0.438)] [G loss: 1.029] [G acc: 0.312]\n",
      "21956 [D loss: (0.653)(R 0.665, F 0.640)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.768] [G acc: 0.375]\n",
      "21957 [D loss: (0.781)(R 0.731, F 0.831)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.798] [G acc: 0.188]\n",
      "21958 [D loss: (0.718)(R 0.725, F 0.710)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.601] [G acc: 0.625]\n",
      "21959 [D loss: (0.577)(R 0.490, F 0.663)] [D acc: (0.781)(0.938, 0.625)] [G loss: 0.756] [G acc: 0.375]\n",
      "21960 [D loss: (0.635)(R 0.595, F 0.676)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.950] [G acc: 0.250]\n",
      "21961 [D loss: (0.776)(R 0.919, F 0.633)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.511] [G acc: 0.625]\n",
      "21962 [D loss: (0.593)(R 0.596, F 0.589)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.970] [G acc: 0.125]\n",
      "21963 [D loss: (0.570)(R 0.504, F 0.636)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.790] [G acc: 0.562]\n",
      "21964 [D loss: (0.698)(R 0.727, F 0.669)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.144] [G acc: 0.188]\n",
      "21965 [D loss: (0.679)(R 0.643, F 0.714)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.751] [G acc: 0.438]\n",
      "21966 [D loss: (0.670)(R 0.648, F 0.692)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.448] [G acc: 0.812]\n",
      "21967 [D loss: (0.621)(R 0.598, F 0.643)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.681] [G acc: 0.438]\n",
      "21968 [D loss: (0.689)(R 0.581, F 0.796)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.419] [G acc: 0.812]\n",
      "21969 [D loss: (1.222)(R 0.590, F 1.854)] [D acc: (0.500)(0.625, 0.375)] [G loss: 1.306] [G acc: 0.188]\n",
      "21970 [D loss: (0.463)(R 0.708, F 0.217)] [D acc: (0.688)(0.438, 0.938)] [G loss: 3.545] [G acc: 0.000]\n",
      "21971 [D loss: (0.658)(R 0.684, F 0.631)] [D acc: (0.688)(0.500, 0.875)] [G loss: 1.496] [G acc: 0.250]\n",
      "21972 [D loss: (0.617)(R 0.661, F 0.573)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.791] [G acc: 0.438]\n",
      "21973 [D loss: (0.629)(R 0.679, F 0.579)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.800] [G acc: 0.438]\n",
      "21974 [D loss: (0.682)(R 0.707, F 0.658)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.954] [G acc: 0.062]\n",
      "21975 [D loss: (0.702)(R 0.777, F 0.626)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.113] [G acc: 0.250]\n",
      "21976 [D loss: (0.632)(R 0.580, F 0.683)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.728] [G acc: 0.500]\n",
      "21977 [D loss: (0.592)(R 0.593, F 0.592)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.770] [G acc: 0.375]\n",
      "21978 [D loss: (0.673)(R 0.694, F 0.652)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.891] [G acc: 0.062]\n",
      "21979 [D loss: (0.698)(R 0.733, F 0.663)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.735] [G acc: 0.375]\n",
      "21980 [D loss: (0.715)(R 0.579, F 0.851)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.495] [G acc: 0.750]\n",
      "21981 [D loss: (0.664)(R 0.660, F 0.668)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.941] [G acc: 0.125]\n",
      "21982 [D loss: (0.573)(R 0.631, F 0.514)] [D acc: (0.719)(0.438, 1.000)] [G loss: 1.400] [G acc: 0.062]\n",
      "21983 [D loss: (0.631)(R 0.669, F 0.594)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.894] [G acc: 0.312]\n",
      "21984 [D loss: (0.476)(R 0.537, F 0.414)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.097] [G acc: 0.375]\n",
      "21985 [D loss: (0.638)(R 0.713, F 0.562)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.840] [G acc: 0.250]\n",
      "21986 [D loss: (0.651)(R 0.622, F 0.680)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.923] [G acc: 0.125]\n",
      "21987 [D loss: (0.685)(R 0.710, F 0.659)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.738] [G acc: 0.312]\n",
      "21988 [D loss: (0.605)(R 0.652, F 0.558)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.984] [G acc: 0.000]\n",
      "21989 [D loss: (0.637)(R 0.633, F 0.641)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.673] [G acc: 0.438]\n",
      "21990 [D loss: (0.708)(R 0.578, F 0.838)] [D acc: (0.562)(0.625, 0.500)] [G loss: 1.369] [G acc: 0.250]\n",
      "21991 [D loss: (0.556)(R 0.738, F 0.374)] [D acc: (0.688)(0.562, 0.812)] [G loss: 2.175] [G acc: 0.188]\n",
      "21992 [D loss: (0.817)(R 0.812, F 0.822)] [D acc: (0.438)(0.250, 0.625)] [G loss: 1.170] [G acc: 0.312]\n",
      "21993 [D loss: (0.554)(R 0.670, F 0.438)] [D acc: (0.656)(0.438, 0.875)] [G loss: 1.172] [G acc: 0.188]\n",
      "21994 [D loss: (0.593)(R 0.663, F 0.522)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.926] [G acc: 0.250]\n",
      "21995 [D loss: (0.860)(R 0.755, F 0.965)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.532] [G acc: 0.750]\n",
      "21996 [D loss: (0.634)(R 0.732, F 0.535)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.056] [G acc: 0.125]\n",
      "21997 [D loss: (0.723)(R 0.823, F 0.623)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.653] [G acc: 0.375]\n",
      "21998 [D loss: (0.681)(R 0.733, F 0.628)] [D acc: (0.562)(0.500, 0.625)] [G loss: 1.230] [G acc: 0.438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21999 [D loss: (0.985)(R 0.659, F 1.311)] [D acc: (0.500)(0.500, 0.500)] [G loss: 6.926] [G acc: 0.312]\n",
      "22000 [D loss: (0.596)(R 0.654, F 0.538)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.989] [G acc: 0.125]\n",
      "22001 [D loss: (0.656)(R 0.647, F 0.664)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.931] [G acc: 0.312]\n",
      "22002 [D loss: (0.516)(R 0.612, F 0.420)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.565] [G acc: 0.562]\n",
      "22003 [D loss: (0.814)(R 0.869, F 0.759)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.748] [G acc: 0.250]\n",
      "22004 [D loss: (0.811)(R 0.679, F 0.942)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.242] [G acc: 0.875]\n",
      "22005 [D loss: (0.896)(R 0.648, F 1.145)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.879] [G acc: 0.188]\n",
      "22006 [D loss: (0.808)(R 0.957, F 0.660)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.399] [G acc: 0.750]\n",
      "22007 [D loss: (0.781)(R 0.660, F 0.903)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.703] [G acc: 0.500]\n",
      "22008 [D loss: (1.089)(R 0.702, F 1.475)] [D acc: (0.469)(0.438, 0.500)] [G loss: 1.006] [G acc: 0.250]\n",
      "22009 [D loss: (0.560)(R 0.623, F 0.498)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.125] [G acc: 0.312]\n",
      "22010 [D loss: (0.909)(R 0.788, F 1.029)] [D acc: (0.469)(0.438, 0.500)] [G loss: 1.098] [G acc: 0.250]\n",
      "22011 [D loss: (0.850)(R 0.756, F 0.945)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.780] [G acc: 0.438]\n",
      "22012 [D loss: (0.618)(R 0.757, F 0.480)] [D acc: (0.531)(0.375, 0.688)] [G loss: 1.293] [G acc: 0.125]\n",
      "22013 [D loss: (0.695)(R 0.777, F 0.613)] [D acc: (0.562)(0.500, 0.625)] [G loss: 1.143] [G acc: 0.562]\n",
      "22014 [D loss: (0.386)(R 0.645, F 0.127)] [D acc: (0.781)(0.562, 1.000)] [G loss: 5.189] [G acc: 0.188]\n",
      "22015 [D loss: (0.738)(R 0.759, F 0.716)] [D acc: (0.500)(0.438, 0.562)] [G loss: 1.867] [G acc: 0.188]\n",
      "22016 [D loss: (0.504)(R 0.650, F 0.358)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.155] [G acc: 0.438]\n",
      "22017 [D loss: (0.575)(R 0.727, F 0.422)] [D acc: (0.656)(0.312, 1.000)] [G loss: 0.796] [G acc: 0.250]\n",
      "22018 [D loss: (0.587)(R 0.623, F 0.552)] [D acc: (0.562)(0.562, 0.562)] [G loss: 1.176] [G acc: 0.125]\n",
      "22019 [D loss: (0.682)(R 0.718, F 0.645)] [D acc: (0.562)(0.562, 0.562)] [G loss: 1.018] [G acc: 0.125]\n",
      "22020 [D loss: (0.623)(R 0.675, F 0.571)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.794] [G acc: 0.375]\n",
      "22021 [D loss: (0.755)(R 0.831, F 0.680)] [D acc: (0.469)(0.312, 0.625)] [G loss: 1.261] [G acc: 0.188]\n",
      "22022 [D loss: (0.685)(R 0.674, F 0.695)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.521] [G acc: 0.750]\n",
      "22023 [D loss: (0.563)(R 0.644, F 0.482)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.574] [G acc: 0.625]\n",
      "22024 [D loss: (0.795)(R 0.935, F 0.655)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.212] [G acc: 0.125]\n",
      "22025 [D loss: (0.640)(R 0.769, F 0.510)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.535] [G acc: 0.625]\n",
      "22026 [D loss: (0.637)(R 0.706, F 0.568)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.756] [G acc: 0.625]\n",
      "22027 [D loss: (0.992)(R 0.946, F 1.038)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.830] [G acc: 0.250]\n",
      "22028 [D loss: (0.648)(R 0.720, F 0.577)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.736] [G acc: 0.250]\n",
      "22029 [D loss: (0.695)(R 0.713, F 0.677)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.944] [G acc: 0.562]\n",
      "22030 [D loss: (1.051)(R 0.667, F 1.436)] [D acc: (0.438)(0.438, 0.438)] [G loss: 1.220] [G acc: 0.438]\n",
      "22031 [D loss: (0.467)(R 0.627, F 0.306)] [D acc: (0.750)(0.688, 0.812)] [G loss: 3.763] [G acc: 0.125]\n",
      "22032 [D loss: (0.802)(R 0.710, F 0.893)] [D acc: (0.562)(0.500, 0.625)] [G loss: 3.485] [G acc: 0.312]\n",
      "22033 [D loss: (0.585)(R 0.651, F 0.519)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.394] [G acc: 0.625]\n",
      "22034 [D loss: (0.652)(R 0.762, F 0.541)] [D acc: (0.625)(0.438, 0.812)] [G loss: 1.446] [G acc: 0.250]\n",
      "22035 [D loss: (0.683)(R 0.627, F 0.739)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.863] [G acc: 0.375]\n",
      "22036 [D loss: (0.639)(R 0.703, F 0.575)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.543] [G acc: 0.688]\n",
      "22037 [D loss: (0.617)(R 0.680, F 0.553)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.007] [G acc: 0.125]\n",
      "22038 [D loss: (0.562)(R 0.580, F 0.543)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.168] [G acc: 0.250]\n",
      "22039 [D loss: (0.582)(R 0.608, F 0.555)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.063] [G acc: 0.125]\n",
      "22040 [D loss: (0.575)(R 0.572, F 0.577)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.914] [G acc: 0.500]\n",
      "22041 [D loss: (0.567)(R 0.650, F 0.485)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.916] [G acc: 0.250]\n",
      "22042 [D loss: (0.629)(R 0.770, F 0.489)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.849] [G acc: 0.375]\n",
      "22043 [D loss: (0.723)(R 0.905, F 0.542)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.960] [G acc: 0.125]\n",
      "22044 [D loss: (0.622)(R 0.592, F 0.652)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.809] [G acc: 0.312]\n",
      "22045 [D loss: (0.660)(R 0.698, F 0.623)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.987] [G acc: 0.250]\n",
      "22046 [D loss: (0.539)(R 0.645, F 0.434)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.268] [G acc: 0.062]\n",
      "22047 [D loss: (0.607)(R 0.702, F 0.513)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.430] [G acc: 0.250]\n",
      "22048 [D loss: (0.526)(R 0.600, F 0.452)] [D acc: (0.688)(0.750, 0.625)] [G loss: 2.156] [G acc: 0.125]\n",
      "22049 [D loss: (0.733)(R 0.782, F 0.684)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.005] [G acc: 0.125]\n",
      "22050 [D loss: (0.698)(R 0.692, F 0.703)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.835] [G acc: 0.188]\n",
      "22051 [D loss: (0.611)(R 0.609, F 0.613)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.975] [G acc: 0.062]\n",
      "22052 [D loss: (0.662)(R 0.770, F 0.555)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.812] [G acc: 0.250]\n",
      "22053 [D loss: (0.557)(R 0.591, F 0.523)] [D acc: (0.844)(0.750, 0.938)] [G loss: 0.851] [G acc: 0.250]\n",
      "22054 [D loss: (0.701)(R 0.740, F 0.662)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.896] [G acc: 0.250]\n",
      "22055 [D loss: (0.751)(R 0.905, F 0.597)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.843] [G acc: 0.062]\n",
      "22056 [D loss: (0.619)(R 0.663, F 0.574)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.888] [G acc: 0.312]\n",
      "22057 [D loss: (0.609)(R 0.570, F 0.649)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.850] [G acc: 0.250]\n",
      "22058 [D loss: (0.629)(R 0.634, F 0.625)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.790] [G acc: 0.312]\n",
      "22059 [D loss: (0.602)(R 0.595, F 0.609)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.799] [G acc: 0.250]\n",
      "22060 [D loss: (0.587)(R 0.720, F 0.454)] [D acc: (0.750)(0.500, 1.000)] [G loss: 0.825] [G acc: 0.438]\n",
      "22061 [D loss: (0.609)(R 0.616, F 0.603)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.898] [G acc: 0.188]\n",
      "22062 [D loss: (0.629)(R 0.696, F 0.561)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.885] [G acc: 0.188]\n",
      "22063 [D loss: (0.652)(R 0.694, F 0.610)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.856] [G acc: 0.250]\n",
      "22064 [D loss: (0.600)(R 0.693, F 0.507)] [D acc: (0.688)(0.500, 0.875)] [G loss: 1.116] [G acc: 0.250]\n",
      "22065 [D loss: (0.541)(R 0.650, F 0.432)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.967] [G acc: 0.125]\n",
      "22066 [D loss: (0.463)(R 0.691, F 0.235)] [D acc: (0.750)(0.500, 1.000)] [G loss: 7.092] [G acc: 0.125]\n",
      "22067 [D loss: (0.638)(R 0.855, F 0.420)] [D acc: (0.531)(0.375, 0.688)] [G loss: 2.143] [G acc: 0.375]\n",
      "22068 [D loss: (0.594)(R 0.556, F 0.632)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.895] [G acc: 0.000]\n",
      "22069 [D loss: (0.606)(R 0.599, F 0.612)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.842] [G acc: 0.188]\n",
      "22070 [D loss: (0.643)(R 0.695, F 0.591)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.570] [G acc: 0.312]\n",
      "22071 [D loss: (0.644)(R 0.519, F 0.769)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.784] [G acc: 0.250]\n",
      "22072 [D loss: (0.719)(R 0.717, F 0.721)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.803] [G acc: 0.250]\n",
      "22073 [D loss: (0.650)(R 0.631, F 0.668)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.788] [G acc: 0.312]\n",
      "22074 [D loss: (0.591)(R 0.554, F 0.628)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.797] [G acc: 0.375]\n",
      "22075 [D loss: (0.660)(R 0.729, F 0.592)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.827] [G acc: 0.375]\n",
      "22076 [D loss: (0.723)(R 0.827, F 0.620)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.881] [G acc: 0.188]\n",
      "22077 [D loss: (0.680)(R 0.692, F 0.667)] [D acc: (0.406)(0.375, 0.438)] [G loss: 0.881] [G acc: 0.250]\n",
      "22078 [D loss: (0.579)(R 0.666, F 0.492)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.035] [G acc: 0.188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22079 [D loss: (0.745)(R 0.730, F 0.760)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.768] [G acc: 0.188]\n",
      "22080 [D loss: (0.619)(R 0.728, F 0.511)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.831] [G acc: 0.562]\n",
      "22081 [D loss: (0.688)(R 0.648, F 0.727)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.489] [G acc: 0.688]\n",
      "22082 [D loss: (0.656)(R 0.622, F 0.691)] [D acc: (0.531)(0.562, 0.500)] [G loss: 1.002] [G acc: 0.125]\n",
      "22083 [D loss: (0.691)(R 0.686, F 0.696)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.739] [G acc: 0.375]\n",
      "22084 [D loss: (0.605)(R 0.660, F 0.550)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.153] [G acc: 0.000]\n",
      "22085 [D loss: (0.607)(R 0.556, F 0.659)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.904] [G acc: 0.375]\n",
      "22086 [D loss: (0.562)(R 0.850, F 0.275)] [D acc: (0.594)(0.250, 0.938)] [G loss: 2.233] [G acc: 0.062]\n",
      "22087 [D loss: (0.548)(R 0.779, F 0.318)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.971] [G acc: 0.188]\n",
      "22088 [D loss: (0.628)(R 0.630, F 0.626)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.887] [G acc: 0.188]\n",
      "22089 [D loss: (0.615)(R 0.758, F 0.473)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.920] [G acc: 0.125]\n",
      "22090 [D loss: (0.657)(R 0.853, F 0.460)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.844] [G acc: 0.188]\n",
      "22091 [D loss: (0.701)(R 0.775, F 0.628)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.756] [G acc: 0.250]\n",
      "22092 [D loss: (0.665)(R 0.865, F 0.465)] [D acc: (0.719)(0.500, 0.938)] [G loss: 0.949] [G acc: 0.188]\n",
      "22093 [D loss: (0.684)(R 0.732, F 0.636)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.883] [G acc: 0.000]\n",
      "22094 [D loss: (0.676)(R 0.653, F 0.698)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.840] [G acc: 0.125]\n",
      "22095 [D loss: (0.640)(R 0.696, F 0.583)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.835] [G acc: 0.062]\n",
      "22096 [D loss: (0.747)(R 0.812, F 0.682)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.737] [G acc: 0.312]\n",
      "22097 [D loss: (0.652)(R 0.615, F 0.689)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.807] [G acc: 0.188]\n",
      "22098 [D loss: (0.553)(R 0.472, F 0.634)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.699] [G acc: 0.438]\n",
      "22099 [D loss: (0.631)(R 0.584, F 0.679)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.788] [G acc: 0.188]\n",
      "22100 [D loss: (0.581)(R 0.556, F 0.606)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.783] [G acc: 0.250]\n",
      "22101 [D loss: (0.776)(R 0.824, F 0.728)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.523] [G acc: 0.562]\n",
      "22102 [D loss: (0.712)(R 0.743, F 0.681)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.345] [G acc: 0.625]\n",
      "22103 [D loss: (0.669)(R 0.680, F 0.658)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.809] [G acc: 0.188]\n",
      "22104 [D loss: (0.650)(R 0.709, F 0.591)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.726] [G acc: 0.500]\n",
      "22105 [D loss: (0.705)(R 0.659, F 0.752)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.741] [G acc: 0.375]\n",
      "22106 [D loss: (0.703)(R 0.726, F 0.680)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.618] [G acc: 0.562]\n",
      "22107 [D loss: (0.713)(R 0.642, F 0.785)] [D acc: (0.375)(0.500, 0.250)] [G loss: 0.776] [G acc: 0.188]\n",
      "22108 [D loss: (0.669)(R 0.649, F 0.689)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.804] [G acc: 0.125]\n",
      "22109 [D loss: (0.824)(R 0.664, F 0.983)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.727] [G acc: 0.312]\n",
      "22110 [D loss: (0.829)(R 0.823, F 0.836)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.666] [G acc: 0.562]\n",
      "22111 [D loss: (0.674)(R 0.681, F 0.667)] [D acc: (0.562)(0.438, 0.688)] [G loss: 1.300] [G acc: 0.438]\n",
      "22112 [D loss: (0.378)(R 0.612, F 0.144)] [D acc: (0.750)(0.562, 0.938)] [G loss: 3.146] [G acc: 0.062]\n",
      "22113 [D loss: (0.667)(R 0.688, F 0.646)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.773] [G acc: 0.250]\n",
      "22114 [D loss: (0.746)(R 0.707, F 0.785)] [D acc: (0.344)(0.312, 0.375)] [G loss: 0.710] [G acc: 0.312]\n",
      "22115 [D loss: (0.686)(R 0.694, F 0.679)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.693] [G acc: 0.312]\n",
      "22116 [D loss: (0.709)(R 0.757, F 0.660)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.797] [G acc: 0.312]\n",
      "22117 [D loss: (0.660)(R 0.804, F 0.515)] [D acc: (0.531)(0.312, 0.750)] [G loss: 1.084] [G acc: 0.188]\n",
      "22118 [D loss: (0.602)(R 0.589, F 0.615)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.909] [G acc: 0.188]\n",
      "22119 [D loss: (0.656)(R 0.649, F 0.663)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.757] [G acc: 0.188]\n",
      "22120 [D loss: (0.651)(R 0.628, F 0.675)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.805] [G acc: 0.312]\n",
      "22121 [D loss: (0.673)(R 0.662, F 0.685)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.827] [G acc: 0.438]\n",
      "22122 [D loss: (0.597)(R 0.723, F 0.471)] [D acc: (0.531)(0.312, 0.750)] [G loss: 1.552] [G acc: 0.125]\n",
      "22123 [D loss: (0.615)(R 0.724, F 0.505)] [D acc: (0.500)(0.312, 0.688)] [G loss: 1.797] [G acc: 0.062]\n",
      "22124 [D loss: (0.508)(R 0.575, F 0.441)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.792] [G acc: 0.125]\n",
      "22125 [D loss: (0.659)(R 0.663, F 0.655)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.780] [G acc: 0.000]\n",
      "22126 [D loss: (0.702)(R 0.653, F 0.751)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.701] [G acc: 0.375]\n",
      "22127 [D loss: (0.616)(R 0.565, F 0.668)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.705] [G acc: 0.562]\n",
      "22128 [D loss: (0.707)(R 0.668, F 0.747)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.746] [G acc: 0.250]\n",
      "22129 [D loss: (0.567)(R 0.594, F 0.540)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.850] [G acc: 0.312]\n",
      "22130 [D loss: (0.517)(R 0.636, F 0.397)] [D acc: (0.656)(0.438, 0.875)] [G loss: 1.516] [G acc: 0.250]\n",
      "22131 [D loss: (0.637)(R 0.745, F 0.529)] [D acc: (0.531)(0.375, 0.688)] [G loss: 1.254] [G acc: 0.125]\n",
      "22132 [D loss: (0.652)(R 0.659, F 0.645)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.812] [G acc: 0.250]\n",
      "22133 [D loss: (0.614)(R 0.651, F 0.578)] [D acc: (0.656)(0.375, 0.938)] [G loss: 0.708] [G acc: 0.375]\n",
      "22134 [D loss: (0.692)(R 0.741, F 0.643)] [D acc: (0.531)(0.250, 0.812)] [G loss: 0.635] [G acc: 0.625]\n",
      "22135 [D loss: (0.631)(R 0.603, F 0.660)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.732] [G acc: 0.375]\n",
      "22136 [D loss: (0.884)(R 1.064, F 0.705)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.925] [G acc: 0.125]\n",
      "22137 [D loss: (0.638)(R 0.600, F 0.676)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.858] [G acc: 0.188]\n",
      "22138 [D loss: (0.539)(R 0.571, F 0.506)] [D acc: (0.750)(0.500, 1.000)] [G loss: 0.858] [G acc: 0.062]\n",
      "22139 [D loss: (0.537)(R 0.534, F 0.540)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.961] [G acc: 0.312]\n",
      "22140 [D loss: (0.590)(R 0.660, F 0.519)] [D acc: (0.531)(0.312, 0.750)] [G loss: 1.658] [G acc: 0.188]\n",
      "22141 [D loss: (0.373)(R 0.689, F 0.057)] [D acc: (0.688)(0.375, 1.000)] [G loss: 6.957] [G acc: 0.188]\n",
      "22142 [D loss: (0.638)(R 0.623, F 0.653)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.950] [G acc: 0.250]\n",
      "22143 [D loss: (0.663)(R 0.543, F 0.782)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.819] [G acc: 0.188]\n",
      "22144 [D loss: (0.867)(R 0.574, F 1.161)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.715] [G acc: 0.438]\n",
      "22145 [D loss: (0.627)(R 0.592, F 0.662)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.891] [G acc: 0.062]\n",
      "22146 [D loss: (0.621)(R 0.625, F 0.617)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.798] [G acc: 0.125]\n",
      "22147 [D loss: (0.615)(R 0.681, F 0.548)] [D acc: (0.719)(0.438, 1.000)] [G loss: 0.823] [G acc: 0.125]\n",
      "22148 [D loss: (0.538)(R 0.530, F 0.545)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.990] [G acc: 0.062]\n",
      "22149 [D loss: (0.539)(R 0.586, F 0.493)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.000] [G acc: 0.188]\n",
      "22150 [D loss: (0.565)(R 0.732, F 0.397)] [D acc: (0.625)(0.375, 0.875)] [G loss: 2.038] [G acc: 0.062]\n",
      "22151 [D loss: (0.558)(R 0.515, F 0.600)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.899] [G acc: 0.125]\n",
      "22152 [D loss: (0.573)(R 0.533, F 0.614)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.908] [G acc: 0.000]\n",
      "22153 [D loss: (0.512)(R 0.444, F 0.579)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.810] [G acc: 0.250]\n",
      "22154 [D loss: (0.605)(R 0.587, F 0.624)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.017] [G acc: 0.125]\n",
      "22155 [D loss: (0.583)(R 0.661, F 0.504)] [D acc: (0.625)(0.438, 0.812)] [G loss: 1.131] [G acc: 0.125]\n",
      "22156 [D loss: (0.485)(R 0.633, F 0.337)] [D acc: (0.812)(0.688, 0.938)] [G loss: 2.647] [G acc: 0.125]\n",
      "22157 [D loss: (0.527)(R 0.510, F 0.544)] [D acc: (0.656)(0.688, 0.625)] [G loss: 2.062] [G acc: 0.312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22158 [D loss: (0.439)(R 0.576, F 0.302)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.895] [G acc: 0.250]\n",
      "22159 [D loss: (0.490)(R 0.391, F 0.589)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.180] [G acc: 0.188]\n",
      "22160 [D loss: (0.565)(R 0.535, F 0.595)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.975] [G acc: 0.188]\n",
      "22161 [D loss: (0.654)(R 0.642, F 0.666)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.807] [G acc: 0.312]\n",
      "22162 [D loss: (0.682)(R 0.774, F 0.591)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.814] [G acc: 0.125]\n",
      "22163 [D loss: (0.567)(R 0.506, F 0.628)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.936] [G acc: 0.062]\n",
      "22164 [D loss: (0.543)(R 0.458, F 0.629)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.845] [G acc: 0.188]\n",
      "22165 [D loss: (0.595)(R 0.619, F 0.571)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.902] [G acc: 0.250]\n",
      "22166 [D loss: (0.564)(R 0.426, F 0.701)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.364] [G acc: 0.125]\n",
      "22167 [D loss: (0.511)(R 0.406, F 0.615)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.798] [G acc: 0.125]\n",
      "22168 [D loss: (0.647)(R 0.600, F 0.695)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.816] [G acc: 0.375]\n",
      "22169 [D loss: (0.454)(R 0.318, F 0.589)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.849] [G acc: 0.375]\n",
      "22170 [D loss: (0.568)(R 0.416, F 0.720)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.065] [G acc: 0.125]\n",
      "22171 [D loss: (0.496)(R 0.383, F 0.609)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.916] [G acc: 0.188]\n",
      "22172 [D loss: (0.556)(R 0.506, F 0.607)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.845] [G acc: 0.250]\n",
      "22173 [D loss: (0.498)(R 0.441, F 0.554)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.957] [G acc: 0.188]\n",
      "22174 [D loss: (0.530)(R 0.542, F 0.518)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.948] [G acc: 0.125]\n",
      "22175 [D loss: (0.611)(R 0.361, F 0.860)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.703] [G acc: 0.562]\n",
      "22176 [D loss: (0.529)(R 0.425, F 0.633)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.038] [G acc: 0.188]\n",
      "22177 [D loss: (1.011)(R 0.512, F 1.509)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.007] [G acc: 0.188]\n",
      "22178 [D loss: (0.626)(R 0.523, F 0.728)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.384] [G acc: 0.750]\n",
      "22179 [D loss: (0.688)(R 0.685, F 0.691)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.712] [G acc: 0.500]\n",
      "22180 [D loss: (0.807)(R 0.592, F 1.022)] [D acc: (0.375)(0.562, 0.188)] [G loss: 0.779] [G acc: 0.250]\n",
      "22181 [D loss: (0.668)(R 0.607, F 0.728)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.421] [G acc: 0.688]\n",
      "22182 [D loss: (1.187)(R 0.619, F 1.754)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.938] [G acc: 0.250]\n",
      "22183 [D loss: (0.386)(R 0.529, F 0.244)] [D acc: (0.781)(0.688, 0.875)] [G loss: 2.870] [G acc: 0.188]\n",
      "22184 [D loss: (0.691)(R 0.635, F 0.747)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.471] [G acc: 0.625]\n",
      "22185 [D loss: (0.740)(R 0.589, F 0.890)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.855] [G acc: 0.500]\n",
      "22186 [D loss: (0.961)(R 0.489, F 1.432)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.942] [G acc: 0.438]\n",
      "22187 [D loss: (0.404)(R 0.427, F 0.380)] [D acc: (0.812)(0.750, 0.875)] [G loss: 2.044] [G acc: 0.062]\n",
      "22188 [D loss: (1.495)(R 0.726, F 2.263)] [D acc: (0.406)(0.312, 0.500)] [G loss: 1.998] [G acc: 0.312]\n",
      "22189 [D loss: (0.493)(R 0.711, F 0.275)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.351] [G acc: 0.062]\n",
      "22190 [D loss: (0.646)(R 0.591, F 0.701)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.835] [G acc: 0.500]\n",
      "22191 [D loss: (0.672)(R 0.607, F 0.738)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.741] [G acc: 0.375]\n",
      "22192 [D loss: (0.682)(R 0.576, F 0.788)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.762] [G acc: 0.188]\n",
      "22193 [D loss: (0.658)(R 0.596, F 0.721)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.808] [G acc: 0.438]\n",
      "22194 [D loss: (0.623)(R 0.580, F 0.665)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.699] [G acc: 0.438]\n",
      "22195 [D loss: (0.745)(R 0.685, F 0.805)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.698] [G acc: 0.375]\n",
      "22196 [D loss: (0.701)(R 0.701, F 0.702)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.676] [G acc: 0.438]\n",
      "22197 [D loss: (0.689)(R 0.677, F 0.701)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.553] [G acc: 0.688]\n",
      "22198 [D loss: (0.773)(R 1.027, F 0.519)] [D acc: (0.562)(0.375, 0.750)] [G loss: 1.290] [G acc: 0.188]\n",
      "22199 [D loss: (0.476)(R 0.630, F 0.323)] [D acc: (0.688)(0.500, 0.875)] [G loss: 2.181] [G acc: 0.125]\n",
      "22200 [D loss: (0.609)(R 0.692, F 0.525)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.855] [G acc: 0.312]\n",
      "22201 [D loss: (0.641)(R 0.777, F 0.506)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.121] [G acc: 0.188]\n",
      "22202 [D loss: (0.643)(R 0.633, F 0.653)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.850] [G acc: 0.438]\n",
      "22203 [D loss: (0.658)(R 0.576, F 0.739)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.763] [G acc: 0.312]\n",
      "22204 [D loss: (0.628)(R 0.587, F 0.668)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.678] [G acc: 0.500]\n",
      "22205 [D loss: (0.572)(R 0.534, F 0.610)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.020] [G acc: 0.062]\n",
      "22206 [D loss: (0.672)(R 0.630, F 0.714)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.716] [G acc: 0.312]\n",
      "22207 [D loss: (0.633)(R 0.568, F 0.698)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.775] [G acc: 0.125]\n",
      "22208 [D loss: (0.666)(R 0.665, F 0.667)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.701] [G acc: 0.438]\n",
      "22209 [D loss: (0.618)(R 0.547, F 0.689)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.791] [G acc: 0.250]\n",
      "22210 [D loss: (0.628)(R 0.647, F 0.608)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.542] [G acc: 0.500]\n",
      "22211 [D loss: (0.715)(R 0.633, F 0.797)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.771] [G acc: 0.375]\n",
      "22212 [D loss: (0.510)(R 0.552, F 0.468)] [D acc: (0.656)(0.500, 0.812)] [G loss: 2.002] [G acc: 0.125]\n",
      "22213 [D loss: (1.144)(R 0.651, F 1.637)] [D acc: (0.625)(0.688, 0.562)] [G loss: 3.174] [G acc: 0.312]\n",
      "22214 [D loss: (0.468)(R 0.529, F 0.407)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.089] [G acc: 0.250]\n",
      "22215 [D loss: (0.639)(R 0.668, F 0.609)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.608] [G acc: 0.562]\n",
      "22216 [D loss: (0.763)(R 0.520, F 1.005)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.815] [G acc: 0.062]\n",
      "22217 [D loss: (0.670)(R 0.693, F 0.647)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.766] [G acc: 0.250]\n",
      "22218 [D loss: (0.890)(R 0.682, F 1.097)] [D acc: (0.562)(0.500, 0.625)] [G loss: 1.326] [G acc: 0.500]\n",
      "22219 [D loss: (0.454)(R 0.627, F 0.282)] [D acc: (0.656)(0.438, 0.875)] [G loss: 4.146] [G acc: 0.188]\n",
      "22220 [D loss: (0.595)(R 0.541, F 0.650)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.024] [G acc: 0.438]\n",
      "22221 [D loss: (0.644)(R 0.788, F 0.500)] [D acc: (0.469)(0.250, 0.688)] [G loss: 1.550] [G acc: 0.250]\n",
      "22222 [D loss: (0.844)(R 0.686, F 1.003)] [D acc: (0.406)(0.375, 0.438)] [G loss: 1.161] [G acc: 0.250]\n",
      "22223 [D loss: (0.482)(R 0.590, F 0.374)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.818] [G acc: 0.125]\n",
      "22224 [D loss: (0.645)(R 0.622, F 0.668)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.976] [G acc: 0.062]\n",
      "22225 [D loss: (0.518)(R 0.607, F 0.428)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.786] [G acc: 0.250]\n",
      "22226 [D loss: (0.575)(R 0.613, F 0.536)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.872] [G acc: 0.000]\n",
      "22227 [D loss: (0.525)(R 0.518, F 0.532)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.026] [G acc: 0.250]\n",
      "22228 [D loss: (0.474)(R 0.616, F 0.331)] [D acc: (0.812)(0.688, 0.938)] [G loss: 5.912] [G acc: 0.250]\n",
      "22229 [D loss: (1.251)(R 0.983, F 1.518)] [D acc: (0.562)(0.438, 0.688)] [G loss: 7.273] [G acc: 0.250]\n",
      "22230 [D loss: (0.742)(R 0.656, F 0.828)] [D acc: (0.500)(0.500, 0.500)] [G loss: 2.656] [G acc: 0.250]\n",
      "22231 [D loss: (0.574)(R 0.658, F 0.489)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.932] [G acc: 0.562]\n",
      "22232 [D loss: (0.513)(R 0.754, F 0.272)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.286] [G acc: 0.562]\n",
      "22233 [D loss: (0.508)(R 0.479, F 0.538)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.740] [G acc: 0.375]\n",
      "22234 [D loss: (0.473)(R 0.601, F 0.345)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.678] [G acc: 0.625]\n",
      "22235 [D loss: (0.646)(R 0.588, F 0.704)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.223] [G acc: 0.062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22236 [D loss: (0.864)(R 0.946, F 0.781)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.898] [G acc: 0.188]\n",
      "22237 [D loss: (0.570)(R 0.604, F 0.536)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.729] [G acc: 0.250]\n",
      "22238 [D loss: (0.586)(R 0.614, F 0.557)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.893] [G acc: 0.188]\n",
      "22239 [D loss: (0.526)(R 0.580, F 0.473)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.861] [G acc: 0.125]\n",
      "22240 [D loss: (0.513)(R 0.615, F 0.411)] [D acc: (0.688)(0.625, 0.750)] [G loss: 2.402] [G acc: 0.125]\n",
      "22241 [D loss: (0.428)(R 0.509, F 0.347)] [D acc: (0.844)(0.938, 0.750)] [G loss: 4.814] [G acc: 0.062]\n",
      "22242 [D loss: (0.526)(R 0.689, F 0.363)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.435] [G acc: 0.188]\n",
      "22243 [D loss: (0.750)(R 0.839, F 0.660)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.323] [G acc: 0.250]\n",
      "22244 [D loss: (0.443)(R 0.572, F 0.315)] [D acc: (0.906)(0.812, 1.000)] [G loss: 2.838] [G acc: 0.312]\n",
      "22245 [D loss: (0.607)(R 0.818, F 0.397)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.884] [G acc: 0.438]\n",
      "22246 [D loss: (0.587)(R 0.536, F 0.638)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.821] [G acc: 0.062]\n",
      "22247 [D loss: (0.598)(R 0.570, F 0.626)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.686] [G acc: 0.375]\n",
      "22248 [D loss: (0.630)(R 0.514, F 0.747)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.888] [G acc: 0.125]\n",
      "22249 [D loss: (0.588)(R 0.557, F 0.619)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.620] [G acc: 0.625]\n",
      "22250 [D loss: (0.666)(R 0.659, F 0.673)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.583] [G acc: 0.750]\n",
      "22251 [D loss: (0.582)(R 0.529, F 0.634)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.544] [G acc: 0.688]\n",
      "22252 [D loss: (0.597)(R 0.601, F 0.593)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.671] [G acc: 0.438]\n",
      "22253 [D loss: (0.392)(R 0.563, F 0.222)] [D acc: (0.875)(0.750, 1.000)] [G loss: 3.182] [G acc: 0.188]\n",
      "22254 [D loss: (0.834)(R 1.085, F 0.584)] [D acc: (0.625)(0.438, 0.812)] [G loss: 1.025] [G acc: 0.438]\n",
      "22255 [D loss: (0.582)(R 0.467, F 0.697)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.010] [G acc: 0.125]\n",
      "22256 [D loss: (0.540)(R 0.557, F 0.522)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.019] [G acc: 0.125]\n",
      "22257 [D loss: (0.694)(R 0.743, F 0.645)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.535] [G acc: 0.188]\n",
      "22258 [D loss: (0.485)(R 0.565, F 0.405)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.506] [G acc: 0.375]\n",
      "22259 [D loss: (0.552)(R 0.597, F 0.508)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.863] [G acc: 0.250]\n",
      "22260 [D loss: (0.502)(R 0.489, F 0.514)] [D acc: (0.875)(0.812, 0.938)] [G loss: 0.923] [G acc: 0.188]\n",
      "22261 [D loss: (0.578)(R 0.596, F 0.559)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.862] [G acc: 0.375]\n",
      "22262 [D loss: (0.681)(R 0.669, F 0.693)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.362] [G acc: 0.250]\n",
      "22263 [D loss: (0.466)(R 0.530, F 0.403)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.889] [G acc: 0.125]\n",
      "22264 [D loss: (0.439)(R 0.548, F 0.330)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.007] [G acc: 0.312]\n",
      "22265 [D loss: (0.513)(R 0.648, F 0.377)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.353] [G acc: 0.125]\n",
      "22266 [D loss: (0.658)(R 0.661, F 0.654)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.920] [G acc: 0.125]\n",
      "22267 [D loss: (0.635)(R 0.573, F 0.696)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.966] [G acc: 0.062]\n",
      "22268 [D loss: (0.703)(R 0.522, F 0.884)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.998] [G acc: 0.125]\n",
      "22269 [D loss: (0.596)(R 0.637, F 0.555)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.628] [G acc: 0.500]\n",
      "22270 [D loss: (0.532)(R 0.532, F 0.533)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.638] [G acc: 0.562]\n",
      "22271 [D loss: (0.656)(R 0.669, F 0.642)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.648] [G acc: 0.625]\n",
      "22272 [D loss: (0.522)(R 0.456, F 0.589)] [D acc: (0.844)(0.875, 0.812)] [G loss: 0.952] [G acc: 0.125]\n",
      "22273 [D loss: (0.637)(R 0.620, F 0.654)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.987] [G acc: 0.250]\n",
      "22274 [D loss: (0.549)(R 0.543, F 0.555)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.651] [G acc: 0.625]\n",
      "22275 [D loss: (0.541)(R 0.463, F 0.618)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.898] [G acc: 0.250]\n",
      "22276 [D loss: (0.639)(R 0.718, F 0.560)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.847] [G acc: 0.188]\n",
      "22277 [D loss: (0.464)(R 0.358, F 0.570)] [D acc: (0.875)(1.000, 0.750)] [G loss: 0.992] [G acc: 0.062]\n",
      "22278 [D loss: (0.553)(R 0.616, F 0.489)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.152] [G acc: 0.188]\n",
      "22279 [D loss: (0.729)(R 0.803, F 0.654)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.823] [G acc: 0.500]\n",
      "22280 [D loss: (0.796)(R 1.006, F 0.585)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.832] [G acc: 0.375]\n",
      "22281 [D loss: (0.725)(R 0.630, F 0.821)] [D acc: (0.594)(0.500, 0.688)] [G loss: 1.401] [G acc: 0.250]\n",
      "22282 [D loss: (0.498)(R 0.683, F 0.312)] [D acc: (0.719)(0.500, 0.938)] [G loss: 6.409] [G acc: 0.062]\n",
      "22283 [D loss: (1.007)(R 0.649, F 1.364)] [D acc: (0.531)(0.562, 0.500)] [G loss: 4.450] [G acc: 0.312]\n",
      "22284 [D loss: (0.594)(R 0.874, F 0.315)] [D acc: (0.688)(0.500, 0.875)] [G loss: 2.253] [G acc: 0.188]\n",
      "22285 [D loss: (0.778)(R 0.843, F 0.713)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.768] [G acc: 0.312]\n",
      "22286 [D loss: (0.686)(R 0.700, F 0.672)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.862] [G acc: 0.188]\n",
      "22287 [D loss: (0.697)(R 0.686, F 0.708)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.810] [G acc: 0.250]\n",
      "22288 [D loss: (0.594)(R 0.585, F 0.603)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.743] [G acc: 0.438]\n",
      "22289 [D loss: (0.715)(R 0.625, F 0.805)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.616] [G acc: 0.688]\n",
      "22290 [D loss: (0.660)(R 0.648, F 0.671)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.658] [G acc: 0.438]\n",
      "22291 [D loss: (0.750)(R 0.621, F 0.878)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.699] [G acc: 0.375]\n",
      "22292 [D loss: (0.678)(R 0.663, F 0.693)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.233] [G acc: 0.125]\n",
      "22293 [D loss: (0.390)(R 0.453, F 0.328)] [D acc: (0.906)(0.938, 0.875)] [G loss: 1.260] [G acc: 0.062]\n",
      "22294 [D loss: (0.561)(R 0.594, F 0.527)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.896] [G acc: 0.500]\n",
      "22295 [D loss: (0.760)(R 0.748, F 0.773)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.608] [G acc: 0.625]\n",
      "22296 [D loss: (0.668)(R 0.671, F 0.665)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.615] [G acc: 0.125]\n",
      "22297 [D loss: (0.488)(R 0.568, F 0.409)] [D acc: (0.781)(0.688, 0.875)] [G loss: 2.718] [G acc: 0.062]\n",
      "22298 [D loss: (0.568)(R 0.515, F 0.622)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.901] [G acc: 0.250]\n",
      "22299 [D loss: (0.647)(R 0.616, F 0.679)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.653] [G acc: 0.500]\n",
      "22300 [D loss: (0.609)(R 0.498, F 0.720)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.870] [G acc: 0.062]\n",
      "22301 [D loss: (0.504)(R 0.408, F 0.601)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.082] [G acc: 0.125]\n",
      "22302 [D loss: (0.553)(R 0.575, F 0.532)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.916] [G acc: 0.188]\n",
      "22303 [D loss: (0.788)(R 1.069, F 0.506)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.020] [G acc: 0.188]\n",
      "22304 [D loss: (0.583)(R 0.523, F 0.643)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.800] [G acc: 0.312]\n",
      "22305 [D loss: (0.410)(R 0.494, F 0.326)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.262] [G acc: 0.062]\n",
      "22306 [D loss: (0.536)(R 0.542, F 0.530)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.097] [G acc: 0.375]\n",
      "22307 [D loss: (0.618)(R 0.632, F 0.604)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.661] [G acc: 0.438]\n",
      "22308 [D loss: (0.398)(R 0.503, F 0.293)] [D acc: (0.875)(0.812, 0.938)] [G loss: 2.463] [G acc: 0.062]\n",
      "22309 [D loss: (0.518)(R 0.753, F 0.283)] [D acc: (0.812)(0.688, 0.938)] [G loss: 2.863] [G acc: 0.125]\n",
      "22310 [D loss: (0.640)(R 0.624, F 0.656)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.931] [G acc: 0.125]\n",
      "22311 [D loss: (0.597)(R 0.577, F 0.617)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.868] [G acc: 0.250]\n",
      "22312 [D loss: (0.646)(R 0.437, F 0.855)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.731] [G acc: 0.375]\n",
      "22313 [D loss: (0.540)(R 0.534, F 0.545)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.733] [G acc: 0.438]\n",
      "22314 [D loss: (0.559)(R 0.460, F 0.657)] [D acc: (0.688)(0.688, 0.688)] [G loss: 2.446] [G acc: 0.375]\n",
      "22315 [D loss: (0.562)(R 0.538, F 0.586)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.858] [G acc: 0.062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22316 [D loss: (0.446)(R 0.451, F 0.441)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.780] [G acc: 0.312]\n",
      "22317 [D loss: (0.477)(R 0.462, F 0.491)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.968] [G acc: 0.250]\n",
      "22318 [D loss: (0.696)(R 0.809, F 0.583)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.863] [G acc: 0.188]\n",
      "22319 [D loss: (0.446)(R 0.299, F 0.593)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.900] [G acc: 0.188]\n",
      "22320 [D loss: (0.524)(R 0.508, F 0.540)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.751] [G acc: 0.312]\n",
      "22321 [D loss: (0.580)(R 0.526, F 0.635)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.841] [G acc: 0.250]\n",
      "22322 [D loss: (0.501)(R 0.470, F 0.532)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.720] [G acc: 0.562]\n",
      "22323 [D loss: (0.515)(R 0.548, F 0.483)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.281] [G acc: 0.062]\n",
      "22324 [D loss: (0.665)(R 0.395, F 0.934)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.805] [G acc: 0.375]\n",
      "22325 [D loss: (0.493)(R 0.476, F 0.510)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.310] [G acc: 0.000]\n",
      "22326 [D loss: (0.591)(R 0.627, F 0.554)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.049] [G acc: 0.062]\n",
      "22327 [D loss: (0.532)(R 0.511, F 0.553)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.477] [G acc: 0.062]\n",
      "22328 [D loss: (0.530)(R 0.608, F 0.453)] [D acc: (0.719)(0.500, 0.938)] [G loss: 1.213] [G acc: 0.062]\n",
      "22329 [D loss: (0.505)(R 0.555, F 0.455)] [D acc: (0.781)(0.562, 1.000)] [G loss: 1.755] [G acc: 0.125]\n",
      "22330 [D loss: (0.486)(R 0.680, F 0.292)] [D acc: (0.719)(0.500, 0.938)] [G loss: 6.632] [G acc: 0.062]\n",
      "22331 [D loss: (0.443)(R 0.563, F 0.322)] [D acc: (0.844)(0.688, 1.000)] [G loss: 3.937] [G acc: 0.062]\n",
      "22332 [D loss: (0.443)(R 0.645, F 0.240)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.931] [G acc: 0.312]\n",
      "22333 [D loss: (0.470)(R 0.497, F 0.443)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.091] [G acc: 0.000]\n",
      "22334 [D loss: (0.514)(R 0.420, F 0.608)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.203] [G acc: 0.062]\n",
      "22335 [D loss: (0.455)(R 0.422, F 0.488)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.115] [G acc: 0.250]\n",
      "22336 [D loss: (0.880)(R 1.217, F 0.542)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.631] [G acc: 0.125]\n",
      "22337 [D loss: (0.665)(R 0.808, F 0.521)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.858] [G acc: 0.250]\n",
      "22338 [D loss: (0.411)(R 0.466, F 0.356)] [D acc: (0.875)(0.812, 0.938)] [G loss: 0.890] [G acc: 0.188]\n",
      "22339 [D loss: (0.418)(R 0.375, F 0.461)] [D acc: (0.844)(0.750, 0.938)] [G loss: 0.824] [G acc: 0.125]\n",
      "22340 [D loss: (0.476)(R 0.536, F 0.417)] [D acc: (0.875)(0.750, 1.000)] [G loss: 0.767] [G acc: 0.250]\n",
      "22341 [D loss: (0.511)(R 0.422, F 0.600)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.024] [G acc: 0.125]\n",
      "22342 [D loss: (0.665)(R 0.656, F 0.673)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.981] [G acc: 0.125]\n",
      "22343 [D loss: (0.493)(R 0.406, F 0.581)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.805] [G acc: 0.312]\n",
      "22344 [D loss: (0.538)(R 0.460, F 0.616)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.000] [G acc: 0.188]\n",
      "22345 [D loss: (0.523)(R 0.455, F 0.590)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.005] [G acc: 0.188]\n",
      "22346 [D loss: (0.585)(R 0.407, F 0.762)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.930] [G acc: 0.438]\n",
      "22347 [D loss: (0.439)(R 0.603, F 0.275)] [D acc: (0.750)(0.562, 0.938)] [G loss: 3.135] [G acc: 0.188]\n",
      "22348 [D loss: (0.519)(R 0.425, F 0.613)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.497] [G acc: 0.688]\n",
      "22349 [D loss: (0.603)(R 0.655, F 0.551)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.183] [G acc: 0.250]\n",
      "22350 [D loss: (0.480)(R 0.467, F 0.494)] [D acc: (0.781)(0.625, 0.938)] [G loss: 2.018] [G acc: 0.312]\n",
      "22351 [D loss: (0.418)(R 0.475, F 0.361)] [D acc: (0.812)(0.750, 0.875)] [G loss: 5.268] [G acc: 0.125]\n",
      "22352 [D loss: (0.588)(R 0.581, F 0.596)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.006] [G acc: 0.062]\n",
      "22353 [D loss: (0.705)(R 0.600, F 0.810)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.950] [G acc: 0.250]\n",
      "22354 [D loss: (0.520)(R 0.499, F 0.540)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.066] [G acc: 0.125]\n",
      "22355 [D loss: (0.525)(R 0.519, F 0.531)] [D acc: (0.844)(0.750, 0.938)] [G loss: 0.982] [G acc: 0.125]\n",
      "22356 [D loss: (0.496)(R 0.418, F 0.573)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.836] [G acc: 0.375]\n",
      "22357 [D loss: (0.931)(R 0.444, F 1.417)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.831] [G acc: 0.312]\n",
      "22358 [D loss: (0.604)(R 0.517, F 0.690)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.699] [G acc: 0.438]\n",
      "22359 [D loss: (0.589)(R 0.445, F 0.733)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.582] [G acc: 0.625]\n",
      "22360 [D loss: (0.642)(R 0.400, F 0.884)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.604] [G acc: 0.625]\n",
      "22361 [D loss: (0.806)(R 0.630, F 0.982)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.750] [G acc: 0.500]\n",
      "22362 [D loss: (1.041)(R 0.579, F 1.503)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.637] [G acc: 0.500]\n",
      "22363 [D loss: (0.516)(R 0.599, F 0.432)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.207] [G acc: 0.188]\n",
      "22364 [D loss: (0.771)(R 0.461, F 1.080)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.715] [G acc: 0.562]\n",
      "22365 [D loss: (0.979)(R 0.454, F 1.503)] [D acc: (0.438)(0.688, 0.188)] [G loss: 0.306] [G acc: 0.750]\n",
      "22366 [D loss: (0.891)(R 0.566, F 1.217)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.452] [G acc: 0.812]\n",
      "22367 [D loss: (1.136)(R 0.478, F 1.794)] [D acc: (0.438)(0.688, 0.188)] [G loss: 1.055] [G acc: 0.188]\n",
      "22368 [D loss: (0.420)(R 0.603, F 0.237)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.869] [G acc: 0.188]\n",
      "22369 [D loss: (1.081)(R 0.685, F 1.477)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.982] [G acc: 0.562]\n",
      "22370 [D loss: (0.751)(R 0.512, F 0.989)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.153] [G acc: 0.312]\n",
      "22371 [D loss: (0.637)(R 0.541, F 0.733)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.785] [G acc: 0.688]\n",
      "22372 [D loss: (1.943)(R 0.848, F 3.037)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.948] [G acc: 0.562]\n",
      "22373 [D loss: (0.765)(R 0.640, F 0.890)] [D acc: (0.531)(0.500, 0.562)] [G loss: 1.474] [G acc: 0.438]\n",
      "22374 [D loss: (0.816)(R 0.655, F 0.977)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.841] [G acc: 0.562]\n",
      "22375 [D loss: (1.243)(R 0.617, F 1.869)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.790] [G acc: 0.438]\n",
      "22376 [D loss: (1.883)(R 0.553, F 3.213)] [D acc: (0.531)(0.562, 0.500)] [G loss: 1.610] [G acc: 0.438]\n",
      "22377 [D loss: (0.684)(R 0.780, F 0.589)] [D acc: (0.531)(0.375, 0.688)] [G loss: 3.827] [G acc: 0.250]\n",
      "22378 [D loss: (1.473)(R 0.677, F 2.268)] [D acc: (0.531)(0.500, 0.562)] [G loss: 3.483] [G acc: 0.250]\n",
      "22379 [D loss: (0.796)(R 0.498, F 1.094)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.771] [G acc: 0.375]\n",
      "22380 [D loss: (0.697)(R 0.630, F 0.764)] [D acc: (0.531)(0.562, 0.500)] [G loss: 1.026] [G acc: 0.375]\n",
      "22381 [D loss: (0.889)(R 0.674, F 1.103)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.662] [G acc: 0.500]\n",
      "22382 [D loss: (0.784)(R 0.568, F 0.999)] [D acc: (0.406)(0.625, 0.188)] [G loss: 0.783] [G acc: 0.500]\n",
      "22383 [D loss: (0.668)(R 0.599, F 0.737)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.723] [G acc: 0.625]\n",
      "22384 [D loss: (0.943)(R 0.783, F 1.104)] [D acc: (0.500)(0.625, 0.375)] [G loss: 1.392] [G acc: 0.500]\n",
      "22385 [D loss: (0.602)(R 0.612, F 0.592)] [D acc: (0.562)(0.625, 0.500)] [G loss: 1.300] [G acc: 0.438]\n",
      "22386 [D loss: (0.584)(R 0.548, F 0.620)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.093] [G acc: 0.500]\n",
      "22387 [D loss: (0.826)(R 0.598, F 1.055)] [D acc: (0.562)(0.562, 0.562)] [G loss: 1.537] [G acc: 0.438]\n",
      "22388 [D loss: (0.690)(R 0.603, F 0.777)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.681] [G acc: 0.188]\n",
      "22389 [D loss: (0.798)(R 0.563, F 1.034)] [D acc: (0.656)(0.688, 0.625)] [G loss: 2.170] [G acc: 0.438]\n",
      "22390 [D loss: (0.822)(R 0.582, F 1.063)] [D acc: (0.500)(0.500, 0.500)] [G loss: 1.016] [G acc: 0.312]\n",
      "22391 [D loss: (0.748)(R 0.507, F 0.990)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.867] [G acc: 0.625]\n",
      "22392 [D loss: (0.800)(R 0.543, F 1.056)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.825] [G acc: 0.438]\n",
      "22393 [D loss: (0.694)(R 0.622, F 0.765)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.752] [G acc: 0.562]\n",
      "22394 [D loss: (0.670)(R 0.584, F 0.756)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.914] [G acc: 0.438]\n",
      "22395 [D loss: (0.556)(R 0.495, F 0.617)] [D acc: (0.844)(0.938, 0.750)] [G loss: 2.309] [G acc: 0.250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22396 [D loss: (0.551)(R 0.796, F 0.307)] [D acc: (0.625)(0.438, 0.812)] [G loss: 4.686] [G acc: 0.250]\n",
      "22397 [D loss: (0.951)(R 0.638, F 1.263)] [D acc: (0.562)(0.688, 0.438)] [G loss: 1.969] [G acc: 0.438]\n",
      "22398 [D loss: (0.544)(R 0.456, F 0.632)] [D acc: (0.750)(0.938, 0.562)] [G loss: 1.418] [G acc: 0.562]\n",
      "22399 [D loss: (0.542)(R 0.450, F 0.635)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.891] [G acc: 0.375]\n",
      "22400 [D loss: (0.820)(R 1.046, F 0.593)] [D acc: (0.625)(0.750, 0.500)] [G loss: 2.313] [G acc: 0.688]\n",
      "22401 [D loss: (0.615)(R 0.462, F 0.768)] [D acc: (0.594)(0.875, 0.312)] [G loss: 1.024] [G acc: 0.562]\n",
      "22402 [D loss: (0.607)(R 0.593, F 0.621)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.635] [G acc: 0.750]\n",
      "22403 [D loss: (0.622)(R 0.528, F 0.715)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.699] [G acc: 0.688]\n",
      "22404 [D loss: (0.507)(R 0.494, F 0.519)] [D acc: (0.781)(0.938, 0.625)] [G loss: 0.559] [G acc: 0.812]\n",
      "22405 [D loss: (0.510)(R 0.476, F 0.544)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.739] [G acc: 0.375]\n",
      "22406 [D loss: (0.655)(R 0.495, F 0.815)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.712] [G acc: 0.500]\n",
      "22407 [D loss: (0.591)(R 0.642, F 0.541)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.695] [G acc: 0.438]\n",
      "22408 [D loss: (0.546)(R 0.446, F 0.646)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.908] [G acc: 0.438]\n",
      "22409 [D loss: (0.593)(R 0.463, F 0.722)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.821] [G acc: 0.438]\n",
      "22410 [D loss: (0.667)(R 0.456, F 0.878)] [D acc: (0.562)(0.875, 0.250)] [G loss: 0.771] [G acc: 0.312]\n",
      "22411 [D loss: (0.611)(R 0.511, F 0.712)] [D acc: (0.750)(0.938, 0.562)] [G loss: 0.894] [G acc: 0.375]\n",
      "22412 [D loss: (0.712)(R 0.886, F 0.537)] [D acc: (0.594)(0.625, 0.562)] [G loss: 2.304] [G acc: 0.125]\n",
      "22413 [D loss: (0.590)(R 0.619, F 0.561)] [D acc: (0.594)(0.625, 0.562)] [G loss: 2.220] [G acc: 0.250]\n",
      "22414 [D loss: (0.505)(R 0.683, F 0.327)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.231] [G acc: 0.312]\n",
      "22415 [D loss: (0.494)(R 0.623, F 0.365)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.445] [G acc: 0.125]\n",
      "22416 [D loss: (0.962)(R 0.983, F 0.940)] [D acc: (0.375)(0.625, 0.125)] [G loss: 0.832] [G acc: 0.562]\n",
      "22417 [D loss: (0.669)(R 0.495, F 0.844)] [D acc: (0.531)(0.750, 0.312)] [G loss: 1.439] [G acc: 0.250]\n",
      "22418 [D loss: (0.415)(R 0.472, F 0.358)] [D acc: (0.844)(0.938, 0.750)] [G loss: 2.146] [G acc: 0.438]\n",
      "22419 [D loss: (0.446)(R 0.351, F 0.541)] [D acc: (0.906)(1.000, 0.812)] [G loss: 2.206] [G acc: 0.125]\n",
      "22420 [D loss: (0.666)(R 0.720, F 0.612)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.736] [G acc: 0.500]\n",
      "22421 [D loss: (0.481)(R 0.416, F 0.545)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.682] [G acc: 0.500]\n",
      "22422 [D loss: (0.533)(R 0.482, F 0.583)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.707] [G acc: 0.438]\n",
      "22423 [D loss: (0.770)(R 0.859, F 0.681)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.683] [G acc: 0.625]\n",
      "22424 [D loss: (1.077)(R 1.497, F 0.658)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.760] [G acc: 0.250]\n",
      "22425 [D loss: (0.602)(R 0.524, F 0.681)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.823] [G acc: 0.375]\n",
      "22426 [D loss: (0.721)(R 0.755, F 0.688)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.869] [G acc: 0.188]\n",
      "22427 [D loss: (0.605)(R 0.564, F 0.646)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.861] [G acc: 0.375]\n",
      "22428 [D loss: (0.532)(R 0.447, F 0.618)] [D acc: (0.906)(0.938, 0.875)] [G loss: 1.022] [G acc: 0.000]\n",
      "22429 [D loss: (0.556)(R 0.543, F 0.569)] [D acc: (0.875)(0.812, 0.938)] [G loss: 0.898] [G acc: 0.188]\n",
      "22430 [D loss: (0.613)(R 0.621, F 0.605)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.771] [G acc: 0.375]\n",
      "22431 [D loss: (0.539)(R 0.491, F 0.588)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.857] [G acc: 0.125]\n",
      "22432 [D loss: (0.584)(R 0.499, F 0.669)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.069] [G acc: 0.000]\n",
      "22433 [D loss: (0.485)(R 0.459, F 0.510)] [D acc: (0.938)(0.875, 1.000)] [G loss: 0.925] [G acc: 0.000]\n",
      "22434 [D loss: (0.579)(R 0.586, F 0.573)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.928] [G acc: 0.250]\n",
      "22435 [D loss: (0.439)(R 0.402, F 0.477)] [D acc: (0.938)(0.875, 1.000)] [G loss: 1.223] [G acc: 0.062]\n",
      "22436 [D loss: (0.712)(R 0.823, F 0.601)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.051] [G acc: 0.125]\n",
      "22437 [D loss: (0.495)(R 0.490, F 0.500)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.935] [G acc: 0.125]\n",
      "22438 [D loss: (0.475)(R 0.458, F 0.493)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.075] [G acc: 0.125]\n",
      "22439 [D loss: (0.509)(R 0.476, F 0.541)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.049] [G acc: 0.062]\n",
      "22440 [D loss: (0.492)(R 0.427, F 0.556)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.092] [G acc: 0.062]\n",
      "22441 [D loss: (0.474)(R 0.457, F 0.491)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.094] [G acc: 0.062]\n",
      "22442 [D loss: (0.482)(R 0.602, F 0.363)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.149] [G acc: 0.125]\n",
      "22443 [D loss: (0.448)(R 0.556, F 0.339)] [D acc: (0.844)(0.688, 1.000)] [G loss: 1.022] [G acc: 0.125]\n",
      "22444 [D loss: (0.405)(R 0.445, F 0.364)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.010] [G acc: 0.125]\n",
      "22445 [D loss: (0.404)(R 0.433, F 0.375)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.315] [G acc: 0.062]\n",
      "22446 [D loss: (0.511)(R 0.505, F 0.518)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.149] [G acc: 0.125]\n",
      "22447 [D loss: (0.484)(R 0.533, F 0.435)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.371] [G acc: 0.312]\n",
      "22448 [D loss: (0.361)(R 0.504, F 0.218)] [D acc: (0.812)(0.750, 0.875)] [G loss: 7.887] [G acc: 0.188]\n",
      "22449 [D loss: (0.364)(R 0.569, F 0.160)] [D acc: (0.938)(0.875, 1.000)] [G loss: 8.299] [G acc: 0.125]\n",
      "22450 [D loss: (0.563)(R 0.450, F 0.676)] [D acc: (0.781)(0.938, 0.625)] [G loss: 2.639] [G acc: 0.188]\n",
      "22451 [D loss: (0.308)(R 0.426, F 0.190)] [D acc: (0.906)(0.875, 0.938)] [G loss: 3.367] [G acc: 0.125]\n",
      "22452 [D loss: (0.328)(R 0.302, F 0.354)] [D acc: (0.938)(0.938, 0.938)] [G loss: 1.348] [G acc: 0.250]\n",
      "22453 [D loss: (0.830)(R 0.863, F 0.797)] [D acc: (0.594)(0.688, 0.500)] [G loss: 1.749] [G acc: 0.438]\n",
      "22454 [D loss: (0.451)(R 0.475, F 0.428)] [D acc: (0.781)(0.750, 0.812)] [G loss: 2.657] [G acc: 0.312]\n",
      "22455 [D loss: (0.618)(R 0.461, F 0.774)] [D acc: (0.688)(0.875, 0.500)] [G loss: 4.198] [G acc: 0.500]\n",
      "22456 [D loss: (0.805)(R 1.156, F 0.453)] [D acc: (0.594)(0.500, 0.688)] [G loss: 1.052] [G acc: 0.500]\n",
      "22457 [D loss: (1.012)(R 0.597, F 1.428)] [D acc: (0.438)(0.688, 0.188)] [G loss: 2.171] [G acc: 0.375]\n",
      "22458 [D loss: (0.624)(R 0.463, F 0.785)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.103] [G acc: 0.625]\n",
      "22459 [D loss: (0.698)(R 0.603, F 0.792)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.765] [G acc: 0.500]\n",
      "22460 [D loss: (0.697)(R 0.590, F 0.804)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.981] [G acc: 0.500]\n",
      "22461 [D loss: (0.552)(R 0.585, F 0.518)] [D acc: (0.656)(0.625, 0.688)] [G loss: 2.485] [G acc: 0.062]\n",
      "22462 [D loss: (0.842)(R 0.528, F 1.157)] [D acc: (0.656)(0.688, 0.625)] [G loss: 4.379] [G acc: 0.312]\n",
      "22463 [D loss: (0.463)(R 0.496, F 0.431)] [D acc: (0.781)(0.812, 0.750)] [G loss: 2.330] [G acc: 0.250]\n",
      "22464 [D loss: (0.607)(R 0.558, F 0.656)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.002] [G acc: 0.500]\n",
      "22465 [D loss: (0.467)(R 0.532, F 0.401)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.312] [G acc: 0.188]\n",
      "22466 [D loss: (0.550)(R 0.653, F 0.447)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.941] [G acc: 0.562]\n",
      "22467 [D loss: (0.583)(R 0.614, F 0.552)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.331] [G acc: 0.375]\n",
      "22468 [D loss: (0.718)(R 0.534, F 0.902)] [D acc: (0.625)(0.750, 0.500)] [G loss: 2.352] [G acc: 0.312]\n",
      "22469 [D loss: (0.393)(R 0.650, F 0.136)] [D acc: (0.781)(0.625, 0.938)] [G loss: 3.922] [G acc: 0.000]\n",
      "22470 [D loss: (0.632)(R 0.602, F 0.663)] [D acc: (0.594)(0.625, 0.562)] [G loss: 2.323] [G acc: 0.375]\n",
      "22471 [D loss: (0.487)(R 0.703, F 0.270)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.967] [G acc: 0.500]\n",
      "22472 [D loss: (0.609)(R 0.550, F 0.668)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.970] [G acc: 0.500]\n",
      "22473 [D loss: (0.581)(R 0.568, F 0.595)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.254] [G acc: 0.375]\n",
      "22474 [D loss: (0.800)(R 0.684, F 0.915)] [D acc: (0.562)(0.875, 0.250)] [G loss: 1.772] [G acc: 0.125]\n",
      "22475 [D loss: (0.517)(R 0.643, F 0.391)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.959] [G acc: 0.312]\n",
      "22476 [D loss: (0.688)(R 0.317, F 1.059)] [D acc: (0.594)(1.000, 0.188)] [G loss: 0.937] [G acc: 0.500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22477 [D loss: (0.704)(R 0.644, F 0.765)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.919] [G acc: 0.312]\n",
      "22478 [D loss: (0.486)(R 0.414, F 0.558)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.286] [G acc: 0.312]\n",
      "22479 [D loss: (0.519)(R 0.488, F 0.550)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.470] [G acc: 0.188]\n",
      "22480 [D loss: (0.598)(R 0.542, F 0.655)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.520] [G acc: 0.312]\n",
      "22481 [D loss: (0.402)(R 0.482, F 0.322)] [D acc: (0.719)(0.688, 0.750)] [G loss: 2.248] [G acc: 0.250]\n",
      "22482 [D loss: (0.533)(R 0.347, F 0.719)] [D acc: (0.781)(1.000, 0.562)] [G loss: 1.039] [G acc: 0.188]\n",
      "22483 [D loss: (0.475)(R 0.508, F 0.442)] [D acc: (0.750)(0.750, 0.750)] [G loss: 2.102] [G acc: 0.438]\n",
      "22484 [D loss: (0.382)(R 0.486, F 0.277)] [D acc: (0.906)(0.812, 1.000)] [G loss: 2.820] [G acc: 0.188]\n",
      "22485 [D loss: (0.754)(R 0.769, F 0.739)] [D acc: (0.625)(0.812, 0.438)] [G loss: 1.208] [G acc: 0.375]\n",
      "22486 [D loss: (0.509)(R 0.411, F 0.607)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.266] [G acc: 0.188]\n",
      "22487 [D loss: (0.583)(R 0.525, F 0.641)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.514] [G acc: 0.188]\n",
      "22488 [D loss: (1.119)(R 1.766, F 0.472)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.975] [G acc: 0.312]\n",
      "22489 [D loss: (0.531)(R 0.470, F 0.592)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.041] [G acc: 0.125]\n",
      "22490 [D loss: (0.549)(R 0.476, F 0.621)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.917] [G acc: 0.250]\n",
      "22491 [D loss: (0.467)(R 0.315, F 0.619)] [D acc: (0.875)(0.938, 0.812)] [G loss: 0.907] [G acc: 0.125]\n",
      "22492 [D loss: (0.503)(R 0.424, F 0.583)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.089] [G acc: 0.312]\n",
      "22493 [D loss: (0.612)(R 0.480, F 0.745)] [D acc: (0.594)(0.688, 0.500)] [G loss: 1.150] [G acc: 0.188]\n",
      "22494 [D loss: (0.511)(R 0.465, F 0.557)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.526] [G acc: 0.188]\n",
      "22495 [D loss: (0.547)(R 0.722, F 0.372)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.077] [G acc: 0.188]\n",
      "22496 [D loss: (0.539)(R 0.491, F 0.587)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.146] [G acc: 0.125]\n",
      "22497 [D loss: (0.607)(R 0.636, F 0.579)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.870] [G acc: 0.312]\n",
      "22498 [D loss: (0.489)(R 0.462, F 0.515)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.075] [G acc: 0.375]\n",
      "22499 [D loss: (0.463)(R 0.472, F 0.453)] [D acc: (0.812)(0.750, 0.875)] [G loss: 3.935] [G acc: 0.000]\n",
      "22500 [D loss: (0.346)(R 0.385, F 0.306)] [D acc: (0.844)(0.938, 0.750)] [G loss: 6.474] [G acc: 0.188]\n",
      "22501 [D loss: (0.494)(R 0.507, F 0.482)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.847] [G acc: 0.250]\n",
      "22502 [D loss: (0.485)(R 0.338, F 0.631)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.980] [G acc: 0.250]\n",
      "22503 [D loss: (0.480)(R 0.406, F 0.553)] [D acc: (0.875)(0.875, 0.875)] [G loss: 0.965] [G acc: 0.312]\n",
      "22504 [D loss: (0.560)(R 0.536, F 0.583)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.042] [G acc: 0.062]\n",
      "22505 [D loss: (0.511)(R 0.409, F 0.613)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.034] [G acc: 0.250]\n",
      "22506 [D loss: (0.509)(R 0.455, F 0.562)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.863] [G acc: 0.250]\n",
      "22507 [D loss: (0.567)(R 0.473, F 0.660)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.685] [G acc: 0.438]\n",
      "22508 [D loss: (0.580)(R 0.537, F 0.622)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.211] [G acc: 0.062]\n",
      "22509 [D loss: (0.658)(R 0.483, F 0.834)] [D acc: (0.594)(0.688, 0.500)] [G loss: 1.797] [G acc: 0.125]\n",
      "22510 [D loss: (0.354)(R 0.598, F 0.110)] [D acc: (0.812)(0.625, 1.000)] [G loss: 4.644] [G acc: 0.125]\n",
      "22511 [D loss: (0.404)(R 0.417, F 0.391)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.775] [G acc: 0.688]\n",
      "22512 [D loss: (0.626)(R 0.263, F 0.989)] [D acc: (0.750)(0.875, 0.625)] [G loss: 1.236] [G acc: 0.438]\n",
      "22513 [D loss: (0.401)(R 0.566, F 0.237)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.350] [G acc: 0.000]\n",
      "22514 [D loss: (1.684)(R 3.041, F 0.326)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.936] [G acc: 0.375]\n",
      "22515 [D loss: (0.633)(R 0.455, F 0.810)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.085] [G acc: 0.125]\n",
      "22516 [D loss: (0.563)(R 0.482, F 0.645)] [D acc: (0.625)(0.750, 0.500)] [G loss: 1.443] [G acc: 0.125]\n",
      "22517 [D loss: (0.409)(R 0.447, F 0.372)] [D acc: (0.812)(0.750, 0.875)] [G loss: 2.021] [G acc: 0.188]\n",
      "22518 [D loss: (0.474)(R 0.476, F 0.472)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.190] [G acc: 0.375]\n",
      "22519 [D loss: (0.505)(R 0.547, F 0.463)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.390] [G acc: 0.062]\n",
      "22520 [D loss: (0.487)(R 0.454, F 0.519)] [D acc: (0.781)(0.812, 0.750)] [G loss: 2.187] [G acc: 0.188]\n",
      "22521 [D loss: (0.339)(R 0.532, F 0.146)] [D acc: (0.875)(0.812, 0.938)] [G loss: 5.360] [G acc: 0.188]\n",
      "22522 [D loss: (0.621)(R 0.369, F 0.873)] [D acc: (0.688)(0.750, 0.625)] [G loss: 5.612] [G acc: 0.438]\n",
      "22523 [D loss: (0.526)(R 0.549, F 0.503)] [D acc: (0.688)(0.688, 0.688)] [G loss: 2.459] [G acc: 0.312]\n",
      "22524 [D loss: (0.417)(R 0.373, F 0.460)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.821] [G acc: 0.125]\n",
      "22525 [D loss: (0.466)(R 0.547, F 0.384)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.179] [G acc: 0.312]\n",
      "22526 [D loss: (0.708)(R 0.536, F 0.880)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.231] [G acc: 0.188]\n",
      "22527 [D loss: (0.654)(R 0.534, F 0.775)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.924] [G acc: 0.312]\n",
      "22528 [D loss: (0.495)(R 0.586, F 0.404)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.377] [G acc: 0.062]\n",
      "22529 [D loss: (0.515)(R 0.669, F 0.360)] [D acc: (0.688)(0.500, 0.875)] [G loss: 1.308] [G acc: 0.000]\n",
      "22530 [D loss: (0.526)(R 0.595, F 0.458)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.490] [G acc: 0.000]\n",
      "22531 [D loss: (0.448)(R 0.582, F 0.315)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.378] [G acc: 0.375]\n",
      "22532 [D loss: (0.594)(R 0.763, F 0.425)] [D acc: (0.750)(0.500, 1.000)] [G loss: 0.926] [G acc: 0.375]\n",
      "22533 [D loss: (0.451)(R 0.702, F 0.200)] [D acc: (0.875)(0.750, 1.000)] [G loss: 2.474] [G acc: 0.125]\n",
      "22534 [D loss: (0.620)(R 0.617, F 0.623)] [D acc: (0.719)(0.812, 0.625)] [G loss: 3.196] [G acc: 0.312]\n",
      "22535 [D loss: (0.389)(R 0.494, F 0.284)] [D acc: (0.844)(0.750, 0.938)] [G loss: 4.189] [G acc: 0.062]\n",
      "22536 [D loss: (0.551)(R 0.475, F 0.627)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.836] [G acc: 0.312]\n",
      "22537 [D loss: (0.431)(R 0.425, F 0.437)] [D acc: (0.906)(0.875, 0.938)] [G loss: 0.948] [G acc: 0.188]\n",
      "22538 [D loss: (0.469)(R 0.397, F 0.542)] [D acc: (0.875)(0.938, 0.812)] [G loss: 0.802] [G acc: 0.562]\n",
      "22539 [D loss: (0.653)(R 0.659, F 0.647)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.286] [G acc: 0.188]\n",
      "22540 [D loss: (0.487)(R 0.457, F 0.517)] [D acc: (0.938)(0.938, 0.938)] [G loss: 0.867] [G acc: 0.375]\n",
      "22541 [D loss: (0.505)(R 0.514, F 0.496)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.199] [G acc: 0.188]\n",
      "22542 [D loss: (0.569)(R 0.606, F 0.532)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.312] [G acc: 0.188]\n",
      "22543 [D loss: (1.081)(R 0.434, F 1.727)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.326] [G acc: 0.250]\n",
      "22544 [D loss: (0.492)(R 0.471, F 0.513)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.044] [G acc: 0.312]\n",
      "22545 [D loss: (0.471)(R 0.425, F 0.516)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.423] [G acc: 0.250]\n",
      "22546 [D loss: (0.702)(R 0.823, F 0.581)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.160] [G acc: 0.000]\n",
      "22547 [D loss: (0.561)(R 0.581, F 0.541)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.431] [G acc: 0.000]\n",
      "22548 [D loss: (0.310)(R 0.445, F 0.175)] [D acc: (0.906)(0.875, 0.938)] [G loss: 1.901] [G acc: 0.188]\n",
      "22549 [D loss: (0.487)(R 0.616, F 0.358)] [D acc: (0.781)(0.688, 0.875)] [G loss: 2.748] [G acc: 0.375]\n",
      "22550 [D loss: (0.311)(R 0.424, F 0.198)] [D acc: (0.844)(0.750, 0.938)] [G loss: 3.604] [G acc: 0.062]\n",
      "22551 [D loss: (0.314)(R 0.425, F 0.203)] [D acc: (0.875)(0.875, 0.875)] [G loss: 2.994] [G acc: 0.188]\n",
      "22552 [D loss: (0.402)(R 0.319, F 0.485)] [D acc: (0.938)(0.938, 0.938)] [G loss: 1.037] [G acc: 0.125]\n",
      "22553 [D loss: (0.520)(R 0.488, F 0.552)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.940] [G acc: 0.250]\n",
      "22554 [D loss: (0.514)(R 0.478, F 0.549)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.908] [G acc: 0.375]\n",
      "22555 [D loss: (0.371)(R 0.321, F 0.421)] [D acc: (0.906)(0.938, 0.875)] [G loss: 1.769] [G acc: 0.062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22556 [D loss: (0.546)(R 0.621, F 0.471)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.610] [G acc: 0.188]\n",
      "22557 [D loss: (0.345)(R 0.493, F 0.196)] [D acc: (0.844)(0.750, 0.938)] [G loss: 3.007] [G acc: 0.125]\n",
      "22558 [D loss: (0.498)(R 0.492, F 0.504)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.470] [G acc: 0.000]\n",
      "22559 [D loss: (0.511)(R 0.427, F 0.596)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.025] [G acc: 0.188]\n",
      "22560 [D loss: (0.404)(R 0.450, F 0.358)] [D acc: (0.906)(0.812, 1.000)] [G loss: 1.322] [G acc: 0.188]\n",
      "22561 [D loss: (0.437)(R 0.400, F 0.474)] [D acc: (0.906)(0.875, 0.938)] [G loss: 1.222] [G acc: 0.000]\n",
      "22562 [D loss: (0.433)(R 0.436, F 0.430)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.659] [G acc: 0.125]\n",
      "22563 [D loss: (0.497)(R 0.621, F 0.372)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.828] [G acc: 0.062]\n",
      "22564 [D loss: (0.452)(R 0.518, F 0.386)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.677] [G acc: 0.000]\n",
      "22565 [D loss: (0.624)(R 0.854, F 0.395)] [D acc: (0.719)(0.500, 0.938)] [G loss: 1.823] [G acc: 0.000]\n",
      "22566 [D loss: (0.332)(R 0.391, F 0.272)] [D acc: (0.906)(0.812, 1.000)] [G loss: 1.603] [G acc: 0.000]\n",
      "22567 [D loss: (0.367)(R 0.543, F 0.191)] [D acc: (0.781)(0.625, 0.938)] [G loss: 4.803] [G acc: 0.000]\n",
      "22568 [D loss: (0.469)(R 0.567, F 0.372)] [D acc: (0.781)(0.688, 0.875)] [G loss: 5.437] [G acc: 0.188]\n",
      "22569 [D loss: (0.314)(R 0.385, F 0.242)] [D acc: (0.875)(0.750, 1.000)] [G loss: 1.754] [G acc: 0.062]\n",
      "22570 [D loss: (0.502)(R 0.606, F 0.398)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.172] [G acc: 0.125]\n",
      "22571 [D loss: (0.444)(R 0.588, F 0.301)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.326] [G acc: 0.062]\n",
      "22572 [D loss: (2.090)(R 3.653, F 0.526)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.741] [G acc: 0.000]\n",
      "22573 [D loss: (0.399)(R 0.450, F 0.349)] [D acc: (0.906)(0.875, 0.938)] [G loss: 1.207] [G acc: 0.062]\n",
      "22574 [D loss: (0.361)(R 0.322, F 0.400)] [D acc: (0.906)(0.875, 0.938)] [G loss: 1.647] [G acc: 0.000]\n",
      "22575 [D loss: (0.443)(R 0.563, F 0.324)] [D acc: (0.875)(0.750, 1.000)] [G loss: 1.060] [G acc: 0.250]\n",
      "22576 [D loss: (0.437)(R 0.506, F 0.368)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.245] [G acc: 0.125]\n",
      "22577 [D loss: (0.578)(R 0.442, F 0.714)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.128] [G acc: 0.312]\n",
      "22578 [D loss: (0.509)(R 0.502, F 0.516)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.238] [G acc: 0.062]\n",
      "22579 [D loss: (0.646)(R 0.541, F 0.752)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.435] [G acc: 0.125]\n",
      "22580 [D loss: (0.509)(R 0.321, F 0.697)] [D acc: (0.750)(0.812, 0.688)] [G loss: 3.163] [G acc: 0.062]\n",
      "22581 [D loss: (0.551)(R 0.975, F 0.127)] [D acc: (0.812)(0.625, 1.000)] [G loss: 7.909] [G acc: 0.062]\n",
      "22582 [D loss: (0.364)(R 0.438, F 0.290)] [D acc: (0.875)(0.750, 1.000)] [G loss: 3.275] [G acc: 0.125]\n",
      "22583 [D loss: (0.418)(R 0.304, F 0.532)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.001] [G acc: 0.375]\n",
      "22584 [D loss: (0.600)(R 0.593, F 0.607)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.486] [G acc: 0.000]\n",
      "22585 [D loss: (0.799)(R 1.303, F 0.295)] [D acc: (0.844)(0.688, 1.000)] [G loss: 1.352] [G acc: 0.125]\n",
      "22586 [D loss: (0.565)(R 0.551, F 0.579)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.459] [G acc: 0.000]\n",
      "22587 [D loss: (0.423)(R 0.403, F 0.443)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.001] [G acc: 0.375]\n",
      "22588 [D loss: (0.564)(R 0.678, F 0.451)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.082] [G acc: 0.250]\n",
      "22589 [D loss: (0.480)(R 0.537, F 0.423)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.281] [G acc: 0.062]\n",
      "22590 [D loss: (0.486)(R 0.454, F 0.517)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.979] [G acc: 0.438]\n",
      "22591 [D loss: (0.703)(R 0.835, F 0.572)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.077] [G acc: 0.188]\n",
      "22592 [D loss: (0.497)(R 0.535, F 0.460)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.270] [G acc: 0.000]\n",
      "22593 [D loss: (0.486)(R 0.542, F 0.430)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.009] [G acc: 0.312]\n",
      "22594 [D loss: (0.815)(R 0.643, F 0.987)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.899] [G acc: 0.375]\n",
      "22595 [D loss: (0.591)(R 0.599, F 0.584)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.717] [G acc: 0.500]\n",
      "22596 [D loss: (0.308)(R 0.323, F 0.294)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.873] [G acc: 0.125]\n",
      "22597 [D loss: (0.708)(R 0.629, F 0.787)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.938] [G acc: 0.000]\n",
      "22598 [D loss: (0.305)(R 0.394, F 0.216)] [D acc: (0.938)(0.875, 1.000)] [G loss: 1.439] [G acc: 0.250]\n",
      "22599 [D loss: (0.323)(R 0.279, F 0.366)] [D acc: (0.906)(0.875, 0.938)] [G loss: 1.513] [G acc: 0.125]\n",
      "22600 [D loss: (0.420)(R 0.381, F 0.458)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.395] [G acc: 0.250]\n",
      "22601 [D loss: (0.236)(R 0.330, F 0.141)] [D acc: (0.875)(0.812, 0.938)] [G loss: 4.248] [G acc: 0.125]\n",
      "22602 [D loss: (0.941)(R 1.427, F 0.454)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.070] [G acc: 0.125]\n",
      "22603 [D loss: (0.498)(R 0.314, F 0.682)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.116] [G acc: 0.125]\n",
      "22604 [D loss: (0.437)(R 0.510, F 0.364)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.928] [G acc: 0.125]\n",
      "22605 [D loss: (0.517)(R 0.406, F 0.628)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.921] [G acc: 0.188]\n",
      "22606 [D loss: (0.391)(R 0.362, F 0.420)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.297] [G acc: 0.312]\n",
      "22607 [D loss: (0.588)(R 0.408, F 0.769)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.530] [G acc: 0.062]\n",
      "22608 [D loss: (0.353)(R 0.273, F 0.432)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.236] [G acc: 0.125]\n",
      "22609 [D loss: (0.487)(R 0.559, F 0.416)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.041] [G acc: 0.188]\n",
      "22610 [D loss: (0.412)(R 0.412, F 0.411)] [D acc: (0.875)(0.812, 0.938)] [G loss: 0.934] [G acc: 0.375]\n",
      "22611 [D loss: (0.445)(R 0.369, F 0.521)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.923] [G acc: 0.250]\n",
      "22612 [D loss: (0.546)(R 0.650, F 0.442)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.287] [G acc: 0.125]\n",
      "22613 [D loss: (0.490)(R 0.580, F 0.399)] [D acc: (0.875)(0.750, 1.000)] [G loss: 1.230] [G acc: 0.250]\n",
      "22614 [D loss: (0.390)(R 0.227, F 0.553)] [D acc: (0.906)(1.000, 0.812)] [G loss: 0.976] [G acc: 0.250]\n",
      "22615 [D loss: (0.603)(R 0.315, F 0.890)] [D acc: (0.906)(0.938, 0.875)] [G loss: 1.136] [G acc: 0.188]\n",
      "22616 [D loss: (0.369)(R 0.535, F 0.203)] [D acc: (0.812)(0.688, 0.938)] [G loss: 2.882] [G acc: 0.000]\n",
      "22617 [D loss: (0.511)(R 0.570, F 0.453)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.980] [G acc: 0.188]\n",
      "22618 [D loss: (0.359)(R 0.506, F 0.212)] [D acc: (0.781)(0.688, 0.875)] [G loss: 6.446] [G acc: 0.125]\n",
      "22619 [D loss: (0.408)(R 0.503, F 0.313)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.112] [G acc: 0.250]\n",
      "22620 [D loss: (0.426)(R 0.400, F 0.451)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.321] [G acc: 0.250]\n",
      "22621 [D loss: (0.552)(R 0.529, F 0.575)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.025] [G acc: 0.562]\n",
      "22622 [D loss: (0.798)(R 0.773, F 0.822)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.149] [G acc: 0.125]\n",
      "22623 [D loss: (0.413)(R 0.373, F 0.453)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.325] [G acc: 0.000]\n",
      "22624 [D loss: (0.429)(R 0.588, F 0.271)] [D acc: (0.844)(0.750, 0.938)] [G loss: 2.121] [G acc: 0.000]\n",
      "22625 [D loss: (0.565)(R 0.592, F 0.537)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.406] [G acc: 0.375]\n",
      "22626 [D loss: (0.340)(R 0.445, F 0.236)] [D acc: (0.875)(0.812, 0.938)] [G loss: 2.668] [G acc: 0.062]\n",
      "22627 [D loss: (0.380)(R 0.350, F 0.410)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.149] [G acc: 0.062]\n",
      "22628 [D loss: (0.735)(R 0.834, F 0.635)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.159] [G acc: 0.312]\n",
      "22629 [D loss: (0.908)(R 0.363, F 1.454)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.105] [G acc: 0.062]\n",
      "22630 [D loss: (0.513)(R 0.647, F 0.379)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.632] [G acc: 0.125]\n",
      "22631 [D loss: (0.461)(R 0.469, F 0.454)] [D acc: (0.750)(0.688, 0.812)] [G loss: 2.560] [G acc: 0.000]\n",
      "22632 [D loss: (0.451)(R 0.646, F 0.256)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.277] [G acc: 0.188]\n",
      "22633 [D loss: (0.330)(R 0.368, F 0.293)] [D acc: (0.844)(0.875, 0.812)] [G loss: 0.760] [G acc: 0.438]\n",
      "22634 [D loss: (0.356)(R 0.375, F 0.337)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.248] [G acc: 0.062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22635 [D loss: (0.639)(R 0.745, F 0.533)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.906] [G acc: 0.375]\n",
      "22636 [D loss: (0.588)(R 0.285, F 0.892)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.999] [G acc: 0.125]\n",
      "22637 [D loss: (0.814)(R 0.662, F 0.966)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.500] [G acc: 0.688]\n",
      "22638 [D loss: (0.532)(R 0.157, F 0.906)] [D acc: (0.781)(1.000, 0.562)] [G loss: 0.675] [G acc: 0.500]\n",
      "22639 [D loss: (0.816)(R 0.421, F 1.212)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.529] [G acc: 0.750]\n",
      "22640 [D loss: (0.945)(R 0.661, F 1.230)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.654] [G acc: 0.688]\n",
      "22641 [D loss: (0.722)(R 0.343, F 1.101)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.739] [G acc: 0.375]\n",
      "22642 [D loss: (0.678)(R 0.391, F 0.965)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.797] [G acc: 0.438]\n",
      "22643 [D loss: (0.814)(R 0.330, F 1.298)] [D acc: (0.594)(0.938, 0.250)] [G loss: 0.692] [G acc: 0.562]\n",
      "22644 [D loss: (0.725)(R 0.721, F 0.730)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.722] [G acc: 0.688]\n",
      "22645 [D loss: (0.501)(R 0.345, F 0.657)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.052] [G acc: 0.312]\n",
      "22646 [D loss: (1.158)(R 0.807, F 1.509)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.839] [G acc: 0.438]\n",
      "22647 [D loss: (0.457)(R 0.490, F 0.424)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.798] [G acc: 0.562]\n",
      "22648 [D loss: (0.846)(R 0.450, F 1.241)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.799] [G acc: 0.312]\n",
      "22649 [D loss: (0.750)(R 0.419, F 1.080)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.513] [G acc: 0.688]\n",
      "22650 [D loss: (1.114)(R 0.665, F 1.564)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.588] [G acc: 0.500]\n",
      "22651 [D loss: (0.754)(R 0.662, F 0.847)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.806] [G acc: 0.375]\n",
      "22652 [D loss: (0.794)(R 0.636, F 0.953)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.308] [G acc: 0.312]\n",
      "22653 [D loss: (0.473)(R 0.653, F 0.294)] [D acc: (0.656)(0.500, 0.812)] [G loss: 3.185] [G acc: 0.062]\n",
      "22654 [D loss: (0.609)(R 0.483, F 0.734)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.747] [G acc: 0.188]\n",
      "22655 [D loss: (0.692)(R 0.282, F 1.101)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.959] [G acc: 0.375]\n",
      "22656 [D loss: (0.584)(R 0.405, F 0.763)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.681] [G acc: 0.625]\n",
      "22657 [D loss: (0.959)(R 0.565, F 1.353)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.598] [G acc: 0.500]\n",
      "22658 [D loss: (0.767)(R 0.665, F 0.869)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.559] [G acc: 0.562]\n",
      "22659 [D loss: (0.884)(R 0.486, F 1.281)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.690] [G acc: 0.438]\n",
      "22660 [D loss: (1.108)(R 0.370, F 1.846)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.792] [G acc: 0.500]\n",
      "22661 [D loss: (0.863)(R 0.522, F 1.203)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.907] [G acc: 0.250]\n",
      "22662 [D loss: (0.805)(R 0.717, F 0.893)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.630] [G acc: 0.500]\n",
      "22663 [D loss: (0.797)(R 0.554, F 1.039)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.563] [G acc: 0.562]\n",
      "22664 [D loss: (0.848)(R 0.540, F 1.155)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.790] [G acc: 0.312]\n",
      "22665 [D loss: (0.923)(R 0.442, F 1.403)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.977] [G acc: 0.188]\n",
      "22666 [D loss: (0.644)(R 0.791, F 0.497)] [D acc: (0.625)(0.438, 0.812)] [G loss: 1.130] [G acc: 0.312]\n",
      "22667 [D loss: (0.679)(R 0.605, F 0.753)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.692] [G acc: 0.625]\n",
      "22668 [D loss: (0.510)(R 0.742, F 0.277)] [D acc: (0.688)(0.438, 0.938)] [G loss: 1.217] [G acc: 0.250]\n",
      "22669 [D loss: (0.632)(R 0.597, F 0.667)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.975] [G acc: 0.312]\n",
      "22670 [D loss: (0.657)(R 0.644, F 0.671)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.992] [G acc: 0.125]\n",
      "22671 [D loss: (0.667)(R 0.499, F 0.836)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.579] [G acc: 0.625]\n",
      "22672 [D loss: (0.594)(R 0.516, F 0.673)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.022] [G acc: 0.188]\n",
      "22673 [D loss: (1.241)(R 0.774, F 1.707)] [D acc: (0.438)(0.375, 0.500)] [G loss: 1.333] [G acc: 0.062]\n",
      "22674 [D loss: (0.382)(R 0.531, F 0.233)] [D acc: (0.781)(0.625, 0.938)] [G loss: 2.425] [G acc: 0.125]\n",
      "22675 [D loss: (0.578)(R 0.625, F 0.532)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.909] [G acc: 0.250]\n",
      "22676 [D loss: (0.617)(R 0.635, F 0.599)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.862] [G acc: 0.375]\n",
      "22677 [D loss: (0.730)(R 0.790, F 0.670)] [D acc: (0.531)(0.500, 0.562)] [G loss: 1.463] [G acc: 0.062]\n",
      "22678 [D loss: (0.640)(R 0.717, F 0.563)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.925] [G acc: 0.375]\n",
      "22679 [D loss: (0.917)(R 0.750, F 1.083)] [D acc: (0.500)(0.500, 0.500)] [G loss: 1.035] [G acc: 0.188]\n",
      "22680 [D loss: (0.544)(R 0.659, F 0.430)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.407] [G acc: 0.312]\n",
      "22681 [D loss: (0.470)(R 0.595, F 0.346)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.832] [G acc: 0.562]\n",
      "22682 [D loss: (0.797)(R 0.704, F 0.890)] [D acc: (0.531)(0.500, 0.562)] [G loss: 1.007] [G acc: 0.188]\n",
      "22683 [D loss: (0.540)(R 0.588, F 0.491)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.755] [G acc: 0.375]\n",
      "22684 [D loss: (0.388)(R 0.622, F 0.153)] [D acc: (0.750)(0.500, 1.000)] [G loss: 3.992] [G acc: 0.125]\n",
      "22685 [D loss: (0.333)(R 0.542, F 0.123)] [D acc: (0.812)(0.625, 1.000)] [G loss: 2.437] [G acc: 0.250]\n",
      "22686 [D loss: (0.430)(R 0.445, F 0.415)] [D acc: (0.812)(0.812, 0.812)] [G loss: 2.500] [G acc: 0.250]\n",
      "22687 [D loss: (0.556)(R 0.392, F 0.719)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.138] [G acc: 0.000]\n",
      "22688 [D loss: (0.502)(R 0.504, F 0.499)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.125] [G acc: 0.000]\n",
      "22689 [D loss: (0.475)(R 0.487, F 0.462)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.149] [G acc: 0.188]\n",
      "22690 [D loss: (0.618)(R 0.782, F 0.455)] [D acc: (0.656)(0.438, 0.875)] [G loss: 1.039] [G acc: 0.250]\n",
      "22691 [D loss: (0.384)(R 0.404, F 0.364)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.055] [G acc: 0.250]\n",
      "22692 [D loss: (0.461)(R 0.526, F 0.396)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.886] [G acc: 0.250]\n",
      "22693 [D loss: (0.683)(R 0.727, F 0.639)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.956] [G acc: 0.438]\n",
      "22694 [D loss: (0.596)(R 0.518, F 0.675)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.239] [G acc: 0.125]\n",
      "22695 [D loss: (0.418)(R 0.456, F 0.380)] [D acc: (0.844)(0.688, 1.000)] [G loss: 0.919] [G acc: 0.250]\n",
      "22696 [D loss: (0.494)(R 0.454, F 0.533)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.872] [G acc: 0.375]\n",
      "22697 [D loss: (0.460)(R 0.446, F 0.474)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.125] [G acc: 0.188]\n",
      "22698 [D loss: (0.612)(R 0.618, F 0.606)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.998] [G acc: 0.375]\n",
      "22699 [D loss: (0.860)(R 1.049, F 0.672)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.184] [G acc: 0.250]\n",
      "22700 [D loss: (0.649)(R 0.693, F 0.605)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.113] [G acc: 0.312]\n",
      "22701 [D loss: (0.476)(R 0.435, F 0.516)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.930] [G acc: 0.250]\n",
      "22702 [D loss: (0.615)(R 0.483, F 0.748)] [D acc: (0.656)(0.875, 0.438)] [G loss: 1.271] [G acc: 0.250]\n",
      "22703 [D loss: (0.374)(R 0.528, F 0.220)] [D acc: (0.875)(0.875, 0.875)] [G loss: 2.657] [G acc: 0.125]\n",
      "22704 [D loss: (0.404)(R 0.391, F 0.416)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.739] [G acc: 0.062]\n",
      "22705 [D loss: (0.326)(R 0.393, F 0.259)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.673] [G acc: 0.250]\n",
      "22706 [D loss: (0.478)(R 0.342, F 0.614)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.965] [G acc: 0.250]\n",
      "22707 [D loss: (0.599)(R 0.495, F 0.704)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.927] [G acc: 0.125]\n",
      "22708 [D loss: (0.522)(R 0.509, F 0.534)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.121] [G acc: 0.312]\n",
      "22709 [D loss: (0.608)(R 0.574, F 0.642)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.767] [G acc: 0.562]\n",
      "22710 [D loss: (0.503)(R 0.522, F 0.484)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.454] [G acc: 0.125]\n",
      "22711 [D loss: (0.653)(R 0.592, F 0.714)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.517] [G acc: 0.062]\n",
      "22712 [D loss: (0.437)(R 0.592, F 0.283)] [D acc: (0.750)(0.625, 0.875)] [G loss: 2.246] [G acc: 0.250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22713 [D loss: (0.417)(R 0.466, F 0.368)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.271] [G acc: 0.250]\n",
      "22714 [D loss: (0.524)(R 0.571, F 0.477)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.757] [G acc: 0.188]\n",
      "22715 [D loss: (0.555)(R 0.773, F 0.338)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.920] [G acc: 0.188]\n",
      "22716 [D loss: (0.635)(R 0.731, F 0.539)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.856] [G acc: 0.375]\n",
      "22717 [D loss: (0.701)(R 0.608, F 0.794)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.992] [G acc: 0.188]\n",
      "22718 [D loss: (0.631)(R 0.640, F 0.621)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.906] [G acc: 0.500]\n",
      "22719 [D loss: (0.428)(R 0.383, F 0.472)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.082] [G acc: 0.062]\n",
      "22720 [D loss: (0.631)(R 0.557, F 0.705)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.250] [G acc: 0.188]\n",
      "22721 [D loss: (0.515)(R 0.525, F 0.506)] [D acc: (0.719)(0.625, 0.812)] [G loss: 2.033] [G acc: 0.000]\n",
      "22722 [D loss: (0.394)(R 0.468, F 0.320)] [D acc: (0.844)(0.812, 0.875)] [G loss: 5.891] [G acc: 0.188]\n",
      "22723 [D loss: (0.453)(R 0.494, F 0.413)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.333] [G acc: 0.125]\n",
      "22724 [D loss: (0.550)(R 0.449, F 0.651)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.654] [G acc: 0.125]\n",
      "22725 [D loss: (0.466)(R 0.593, F 0.338)] [D acc: (0.688)(0.562, 0.812)] [G loss: 3.362] [G acc: 0.188]\n",
      "22726 [D loss: (0.376)(R 0.376, F 0.375)] [D acc: (0.844)(0.875, 0.812)] [G loss: 4.614] [G acc: 0.312]\n",
      "22727 [D loss: (0.452)(R 0.453, F 0.452)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.971] [G acc: 0.188]\n",
      "22728 [D loss: (0.655)(R 0.684, F 0.627)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.134] [G acc: 0.125]\n",
      "22729 [D loss: (0.649)(R 0.548, F 0.749)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.895] [G acc: 0.250]\n",
      "22730 [D loss: (0.548)(R 0.493, F 0.603)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.898] [G acc: 0.188]\n",
      "22731 [D loss: (0.564)(R 0.508, F 0.621)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.911] [G acc: 0.375]\n",
      "22732 [D loss: (0.517)(R 0.432, F 0.603)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.858] [G acc: 0.438]\n",
      "22733 [D loss: (0.655)(R 0.700, F 0.610)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.888] [G acc: 0.250]\n",
      "22734 [D loss: (0.540)(R 0.507, F 0.574)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.930] [G acc: 0.188]\n",
      "22735 [D loss: (0.570)(R 0.498, F 0.643)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.172] [G acc: 0.125]\n",
      "22736 [D loss: (0.906)(R 0.531, F 1.281)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.883] [G acc: 0.312]\n",
      "22737 [D loss: (0.571)(R 0.433, F 0.710)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.967] [G acc: 0.438]\n",
      "22738 [D loss: (0.595)(R 0.582, F 0.609)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.670] [G acc: 0.688]\n",
      "22739 [D loss: (0.709)(R 0.529, F 0.890)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.794] [G acc: 0.438]\n",
      "22740 [D loss: (0.671)(R 0.585, F 0.757)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.803] [G acc: 0.438]\n",
      "22741 [D loss: (0.696)(R 0.594, F 0.797)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.717] [G acc: 0.562]\n",
      "22742 [D loss: (0.726)(R 0.567, F 0.884)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.798] [G acc: 0.500]\n",
      "22743 [D loss: (0.648)(R 0.562, F 0.734)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.961] [G acc: 0.250]\n",
      "22744 [D loss: (0.688)(R 0.540, F 0.836)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.714] [G acc: 0.562]\n",
      "22745 [D loss: (0.833)(R 0.574, F 1.092)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.808] [G acc: 0.500]\n",
      "22746 [D loss: (0.731)(R 0.587, F 0.875)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.736] [G acc: 0.500]\n",
      "22747 [D loss: (0.609)(R 0.740, F 0.478)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.499] [G acc: 0.312]\n",
      "22748 [D loss: (0.565)(R 0.507, F 0.623)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.004] [G acc: 0.500]\n",
      "22749 [D loss: (0.480)(R 0.706, F 0.253)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.742] [G acc: 0.500]\n",
      "22750 [D loss: (0.546)(R 0.351, F 0.741)] [D acc: (0.812)(0.938, 0.688)] [G loss: 1.558] [G acc: 0.375]\n",
      "22751 [D loss: (0.764)(R 0.613, F 0.916)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.530] [G acc: 0.875]\n",
      "22752 [D loss: (0.961)(R 0.530, F 1.391)] [D acc: (0.375)(0.750, 0.000)] [G loss: 0.505] [G acc: 0.750]\n",
      "22753 [D loss: (0.848)(R 0.532, F 1.165)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.488] [G acc: 0.750]\n",
      "22754 [D loss: (0.731)(R 0.467, F 0.996)] [D acc: (0.531)(0.812, 0.250)] [G loss: 0.667] [G acc: 0.625]\n",
      "22755 [D loss: (0.654)(R 0.445, F 0.863)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.639] [G acc: 0.750]\n",
      "22756 [D loss: (0.600)(R 0.573, F 0.627)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.640] [G acc: 0.562]\n",
      "22757 [D loss: (0.702)(R 0.501, F 0.903)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.610] [G acc: 0.500]\n",
      "22758 [D loss: (1.074)(R 0.540, F 1.607)] [D acc: (0.531)(0.875, 0.188)] [G loss: 0.572] [G acc: 0.812]\n",
      "22759 [D loss: (0.665)(R 0.575, F 0.755)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.757] [G acc: 0.438]\n",
      "22760 [D loss: (0.854)(R 0.542, F 1.165)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.565] [G acc: 0.812]\n",
      "22761 [D loss: (0.715)(R 0.551, F 0.879)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.557] [G acc: 0.750]\n",
      "22762 [D loss: (1.026)(R 1.024, F 1.027)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.538] [G acc: 0.812]\n",
      "22763 [D loss: (0.679)(R 0.533, F 0.825)] [D acc: (0.594)(0.875, 0.312)] [G loss: 0.622] [G acc: 0.562]\n",
      "22764 [D loss: (0.771)(R 0.680, F 0.862)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.654] [G acc: 0.562]\n",
      "22765 [D loss: (0.655)(R 0.439, F 0.871)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.638] [G acc: 0.625]\n",
      "22766 [D loss: (0.718)(R 0.572, F 0.865)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.790] [G acc: 0.375]\n",
      "22767 [D loss: (0.659)(R 0.628, F 0.690)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.645] [G acc: 0.625]\n",
      "22768 [D loss: (0.887)(R 0.629, F 1.146)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.433] [G acc: 0.688]\n",
      "22769 [D loss: (0.863)(R 0.778, F 0.949)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.635] [G acc: 0.500]\n",
      "22770 [D loss: (0.807)(R 0.697, F 0.918)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.545] [G acc: 0.688]\n",
      "22771 [D loss: (1.135)(R 0.592, F 1.678)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.740] [G acc: 0.438]\n",
      "22772 [D loss: (1.344)(R 1.472, F 1.216)] [D acc: (0.719)(0.750, 0.688)] [G loss: 6.914] [G acc: 0.125]\n",
      "22773 [D loss: (1.461)(R 0.435, F 2.488)] [D acc: (0.750)(0.875, 0.625)] [G loss: 5.097] [G acc: 0.500]\n",
      "22774 [D loss: (0.704)(R 0.692, F 0.716)] [D acc: (0.656)(0.812, 0.500)] [G loss: 1.335] [G acc: 0.438]\n",
      "22775 [D loss: (1.059)(R 0.664, F 1.453)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.526] [G acc: 0.625]\n",
      "22776 [D loss: (0.900)(R 0.436, F 1.364)] [D acc: (0.719)(0.938, 0.500)] [G loss: 0.485] [G acc: 0.750]\n",
      "22777 [D loss: (0.845)(R 0.672, F 1.019)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.797] [G acc: 0.562]\n",
      "22778 [D loss: (1.431)(R 0.569, F 2.293)] [D acc: (0.625)(0.750, 0.500)] [G loss: 1.295] [G acc: 0.250]\n",
      "22779 [D loss: (1.487)(R 0.555, F 2.420)] [D acc: (0.531)(0.750, 0.312)] [G loss: 2.159] [G acc: 0.438]\n",
      "22780 [D loss: (0.847)(R 0.801, F 0.893)] [D acc: (0.688)(0.625, 0.750)] [G loss: 3.051] [G acc: 0.312]\n",
      "22781 [D loss: (2.367)(R 0.611, F 4.123)] [D acc: (0.500)(0.625, 0.375)] [G loss: 9.368] [G acc: 0.062]\n",
      "22782 [D loss: (0.752)(R 0.627, F 0.877)] [D acc: (0.688)(0.625, 0.750)] [G loss: 5.119] [G acc: 0.125]\n",
      "22783 [D loss: (0.720)(R 0.516, F 0.924)] [D acc: (0.906)(0.938, 0.875)] [G loss: 4.382] [G acc: 0.000]\n",
      "22784 [D loss: (1.028)(R 0.629, F 1.428)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.755] [G acc: 0.188]\n",
      "22785 [D loss: (0.453)(R 0.595, F 0.311)] [D acc: (0.844)(0.812, 0.875)] [G loss: 2.057] [G acc: 0.250]\n",
      "22786 [D loss: (0.630)(R 0.717, F 0.542)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.747] [G acc: 0.250]\n",
      "22787 [D loss: (0.500)(R 0.484, F 0.515)] [D acc: (0.844)(0.938, 0.750)] [G loss: 1.572] [G acc: 0.188]\n",
      "22788 [D loss: (0.482)(R 0.548, F 0.417)] [D acc: (0.812)(0.875, 0.750)] [G loss: 3.076] [G acc: 0.125]\n",
      "22789 [D loss: (0.797)(R 0.643, F 0.952)] [D acc: (0.719)(0.625, 0.812)] [G loss: 2.643] [G acc: 0.000]\n",
      "22790 [D loss: (0.433)(R 0.628, F 0.238)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.439] [G acc: 0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22791 [D loss: (0.572)(R 0.573, F 0.570)] [D acc: (0.688)(0.812, 0.562)] [G loss: 1.307] [G acc: 0.188]\n",
      "22792 [D loss: (0.500)(R 0.604, F 0.396)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.781] [G acc: 0.125]\n",
      "22793 [D loss: (0.684)(R 0.875, F 0.494)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.062] [G acc: 0.188]\n",
      "22794 [D loss: (0.533)(R 0.572, F 0.493)] [D acc: (0.781)(0.688, 0.875)] [G loss: 2.363] [G acc: 0.000]\n",
      "22795 [D loss: (0.392)(R 0.543, F 0.241)] [D acc: (0.906)(0.875, 0.938)] [G loss: 2.463] [G acc: 0.250]\n",
      "22796 [D loss: (0.416)(R 0.575, F 0.257)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.998] [G acc: 0.188]\n",
      "22797 [D loss: (0.476)(R 0.565, F 0.388)] [D acc: (0.844)(0.750, 0.938)] [G loss: 3.483] [G acc: 0.000]\n",
      "22798 [D loss: (0.452)(R 0.464, F 0.440)] [D acc: (0.781)(0.938, 0.625)] [G loss: 5.065] [G acc: 0.125]\n",
      "22799 [D loss: (0.486)(R 0.623, F 0.350)] [D acc: (0.781)(0.688, 0.875)] [G loss: 2.431] [G acc: 0.312]\n",
      "22800 [D loss: (0.541)(R 0.560, F 0.523)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.897] [G acc: 0.312]\n",
      "22801 [D loss: (0.535)(R 0.493, F 0.577)] [D acc: (0.750)(0.875, 0.625)] [G loss: 1.248] [G acc: 0.000]\n",
      "22802 [D loss: (0.520)(R 0.570, F 0.470)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.146] [G acc: 0.062]\n",
      "22803 [D loss: (0.679)(R 0.843, F 0.515)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.170] [G acc: 0.188]\n",
      "22804 [D loss: (0.505)(R 0.558, F 0.453)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.007] [G acc: 0.188]\n",
      "22805 [D loss: (0.641)(R 0.744, F 0.537)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.906] [G acc: 0.250]\n",
      "22806 [D loss: (0.470)(R 0.492, F 0.448)] [D acc: (0.906)(0.938, 0.875)] [G loss: 1.552] [G acc: 0.125]\n",
      "22807 [D loss: (1.107)(R 1.875, F 0.339)] [D acc: (0.812)(0.812, 0.812)] [G loss: 4.677] [G acc: 0.125]\n",
      "22808 [D loss: (0.595)(R 0.794, F 0.396)] [D acc: (0.812)(0.812, 0.812)] [G loss: 8.500] [G acc: 0.062]\n",
      "22809 [D loss: (0.401)(R 0.567, F 0.236)] [D acc: (0.781)(0.688, 0.875)] [G loss: 3.805] [G acc: 0.062]\n",
      "22810 [D loss: (0.431)(R 0.531, F 0.331)] [D acc: (0.812)(0.812, 0.812)] [G loss: 3.680] [G acc: 0.062]\n",
      "22811 [D loss: (0.549)(R 0.554, F 0.545)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.048] [G acc: 0.188]\n",
      "22812 [D loss: (0.519)(R 0.626, F 0.413)] [D acc: (0.906)(0.875, 0.938)] [G loss: 1.026] [G acc: 0.188]\n",
      "22813 [D loss: (0.525)(R 0.528, F 0.522)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.050] [G acc: 0.062]\n",
      "22814 [D loss: (0.407)(R 0.472, F 0.342)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.663] [G acc: 0.188]\n",
      "22815 [D loss: (0.416)(R 0.520, F 0.313)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.610] [G acc: 0.188]\n",
      "22816 [D loss: (0.499)(R 0.592, F 0.405)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.610] [G acc: 0.062]\n",
      "22817 [D loss: (0.503)(R 0.618, F 0.389)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.208] [G acc: 0.188]\n",
      "22818 [D loss: (0.443)(R 0.506, F 0.379)] [D acc: (0.906)(0.812, 1.000)] [G loss: 1.345] [G acc: 0.062]\n",
      "22819 [D loss: (0.567)(R 0.530, F 0.604)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.997] [G acc: 0.062]\n",
      "22820 [D loss: (0.438)(R 0.501, F 0.375)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.607] [G acc: 0.188]\n",
      "22821 [D loss: (0.498)(R 0.525, F 0.471)] [D acc: (0.844)(0.938, 0.750)] [G loss: 1.536] [G acc: 0.000]\n",
      "22822 [D loss: (0.337)(R 0.392, F 0.282)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.906] [G acc: 0.125]\n",
      "22823 [D loss: (0.631)(R 0.764, F 0.498)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.664] [G acc: 0.000]\n",
      "22824 [D loss: (0.360)(R 0.428, F 0.293)] [D acc: (0.938)(1.000, 0.875)] [G loss: 1.991] [G acc: 0.062]\n",
      "22825 [D loss: (0.407)(R 0.449, F 0.366)] [D acc: (0.875)(0.938, 0.812)] [G loss: 1.447] [G acc: 0.125]\n",
      "22826 [D loss: (0.338)(R 0.466, F 0.210)] [D acc: (0.938)(0.875, 1.000)] [G loss: 1.515] [G acc: 0.188]\n",
      "22827 [D loss: (0.433)(R 0.527, F 0.338)] [D acc: (0.875)(0.812, 0.938)] [G loss: 2.026] [G acc: 0.125]\n",
      "22828 [D loss: (0.383)(R 0.446, F 0.320)] [D acc: (0.906)(0.938, 0.875)] [G loss: 1.124] [G acc: 0.125]\n",
      "22829 [D loss: (0.512)(R 0.504, F 0.519)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.204] [G acc: 0.125]\n",
      "22830 [D loss: (0.449)(R 0.650, F 0.247)] [D acc: (0.812)(0.625, 1.000)] [G loss: 1.295] [G acc: 0.125]\n",
      "22831 [D loss: (0.449)(R 0.544, F 0.354)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.115] [G acc: 0.000]\n",
      "22832 [D loss: (0.553)(R 0.693, F 0.412)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.388] [G acc: 0.062]\n",
      "22833 [D loss: (0.613)(R 0.611, F 0.614)] [D acc: (0.594)(0.688, 0.500)] [G loss: 1.342] [G acc: 0.125]\n",
      "22834 [D loss: (0.419)(R 0.491, F 0.347)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.395] [G acc: 0.062]\n",
      "22835 [D loss: (0.471)(R 0.390, F 0.552)] [D acc: (0.812)(0.938, 0.688)] [G loss: 1.705] [G acc: 0.188]\n",
      "22836 [D loss: (0.338)(R 0.503, F 0.172)] [D acc: (0.844)(0.750, 0.938)] [G loss: 3.155] [G acc: 0.000]\n",
      "22837 [D loss: (0.572)(R 0.882, F 0.262)] [D acc: (0.812)(0.625, 1.000)] [G loss: 2.900] [G acc: 0.188]\n",
      "22838 [D loss: (0.212)(R 0.403, F 0.021)] [D acc: (0.938)(0.875, 1.000)] [G loss: 4.659] [G acc: 0.125]\n",
      "22839 [D loss: (0.418)(R 0.351, F 0.484)] [D acc: (0.844)(0.938, 0.750)] [G loss: 1.252] [G acc: 0.000]\n",
      "22840 [D loss: (0.381)(R 0.454, F 0.307)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.105] [G acc: 0.062]\n",
      "22841 [D loss: (0.626)(R 0.914, F 0.338)] [D acc: (0.781)(0.562, 1.000)] [G loss: 2.024] [G acc: 0.062]\n",
      "22842 [D loss: (0.395)(R 0.370, F 0.420)] [D acc: (0.938)(0.938, 0.938)] [G loss: 1.662] [G acc: 0.062]\n",
      "22843 [D loss: (0.321)(R 0.442, F 0.201)] [D acc: (0.938)(0.875, 1.000)] [G loss: 1.119] [G acc: 0.062]\n",
      "22844 [D loss: (0.451)(R 0.568, F 0.334)] [D acc: (0.844)(0.688, 1.000)] [G loss: 4.654] [G acc: 0.000]\n",
      "22845 [D loss: (0.390)(R 0.433, F 0.346)] [D acc: (0.812)(0.812, 0.812)] [G loss: 2.176] [G acc: 0.250]\n",
      "22846 [D loss: (0.420)(R 0.385, F 0.456)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.014] [G acc: 0.188]\n",
      "22847 [D loss: (0.501)(R 0.470, F 0.532)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.899] [G acc: 0.500]\n",
      "22848 [D loss: (0.439)(R 0.449, F 0.430)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.254] [G acc: 0.125]\n",
      "22849 [D loss: (0.490)(R 0.431, F 0.549)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.755] [G acc: 0.000]\n",
      "22850 [D loss: (0.389)(R 0.367, F 0.412)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.612] [G acc: 0.125]\n",
      "22851 [D loss: (0.533)(R 0.805, F 0.260)] [D acc: (0.844)(0.750, 0.938)] [G loss: 4.083] [G acc: 0.000]\n",
      "22852 [D loss: (0.363)(R 0.583, F 0.144)] [D acc: (0.938)(0.875, 1.000)] [G loss: 4.373] [G acc: 0.125]\n",
      "22853 [D loss: (0.313)(R 0.465, F 0.161)] [D acc: (0.875)(0.812, 0.938)] [G loss: 2.046] [G acc: 0.062]\n",
      "22854 [D loss: (0.355)(R 0.493, F 0.217)] [D acc: (0.844)(0.812, 0.875)] [G loss: 2.543] [G acc: 0.125]\n",
      "22855 [D loss: (0.332)(R 0.316, F 0.349)] [D acc: (0.938)(0.938, 0.938)] [G loss: 1.748] [G acc: 0.000]\n",
      "22856 [D loss: (0.414)(R 0.449, F 0.380)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.025] [G acc: 0.312]\n",
      "22857 [D loss: (0.435)(R 0.513, F 0.357)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.998] [G acc: 0.062]\n",
      "22858 [D loss: (0.487)(R 0.600, F 0.374)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.523] [G acc: 0.125]\n",
      "22859 [D loss: (0.275)(R 0.269, F 0.281)] [D acc: (0.969)(1.000, 0.938)] [G loss: 1.744] [G acc: 0.125]\n",
      "22860 [D loss: (0.404)(R 0.492, F 0.316)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.271] [G acc: 0.188]\n",
      "22861 [D loss: (0.332)(R 0.265, F 0.400)] [D acc: (0.906)(1.000, 0.812)] [G loss: 1.266] [G acc: 0.438]\n",
      "22862 [D loss: (0.266)(R 0.280, F 0.252)] [D acc: (0.969)(1.000, 0.938)] [G loss: 1.767] [G acc: 0.188]\n",
      "22863 [D loss: (0.503)(R 0.697, F 0.308)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.599] [G acc: 0.062]\n",
      "22864 [D loss: (0.553)(R 0.276, F 0.829)] [D acc: (0.812)(1.000, 0.625)] [G loss: 0.867] [G acc: 0.500]\n",
      "22865 [D loss: (0.580)(R 0.428, F 0.731)] [D acc: (0.719)(0.938, 0.500)] [G loss: 1.766] [G acc: 0.125]\n",
      "22866 [D loss: (0.485)(R 0.516, F 0.453)] [D acc: (0.750)(0.688, 0.812)] [G loss: 5.332] [G acc: 0.125]\n",
      "22867 [D loss: (0.332)(R 0.463, F 0.201)] [D acc: (0.812)(0.750, 0.875)] [G loss: 9.117] [G acc: 0.062]\n",
      "22868 [D loss: (0.347)(R 0.448, F 0.246)] [D acc: (0.906)(0.875, 0.938)] [G loss: 2.958] [G acc: 0.125]\n",
      "22869 [D loss: (0.641)(R 0.679, F 0.603)] [D acc: (0.719)(0.875, 0.562)] [G loss: 1.775] [G acc: 0.188]\n",
      "22870 [D loss: (0.547)(R 0.492, F 0.603)] [D acc: (0.812)(0.812, 0.812)] [G loss: 3.545] [G acc: 0.062]\n",
      "22871 [D loss: (0.382)(R 0.445, F 0.319)] [D acc: (0.906)(0.875, 0.938)] [G loss: 1.250] [G acc: 0.188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22872 [D loss: (0.459)(R 0.587, F 0.332)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.599] [G acc: 0.375]\n",
      "22873 [D loss: (0.564)(R 0.571, F 0.558)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.961] [G acc: 0.500]\n",
      "22874 [D loss: (0.768)(R 0.847, F 0.690)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.787] [G acc: 0.562]\n",
      "22875 [D loss: (0.580)(R 0.232, F 0.928)] [D acc: (0.594)(0.938, 0.250)] [G loss: 1.051] [G acc: 0.312]\n",
      "22876 [D loss: (0.604)(R 0.523, F 0.684)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.146] [G acc: 0.375]\n",
      "22877 [D loss: (0.471)(R 0.580, F 0.362)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.938] [G acc: 0.188]\n",
      "22878 [D loss: (0.576)(R 0.382, F 0.770)] [D acc: (0.656)(0.875, 0.438)] [G loss: 1.612] [G acc: 0.312]\n",
      "22879 [D loss: (0.373)(R 0.466, F 0.281)] [D acc: (0.875)(0.812, 0.938)] [G loss: 2.250] [G acc: 0.188]\n",
      "22880 [D loss: (0.523)(R 0.400, F 0.646)] [D acc: (0.719)(0.875, 0.562)] [G loss: 1.553] [G acc: 0.500]\n",
      "22881 [D loss: (0.476)(R 0.582, F 0.370)] [D acc: (0.719)(0.688, 0.750)] [G loss: 2.247] [G acc: 0.312]\n",
      "22882 [D loss: (1.167)(R 0.574, F 1.759)] [D acc: (0.406)(0.688, 0.125)] [G loss: 1.243] [G acc: 0.438]\n",
      "22883 [D loss: (0.469)(R 0.460, F 0.478)] [D acc: (0.719)(0.750, 0.688)] [G loss: 4.471] [G acc: 0.250]\n",
      "22884 [D loss: (0.531)(R 0.655, F 0.407)] [D acc: (0.719)(0.688, 0.750)] [G loss: 6.242] [G acc: 0.312]\n",
      "22885 [D loss: (1.099)(R 1.006, F 1.191)] [D acc: (0.531)(0.375, 0.688)] [G loss: 3.042] [G acc: 0.375]\n",
      "22886 [D loss: (0.743)(R 0.871, F 0.615)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.652] [G acc: 0.812]\n",
      "22887 [D loss: (0.788)(R 0.455, F 1.120)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.671] [G acc: 0.625]\n",
      "22888 [D loss: (0.901)(R 0.638, F 1.165)] [D acc: (0.500)(0.750, 0.250)] [G loss: 1.168] [G acc: 0.375]\n",
      "22889 [D loss: (0.672)(R 0.754, F 0.589)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.267] [G acc: 0.250]\n",
      "22890 [D loss: (0.532)(R 0.469, F 0.596)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.810] [G acc: 0.688]\n",
      "22891 [D loss: (0.801)(R 0.568, F 1.034)] [D acc: (0.688)(0.875, 0.500)] [G loss: 1.047] [G acc: 0.438]\n",
      "22892 [D loss: (0.621)(R 0.658, F 0.585)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.188] [G acc: 0.188]\n",
      "22893 [D loss: (0.639)(R 0.451, F 0.828)] [D acc: (0.750)(0.938, 0.562)] [G loss: 2.017] [G acc: 0.188]\n",
      "22894 [D loss: (0.318)(R 0.365, F 0.271)] [D acc: (0.781)(0.750, 0.812)] [G loss: 2.016] [G acc: 0.125]\n",
      "22895 [D loss: (0.364)(R 0.343, F 0.386)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.054] [G acc: 0.250]\n",
      "22896 [D loss: (0.489)(R 0.443, F 0.536)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.162] [G acc: 0.188]\n",
      "22897 [D loss: (0.645)(R 0.649, F 0.640)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.866] [G acc: 0.312]\n",
      "22898 [D loss: (0.558)(R 0.449, F 0.667)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.288] [G acc: 0.562]\n",
      "22899 [D loss: (0.451)(R 0.569, F 0.333)] [D acc: (0.875)(0.875, 0.875)] [G loss: 2.438] [G acc: 0.125]\n",
      "22900 [D loss: (0.784)(R 0.540, F 1.029)] [D acc: (0.562)(0.750, 0.375)] [G loss: 2.641] [G acc: 0.375]\n",
      "22901 [D loss: (0.493)(R 0.427, F 0.560)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.319] [G acc: 0.250]\n",
      "22902 [D loss: (0.664)(R 0.872, F 0.456)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.122] [G acc: 0.188]\n",
      "22903 [D loss: (0.545)(R 0.518, F 0.571)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.849] [G acc: 0.312]\n",
      "22904 [D loss: (0.612)(R 0.522, F 0.702)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.678] [G acc: 0.000]\n",
      "22905 [D loss: (0.655)(R 0.707, F 0.603)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.642] [G acc: 0.438]\n",
      "22906 [D loss: (0.373)(R 0.377, F 0.370)] [D acc: (0.906)(0.875, 0.938)] [G loss: 2.284] [G acc: 0.125]\n",
      "22907 [D loss: (0.558)(R 0.753, F 0.364)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.485] [G acc: 0.375]\n",
      "22908 [D loss: (0.382)(R 0.489, F 0.275)] [D acc: (0.906)(0.812, 1.000)] [G loss: 1.673] [G acc: 0.312]\n",
      "22909 [D loss: (0.688)(R 0.747, F 0.629)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.929] [G acc: 0.375]\n",
      "22910 [D loss: (0.696)(R 0.418, F 0.973)] [D acc: (0.562)(0.812, 0.312)] [G loss: 0.806] [G acc: 0.500]\n",
      "22911 [D loss: (0.658)(R 0.665, F 0.650)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.087] [G acc: 0.312]\n",
      "22912 [D loss: (0.602)(R 0.504, F 0.699)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.940] [G acc: 0.312]\n",
      "22913 [D loss: (0.675)(R 0.631, F 0.719)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.951] [G acc: 0.375]\n",
      "22914 [D loss: (0.418)(R 0.497, F 0.339)] [D acc: (0.875)(0.750, 1.000)] [G loss: 1.830] [G acc: 0.125]\n",
      "22915 [D loss: (0.501)(R 0.458, F 0.544)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.517] [G acc: 0.188]\n",
      "22916 [D loss: (0.451)(R 0.584, F 0.318)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.262] [G acc: 0.188]\n",
      "22917 [D loss: (0.589)(R 0.518, F 0.659)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.117] [G acc: 0.125]\n",
      "22918 [D loss: (0.419)(R 0.636, F 0.201)] [D acc: (0.781)(0.562, 1.000)] [G loss: 0.969] [G acc: 0.375]\n",
      "22919 [D loss: (0.666)(R 0.529, F 0.803)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.668] [G acc: 0.500]\n",
      "22920 [D loss: (0.755)(R 0.661, F 0.850)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.737] [G acc: 0.438]\n",
      "22921 [D loss: (0.672)(R 0.480, F 0.864)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.779] [G acc: 0.500]\n",
      "22922 [D loss: (0.749)(R 0.485, F 1.014)] [D acc: (0.625)(0.750, 0.500)] [G loss: 1.427] [G acc: 0.562]\n",
      "22923 [D loss: (0.489)(R 0.450, F 0.529)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.709] [G acc: 0.438]\n",
      "22924 [D loss: (0.533)(R 0.693, F 0.374)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.886] [G acc: 0.375]\n",
      "22925 [D loss: (0.667)(R 0.559, F 0.775)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.036] [G acc: 0.125]\n",
      "22926 [D loss: (0.792)(R 0.517, F 1.066)] [D acc: (0.625)(0.688, 0.562)] [G loss: 2.377] [G acc: 0.250]\n",
      "22927 [D loss: (0.434)(R 0.741, F 0.126)] [D acc: (0.750)(0.500, 1.000)] [G loss: 6.487] [G acc: 0.188]\n",
      "22928 [D loss: (0.889)(R 0.745, F 1.033)] [D acc: (0.656)(0.625, 0.688)] [G loss: 6.352] [G acc: 0.188]\n",
      "22929 [D loss: (0.621)(R 0.631, F 0.611)] [D acc: (0.719)(0.750, 0.688)] [G loss: 5.040] [G acc: 0.062]\n",
      "22930 [D loss: (0.649)(R 0.644, F 0.653)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.977] [G acc: 0.375]\n",
      "22931 [D loss: (0.481)(R 0.671, F 0.290)] [D acc: (0.844)(0.750, 0.938)] [G loss: 0.593] [G acc: 0.625]\n",
      "22932 [D loss: (0.548)(R 0.622, F 0.474)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.884] [G acc: 0.438]\n",
      "22933 [D loss: (0.391)(R 0.368, F 0.414)] [D acc: (0.906)(0.875, 0.938)] [G loss: 1.664] [G acc: 0.500]\n",
      "22934 [D loss: (0.630)(R 0.713, F 0.547)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.292] [G acc: 0.312]\n",
      "22935 [D loss: (0.598)(R 0.554, F 0.643)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.747] [G acc: 0.562]\n",
      "22936 [D loss: (0.623)(R 0.641, F 0.604)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.145] [G acc: 0.188]\n",
      "22937 [D loss: (0.563)(R 0.583, F 0.543)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.063] [G acc: 0.625]\n",
      "22938 [D loss: (0.562)(R 0.923, F 0.202)] [D acc: (0.750)(0.562, 0.938)] [G loss: 2.984] [G acc: 0.000]\n",
      "22939 [D loss: (0.654)(R 0.448, F 0.860)] [D acc: (0.656)(0.812, 0.500)] [G loss: 1.681] [G acc: 0.250]\n",
      "22940 [D loss: (0.427)(R 0.496, F 0.359)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.531] [G acc: 0.625]\n",
      "22941 [D loss: (0.561)(R 0.602, F 0.521)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.137] [G acc: 0.250]\n",
      "22942 [D loss: (0.534)(R 0.507, F 0.560)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.148] [G acc: 0.188]\n",
      "22943 [D loss: (0.541)(R 0.509, F 0.572)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.777] [G acc: 0.062]\n",
      "22944 [D loss: (1.077)(R 0.842, F 1.313)] [D acc: (0.562)(0.625, 0.500)] [G loss: 1.603] [G acc: 0.312]\n",
      "22945 [D loss: (0.391)(R 0.500, F 0.282)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.137] [G acc: 0.375]\n",
      "22946 [D loss: (0.624)(R 0.505, F 0.744)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.689] [G acc: 0.562]\n",
      "22947 [D loss: (0.555)(R 0.490, F 0.620)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.349] [G acc: 0.062]\n",
      "22948 [D loss: (0.561)(R 0.603, F 0.519)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.309] [G acc: 0.125]\n",
      "22949 [D loss: (0.581)(R 0.646, F 0.517)] [D acc: (0.781)(0.812, 0.750)] [G loss: 2.465] [G acc: 0.125]\n",
      "22950 [D loss: (0.518)(R 0.564, F 0.472)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.043] [G acc: 0.188]\n",
      "22951 [D loss: (0.738)(R 0.671, F 0.804)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.826] [G acc: 0.375]\n",
      "22952 [D loss: (0.497)(R 0.460, F 0.534)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.158] [G acc: 0.375]\n",
      "22953 [D loss: (0.648)(R 0.691, F 0.605)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.836] [G acc: 0.375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22954 [D loss: (0.616)(R 0.569, F 0.663)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.115] [G acc: 0.125]\n",
      "22955 [D loss: (0.615)(R 0.777, F 0.452)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.348] [G acc: 0.125]\n",
      "22956 [D loss: (0.612)(R 0.496, F 0.727)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.591] [G acc: 0.500]\n",
      "22957 [D loss: (0.682)(R 0.779, F 0.584)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.931] [G acc: 0.125]\n",
      "22958 [D loss: (0.571)(R 0.485, F 0.657)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.551] [G acc: 0.688]\n",
      "22959 [D loss: (0.681)(R 0.473, F 0.890)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.706] [G acc: 0.562]\n",
      "22960 [D loss: (0.587)(R 0.653, F 0.522)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.856] [G acc: 0.375]\n",
      "22961 [D loss: (0.655)(R 0.753, F 0.557)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.970] [G acc: 0.188]\n",
      "22962 [D loss: (0.662)(R 0.631, F 0.694)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.515] [G acc: 0.750]\n",
      "22963 [D loss: (0.691)(R 0.487, F 0.895)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.813] [G acc: 0.250]\n",
      "22964 [D loss: (0.728)(R 0.568, F 0.889)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.995] [G acc: 0.062]\n",
      "22965 [D loss: (0.700)(R 0.515, F 0.885)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.334] [G acc: 0.000]\n",
      "22966 [D loss: (0.448)(R 0.460, F 0.437)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.562] [G acc: 0.188]\n",
      "22967 [D loss: (0.376)(R 0.609, F 0.143)] [D acc: (0.812)(0.625, 1.000)] [G loss: 4.179] [G acc: 0.125]\n",
      "22968 [D loss: (0.493)(R 0.556, F 0.431)] [D acc: (0.688)(0.688, 0.688)] [G loss: 3.125] [G acc: 0.250]\n",
      "22969 [D loss: (0.583)(R 0.596, F 0.570)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.190] [G acc: 0.188]\n",
      "22970 [D loss: (0.598)(R 0.547, F 0.649)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.791] [G acc: 0.500]\n",
      "22971 [D loss: (0.501)(R 0.463, F 0.539)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.006] [G acc: 0.125]\n",
      "22972 [D loss: (0.807)(R 1.044, F 0.570)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.693] [G acc: 0.562]\n",
      "22973 [D loss: (0.395)(R 0.494, F 0.297)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.139] [G acc: 0.188]\n",
      "22974 [D loss: (0.619)(R 0.619, F 0.619)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.905] [G acc: 0.375]\n",
      "22975 [D loss: (0.616)(R 0.643, F 0.590)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.172] [G acc: 0.125]\n",
      "22976 [D loss: (0.540)(R 0.723, F 0.357)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.033] [G acc: 0.125]\n",
      "22977 [D loss: (0.542)(R 0.511, F 0.573)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.842] [G acc: 0.500]\n",
      "22978 [D loss: (0.429)(R 0.641, F 0.218)] [D acc: (0.781)(0.562, 1.000)] [G loss: 1.733] [G acc: 0.188]\n",
      "22979 [D loss: (0.441)(R 0.458, F 0.423)] [D acc: (0.844)(0.875, 0.812)] [G loss: 0.678] [G acc: 0.500]\n",
      "22980 [D loss: (0.540)(R 0.519, F 0.561)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.807] [G acc: 0.312]\n",
      "22981 [D loss: (0.624)(R 0.638, F 0.610)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.971] [G acc: 0.188]\n",
      "22982 [D loss: (0.621)(R 0.704, F 0.538)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.912] [G acc: 0.250]\n",
      "22983 [D loss: (0.495)(R 0.497, F 0.492)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.863] [G acc: 0.375]\n",
      "22984 [D loss: (0.648)(R 0.676, F 0.620)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.535] [G acc: 0.188]\n",
      "22985 [D loss: (0.437)(R 0.601, F 0.274)] [D acc: (0.844)(0.688, 1.000)] [G loss: 2.890] [G acc: 0.125]\n",
      "22986 [D loss: (0.617)(R 0.722, F 0.512)] [D acc: (0.594)(0.500, 0.688)] [G loss: 2.524] [G acc: 0.250]\n",
      "22987 [D loss: (0.468)(R 0.561, F 0.376)] [D acc: (0.750)(0.688, 0.812)] [G loss: 7.044] [G acc: 0.125]\n",
      "22988 [D loss: (0.550)(R 0.443, F 0.658)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.480] [G acc: 0.688]\n",
      "22989 [D loss: (0.602)(R 0.608, F 0.596)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.328] [G acc: 0.812]\n",
      "22990 [D loss: (0.783)(R 0.594, F 0.972)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.877] [G acc: 0.125]\n",
      "22991 [D loss: (0.628)(R 0.616, F 0.640)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.325] [G acc: 0.750]\n",
      "22992 [D loss: (0.380)(R 0.433, F 0.327)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.363] [G acc: 0.188]\n",
      "22993 [D loss: (0.538)(R 0.637, F 0.438)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.746] [G acc: 0.562]\n",
      "22994 [D loss: (0.784)(R 0.595, F 0.973)] [D acc: (0.562)(0.625, 0.500)] [G loss: 1.400] [G acc: 0.188]\n",
      "22995 [D loss: (0.516)(R 0.525, F 0.508)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.954] [G acc: 0.375]\n",
      "22996 [D loss: (0.506)(R 0.512, F 0.501)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.920] [G acc: 0.125]\n",
      "22997 [D loss: (0.597)(R 0.745, F 0.449)] [D acc: (0.688)(0.625, 0.750)] [G loss: 2.332] [G acc: 0.125]\n",
      "22998 [D loss: (0.566)(R 0.613, F 0.519)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.099] [G acc: 0.562]\n",
      "22999 [D loss: (0.561)(R 0.590, F 0.531)] [D acc: (0.656)(0.688, 0.625)] [G loss: 2.188] [G acc: 0.125]\n",
      "23000 [D loss: (0.409)(R 0.493, F 0.325)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.728] [G acc: 0.188]\n",
      "23001 [D loss: (0.347)(R 0.477, F 0.217)] [D acc: (0.781)(0.625, 0.938)] [G loss: 4.961] [G acc: 0.000]\n",
      "23002 [D loss: (0.476)(R 0.541, F 0.410)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.895] [G acc: 0.562]\n",
      "23003 [D loss: (1.791)(R 2.793, F 0.789)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.778] [G acc: 0.438]\n",
      "23004 [D loss: (0.762)(R 0.644, F 0.880)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.653] [G acc: 0.625]\n",
      "23005 [D loss: (0.619)(R 0.570, F 0.668)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.851] [G acc: 0.250]\n",
      "23006 [D loss: (0.709)(R 0.618, F 0.799)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.783] [G acc: 0.312]\n",
      "23007 [D loss: (0.533)(R 0.505, F 0.561)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.995] [G acc: 0.250]\n",
      "23008 [D loss: (0.631)(R 0.619, F 0.642)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.992] [G acc: 0.250]\n",
      "23009 [D loss: (0.618)(R 0.524, F 0.713)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.727] [G acc: 0.500]\n",
      "23010 [D loss: (0.618)(R 0.527, F 0.709)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.764] [G acc: 0.438]\n",
      "23011 [D loss: (0.548)(R 0.550, F 0.545)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.870] [G acc: 0.312]\n",
      "23012 [D loss: (0.752)(R 0.451, F 1.053)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.898] [G acc: 0.312]\n",
      "23013 [D loss: (0.577)(R 0.665, F 0.489)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.918] [G acc: 0.250]\n",
      "23014 [D loss: (1.357)(R 2.029, F 0.685)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.815] [G acc: 0.312]\n",
      "23015 [D loss: (0.572)(R 0.573, F 0.572)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.891] [G acc: 0.312]\n",
      "23016 [D loss: (0.702)(R 0.694, F 0.709)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.751] [G acc: 0.438]\n",
      "23017 [D loss: (0.617)(R 0.692, F 0.542)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.933] [G acc: 0.312]\n",
      "23018 [D loss: (0.701)(R 0.652, F 0.749)] [D acc: (0.438)(0.500, 0.375)] [G loss: 1.123] [G acc: 0.188]\n",
      "23019 [D loss: (0.570)(R 0.633, F 0.508)] [D acc: (0.625)(0.438, 0.812)] [G loss: 1.068] [G acc: 0.250]\n",
      "23020 [D loss: (0.657)(R 0.782, F 0.533)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.760] [G acc: 0.438]\n",
      "23021 [D loss: (0.460)(R 0.513, F 0.407)] [D acc: (0.688)(0.688, 0.688)] [G loss: 2.082] [G acc: 0.250]\n",
      "23022 [D loss: (0.546)(R 0.563, F 0.529)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.847] [G acc: 0.375]\n",
      "23023 [D loss: (0.568)(R 0.564, F 0.572)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.096] [G acc: 0.438]\n",
      "23024 [D loss: (0.556)(R 0.740, F 0.371)] [D acc: (0.688)(0.438, 0.938)] [G loss: 2.631] [G acc: 0.375]\n",
      "23025 [D loss: (0.544)(R 0.550, F 0.537)] [D acc: (0.688)(0.688, 0.688)] [G loss: 5.782] [G acc: 0.250]\n",
      "23026 [D loss: (0.609)(R 0.536, F 0.682)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.505] [G acc: 0.188]\n",
      "23027 [D loss: (0.677)(R 0.534, F 0.819)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.520] [G acc: 0.750]\n",
      "23028 [D loss: (0.634)(R 0.422, F 0.846)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.672] [G acc: 0.500]\n",
      "23029 [D loss: (0.730)(R 0.700, F 0.760)] [D acc: (0.562)(0.625, 0.500)] [G loss: 1.085] [G acc: 0.125]\n",
      "23030 [D loss: (0.572)(R 0.540, F 0.605)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.834] [G acc: 0.125]\n",
      "23031 [D loss: (0.669)(R 0.613, F 0.726)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.653] [G acc: 0.562]\n",
      "23032 [D loss: (0.875)(R 0.988, F 0.763)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.658] [G acc: 0.625]\n",
      "23033 [D loss: (0.696)(R 0.514, F 0.879)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.599] [G acc: 0.625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23034 [D loss: (0.655)(R 0.621, F 0.689)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.817] [G acc: 0.250]\n",
      "23035 [D loss: (0.824)(R 0.847, F 0.802)] [D acc: (0.375)(0.312, 0.438)] [G loss: 0.642] [G acc: 0.562]\n",
      "23036 [D loss: (0.598)(R 0.657, F 0.540)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.861] [G acc: 0.188]\n",
      "23037 [D loss: (0.677)(R 0.619, F 0.734)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.873] [G acc: 0.312]\n",
      "23038 [D loss: (0.653)(R 0.587, F 0.719)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.691] [G acc: 0.438]\n",
      "23039 [D loss: (0.645)(R 0.693, F 0.597)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.498] [G acc: 0.688]\n",
      "23040 [D loss: (0.578)(R 0.599, F 0.556)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.974] [G acc: 0.125]\n",
      "23041 [D loss: (0.751)(R 0.614, F 0.888)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.513] [G acc: 0.688]\n",
      "23042 [D loss: (0.671)(R 0.655, F 0.687)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.834] [G acc: 0.312]\n",
      "23043 [D loss: (0.725)(R 0.700, F 0.749)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.619] [G acc: 0.562]\n",
      "23044 [D loss: (0.635)(R 0.809, F 0.461)] [D acc: (0.531)(0.250, 0.812)] [G loss: 1.281] [G acc: 0.188]\n",
      "23045 [D loss: (0.760)(R 0.705, F 0.816)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.751] [G acc: 0.312]\n",
      "23046 [D loss: (0.698)(R 0.621, F 0.775)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.528] [G acc: 0.688]\n",
      "23047 [D loss: (0.650)(R 0.457, F 0.843)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.749] [G acc: 0.312]\n",
      "23048 [D loss: (0.638)(R 0.619, F 0.657)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.559] [G acc: 0.625]\n",
      "23049 [D loss: (0.708)(R 0.724, F 0.692)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.956] [G acc: 0.125]\n",
      "23050 [D loss: (0.640)(R 0.647, F 0.633)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.903] [G acc: 0.188]\n",
      "23051 [D loss: (0.849)(R 0.714, F 0.984)] [D acc: (0.375)(0.500, 0.250)] [G loss: 0.882] [G acc: 0.188]\n",
      "23052 [D loss: (0.628)(R 0.728, F 0.527)] [D acc: (0.594)(0.375, 0.812)] [G loss: 1.301] [G acc: 0.312]\n",
      "23053 [D loss: (0.625)(R 0.811, F 0.439)] [D acc: (0.438)(0.250, 0.625)] [G loss: 2.360] [G acc: 0.500]\n",
      "23054 [D loss: (0.605)(R 0.651, F 0.560)] [D acc: (0.562)(0.500, 0.625)] [G loss: 2.195] [G acc: 0.125]\n",
      "23055 [D loss: (0.638)(R 0.654, F 0.623)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.926] [G acc: 0.188]\n",
      "23056 [D loss: (0.770)(R 0.623, F 0.918)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.620] [G acc: 0.562]\n",
      "23057 [D loss: (0.716)(R 0.706, F 0.725)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.718] [G acc: 0.375]\n",
      "23058 [D loss: (0.835)(R 0.660, F 1.010)] [D acc: (0.438)(0.500, 0.375)] [G loss: 1.018] [G acc: 0.312]\n",
      "23059 [D loss: (0.499)(R 0.492, F 0.505)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.796] [G acc: 0.375]\n",
      "23060 [D loss: (0.682)(R 0.595, F 0.768)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.805] [G acc: 0.312]\n",
      "23061 [D loss: (0.741)(R 0.705, F 0.778)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.901] [G acc: 0.375]\n",
      "23062 [D loss: (0.746)(R 0.680, F 0.812)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.669] [G acc: 0.500]\n",
      "23063 [D loss: (0.589)(R 0.610, F 0.568)] [D acc: (0.469)(0.375, 0.562)] [G loss: 1.046] [G acc: 0.312]\n",
      "23064 [D loss: (0.501)(R 0.521, F 0.481)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.286] [G acc: 0.125]\n",
      "23065 [D loss: (0.749)(R 0.703, F 0.796)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.608] [G acc: 0.625]\n",
      "23066 [D loss: (0.674)(R 0.559, F 0.790)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.982] [G acc: 0.188]\n",
      "23067 [D loss: (0.479)(R 0.680, F 0.279)] [D acc: (0.625)(0.312, 0.938)] [G loss: 1.497] [G acc: 0.188]\n",
      "23068 [D loss: (0.715)(R 0.746, F 0.684)] [D acc: (0.500)(0.438, 0.562)] [G loss: 1.203] [G acc: 0.250]\n",
      "23069 [D loss: (0.366)(R 0.523, F 0.210)] [D acc: (0.719)(0.562, 0.875)] [G loss: 2.743] [G acc: 0.125]\n",
      "23070 [D loss: (0.480)(R 0.617, F 0.343)] [D acc: (0.656)(0.500, 0.812)] [G loss: 3.732] [G acc: 0.312]\n",
      "23071 [D loss: (0.580)(R 0.616, F 0.544)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.771] [G acc: 0.312]\n",
      "23072 [D loss: (0.627)(R 0.551, F 0.703)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.574] [G acc: 0.562]\n",
      "23073 [D loss: (0.722)(R 0.761, F 0.682)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.769] [G acc: 0.438]\n",
      "23074 [D loss: (0.650)(R 0.513, F 0.788)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.697] [G acc: 0.375]\n",
      "23075 [D loss: (0.621)(R 0.505, F 0.737)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.876] [G acc: 0.000]\n",
      "23076 [D loss: (0.919)(R 0.522, F 1.316)] [D acc: (0.781)(0.812, 0.750)] [G loss: 3.498] [G acc: 0.188]\n",
      "23077 [D loss: (0.454)(R 0.645, F 0.262)] [D acc: (0.812)(0.625, 1.000)] [G loss: 1.626] [G acc: 0.000]\n",
      "23078 [D loss: (0.539)(R 0.713, F 0.365)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.097] [G acc: 0.188]\n",
      "23079 [D loss: (0.484)(R 0.494, F 0.473)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.532] [G acc: 0.000]\n",
      "23080 [D loss: (0.585)(R 0.646, F 0.524)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.095] [G acc: 0.312]\n",
      "23081 [D loss: (0.548)(R 0.588, F 0.509)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.766] [G acc: 0.375]\n",
      "23082 [D loss: (0.710)(R 0.653, F 0.767)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.966] [G acc: 0.188]\n",
      "23083 [D loss: (0.469)(R 0.535, F 0.404)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.256] [G acc: 0.438]\n",
      "23084 [D loss: (0.375)(R 0.478, F 0.273)] [D acc: (0.875)(0.812, 0.938)] [G loss: 2.269] [G acc: 0.062]\n",
      "23085 [D loss: (0.500)(R 0.503, F 0.497)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.012] [G acc: 0.250]\n",
      "23086 [D loss: (0.480)(R 0.470, F 0.490)] [D acc: (0.938)(0.875, 1.000)] [G loss: 0.985] [G acc: 0.188]\n",
      "23087 [D loss: (0.499)(R 0.523, F 0.475)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.954] [G acc: 0.125]\n",
      "23088 [D loss: (0.600)(R 0.510, F 0.689)] [D acc: (0.656)(0.812, 0.500)] [G loss: 1.115] [G acc: 0.250]\n",
      "23089 [D loss: (0.399)(R 0.473, F 0.326)] [D acc: (0.938)(0.938, 0.938)] [G loss: 1.589] [G acc: 0.125]\n",
      "23090 [D loss: (0.482)(R 0.592, F 0.371)] [D acc: (0.688)(0.625, 0.750)] [G loss: 2.819] [G acc: 0.000]\n",
      "23091 [D loss: (0.523)(R 0.750, F 0.297)] [D acc: (0.812)(0.625, 1.000)] [G loss: 2.556] [G acc: 0.188]\n",
      "23092 [D loss: (0.477)(R 0.547, F 0.407)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.206] [G acc: 0.375]\n",
      "23093 [D loss: (0.447)(R 0.409, F 0.484)] [D acc: (0.875)(0.938, 0.812)] [G loss: 1.412] [G acc: 0.188]\n",
      "23094 [D loss: (0.463)(R 0.420, F 0.506)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.960] [G acc: 0.250]\n",
      "23095 [D loss: (0.487)(R 0.626, F 0.349)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.848] [G acc: 0.250]\n",
      "23096 [D loss: (0.615)(R 0.680, F 0.549)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.003] [G acc: 0.188]\n",
      "23097 [D loss: (0.493)(R 0.462, F 0.524)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.293] [G acc: 0.125]\n",
      "23098 [D loss: (0.583)(R 0.550, F 0.616)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.872] [G acc: 0.375]\n",
      "23099 [D loss: (0.502)(R 0.470, F 0.533)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.133] [G acc: 0.312]\n",
      "23100 [D loss: (0.478)(R 0.673, F 0.284)] [D acc: (0.750)(0.688, 0.812)] [G loss: 2.671] [G acc: 0.000]\n",
      "23101 [D loss: (0.282)(R 0.295, F 0.269)] [D acc: (0.906)(0.875, 0.938)] [G loss: 2.979] [G acc: 0.062]\n",
      "23102 [D loss: (0.557)(R 0.801, F 0.313)] [D acc: (0.656)(0.438, 0.875)] [G loss: 1.008] [G acc: 0.062]\n",
      "23103 [D loss: (0.325)(R 0.414, F 0.236)] [D acc: (0.906)(0.812, 1.000)] [G loss: 0.892] [G acc: 0.375]\n",
      "23104 [D loss: (0.568)(R 0.507, F 0.628)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.850] [G acc: 0.188]\n",
      "23105 [D loss: (0.450)(R 0.332, F 0.567)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.119] [G acc: 0.062]\n",
      "23106 [D loss: (0.438)(R 0.516, F 0.359)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.915] [G acc: 0.125]\n",
      "23107 [D loss: (0.445)(R 0.318, F 0.572)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.982] [G acc: 0.000]\n",
      "23108 [D loss: (0.576)(R 0.632, F 0.519)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.152] [G acc: 0.125]\n",
      "23109 [D loss: (0.399)(R 0.525, F 0.272)] [D acc: (0.844)(0.688, 1.000)] [G loss: 2.654] [G acc: 0.000]\n",
      "23110 [D loss: (0.287)(R 0.454, F 0.120)] [D acc: (0.906)(0.875, 0.938)] [G loss: 2.622] [G acc: 0.188]\n",
      "23111 [D loss: (0.417)(R 0.439, F 0.395)] [D acc: (0.781)(0.875, 0.688)] [G loss: 5.012] [G acc: 0.188]\n",
      "23112 [D loss: (0.420)(R 0.458, F 0.382)] [D acc: (0.844)(0.812, 0.875)] [G loss: 4.326] [G acc: 0.188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23113 [D loss: (0.522)(R 0.562, F 0.483)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.162] [G acc: 0.125]\n",
      "23114 [D loss: (0.400)(R 0.501, F 0.299)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.508] [G acc: 0.062]\n",
      "23115 [D loss: (0.487)(R 0.601, F 0.373)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.403] [G acc: 0.000]\n",
      "23116 [D loss: (0.582)(R 0.478, F 0.685)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.248] [G acc: 0.000]\n",
      "23117 [D loss: (0.497)(R 0.434, F 0.560)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.088] [G acc: 0.062]\n",
      "23118 [D loss: (0.547)(R 0.410, F 0.685)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.212] [G acc: 0.062]\n",
      "23119 [D loss: (0.665)(R 0.777, F 0.553)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.461] [G acc: 0.062]\n",
      "23120 [D loss: (0.296)(R 0.344, F 0.247)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.402] [G acc: 0.062]\n",
      "23121 [D loss: (0.356)(R 0.470, F 0.241)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.458] [G acc: 0.000]\n",
      "23122 [D loss: (0.359)(R 0.222, F 0.495)] [D acc: (0.906)(0.938, 0.875)] [G loss: 1.176] [G acc: 0.125]\n",
      "23123 [D loss: (0.465)(R 0.476, F 0.454)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.289] [G acc: 0.062]\n",
      "23124 [D loss: (0.523)(R 0.446, F 0.600)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.116] [G acc: 0.188]\n",
      "23125 [D loss: (0.384)(R 0.314, F 0.454)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.282] [G acc: 0.125]\n",
      "23126 [D loss: (0.383)(R 0.480, F 0.287)] [D acc: (0.750)(0.625, 0.875)] [G loss: 2.208] [G acc: 0.000]\n",
      "23127 [D loss: (0.360)(R 0.332, F 0.388)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.415] [G acc: 0.125]\n",
      "23128 [D loss: (0.501)(R 0.458, F 0.543)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.206] [G acc: 0.062]\n",
      "23129 [D loss: (0.545)(R 0.604, F 0.487)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.259] [G acc: 0.062]\n",
      "23130 [D loss: (0.425)(R 0.354, F 0.496)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.149] [G acc: 0.125]\n",
      "23131 [D loss: (0.365)(R 0.476, F 0.254)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.541] [G acc: 0.188]\n",
      "23132 [D loss: (0.498)(R 0.470, F 0.527)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.152] [G acc: 0.062]\n",
      "23133 [D loss: (0.579)(R 0.768, F 0.391)] [D acc: (0.781)(0.625, 0.938)] [G loss: 2.140] [G acc: 0.250]\n",
      "23134 [D loss: (0.290)(R 0.403, F 0.177)] [D acc: (0.875)(0.750, 1.000)] [G loss: 8.904] [G acc: 0.062]\n",
      "23135 [D loss: (0.348)(R 0.560, F 0.136)] [D acc: (0.844)(0.688, 1.000)] [G loss: 5.482] [G acc: 0.062]\n",
      "23136 [D loss: (0.463)(R 0.511, F 0.414)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.132] [G acc: 0.188]\n",
      "23137 [D loss: (0.327)(R 0.431, F 0.222)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.150] [G acc: 0.250]\n",
      "23138 [D loss: (0.546)(R 0.561, F 0.531)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.018] [G acc: 0.125]\n",
      "23139 [D loss: (0.578)(R 0.673, F 0.484)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.623] [G acc: 0.125]\n",
      "23140 [D loss: (0.483)(R 0.400, F 0.567)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.527] [G acc: 0.062]\n",
      "23141 [D loss: (0.739)(R 0.700, F 0.779)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.300] [G acc: 0.125]\n",
      "23142 [D loss: (0.413)(R 0.462, F 0.364)] [D acc: (0.812)(0.750, 0.875)] [G loss: 2.594] [G acc: 0.062]\n",
      "23143 [D loss: (0.418)(R 0.450, F 0.387)] [D acc: (0.750)(0.750, 0.750)] [G loss: 7.156] [G acc: 0.250]\n",
      "23144 [D loss: (0.800)(R 1.203, F 0.396)] [D acc: (0.812)(0.750, 0.875)] [G loss: 7.879] [G acc: 0.250]\n",
      "23145 [D loss: (0.549)(R 0.539, F 0.558)] [D acc: (0.688)(0.688, 0.688)] [G loss: 4.090] [G acc: 0.250]\n",
      "23146 [D loss: (0.581)(R 0.454, F 0.707)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.628] [G acc: 0.125]\n",
      "23147 [D loss: (0.494)(R 0.497, F 0.491)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.396] [G acc: 0.250]\n",
      "23148 [D loss: (0.463)(R 0.531, F 0.396)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.438] [G acc: 0.062]\n",
      "23149 [D loss: (0.530)(R 0.442, F 0.618)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.934] [G acc: 0.438]\n",
      "23150 [D loss: (0.347)(R 0.319, F 0.376)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.072] [G acc: 0.250]\n",
      "23151 [D loss: (0.487)(R 0.420, F 0.554)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.854] [G acc: 0.438]\n",
      "23152 [D loss: (0.619)(R 0.667, F 0.571)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.628] [G acc: 0.375]\n",
      "23153 [D loss: (0.498)(R 0.500, F 0.497)] [D acc: (0.656)(0.688, 0.625)] [G loss: 2.872] [G acc: 0.188]\n",
      "23154 [D loss: (0.482)(R 0.492, F 0.473)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.190] [G acc: 0.250]\n",
      "23155 [D loss: (0.385)(R 0.560, F 0.210)] [D acc: (0.812)(0.625, 1.000)] [G loss: 1.963] [G acc: 0.375]\n",
      "23156 [D loss: (0.419)(R 0.402, F 0.435)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.314] [G acc: 0.250]\n",
      "23157 [D loss: (0.445)(R 0.489, F 0.401)] [D acc: (0.781)(0.688, 0.875)] [G loss: 2.023] [G acc: 0.062]\n",
      "23158 [D loss: (0.445)(R 0.351, F 0.539)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.101] [G acc: 0.000]\n",
      "23159 [D loss: (0.652)(R 0.644, F 0.660)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.793] [G acc: 0.500]\n",
      "23160 [D loss: (0.482)(R 0.411, F 0.554)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.928] [G acc: 0.125]\n",
      "23161 [D loss: (0.442)(R 0.552, F 0.331)] [D acc: (0.750)(0.500, 1.000)] [G loss: 1.316] [G acc: 0.062]\n",
      "23162 [D loss: (0.578)(R 0.443, F 0.712)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.232] [G acc: 0.125]\n",
      "23163 [D loss: (0.598)(R 0.742, F 0.454)] [D acc: (0.688)(0.438, 0.938)] [G loss: 2.037] [G acc: 0.000]\n",
      "23164 [D loss: (0.490)(R 0.540, F 0.439)] [D acc: (0.625)(0.562, 0.688)] [G loss: 2.064] [G acc: 0.312]\n",
      "23165 [D loss: (0.360)(R 0.519, F 0.201)] [D acc: (0.812)(0.688, 0.938)] [G loss: 7.970] [G acc: 0.188]\n",
      "23166 [D loss: (0.479)(R 0.622, F 0.336)] [D acc: (0.688)(0.500, 0.875)] [G loss: 2.317] [G acc: 0.375]\n",
      "23167 [D loss: (0.932)(R 0.352, F 1.512)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.122] [G acc: 0.562]\n",
      "23168 [D loss: (0.604)(R 0.659, F 0.549)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.836] [G acc: 0.062]\n",
      "23169 [D loss: (0.651)(R 0.570, F 0.732)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.941] [G acc: 0.188]\n",
      "23170 [D loss: (0.373)(R 0.306, F 0.440)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.281] [G acc: 0.062]\n",
      "23171 [D loss: (0.613)(R 0.692, F 0.534)] [D acc: (0.531)(0.375, 0.688)] [G loss: 1.360] [G acc: 0.000]\n",
      "23172 [D loss: (0.454)(R 0.333, F 0.575)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.082] [G acc: 0.062]\n",
      "23173 [D loss: (0.271)(R 0.238, F 0.303)] [D acc: (0.969)(0.938, 1.000)] [G loss: 1.471] [G acc: 0.250]\n",
      "23174 [D loss: (0.357)(R 0.450, F 0.264)] [D acc: (0.844)(0.812, 0.875)] [G loss: 3.077] [G acc: 0.250]\n",
      "23175 [D loss: (0.403)(R 0.707, F 0.099)] [D acc: (0.781)(0.562, 1.000)] [G loss: 8.873] [G acc: 0.000]\n",
      "23176 [D loss: (0.417)(R 0.368, F 0.465)] [D acc: (0.750)(0.812, 0.688)] [G loss: 2.169] [G acc: 0.062]\n",
      "23177 [D loss: (0.513)(R 0.512, F 0.514)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.876] [G acc: 0.500]\n",
      "23178 [D loss: (0.500)(R 0.443, F 0.557)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.052] [G acc: 0.375]\n",
      "23179 [D loss: (0.501)(R 0.504, F 0.497)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.104] [G acc: 0.062]\n",
      "23180 [D loss: (0.527)(R 0.612, F 0.443)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.175] [G acc: 0.562]\n",
      "23181 [D loss: (0.513)(R 0.366, F 0.660)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.397] [G acc: 0.125]\n",
      "23182 [D loss: (0.520)(R 0.485, F 0.555)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.369] [G acc: 0.000]\n",
      "23183 [D loss: (0.390)(R 0.446, F 0.333)] [D acc: (0.875)(0.750, 1.000)] [G loss: 2.083] [G acc: 0.062]\n",
      "23184 [D loss: (0.493)(R 0.698, F 0.288)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.389] [G acc: 0.125]\n",
      "23185 [D loss: (0.417)(R 0.454, F 0.379)] [D acc: (0.812)(0.688, 0.938)] [G loss: 2.025] [G acc: 0.062]\n",
      "23186 [D loss: (0.632)(R 0.889, F 0.376)] [D acc: (0.781)(0.562, 1.000)] [G loss: 1.990] [G acc: 0.312]\n",
      "23187 [D loss: (0.435)(R 0.340, F 0.530)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.203] [G acc: 0.188]\n",
      "23188 [D loss: (0.529)(R 0.602, F 0.456)] [D acc: (0.688)(0.500, 0.875)] [G loss: 1.090] [G acc: 0.250]\n",
      "23189 [D loss: (0.439)(R 0.228, F 0.650)] [D acc: (0.875)(0.938, 0.812)] [G loss: 1.224] [G acc: 0.250]\n",
      "23190 [D loss: (0.453)(R 0.352, F 0.555)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.011] [G acc: 0.188]\n",
      "23191 [D loss: (0.417)(R 0.349, F 0.485)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.164] [G acc: 0.062]\n",
      "23192 [D loss: (0.475)(R 0.367, F 0.583)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.078] [G acc: 0.188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23193 [D loss: (0.465)(R 0.640, F 0.290)] [D acc: (0.844)(0.688, 1.000)] [G loss: 1.153] [G acc: 0.125]\n",
      "23194 [D loss: (0.326)(R 0.321, F 0.331)] [D acc: (0.906)(0.875, 0.938)] [G loss: 1.233] [G acc: 0.062]\n",
      "23195 [D loss: (0.387)(R 0.343, F 0.430)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.206] [G acc: 0.125]\n",
      "23196 [D loss: (1.076)(R 1.549, F 0.604)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.893] [G acc: 0.312]\n",
      "23197 [D loss: (0.317)(R 0.288, F 0.346)] [D acc: (0.938)(0.938, 0.938)] [G loss: 1.412] [G acc: 0.125]\n",
      "23198 [D loss: (0.499)(R 0.622, F 0.375)] [D acc: (0.781)(0.625, 0.938)] [G loss: 3.096] [G acc: 0.312]\n",
      "23199 [D loss: (0.130)(R 0.139, F 0.122)] [D acc: (0.969)(1.000, 0.938)] [G loss: 7.058] [G acc: 0.250]\n",
      "23200 [D loss: (0.275)(R 0.356, F 0.195)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.246] [G acc: 0.250]\n",
      "23201 [D loss: (0.422)(R 0.209, F 0.636)] [D acc: (0.906)(0.938, 0.875)] [G loss: 1.492] [G acc: 0.750]\n",
      "23202 [D loss: (0.321)(R 0.392, F 0.251)] [D acc: (0.844)(0.812, 0.875)] [G loss: 3.179] [G acc: 0.125]\n",
      "23203 [D loss: (0.368)(R 0.502, F 0.234)] [D acc: (0.781)(0.688, 0.875)] [G loss: 5.161] [G acc: 0.125]\n",
      "23204 [D loss: (0.508)(R 0.583, F 0.433)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.132] [G acc: 0.125]\n",
      "23205 [D loss: (0.415)(R 0.278, F 0.551)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.336] [G acc: 0.188]\n",
      "23206 [D loss: (0.429)(R 0.317, F 0.541)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.269] [G acc: 0.062]\n",
      "23207 [D loss: (0.972)(R 0.337, F 1.607)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.378] [G acc: 0.188]\n",
      "23208 [D loss: (0.398)(R 0.347, F 0.448)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.055] [G acc: 0.250]\n",
      "23209 [D loss: (0.267)(R 0.350, F 0.185)] [D acc: (0.875)(0.812, 0.938)] [G loss: 2.284] [G acc: 0.250]\n",
      "23210 [D loss: (0.256)(R 0.355, F 0.158)] [D acc: (0.844)(0.750, 0.938)] [G loss: 3.623] [G acc: 0.062]\n",
      "23211 [D loss: (0.375)(R 0.279, F 0.471)] [D acc: (0.906)(0.875, 0.938)] [G loss: 1.271] [G acc: 0.125]\n",
      "23212 [D loss: (0.509)(R 0.562, F 0.456)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.912] [G acc: 0.312]\n",
      "23213 [D loss: (0.405)(R 0.358, F 0.452)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.156] [G acc: 0.250]\n",
      "23214 [D loss: (0.524)(R 0.572, F 0.476)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.290] [G acc: 0.188]\n",
      "23215 [D loss: (0.474)(R 0.497, F 0.450)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.801] [G acc: 0.312]\n",
      "23216 [D loss: (1.245)(R 2.063, F 0.426)] [D acc: (0.906)(0.812, 1.000)] [G loss: 1.209] [G acc: 0.125]\n",
      "23217 [D loss: (0.379)(R 0.239, F 0.519)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.035] [G acc: 0.312]\n",
      "23218 [D loss: (0.614)(R 0.570, F 0.657)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.691] [G acc: 0.125]\n",
      "23219 [D loss: (0.221)(R 0.369, F 0.072)] [D acc: (0.844)(0.688, 1.000)] [G loss: 2.230] [G acc: 0.125]\n",
      "23220 [D loss: (0.369)(R 0.436, F 0.303)] [D acc: (0.875)(0.750, 1.000)] [G loss: 1.169] [G acc: 0.188]\n",
      "23221 [D loss: (0.385)(R 0.381, F 0.390)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.063] [G acc: 0.125]\n",
      "23222 [D loss: (0.592)(R 0.554, F 0.629)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.622] [G acc: 0.000]\n",
      "23223 [D loss: (0.326)(R 0.271, F 0.380)] [D acc: (0.875)(0.812, 0.938)] [G loss: 3.664] [G acc: 0.250]\n",
      "23224 [D loss: (0.318)(R 0.304, F 0.333)] [D acc: (0.906)(0.875, 0.938)] [G loss: 2.726] [G acc: 0.062]\n",
      "23225 [D loss: (0.608)(R 0.752, F 0.463)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.178] [G acc: 0.250]\n",
      "23226 [D loss: (0.519)(R 0.540, F 0.497)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.097] [G acc: 0.188]\n",
      "23227 [D loss: (0.445)(R 0.334, F 0.557)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.076] [G acc: 0.312]\n",
      "23228 [D loss: (0.422)(R 0.281, F 0.563)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.954] [G acc: 0.188]\n",
      "23229 [D loss: (0.367)(R 0.291, F 0.442)] [D acc: (0.875)(0.875, 0.875)] [G loss: 0.557] [G acc: 0.562]\n",
      "23230 [D loss: (0.784)(R 0.334, F 1.234)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.298] [G acc: 0.000]\n",
      "23231 [D loss: (0.650)(R 0.714, F 0.587)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.186] [G acc: 0.188]\n",
      "23232 [D loss: (0.580)(R 0.579, F 0.581)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.124] [G acc: 0.188]\n",
      "23233 [D loss: (0.607)(R 0.531, F 0.682)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.988] [G acc: 0.562]\n",
      "23234 [D loss: (0.609)(R 0.568, F 0.650)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.161] [G acc: 0.250]\n",
      "23235 [D loss: (0.487)(R 0.405, F 0.569)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.520] [G acc: 0.438]\n",
      "23236 [D loss: (0.975)(R 0.396, F 1.554)] [D acc: (0.625)(0.750, 0.500)] [G loss: 5.366] [G acc: 0.125]\n",
      "23237 [D loss: (0.550)(R 0.716, F 0.384)] [D acc: (0.656)(0.500, 0.812)] [G loss: 3.202] [G acc: 0.062]\n",
      "23238 [D loss: (0.432)(R 0.512, F 0.352)] [D acc: (0.812)(0.625, 1.000)] [G loss: 1.146] [G acc: 0.125]\n",
      "23239 [D loss: (0.446)(R 0.329, F 0.562)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.091] [G acc: 0.125]\n",
      "23240 [D loss: (0.374)(R 0.199, F 0.550)] [D acc: (0.844)(0.875, 0.812)] [G loss: 0.595] [G acc: 0.562]\n",
      "23241 [D loss: (0.680)(R 0.431, F 0.928)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.173] [G acc: 0.188]\n",
      "23242 [D loss: (0.638)(R 0.872, F 0.404)] [D acc: (0.812)(0.625, 1.000)] [G loss: 0.518] [G acc: 0.625]\n",
      "23243 [D loss: (1.301)(R 1.080, F 1.522)] [D acc: (0.531)(0.500, 0.562)] [G loss: 1.149] [G acc: 0.562]\n",
      "23244 [D loss: (0.754)(R 0.837, F 0.670)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.293] [G acc: 0.125]\n",
      "23245 [D loss: (0.623)(R 1.000, F 0.247)] [D acc: (0.594)(0.250, 0.938)] [G loss: 1.794] [G acc: 0.125]\n",
      "23246 [D loss: (0.939)(R 0.546, F 1.332)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.054] [G acc: 0.250]\n",
      "23247 [D loss: (0.547)(R 0.589, F 0.504)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.046] [G acc: 0.125]\n",
      "23248 [D loss: (0.388)(R 0.314, F 0.462)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.080] [G acc: 0.625]\n",
      "23249 [D loss: (0.433)(R 0.561, F 0.304)] [D acc: (0.750)(0.562, 0.938)] [G loss: 2.222] [G acc: 0.125]\n",
      "23250 [D loss: (0.631)(R 0.522, F 0.740)] [D acc: (0.688)(0.625, 0.750)] [G loss: 2.030] [G acc: 0.062]\n",
      "23251 [D loss: (0.272)(R 0.354, F 0.190)] [D acc: (0.875)(0.750, 1.000)] [G loss: 2.258] [G acc: 0.125]\n",
      "23252 [D loss: (0.723)(R 0.830, F 0.617)] [D acc: (0.625)(0.438, 0.812)] [G loss: 1.085] [G acc: 0.188]\n",
      "23253 [D loss: (0.492)(R 0.596, F 0.389)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.321] [G acc: 0.812]\n",
      "23254 [D loss: (0.434)(R 0.528, F 0.339)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.828] [G acc: 0.438]\n",
      "23255 [D loss: (0.710)(R 0.670, F 0.749)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.852] [G acc: 0.438]\n",
      "23256 [D loss: (0.622)(R 0.562, F 0.683)] [D acc: (0.531)(0.500, 0.562)] [G loss: 1.325] [G acc: 0.000]\n",
      "23257 [D loss: (0.610)(R 0.524, F 0.696)] [D acc: (0.531)(0.562, 0.500)] [G loss: 1.140] [G acc: 0.188]\n",
      "23258 [D loss: (0.481)(R 0.452, F 0.511)] [D acc: (0.688)(0.688, 0.688)] [G loss: 7.905] [G acc: 0.062]\n",
      "23259 [D loss: (0.768)(R 0.485, F 1.052)] [D acc: (0.625)(0.750, 0.500)] [G loss: 2.464] [G acc: 0.062]\n",
      "23260 [D loss: (0.474)(R 0.486, F 0.462)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.307] [G acc: 0.375]\n",
      "23261 [D loss: (0.717)(R 0.533, F 0.901)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.595] [G acc: 0.562]\n",
      "23262 [D loss: (1.276)(R 0.431, F 2.120)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.867] [G acc: 0.188]\n",
      "23263 [D loss: (0.748)(R 0.476, F 1.021)] [D acc: (0.656)(0.625, 0.688)] [G loss: 2.682] [G acc: 0.438]\n",
      "23264 [D loss: (0.556)(R 0.691, F 0.422)] [D acc: (0.688)(0.625, 0.750)] [G loss: 3.268] [G acc: 0.125]\n",
      "23265 [D loss: (0.669)(R 0.413, F 0.924)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.762] [G acc: 0.625]\n",
      "23266 [D loss: (0.550)(R 0.462, F 0.638)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.913] [G acc: 0.375]\n",
      "23267 [D loss: (0.672)(R 0.602, F 0.742)] [D acc: (0.500)(0.625, 0.375)] [G loss: 1.071] [G acc: 0.438]\n",
      "23268 [D loss: (0.665)(R 0.771, F 0.559)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.688] [G acc: 0.625]\n",
      "23269 [D loss: (1.232)(R 0.725, F 1.740)] [D acc: (0.688)(0.562, 0.812)] [G loss: 7.239] [G acc: 0.125]\n",
      "23270 [D loss: (1.198)(R 0.602, F 1.795)] [D acc: (0.656)(0.562, 0.750)] [G loss: 2.694] [G acc: 0.375]\n",
      "23271 [D loss: (0.740)(R 0.540, F 0.940)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.497] [G acc: 0.562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23272 [D loss: (0.938)(R 0.460, F 1.415)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.785] [G acc: 0.375]\n",
      "23273 [D loss: (0.616)(R 0.530, F 0.703)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.899] [G acc: 0.438]\n",
      "23274 [D loss: (0.685)(R 0.510, F 0.860)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.761] [G acc: 0.500]\n",
      "23275 [D loss: (0.774)(R 0.672, F 0.875)] [D acc: (0.500)(0.562, 0.438)] [G loss: 1.042] [G acc: 0.188]\n",
      "23276 [D loss: (0.877)(R 0.413, F 1.341)] [D acc: (0.688)(0.812, 0.562)] [G loss: 1.195] [G acc: 0.188]\n",
      "23277 [D loss: (0.673)(R 0.611, F 0.736)] [D acc: (0.531)(0.500, 0.562)] [G loss: 1.256] [G acc: 0.062]\n",
      "23278 [D loss: (0.425)(R 0.555, F 0.294)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.871] [G acc: 0.125]\n",
      "23279 [D loss: (0.488)(R 0.400, F 0.575)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.325] [G acc: 0.188]\n",
      "23280 [D loss: (0.581)(R 0.734, F 0.428)] [D acc: (0.531)(0.375, 0.688)] [G loss: 1.212] [G acc: 0.312]\n",
      "23281 [D loss: (0.597)(R 0.601, F 0.593)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.849] [G acc: 0.312]\n",
      "23282 [D loss: (0.420)(R 0.502, F 0.338)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.851] [G acc: 0.188]\n",
      "23283 [D loss: (0.436)(R 0.572, F 0.299)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.207] [G acc: 0.125]\n",
      "23284 [D loss: (0.776)(R 0.907, F 0.645)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.690] [G acc: 0.438]\n",
      "23285 [D loss: (0.464)(R 0.407, F 0.522)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.945] [G acc: 0.125]\n",
      "23286 [D loss: (0.512)(R 0.352, F 0.673)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.818] [G acc: 0.312]\n",
      "23287 [D loss: (0.504)(R 0.497, F 0.511)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.972] [G acc: 0.062]\n",
      "23288 [D loss: (0.614)(R 0.683, F 0.544)] [D acc: (0.781)(0.562, 1.000)] [G loss: 0.816] [G acc: 0.188]\n",
      "23289 [D loss: (0.530)(R 0.516, F 0.544)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.357] [G acc: 0.062]\n",
      "23290 [D loss: (0.349)(R 0.372, F 0.327)] [D acc: (0.938)(0.875, 1.000)] [G loss: 2.779] [G acc: 0.375]\n",
      "23291 [D loss: (0.775)(R 0.340, F 1.210)] [D acc: (0.781)(0.875, 0.688)] [G loss: 3.319] [G acc: 0.312]\n",
      "23292 [D loss: (0.428)(R 0.662, F 0.195)] [D acc: (0.750)(0.562, 0.938)] [G loss: 4.063] [G acc: 0.062]\n",
      "23293 [D loss: (0.708)(R 0.612, F 0.804)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.617] [G acc: 0.562]\n",
      "23294 [D loss: (1.012)(R 0.741, F 1.283)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.867] [G acc: 0.375]\n",
      "23295 [D loss: (0.498)(R 0.507, F 0.490)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.941] [G acc: 0.188]\n",
      "23296 [D loss: (0.558)(R 0.510, F 0.605)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.966] [G acc: 0.438]\n",
      "23297 [D loss: (0.538)(R 0.492, F 0.584)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.684] [G acc: 0.438]\n",
      "23298 [D loss: (0.622)(R 0.517, F 0.727)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.835] [G acc: 0.250]\n",
      "23299 [D loss: (0.447)(R 0.476, F 0.419)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.699] [G acc: 0.312]\n",
      "23300 [D loss: (0.502)(R 0.403, F 0.600)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.293] [G acc: 0.062]\n",
      "23301 [D loss: (0.484)(R 0.522, F 0.446)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.125] [G acc: 0.062]\n",
      "23302 [D loss: (0.603)(R 0.565, F 0.642)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.168] [G acc: 0.188]\n",
      "23303 [D loss: (0.444)(R 0.489, F 0.398)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.101] [G acc: 0.375]\n",
      "23304 [D loss: (0.641)(R 0.766, F 0.516)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.147] [G acc: 0.250]\n",
      "23305 [D loss: (0.502)(R 0.430, F 0.575)] [D acc: (0.781)(0.875, 0.688)] [G loss: 2.248] [G acc: 0.188]\n",
      "23306 [D loss: (0.547)(R 0.814, F 0.280)] [D acc: (0.625)(0.312, 0.938)] [G loss: 4.074] [G acc: 0.188]\n",
      "23307 [D loss: (0.783)(R 1.205, F 0.360)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.319] [G acc: 0.062]\n",
      "23308 [D loss: (0.392)(R 0.253, F 0.531)] [D acc: (0.906)(0.938, 0.875)] [G loss: 1.271] [G acc: 0.188]\n",
      "23309 [D loss: (0.427)(R 0.561, F 0.293)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.416] [G acc: 0.000]\n",
      "23310 [D loss: (0.462)(R 0.459, F 0.466)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.074] [G acc: 0.312]\n",
      "23311 [D loss: (0.658)(R 0.736, F 0.580)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.065] [G acc: 0.125]\n",
      "23312 [D loss: (0.412)(R 0.352, F 0.473)] [D acc: (0.781)(0.750, 0.812)] [G loss: 2.914] [G acc: 0.375]\n",
      "23313 [D loss: (0.563)(R 0.637, F 0.490)] [D acc: (0.688)(0.562, 0.812)] [G loss: 3.347] [G acc: 0.062]\n",
      "23314 [D loss: (1.638)(R 0.320, F 2.955)] [D acc: (0.719)(0.875, 0.562)] [G loss: 1.293] [G acc: 0.625]\n",
      "23315 [D loss: (1.788)(R 0.319, F 3.257)] [D acc: (0.844)(1.000, 0.688)] [G loss: 1.059] [G acc: 0.750]\n",
      "23316 [D loss: (1.782)(R 0.419, F 3.145)] [D acc: (0.594)(0.750, 0.438)] [G loss: 1.014] [G acc: 0.438]\n",
      "23317 [D loss: (1.679)(R 0.412, F 2.945)] [D acc: (0.719)(0.812, 0.625)] [G loss: 2.271] [G acc: 0.312]\n",
      "23318 [D loss: (0.547)(R 0.663, F 0.431)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.966] [G acc: 0.438]\n",
      "23319 [D loss: (0.437)(R 0.407, F 0.468)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.919] [G acc: 0.125]\n",
      "23320 [D loss: (0.795)(R 0.618, F 0.972)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.789] [G acc: 0.000]\n",
      "23321 [D loss: (0.447)(R 0.471, F 0.422)] [D acc: (0.781)(0.750, 0.812)] [G loss: 4.299] [G acc: 0.188]\n",
      "23322 [D loss: (0.832)(R 0.675, F 0.988)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.807] [G acc: 0.375]\n",
      "23323 [D loss: (0.431)(R 0.379, F 0.483)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.177] [G acc: 0.312]\n",
      "23324 [D loss: (0.600)(R 0.754, F 0.445)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.254] [G acc: 0.250]\n",
      "23325 [D loss: (0.546)(R 0.451, F 0.640)] [D acc: (0.719)(0.875, 0.562)] [G loss: 1.087] [G acc: 0.125]\n",
      "23326 [D loss: (0.471)(R 0.462, F 0.480)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.093] [G acc: 0.125]\n",
      "23327 [D loss: (0.566)(R 0.656, F 0.477)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.780] [G acc: 0.312]\n",
      "23328 [D loss: (0.641)(R 0.716, F 0.565)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.924] [G acc: 0.250]\n",
      "23329 [D loss: (0.521)(R 0.501, F 0.541)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.636] [G acc: 0.250]\n",
      "23330 [D loss: (0.270)(R 0.463, F 0.078)] [D acc: (0.812)(0.688, 0.938)] [G loss: 6.823] [G acc: 0.062]\n",
      "23331 [D loss: (0.870)(R 0.634, F 1.107)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.159] [G acc: 0.125]\n",
      "23332 [D loss: (0.404)(R 0.362, F 0.445)] [D acc: (0.969)(0.938, 1.000)] [G loss: 1.338] [G acc: 0.125]\n",
      "23333 [D loss: (0.691)(R 0.613, F 0.769)] [D acc: (0.500)(0.562, 0.438)] [G loss: 1.038] [G acc: 0.188]\n",
      "23334 [D loss: (0.479)(R 0.390, F 0.569)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.197] [G acc: 0.188]\n",
      "23335 [D loss: (0.489)(R 0.370, F 0.607)] [D acc: (0.844)(0.938, 0.750)] [G loss: 0.903] [G acc: 0.375]\n",
      "23336 [D loss: (0.443)(R 0.334, F 0.552)] [D acc: (0.906)(1.000, 0.812)] [G loss: 1.112] [G acc: 0.312]\n",
      "23337 [D loss: (0.390)(R 0.568, F 0.213)] [D acc: (0.875)(0.750, 1.000)] [G loss: 1.565] [G acc: 0.312]\n",
      "23338 [D loss: (0.421)(R 0.393, F 0.449)] [D acc: (0.812)(0.750, 0.875)] [G loss: 2.607] [G acc: 0.250]\n",
      "23339 [D loss: (0.326)(R 0.448, F 0.205)] [D acc: (0.875)(0.750, 1.000)] [G loss: 3.586] [G acc: 0.000]\n",
      "23340 [D loss: (0.567)(R 0.586, F 0.549)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.043] [G acc: 0.375]\n",
      "23341 [D loss: (0.658)(R 0.646, F 0.669)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.913] [G acc: 0.375]\n",
      "23342 [D loss: (0.434)(R 0.289, F 0.580)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.837] [G acc: 0.250]\n",
      "23343 [D loss: (0.530)(R 0.459, F 0.601)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.990] [G acc: 0.062]\n",
      "23344 [D loss: (0.468)(R 0.443, F 0.493)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.981] [G acc: 0.438]\n",
      "23345 [D loss: (0.852)(R 1.081, F 0.623)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.985] [G acc: 0.125]\n",
      "23346 [D loss: (0.559)(R 0.466, F 0.652)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.066] [G acc: 0.188]\n",
      "23347 [D loss: (0.539)(R 0.566, F 0.512)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.062] [G acc: 0.125]\n",
      "23348 [D loss: (0.845)(R 0.372, F 1.318)] [D acc: (0.688)(0.812, 0.562)] [G loss: 1.225] [G acc: 0.250]\n",
      "23349 [D loss: (0.570)(R 0.654, F 0.486)] [D acc: (0.625)(0.375, 0.875)] [G loss: 1.170] [G acc: 0.062]\n",
      "23350 [D loss: (0.426)(R 0.370, F 0.483)] [D acc: (0.906)(0.875, 0.938)] [G loss: 1.185] [G acc: 0.125]\n",
      "23351 [D loss: (0.660)(R 0.746, F 0.573)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.859] [G acc: 0.438]\n",
      "23352 [D loss: (0.570)(R 0.548, F 0.591)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.914] [G acc: 0.250]\n",
      "23353 [D loss: (0.481)(R 0.423, F 0.539)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.153] [G acc: 0.188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23354 [D loss: (0.511)(R 0.440, F 0.582)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.257] [G acc: 0.000]\n",
      "23355 [D loss: (0.466)(R 0.443, F 0.489)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.969] [G acc: 0.188]\n",
      "23356 [D loss: (0.655)(R 0.444, F 0.866)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.133] [G acc: 0.188]\n",
      "23357 [D loss: (0.581)(R 0.563, F 0.598)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.105] [G acc: 0.312]\n",
      "23358 [D loss: (0.569)(R 0.645, F 0.494)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.923] [G acc: 0.375]\n",
      "23359 [D loss: (0.497)(R 0.431, F 0.563)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.128] [G acc: 0.188]\n",
      "23360 [D loss: (0.646)(R 0.839, F 0.453)] [D acc: (0.688)(0.500, 0.875)] [G loss: 1.762] [G acc: 0.312]\n",
      "23361 [D loss: (0.430)(R 0.616, F 0.243)] [D acc: (0.781)(0.562, 1.000)] [G loss: 2.355] [G acc: 0.000]\n",
      "23362 [D loss: (0.427)(R 0.405, F 0.450)] [D acc: (0.875)(0.750, 1.000)] [G loss: 1.395] [G acc: 0.062]\n",
      "23363 [D loss: (0.461)(R 0.522, F 0.400)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.471] [G acc: 0.188]\n",
      "23364 [D loss: (0.629)(R 0.667, F 0.591)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.021] [G acc: 0.312]\n",
      "23365 [D loss: (0.502)(R 0.456, F 0.547)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.863] [G acc: 0.125]\n",
      "23366 [D loss: (0.425)(R 0.736, F 0.114)] [D acc: (0.781)(0.562, 1.000)] [G loss: 3.833] [G acc: 0.125]\n",
      "23367 [D loss: (0.690)(R 0.413, F 0.968)] [D acc: (0.750)(0.750, 0.750)] [G loss: 3.958] [G acc: 0.188]\n",
      "23368 [D loss: (0.350)(R 0.478, F 0.222)] [D acc: (0.844)(0.750, 0.938)] [G loss: 9.577] [G acc: 0.062]\n",
      "23369 [D loss: (0.418)(R 0.556, F 0.281)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.837] [G acc: 0.062]\n",
      "23370 [D loss: (0.598)(R 0.619, F 0.577)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.809] [G acc: 0.438]\n",
      "23371 [D loss: (0.556)(R 0.527, F 0.586)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.659] [G acc: 0.438]\n",
      "23372 [D loss: (0.861)(R 0.246, F 1.475)] [D acc: (0.750)(0.938, 0.562)] [G loss: 0.999] [G acc: 0.250]\n",
      "23373 [D loss: (0.650)(R 0.496, F 0.804)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.507] [G acc: 0.250]\n",
      "23374 [D loss: (0.711)(R 0.964, F 0.458)] [D acc: (0.594)(0.375, 0.812)] [G loss: 1.450] [G acc: 0.062]\n",
      "23375 [D loss: (0.740)(R 0.786, F 0.693)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.329] [G acc: 0.125]\n",
      "23376 [D loss: (0.813)(R 0.596, F 1.029)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.469] [G acc: 0.000]\n",
      "23377 [D loss: (0.408)(R 0.674, F 0.141)] [D acc: (0.750)(0.562, 0.938)] [G loss: 2.539] [G acc: 0.125]\n",
      "23378 [D loss: (0.538)(R 0.887, F 0.189)] [D acc: (0.688)(0.375, 1.000)] [G loss: 2.571] [G acc: 0.125]\n",
      "23379 [D loss: (0.537)(R 0.761, F 0.313)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.006] [G acc: 0.250]\n",
      "23380 [D loss: (0.988)(R 0.596, F 1.380)] [D acc: (0.531)(0.500, 0.562)] [G loss: 1.079] [G acc: 0.125]\n",
      "23381 [D loss: (0.546)(R 0.646, F 0.446)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.185] [G acc: 0.062]\n",
      "23382 [D loss: (0.627)(R 0.741, F 0.514)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.081] [G acc: 0.125]\n",
      "23383 [D loss: (0.533)(R 0.567, F 0.499)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.827] [G acc: 0.375]\n",
      "23384 [D loss: (0.658)(R 0.750, F 0.565)] [D acc: (0.594)(0.375, 0.812)] [G loss: 1.075] [G acc: 0.188]\n",
      "23385 [D loss: (0.508)(R 0.438, F 0.578)] [D acc: (0.781)(0.812, 0.750)] [G loss: 3.306] [G acc: 0.375]\n",
      "23386 [D loss: (0.707)(R 0.583, F 0.831)] [D acc: (0.656)(0.625, 0.688)] [G loss: 2.475] [G acc: 0.125]\n",
      "23387 [D loss: (0.403)(R 0.530, F 0.277)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.452] [G acc: 0.062]\n",
      "23388 [D loss: (0.829)(R 0.861, F 0.797)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.355] [G acc: 0.125]\n",
      "23389 [D loss: (0.995)(R 0.629, F 1.361)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.985] [G acc: 0.188]\n",
      "23390 [D loss: (0.718)(R 0.661, F 0.776)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.054] [G acc: 0.500]\n",
      "23391 [D loss: (0.492)(R 0.493, F 0.492)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.077] [G acc: 0.125]\n",
      "23392 [D loss: (0.941)(R 0.845, F 1.037)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.956] [G acc: 0.188]\n",
      "23393 [D loss: (0.780)(R 0.640, F 0.920)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.053] [G acc: 0.250]\n",
      "23394 [D loss: (1.254)(R 0.961, F 1.548)] [D acc: (0.562)(0.438, 0.688)] [G loss: 1.194] [G acc: 0.125]\n",
      "23395 [D loss: (0.656)(R 0.487, F 0.826)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.295] [G acc: 0.125]\n",
      "23396 [D loss: (0.594)(R 0.551, F 0.638)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.230] [G acc: 0.125]\n",
      "23397 [D loss: (0.753)(R 0.579, F 0.927)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.837] [G acc: 0.375]\n",
      "23398 [D loss: (0.680)(R 0.647, F 0.713)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.236] [G acc: 0.125]\n",
      "23399 [D loss: (0.462)(R 0.570, F 0.355)] [D acc: (0.781)(0.625, 0.938)] [G loss: 2.348] [G acc: 0.250]\n",
      "23400 [D loss: (0.738)(R 1.060, F 0.415)] [D acc: (0.688)(0.438, 0.938)] [G loss: 2.406] [G acc: 0.000]\n",
      "23401 [D loss: (1.044)(R 0.669, F 1.418)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.989] [G acc: 0.125]\n",
      "23402 [D loss: (0.681)(R 1.048, F 0.314)] [D acc: (0.594)(0.250, 0.938)] [G loss: 1.579] [G acc: 0.062]\n",
      "23403 [D loss: (0.591)(R 0.801, F 0.381)] [D acc: (0.688)(0.438, 0.938)] [G loss: 1.298] [G acc: 0.125]\n",
      "23404 [D loss: (0.703)(R 0.731, F 0.675)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.968] [G acc: 0.312]\n",
      "23405 [D loss: (0.606)(R 0.362, F 0.851)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.181] [G acc: 0.312]\n",
      "23406 [D loss: (0.501)(R 0.735, F 0.267)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.356] [G acc: 0.188]\n",
      "23407 [D loss: (0.608)(R 0.450, F 0.766)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.141] [G acc: 0.188]\n",
      "23408 [D loss: (0.600)(R 0.583, F 0.618)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.103] [G acc: 0.188]\n",
      "23409 [D loss: (0.727)(R 0.543, F 0.911)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.200] [G acc: 0.062]\n",
      "23410 [D loss: (0.559)(R 0.778, F 0.341)] [D acc: (0.719)(0.438, 1.000)] [G loss: 0.986] [G acc: 0.125]\n",
      "23411 [D loss: (0.475)(R 0.469, F 0.482)] [D acc: (0.750)(0.625, 0.875)] [G loss: 2.100] [G acc: 0.438]\n",
      "23412 [D loss: (0.412)(R 0.556, F 0.268)] [D acc: (0.875)(0.750, 1.000)] [G loss: 2.624] [G acc: 0.062]\n",
      "23413 [D loss: (0.733)(R 0.742, F 0.724)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.506] [G acc: 0.188]\n",
      "23414 [D loss: (0.467)(R 0.615, F 0.319)] [D acc: (0.781)(0.625, 0.938)] [G loss: 6.245] [G acc: 0.125]\n",
      "23415 [D loss: (0.649)(R 0.807, F 0.492)] [D acc: (0.719)(0.625, 0.812)] [G loss: 2.988] [G acc: 0.125]\n",
      "23416 [D loss: (0.644)(R 0.756, F 0.532)] [D acc: (0.719)(0.500, 0.938)] [G loss: 1.026] [G acc: 0.000]\n",
      "23417 [D loss: (0.485)(R 0.515, F 0.456)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.057] [G acc: 0.062]\n",
      "23418 [D loss: (0.542)(R 0.625, F 0.459)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.075] [G acc: 0.062]\n",
      "23419 [D loss: (0.525)(R 0.551, F 0.500)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.992] [G acc: 0.250]\n",
      "23420 [D loss: (0.672)(R 0.692, F 0.652)] [D acc: (0.562)(0.375, 0.750)] [G loss: 1.040] [G acc: 0.188]\n",
      "23421 [D loss: (0.510)(R 0.530, F 0.491)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.072] [G acc: 0.188]\n",
      "23422 [D loss: (0.582)(R 0.631, F 0.533)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.991] [G acc: 0.438]\n",
      "23423 [D loss: (0.522)(R 0.620, F 0.425)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.053] [G acc: 0.250]\n",
      "23424 [D loss: (0.632)(R 0.651, F 0.614)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.961] [G acc: 0.438]\n",
      "23425 [D loss: (0.431)(R 0.507, F 0.355)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.927] [G acc: 0.062]\n",
      "23426 [D loss: (0.442)(R 0.569, F 0.315)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.460] [G acc: 0.062]\n",
      "23427 [D loss: (0.457)(R 0.505, F 0.409)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.486] [G acc: 0.000]\n",
      "23428 [D loss: (0.613)(R 0.721, F 0.506)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.243] [G acc: 0.188]\n",
      "23429 [D loss: (0.534)(R 0.638, F 0.430)] [D acc: (0.656)(0.438, 0.875)] [G loss: 2.346] [G acc: 0.062]\n",
      "23430 [D loss: (0.561)(R 0.536, F 0.587)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.230] [G acc: 0.062]\n",
      "23431 [D loss: (0.795)(R 0.962, F 0.627)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.963] [G acc: 0.125]\n",
      "23432 [D loss: (0.602)(R 0.587, F 0.618)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.917] [G acc: 0.312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23433 [D loss: (0.804)(R 0.656, F 0.952)] [D acc: (0.469)(0.375, 0.562)] [G loss: 1.100] [G acc: 0.188]\n",
      "23434 [D loss: (0.578)(R 0.648, F 0.508)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.640] [G acc: 0.188]\n",
      "23435 [D loss: (0.502)(R 0.377, F 0.627)] [D acc: (0.875)(0.938, 0.812)] [G loss: 1.524] [G acc: 0.125]\n",
      "23436 [D loss: (0.338)(R 0.328, F 0.348)] [D acc: (0.938)(0.938, 0.938)] [G loss: 1.343] [G acc: 0.125]\n",
      "23437 [D loss: (0.521)(R 0.548, F 0.494)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.111] [G acc: 0.125]\n",
      "23438 [D loss: (0.467)(R 0.492, F 0.441)] [D acc: (0.812)(0.750, 0.875)] [G loss: 2.768] [G acc: 0.188]\n",
      "23439 [D loss: (0.386)(R 0.478, F 0.294)] [D acc: (0.750)(0.625, 0.875)] [G loss: 2.786] [G acc: 0.062]\n",
      "23440 [D loss: (0.433)(R 0.328, F 0.538)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.439] [G acc: 0.062]\n",
      "23441 [D loss: (0.540)(R 0.585, F 0.495)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.806] [G acc: 0.500]\n",
      "23442 [D loss: (0.614)(R 0.619, F 0.608)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.927] [G acc: 0.250]\n",
      "23443 [D loss: (0.617)(R 0.682, F 0.552)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.453] [G acc: 0.875]\n",
      "23444 [D loss: (0.593)(R 0.638, F 0.548)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.191] [G acc: 0.125]\n",
      "23445 [D loss: (0.492)(R 0.476, F 0.509)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.559] [G acc: 0.250]\n",
      "23446 [D loss: (0.486)(R 0.431, F 0.541)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.888] [G acc: 0.188]\n",
      "23447 [D loss: (0.530)(R 0.410, F 0.650)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.148] [G acc: 0.375]\n",
      "23448 [D loss: (0.489)(R 0.555, F 0.423)] [D acc: (0.688)(0.625, 0.750)] [G loss: 2.381] [G acc: 0.250]\n",
      "23449 [D loss: (0.730)(R 0.486, F 0.975)] [D acc: (0.781)(0.750, 0.812)] [G loss: 9.517] [G acc: 0.125]\n",
      "23450 [D loss: (0.394)(R 0.642, F 0.145)] [D acc: (0.812)(0.625, 1.000)] [G loss: 3.259] [G acc: 0.188]\n",
      "23451 [D loss: (0.434)(R 0.470, F 0.398)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.470] [G acc: 0.125]\n",
      "23452 [D loss: (0.614)(R 0.509, F 0.720)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.720] [G acc: 0.250]\n",
      "23453 [D loss: (0.490)(R 0.557, F 0.422)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.262] [G acc: 0.062]\n",
      "23454 [D loss: (0.452)(R 0.473, F 0.431)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.878] [G acc: 0.500]\n",
      "23455 [D loss: (0.525)(R 0.489, F 0.561)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.079] [G acc: 0.375]\n",
      "23456 [D loss: (0.443)(R 0.624, F 0.263)] [D acc: (0.781)(0.625, 0.938)] [G loss: 2.631] [G acc: 0.125]\n",
      "23457 [D loss: (0.582)(R 0.279, F 0.885)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.700] [G acc: 0.500]\n",
      "23458 [D loss: (0.665)(R 0.639, F 0.691)] [D acc: (0.562)(0.500, 0.625)] [G loss: 1.113] [G acc: 0.188]\n",
      "23459 [D loss: (0.516)(R 0.444, F 0.588)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.761] [G acc: 0.125]\n",
      "23460 [D loss: (0.518)(R 0.560, F 0.476)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.689] [G acc: 0.438]\n",
      "23461 [D loss: (0.587)(R 0.520, F 0.654)] [D acc: (0.688)(0.625, 0.750)] [G loss: 2.049] [G acc: 0.312]\n",
      "23462 [D loss: (0.587)(R 0.785, F 0.389)] [D acc: (0.750)(0.625, 0.875)] [G loss: 3.760] [G acc: 0.188]\n",
      "23463 [D loss: (0.429)(R 0.479, F 0.378)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.891] [G acc: 0.000]\n",
      "23464 [D loss: (0.450)(R 0.372, F 0.528)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.985] [G acc: 0.312]\n",
      "23465 [D loss: (0.681)(R 0.560, F 0.802)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.878] [G acc: 0.312]\n",
      "23466 [D loss: (0.450)(R 0.402, F 0.497)] [D acc: (0.906)(0.938, 0.875)] [G loss: 1.578] [G acc: 0.250]\n",
      "23467 [D loss: (0.633)(R 0.757, F 0.509)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.295] [G acc: 0.312]\n",
      "23468 [D loss: (0.790)(R 0.803, F 0.776)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.896] [G acc: 0.188]\n",
      "23469 [D loss: (0.574)(R 0.588, F 0.561)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.399] [G acc: 0.188]\n",
      "23470 [D loss: (0.418)(R 0.599, F 0.236)] [D acc: (0.750)(0.688, 0.812)] [G loss: 2.453] [G acc: 0.125]\n",
      "23471 [D loss: (0.363)(R 0.330, F 0.397)] [D acc: (0.875)(0.938, 0.812)] [G loss: 0.858] [G acc: 0.312]\n",
      "23472 [D loss: (0.520)(R 0.511, F 0.529)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.077] [G acc: 0.312]\n",
      "23473 [D loss: (0.549)(R 0.552, F 0.545)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.054] [G acc: 0.062]\n",
      "23474 [D loss: (0.464)(R 0.422, F 0.506)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.042] [G acc: 0.375]\n",
      "23475 [D loss: (0.581)(R 0.571, F 0.590)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.169] [G acc: 0.125]\n",
      "23476 [D loss: (0.532)(R 0.610, F 0.453)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.045] [G acc: 0.188]\n",
      "23477 [D loss: (0.492)(R 0.565, F 0.418)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.076] [G acc: 0.312]\n",
      "23478 [D loss: (0.495)(R 0.586, F 0.404)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.123] [G acc: 0.312]\n",
      "23479 [D loss: (0.620)(R 0.626, F 0.614)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.744] [G acc: 0.188]\n",
      "23480 [D loss: (0.529)(R 0.482, F 0.576)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.956] [G acc: 0.312]\n",
      "23481 [D loss: (1.075)(R 1.565, F 0.584)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.961] [G acc: 0.188]\n",
      "23482 [D loss: (0.492)(R 0.446, F 0.539)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.208] [G acc: 0.062]\n",
      "23483 [D loss: (0.623)(R 0.552, F 0.694)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.082] [G acc: 0.125]\n",
      "23484 [D loss: (0.381)(R 0.252, F 0.510)] [D acc: (0.938)(1.000, 0.875)] [G loss: 0.886] [G acc: 0.250]\n",
      "23485 [D loss: (0.723)(R 0.527, F 0.919)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.899] [G acc: 0.250]\n",
      "23486 [D loss: (0.460)(R 0.441, F 0.478)] [D acc: (0.875)(0.812, 0.938)] [G loss: 0.924] [G acc: 0.188]\n",
      "23487 [D loss: (0.475)(R 0.300, F 0.650)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.068] [G acc: 0.125]\n",
      "23488 [D loss: (0.421)(R 0.517, F 0.325)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.579] [G acc: 0.125]\n",
      "23489 [D loss: (0.555)(R 0.482, F 0.628)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.182] [G acc: 0.125]\n",
      "23490 [D loss: (0.478)(R 0.549, F 0.406)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.230] [G acc: 0.250]\n",
      "23491 [D loss: (0.307)(R 0.336, F 0.278)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.564] [G acc: 0.125]\n",
      "23492 [D loss: (0.628)(R 0.596, F 0.661)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.562] [G acc: 0.188]\n",
      "23493 [D loss: (0.475)(R 0.538, F 0.411)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.357] [G acc: 0.250]\n",
      "23494 [D loss: (0.584)(R 0.512, F 0.657)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.773] [G acc: 0.062]\n",
      "23495 [D loss: (0.425)(R 0.310, F 0.540)] [D acc: (0.844)(0.938, 0.750)] [G loss: 1.922] [G acc: 0.250]\n",
      "23496 [D loss: (0.490)(R 0.626, F 0.354)] [D acc: (0.688)(0.562, 0.812)] [G loss: 4.396] [G acc: 0.125]\n",
      "23497 [D loss: (0.568)(R 0.370, F 0.767)] [D acc: (0.688)(0.812, 0.562)] [G loss: 3.654] [G acc: 0.125]\n",
      "23498 [D loss: (0.585)(R 0.385, F 0.785)] [D acc: (0.719)(0.875, 0.562)] [G loss: 1.082] [G acc: 0.250]\n",
      "23499 [D loss: (0.630)(R 0.501, F 0.759)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.962] [G acc: 0.438]\n",
      "23500 [D loss: (0.535)(R 0.436, F 0.634)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.057] [G acc: 0.125]\n",
      "23501 [D loss: (0.524)(R 0.328, F 0.721)] [D acc: (0.688)(0.812, 0.562)] [G loss: 1.007] [G acc: 0.188]\n",
      "23502 [D loss: (0.472)(R 0.442, F 0.502)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.838] [G acc: 0.375]\n",
      "23503 [D loss: (0.596)(R 0.633, F 0.559)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.871] [G acc: 0.312]\n",
      "23504 [D loss: (0.529)(R 0.509, F 0.549)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.613] [G acc: 0.562]\n",
      "23505 [D loss: (0.608)(R 0.634, F 0.582)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.184] [G acc: 0.500]\n",
      "23506 [D loss: (0.515)(R 0.515, F 0.516)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.976] [G acc: 0.250]\n",
      "23507 [D loss: (0.582)(R 0.424, F 0.741)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.140] [G acc: 0.188]\n",
      "23508 [D loss: (0.654)(R 0.425, F 0.882)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.115] [G acc: 0.375]\n",
      "23509 [D loss: (0.652)(R 0.588, F 0.716)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.252] [G acc: 0.125]\n",
      "23510 [D loss: (0.741)(R 0.691, F 0.792)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.006] [G acc: 0.250]\n",
      "23511 [D loss: (0.596)(R 0.524, F 0.669)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.191] [G acc: 0.062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23512 [D loss: (0.937)(R 1.014, F 0.861)] [D acc: (0.438)(0.250, 0.625)] [G loss: 1.032] [G acc: 0.125]\n",
      "23513 [D loss: (0.633)(R 0.520, F 0.747)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.030] [G acc: 0.125]\n",
      "23514 [D loss: (0.457)(R 0.481, F 0.433)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.892] [G acc: 0.375]\n",
      "23515 [D loss: (0.462)(R 0.578, F 0.347)] [D acc: (0.750)(0.562, 0.938)] [G loss: 2.589] [G acc: 0.000]\n",
      "23516 [D loss: (0.547)(R 0.646, F 0.449)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.652] [G acc: 0.188]\n",
      "23517 [D loss: (0.777)(R 0.751, F 0.802)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.577] [G acc: 0.562]\n",
      "23518 [D loss: (1.061)(R 0.651, F 1.471)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.652] [G acc: 0.500]\n",
      "23519 [D loss: (1.011)(R 0.993, F 1.029)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.904] [G acc: 0.312]\n",
      "23520 [D loss: (0.565)(R 0.586, F 0.544)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.860] [G acc: 0.312]\n",
      "23521 [D loss: (0.872)(R 0.689, F 1.054)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.502] [G acc: 0.625]\n",
      "23522 [D loss: (0.620)(R 0.674, F 0.566)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.481] [G acc: 0.688]\n",
      "23523 [D loss: (1.946)(R 2.945, F 0.946)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.885] [G acc: 0.125]\n",
      "23524 [D loss: (0.557)(R 0.523, F 0.591)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.946] [G acc: 0.250]\n",
      "23525 [D loss: (0.697)(R 0.564, F 0.829)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.916] [G acc: 0.250]\n",
      "23526 [D loss: (0.562)(R 0.512, F 0.612)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.820] [G acc: 0.312]\n",
      "23527 [D loss: (0.664)(R 0.680, F 0.648)] [D acc: (0.594)(0.438, 0.750)] [G loss: 1.171] [G acc: 0.125]\n",
      "23528 [D loss: (0.424)(R 0.538, F 0.309)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.212] [G acc: 0.062]\n",
      "23529 [D loss: (0.646)(R 0.674, F 0.618)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.681] [G acc: 0.562]\n",
      "23530 [D loss: (0.574)(R 0.855, F 0.293)] [D acc: (0.562)(0.312, 0.812)] [G loss: 2.166] [G acc: 0.312]\n",
      "23531 [D loss: (0.415)(R 0.592, F 0.239)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.817] [G acc: 0.062]\n",
      "23532 [D loss: (0.534)(R 0.569, F 0.499)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.820] [G acc: 0.375]\n",
      "23533 [D loss: (0.652)(R 0.692, F 0.613)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.882] [G acc: 0.188]\n",
      "23534 [D loss: (0.643)(R 0.532, F 0.754)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.665] [G acc: 0.438]\n",
      "23535 [D loss: (0.773)(R 0.876, F 0.670)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.702] [G acc: 0.625]\n",
      "23536 [D loss: (0.740)(R 0.534, F 0.947)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.919] [G acc: 0.312]\n",
      "23537 [D loss: (0.592)(R 0.540, F 0.644)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.898] [G acc: 0.250]\n",
      "23538 [D loss: (0.630)(R 0.644, F 0.616)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.917] [G acc: 0.188]\n",
      "23539 [D loss: (0.470)(R 0.432, F 0.508)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.789] [G acc: 0.500]\n",
      "23540 [D loss: (0.557)(R 0.601, F 0.512)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.985] [G acc: 0.125]\n",
      "23541 [D loss: (0.990)(R 1.431, F 0.550)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.013] [G acc: 0.188]\n",
      "23542 [D loss: (0.675)(R 0.799, F 0.550)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.944] [G acc: 0.250]\n",
      "23543 [D loss: (0.590)(R 0.571, F 0.608)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.083] [G acc: 0.500]\n",
      "23544 [D loss: (0.639)(R 0.598, F 0.679)] [D acc: (0.562)(0.562, 0.562)] [G loss: 1.493] [G acc: 0.062]\n",
      "23545 [D loss: (0.492)(R 0.630, F 0.353)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.764] [G acc: 0.062]\n",
      "23546 [D loss: (0.615)(R 0.555, F 0.675)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.817] [G acc: 0.375]\n",
      "23547 [D loss: (0.567)(R 0.519, F 0.614)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.818] [G acc: 0.188]\n",
      "23548 [D loss: (0.599)(R 0.542, F 0.655)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.841] [G acc: 0.312]\n",
      "23549 [D loss: (0.647)(R 0.597, F 0.696)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.827] [G acc: 0.500]\n",
      "23550 [D loss: (1.062)(R 0.759, F 1.366)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.749] [G acc: 0.312]\n",
      "23551 [D loss: (0.572)(R 0.490, F 0.653)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.809] [G acc: 0.250]\n",
      "23552 [D loss: (0.578)(R 0.619, F 0.538)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.506] [G acc: 0.688]\n",
      "23553 [D loss: (0.601)(R 0.562, F 0.639)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.906] [G acc: 0.188]\n",
      "23554 [D loss: (0.599)(R 0.611, F 0.587)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.956] [G acc: 0.500]\n",
      "23555 [D loss: (0.770)(R 0.639, F 0.901)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.021] [G acc: 0.312]\n",
      "23556 [D loss: (0.487)(R 0.546, F 0.429)] [D acc: (0.719)(0.562, 0.875)] [G loss: 2.261] [G acc: 0.250]\n",
      "23557 [D loss: (0.622)(R 0.555, F 0.688)] [D acc: (0.562)(0.625, 0.500)] [G loss: 1.593] [G acc: 0.250]\n",
      "23558 [D loss: (0.484)(R 0.510, F 0.457)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.877] [G acc: 0.312]\n",
      "23559 [D loss: (0.611)(R 0.543, F 0.679)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.110] [G acc: 0.125]\n",
      "23560 [D loss: (0.665)(R 0.986, F 0.344)] [D acc: (0.625)(0.250, 1.000)] [G loss: 1.229] [G acc: 0.250]\n",
      "23561 [D loss: (0.688)(R 0.627, F 0.750)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.863] [G acc: 0.125]\n",
      "23562 [D loss: (0.543)(R 0.575, F 0.511)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.806] [G acc: 0.250]\n",
      "23563 [D loss: (0.555)(R 0.697, F 0.413)] [D acc: (0.750)(0.500, 1.000)] [G loss: 0.885] [G acc: 0.438]\n",
      "23564 [D loss: (0.724)(R 0.693, F 0.754)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.876] [G acc: 0.312]\n",
      "23565 [D loss: (0.605)(R 0.592, F 0.618)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.991] [G acc: 0.312]\n",
      "23566 [D loss: (0.692)(R 0.521, F 0.863)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.402] [G acc: 0.688]\n",
      "23567 [D loss: (0.712)(R 0.761, F 0.664)] [D acc: (0.531)(0.438, 0.625)] [G loss: 1.011] [G acc: 0.250]\n",
      "23568 [D loss: (0.708)(R 0.595, F 0.820)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.765] [G acc: 0.562]\n",
      "23569 [D loss: (0.812)(R 0.634, F 0.991)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.549] [G acc: 0.562]\n",
      "23570 [D loss: (0.586)(R 0.619, F 0.552)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.326] [G acc: 0.375]\n",
      "23571 [D loss: (0.817)(R 0.630, F 1.004)] [D acc: (0.594)(0.625, 0.562)] [G loss: 2.311] [G acc: 0.312]\n",
      "23572 [D loss: (0.662)(R 0.886, F 0.439)] [D acc: (0.625)(0.438, 0.812)] [G loss: 2.218] [G acc: 0.062]\n",
      "23573 [D loss: (0.702)(R 0.695, F 0.710)] [D acc: (0.562)(0.438, 0.688)] [G loss: 1.281] [G acc: 0.438]\n",
      "23574 [D loss: (0.640)(R 0.515, F 0.766)] [D acc: (0.719)(0.625, 0.812)] [G loss: 5.066] [G acc: 0.438]\n",
      "23575 [D loss: (0.635)(R 0.652, F 0.617)] [D acc: (0.688)(0.500, 0.875)] [G loss: 3.755] [G acc: 0.312]\n",
      "23576 [D loss: (0.716)(R 0.650, F 0.783)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.999] [G acc: 0.250]\n",
      "23577 [D loss: (0.632)(R 0.614, F 0.650)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.122] [G acc: 0.375]\n",
      "23578 [D loss: (0.710)(R 0.855, F 0.566)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.472] [G acc: 0.375]\n",
      "23579 [D loss: (0.634)(R 0.799, F 0.468)] [D acc: (0.594)(0.438, 0.750)] [G loss: 1.432] [G acc: 0.250]\n",
      "23580 [D loss: (0.981)(R 0.718, F 1.243)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.993] [G acc: 0.312]\n",
      "23581 [D loss: (0.726)(R 0.763, F 0.689)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.638] [G acc: 0.562]\n",
      "23582 [D loss: (0.538)(R 0.638, F 0.439)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.114] [G acc: 0.250]\n",
      "23583 [D loss: (0.713)(R 0.712, F 0.714)] [D acc: (0.625)(0.375, 0.875)] [G loss: 1.132] [G acc: 0.062]\n",
      "23584 [D loss: (0.820)(R 0.686, F 0.954)] [D acc: (0.500)(0.500, 0.500)] [G loss: 1.071] [G acc: 0.188]\n",
      "23585 [D loss: (0.733)(R 0.979, F 0.487)] [D acc: (0.656)(0.438, 0.875)] [G loss: 1.431] [G acc: 0.312]\n",
      "23586 [D loss: (0.786)(R 0.704, F 0.868)] [D acc: (0.469)(0.500, 0.438)] [G loss: 1.500] [G acc: 0.312]\n",
      "23587 [D loss: (0.594)(R 0.760, F 0.428)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.965] [G acc: 0.188]\n",
      "23588 [D loss: (0.463)(R 0.632, F 0.294)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.291] [G acc: 0.000]\n",
      "23589 [D loss: (0.603)(R 0.717, F 0.489)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.591] [G acc: 0.188]\n",
      "23590 [D loss: (0.435)(R 0.543, F 0.326)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.520] [G acc: 0.312]\n",
      "23591 [D loss: (0.641)(R 0.810, F 0.472)] [D acc: (0.625)(0.438, 0.812)] [G loss: 1.115] [G acc: 0.062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23592 [D loss: (0.592)(R 0.630, F 0.553)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.846] [G acc: 0.312]\n",
      "23593 [D loss: (0.621)(R 0.580, F 0.663)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.972] [G acc: 0.188]\n",
      "23594 [D loss: (0.557)(R 0.490, F 0.624)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.898] [G acc: 0.188]\n",
      "23595 [D loss: (0.602)(R 0.632, F 0.572)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.887] [G acc: 0.188]\n",
      "23596 [D loss: (0.575)(R 0.609, F 0.541)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.888] [G acc: 0.125]\n",
      "23597 [D loss: (0.640)(R 0.725, F 0.556)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.921] [G acc: 0.188]\n",
      "23598 [D loss: (0.603)(R 0.620, F 0.587)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.970] [G acc: 0.375]\n",
      "23599 [D loss: (0.513)(R 0.584, F 0.441)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.929] [G acc: 0.250]\n",
      "23600 [D loss: (0.591)(R 0.652, F 0.530)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.954] [G acc: 0.125]\n",
      "23601 [D loss: (0.587)(R 0.550, F 0.625)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.416] [G acc: 0.312]\n",
      "23602 [D loss: (0.541)(R 0.787, F 0.295)] [D acc: (0.562)(0.312, 0.812)] [G loss: 1.781] [G acc: 0.188]\n",
      "23603 [D loss: (0.826)(R 0.713, F 0.939)] [D acc: (0.562)(0.562, 0.562)] [G loss: 3.455] [G acc: 0.438]\n",
      "23604 [D loss: (0.449)(R 0.645, F 0.253)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.368] [G acc: 0.188]\n",
      "23605 [D loss: (0.505)(R 0.591, F 0.418)] [D acc: (0.719)(0.625, 0.812)] [G loss: 5.282] [G acc: 0.125]\n",
      "23606 [D loss: (0.682)(R 0.513, F 0.852)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.826] [G acc: 0.188]\n",
      "23607 [D loss: (0.582)(R 0.650, F 0.513)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.047] [G acc: 0.125]\n",
      "23608 [D loss: (0.606)(R 0.656, F 0.556)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.789] [G acc: 0.375]\n",
      "23609 [D loss: (0.572)(R 0.555, F 0.589)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.065] [G acc: 0.125]\n",
      "23610 [D loss: (0.552)(R 0.464, F 0.640)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.805] [G acc: 0.438]\n",
      "23611 [D loss: (0.593)(R 0.487, F 0.699)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.928] [G acc: 0.188]\n",
      "23612 [D loss: (0.628)(R 0.692, F 0.563)] [D acc: (0.562)(0.312, 0.812)] [G loss: 0.818] [G acc: 0.375]\n",
      "23613 [D loss: (0.680)(R 0.751, F 0.609)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.851] [G acc: 0.375]\n",
      "23614 [D loss: (0.534)(R 0.502, F 0.566)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.706] [G acc: 0.438]\n",
      "23615 [D loss: (0.646)(R 0.759, F 0.534)] [D acc: (0.688)(0.438, 0.938)] [G loss: 0.748] [G acc: 0.375]\n",
      "23616 [D loss: (0.625)(R 0.666, F 0.583)] [D acc: (0.719)(0.688, 0.750)] [G loss: 2.523] [G acc: 0.312]\n",
      "23617 [D loss: (0.652)(R 0.577, F 0.728)] [D acc: (0.719)(0.750, 0.688)] [G loss: 4.632] [G acc: 0.188]\n",
      "23618 [D loss: (0.567)(R 0.535, F 0.600)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.084] [G acc: 0.312]\n",
      "23619 [D loss: (0.569)(R 0.531, F 0.607)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.040] [G acc: 0.188]\n",
      "23620 [D loss: (0.517)(R 0.577, F 0.457)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.863] [G acc: 0.125]\n",
      "23621 [D loss: (0.644)(R 0.747, F 0.541)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.014] [G acc: 0.250]\n",
      "23622 [D loss: (0.511)(R 0.513, F 0.508)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.811] [G acc: 0.312]\n",
      "23623 [D loss: (0.645)(R 0.747, F 0.543)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.948] [G acc: 0.188]\n",
      "23624 [D loss: (0.608)(R 0.529, F 0.687)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.862] [G acc: 0.188]\n",
      "23625 [D loss: (0.582)(R 0.491, F 0.673)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.066] [G acc: 0.250]\n",
      "23626 [D loss: (0.580)(R 0.597, F 0.563)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.756] [G acc: 0.375]\n",
      "23627 [D loss: (0.572)(R 0.583, F 0.560)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.071] [G acc: 0.188]\n",
      "23628 [D loss: (0.699)(R 0.652, F 0.747)] [D acc: (0.531)(0.562, 0.500)] [G loss: 1.027] [G acc: 0.375]\n",
      "23629 [D loss: (0.483)(R 0.583, F 0.382)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.227] [G acc: 0.188]\n",
      "23630 [D loss: (0.603)(R 0.612, F 0.593)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.941] [G acc: 0.312]\n",
      "23631 [D loss: (0.489)(R 0.606, F 0.373)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.985] [G acc: 0.125]\n",
      "23632 [D loss: (0.568)(R 0.500, F 0.636)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.189] [G acc: 0.188]\n",
      "23633 [D loss: (0.823)(R 1.017, F 0.629)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.836] [G acc: 0.375]\n",
      "23634 [D loss: (0.693)(R 0.705, F 0.681)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.718] [G acc: 0.500]\n",
      "23635 [D loss: (0.548)(R 0.605, F 0.490)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.266] [G acc: 0.250]\n",
      "23636 [D loss: (0.776)(R 0.657, F 0.895)] [D acc: (0.531)(0.562, 0.500)] [G loss: 1.066] [G acc: 0.312]\n",
      "23637 [D loss: (0.593)(R 0.618, F 0.568)] [D acc: (0.594)(0.500, 0.688)] [G loss: 1.301] [G acc: 0.188]\n",
      "23638 [D loss: (0.669)(R 0.659, F 0.679)] [D acc: (0.469)(0.500, 0.438)] [G loss: 1.230] [G acc: 0.312]\n",
      "23639 [D loss: (0.517)(R 0.586, F 0.449)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.291] [G acc: 0.125]\n",
      "23640 [D loss: (0.770)(R 0.631, F 0.909)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.907] [G acc: 0.312]\n",
      "23641 [D loss: (0.406)(R 0.517, F 0.294)] [D acc: (0.844)(0.750, 0.938)] [G loss: 2.598] [G acc: 0.250]\n",
      "23642 [D loss: (0.576)(R 0.515, F 0.636)] [D acc: (0.688)(0.688, 0.688)] [G loss: 3.012] [G acc: 0.375]\n",
      "23643 [D loss: (0.634)(R 0.546, F 0.722)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.802] [G acc: 0.312]\n",
      "23644 [D loss: (0.767)(R 0.782, F 0.752)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.700] [G acc: 0.312]\n",
      "23645 [D loss: (0.599)(R 0.503, F 0.695)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.826] [G acc: 0.375]\n",
      "23646 [D loss: (0.650)(R 0.604, F 0.695)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.722] [G acc: 0.312]\n",
      "23647 [D loss: (0.734)(R 0.523, F 0.946)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.775] [G acc: 0.438]\n",
      "23648 [D loss: (0.776)(R 0.728, F 0.824)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.754] [G acc: 0.312]\n",
      "23649 [D loss: (0.773)(R 0.675, F 0.871)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.788] [G acc: 0.312]\n",
      "23650 [D loss: (0.701)(R 0.743, F 0.658)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.697] [G acc: 0.375]\n",
      "23651 [D loss: (0.961)(R 0.644, F 1.279)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.787] [G acc: 0.312]\n",
      "23652 [D loss: (0.658)(R 0.509, F 0.807)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.742] [G acc: 0.375]\n",
      "23653 [D loss: (0.788)(R 0.913, F 0.662)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.806] [G acc: 0.125]\n",
      "23654 [D loss: (0.665)(R 0.651, F 0.679)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.899] [G acc: 0.250]\n",
      "23655 [D loss: (0.917)(R 1.211, F 0.624)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.818] [G acc: 0.250]\n",
      "23656 [D loss: (0.650)(R 0.638, F 0.663)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.783] [G acc: 0.125]\n",
      "23657 [D loss: (0.695)(R 0.649, F 0.741)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.895] [G acc: 0.125]\n",
      "23658 [D loss: (0.650)(R 0.490, F 0.811)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.768] [G acc: 0.312]\n",
      "23659 [D loss: (0.697)(R 0.798, F 0.596)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.843] [G acc: 0.250]\n",
      "23660 [D loss: (0.569)(R 0.642, F 0.496)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.978] [G acc: 0.062]\n",
      "23661 [D loss: (0.610)(R 0.485, F 0.735)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.796] [G acc: 0.312]\n",
      "23662 [D loss: (0.595)(R 0.559, F 0.631)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.854] [G acc: 0.312]\n",
      "23663 [D loss: (0.646)(R 0.630, F 0.662)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.044] [G acc: 0.125]\n",
      "23664 [D loss: (0.691)(R 0.692, F 0.690)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.760] [G acc: 0.250]\n",
      "23665 [D loss: (0.510)(R 0.422, F 0.599)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.781] [G acc: 0.188]\n",
      "23666 [D loss: (0.704)(R 0.619, F 0.788)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.861] [G acc: 0.188]\n",
      "23667 [D loss: (0.692)(R 0.628, F 0.757)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.852] [G acc: 0.500]\n",
      "23668 [D loss: (0.589)(R 0.661, F 0.518)] [D acc: (0.594)(0.500, 0.688)] [G loss: 1.185] [G acc: 0.125]\n",
      "23669 [D loss: (0.638)(R 0.638, F 0.638)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.818] [G acc: 0.312]\n",
      "23670 [D loss: (0.640)(R 0.741, F 0.540)] [D acc: (0.500)(0.312, 0.688)] [G loss: 0.785] [G acc: 0.188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23671 [D loss: (0.698)(R 0.737, F 0.658)] [D acc: (0.406)(0.250, 0.562)] [G loss: 0.700] [G acc: 0.375]\n",
      "23672 [D loss: (0.562)(R 0.554, F 0.569)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.793] [G acc: 0.375]\n",
      "23673 [D loss: (0.917)(R 0.464, F 1.370)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.849] [G acc: 0.250]\n",
      "23674 [D loss: (0.665)(R 0.572, F 0.758)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.756] [G acc: 0.250]\n",
      "23675 [D loss: (0.648)(R 0.657, F 0.639)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.664] [G acc: 0.562]\n",
      "23676 [D loss: (0.761)(R 0.724, F 0.797)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.767] [G acc: 0.250]\n",
      "23677 [D loss: (0.742)(R 0.728, F 0.757)] [D acc: (0.438)(0.250, 0.625)] [G loss: 0.641] [G acc: 0.438]\n",
      "23678 [D loss: (0.744)(R 0.714, F 0.774)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.686] [G acc: 0.500]\n",
      "23679 [D loss: (0.652)(R 0.677, F 0.628)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.736] [G acc: 0.312]\n",
      "23680 [D loss: (0.791)(R 0.677, F 0.905)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.811] [G acc: 0.500]\n",
      "23681 [D loss: (0.656)(R 0.727, F 0.586)] [D acc: (0.594)(0.375, 0.812)] [G loss: 1.820] [G acc: 0.000]\n",
      "23682 [D loss: (0.921)(R 0.740, F 1.103)] [D acc: (0.406)(0.250, 0.562)] [G loss: 0.579] [G acc: 0.625]\n",
      "23683 [D loss: (1.301)(R 0.543, F 2.058)] [D acc: (0.500)(0.500, 0.500)] [G loss: 1.136] [G acc: 0.375]\n",
      "23684 [D loss: (0.553)(R 0.649, F 0.457)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.985] [G acc: 0.250]\n",
      "23685 [D loss: (0.646)(R 0.591, F 0.700)] [D acc: (0.531)(0.500, 0.562)] [G loss: 1.659] [G acc: 0.562]\n",
      "23686 [D loss: (0.579)(R 0.675, F 0.482)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.576] [G acc: 0.625]\n",
      "23687 [D loss: (1.164)(R 0.657, F 1.670)] [D acc: (0.375)(0.438, 0.312)] [G loss: 0.826] [G acc: 0.188]\n",
      "23688 [D loss: (0.699)(R 0.595, F 0.803)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.471] [G acc: 0.688]\n",
      "23689 [D loss: (0.983)(R 0.689, F 1.278)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.474] [G acc: 0.625]\n",
      "23690 [D loss: (0.808)(R 0.652, F 0.964)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.696] [G acc: 0.375]\n",
      "23691 [D loss: (0.991)(R 0.726, F 1.257)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.770] [G acc: 0.375]\n",
      "23692 [D loss: (0.727)(R 0.779, F 0.675)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.777] [G acc: 0.500]\n",
      "23693 [D loss: (0.983)(R 0.838, F 1.128)] [D acc: (0.469)(0.438, 0.500)] [G loss: 1.311] [G acc: 0.125]\n",
      "23694 [D loss: (0.533)(R 0.702, F 0.363)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.893] [G acc: 0.250]\n",
      "23695 [D loss: (0.647)(R 0.704, F 0.589)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.102] [G acc: 0.125]\n",
      "23696 [D loss: (0.753)(R 0.757, F 0.749)] [D acc: (0.406)(0.312, 0.500)] [G loss: 0.937] [G acc: 0.250]\n",
      "23697 [D loss: (0.673)(R 0.669, F 0.677)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.895] [G acc: 0.250]\n",
      "23698 [D loss: (0.757)(R 0.728, F 0.785)] [D acc: (0.406)(0.375, 0.438)] [G loss: 0.792] [G acc: 0.312]\n",
      "23699 [D loss: (0.713)(R 0.690, F 0.737)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.743] [G acc: 0.250]\n",
      "23700 [D loss: (0.632)(R 0.579, F 0.685)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.700] [G acc: 0.375]\n",
      "23701 [D loss: (0.684)(R 0.677, F 0.692)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.787] [G acc: 0.125]\n",
      "23702 [D loss: (0.638)(R 0.630, F 0.647)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.765] [G acc: 0.188]\n",
      "23703 [D loss: (0.643)(R 0.657, F 0.629)] [D acc: (0.500)(0.250, 0.750)] [G loss: 0.822] [G acc: 0.250]\n",
      "23704 [D loss: (0.650)(R 0.686, F 0.613)] [D acc: (0.500)(0.250, 0.750)] [G loss: 0.855] [G acc: 0.125]\n",
      "23705 [D loss: (0.703)(R 0.735, F 0.670)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.794] [G acc: 0.250]\n",
      "23706 [D loss: (0.697)(R 0.698, F 0.696)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.665] [G acc: 0.500]\n",
      "23707 [D loss: (0.643)(R 0.607, F 0.679)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.658] [G acc: 0.438]\n",
      "23708 [D loss: (0.641)(R 0.675, F 0.607)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.873] [G acc: 0.250]\n",
      "23709 [D loss: (0.663)(R 0.553, F 0.774)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.765] [G acc: 0.375]\n",
      "23710 [D loss: (0.733)(R 0.654, F 0.812)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.501] [G acc: 0.625]\n",
      "23711 [D loss: (0.673)(R 0.566, F 0.780)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.840] [G acc: 0.125]\n",
      "23712 [D loss: (0.680)(R 0.705, F 0.654)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.869] [G acc: 0.250]\n",
      "23713 [D loss: (0.528)(R 0.664, F 0.392)] [D acc: (0.625)(0.375, 0.875)] [G loss: 1.642] [G acc: 0.188]\n",
      "23714 [D loss: (0.939)(R 0.674, F 1.205)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.665] [G acc: 0.375]\n",
      "23715 [D loss: (0.727)(R 0.829, F 0.626)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.644] [G acc: 0.438]\n",
      "23716 [D loss: (0.640)(R 0.665, F 0.615)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.634] [G acc: 0.500]\n",
      "23717 [D loss: (0.571)(R 0.588, F 0.553)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.950] [G acc: 0.250]\n",
      "23718 [D loss: (0.620)(R 0.617, F 0.624)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.168] [G acc: 0.125]\n",
      "23719 [D loss: (0.691)(R 0.658, F 0.724)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.744] [G acc: 0.438]\n",
      "23720 [D loss: (0.687)(R 0.691, F 0.682)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.905] [G acc: 0.438]\n",
      "23721 [D loss: (0.507)(R 0.604, F 0.410)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.311] [G acc: 0.312]\n",
      "23722 [D loss: (0.499)(R 0.679, F 0.318)] [D acc: (0.562)(0.250, 0.875)] [G loss: 3.148] [G acc: 0.312]\n",
      "23723 [D loss: (0.572)(R 0.616, F 0.527)] [D acc: (0.594)(0.500, 0.688)] [G loss: 2.198] [G acc: 0.125]\n",
      "23724 [D loss: (0.584)(R 0.526, F 0.642)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.544] [G acc: 0.562]\n",
      "23725 [D loss: (0.533)(R 0.554, F 0.513)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.892] [G acc: 0.250]\n",
      "23726 [D loss: (0.657)(R 0.590, F 0.725)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.678] [G acc: 0.625]\n",
      "23727 [D loss: (0.795)(R 0.660, F 0.930)] [D acc: (0.312)(0.375, 0.250)] [G loss: 0.796] [G acc: 0.438]\n",
      "23728 [D loss: (0.668)(R 0.660, F 0.675)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.970] [G acc: 0.312]\n",
      "23729 [D loss: (0.667)(R 0.655, F 0.680)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.819] [G acc: 0.375]\n",
      "23730 [D loss: (0.598)(R 0.760, F 0.437)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.956] [G acc: 0.312]\n",
      "23731 [D loss: (0.593)(R 0.567, F 0.620)] [D acc: (0.562)(0.625, 0.500)] [G loss: 1.462] [G acc: 0.000]\n",
      "23732 [D loss: (0.559)(R 0.609, F 0.509)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.880] [G acc: 0.125]\n",
      "23733 [D loss: (0.645)(R 0.652, F 0.637)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.813] [G acc: 0.312]\n",
      "23734 [D loss: (0.563)(R 0.639, F 0.486)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.610] [G acc: 0.500]\n",
      "23735 [D loss: (0.641)(R 0.606, F 0.675)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.742] [G acc: 0.562]\n",
      "23736 [D loss: (0.687)(R 0.601, F 0.772)] [D acc: (0.406)(0.500, 0.312)] [G loss: 0.719] [G acc: 0.438]\n",
      "23737 [D loss: (0.701)(R 0.690, F 0.712)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.843] [G acc: 0.312]\n",
      "23738 [D loss: (0.589)(R 0.631, F 0.546)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.005] [G acc: 0.562]\n",
      "23739 [D loss: (0.406)(R 0.625, F 0.187)] [D acc: (0.719)(0.625, 0.812)] [G loss: 5.718] [G acc: 0.188]\n",
      "23740 [D loss: (0.532)(R 0.643, F 0.421)] [D acc: (0.625)(0.562, 0.688)] [G loss: 6.356] [G acc: 0.250]\n",
      "23741 [D loss: (0.412)(R 0.602, F 0.222)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.898] [G acc: 0.438]\n",
      "23742 [D loss: (0.483)(R 0.479, F 0.487)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.160] [G acc: 0.562]\n",
      "23743 [D loss: (0.705)(R 0.639, F 0.770)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.999] [G acc: 0.312]\n",
      "23744 [D loss: (0.603)(R 0.542, F 0.664)] [D acc: (0.531)(0.625, 0.438)] [G loss: 1.171] [G acc: 0.250]\n",
      "23745 [D loss: (0.450)(R 0.499, F 0.401)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.125] [G acc: 0.125]\n",
      "23746 [D loss: (0.647)(R 0.537, F 0.758)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.711] [G acc: 0.375]\n",
      "23747 [D loss: (0.609)(R 0.442, F 0.776)] [D acc: (0.625)(0.875, 0.375)] [G loss: 0.680] [G acc: 0.562]\n",
      "23748 [D loss: (0.685)(R 0.639, F 0.731)] [D acc: (0.375)(0.375, 0.375)] [G loss: 0.712] [G acc: 0.438]\n",
      "23749 [D loss: (0.604)(R 0.530, F 0.679)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.875] [G acc: 0.188]\n",
      "23750 [D loss: (0.695)(R 0.687, F 0.702)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.752] [G acc: 0.562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23751 [D loss: (0.540)(R 0.598, F 0.482)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.831] [G acc: 0.250]\n",
      "23752 [D loss: (0.512)(R 0.430, F 0.595)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.708] [G acc: 0.500]\n",
      "23753 [D loss: (0.635)(R 0.641, F 0.630)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.871] [G acc: 0.312]\n",
      "23754 [D loss: (0.601)(R 0.738, F 0.464)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.292] [G acc: 0.062]\n",
      "23755 [D loss: (0.384)(R 0.399, F 0.368)] [D acc: (0.812)(0.875, 0.750)] [G loss: 2.738] [G acc: 0.188]\n",
      "23756 [D loss: (0.434)(R 0.567, F 0.300)] [D acc: (0.719)(0.500, 0.938)] [G loss: 3.921] [G acc: 0.000]\n",
      "23757 [D loss: (0.412)(R 0.439, F 0.386)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.629] [G acc: 0.312]\n",
      "23758 [D loss: (0.342)(R 0.444, F 0.241)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.770] [G acc: 0.125]\n",
      "23759 [D loss: (0.514)(R 0.345, F 0.683)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.777] [G acc: 0.250]\n",
      "23760 [D loss: (0.565)(R 0.550, F 0.580)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.743] [G acc: 0.312]\n",
      "23761 [D loss: (0.463)(R 0.365, F 0.560)] [D acc: (0.906)(0.875, 0.938)] [G loss: 0.828] [G acc: 0.125]\n",
      "23762 [D loss: (0.495)(R 0.387, F 0.602)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.932] [G acc: 0.188]\n",
      "23763 [D loss: (0.537)(R 0.455, F 0.620)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.930] [G acc: 0.250]\n",
      "23764 [D loss: (0.608)(R 0.403, F 0.813)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.504] [G acc: 0.562]\n",
      "23765 [D loss: (0.509)(R 0.463, F 0.555)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.924] [G acc: 0.188]\n",
      "23766 [D loss: (0.526)(R 0.520, F 0.532)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.930] [G acc: 0.062]\n",
      "23767 [D loss: (0.488)(R 0.459, F 0.517)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.311] [G acc: 0.125]\n",
      "23768 [D loss: (0.404)(R 0.392, F 0.416)] [D acc: (0.750)(0.688, 0.812)] [G loss: 2.351] [G acc: 0.000]\n",
      "23769 [D loss: (0.467)(R 0.476, F 0.458)] [D acc: (0.719)(0.688, 0.750)] [G loss: 2.506] [G acc: 0.188]\n",
      "23770 [D loss: (0.341)(R 0.426, F 0.256)] [D acc: (0.812)(0.688, 0.938)] [G loss: 5.306] [G acc: 0.062]\n",
      "23771 [D loss: (0.582)(R 0.526, F 0.638)] [D acc: (0.625)(0.562, 0.688)] [G loss: 3.159] [G acc: 0.125]\n",
      "23772 [D loss: (0.439)(R 0.528, F 0.350)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.968] [G acc: 0.125]\n",
      "23773 [D loss: (0.475)(R 0.662, F 0.288)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.114] [G acc: 0.125]\n",
      "23774 [D loss: (0.372)(R 0.435, F 0.309)] [D acc: (0.812)(0.625, 1.000)] [G loss: 0.797] [G acc: 0.375]\n",
      "23775 [D loss: (0.493)(R 0.601, F 0.384)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.897] [G acc: 0.312]\n",
      "23776 [D loss: (0.524)(R 0.441, F 0.607)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.414] [G acc: 0.125]\n",
      "23777 [D loss: (0.430)(R 0.448, F 0.411)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.747] [G acc: 0.062]\n",
      "23778 [D loss: (0.586)(R 0.625, F 0.547)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.071] [G acc: 0.125]\n",
      "23779 [D loss: (0.435)(R 0.298, F 0.573)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.044] [G acc: 0.062]\n",
      "23780 [D loss: (0.670)(R 0.472, F 0.867)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.089] [G acc: 0.000]\n",
      "23781 [D loss: (0.401)(R 0.384, F 0.417)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.075] [G acc: 0.438]\n",
      "23782 [D loss: (0.377)(R 0.549, F 0.205)] [D acc: (0.750)(0.562, 0.938)] [G loss: 6.118] [G acc: 0.125]\n",
      "23783 [D loss: (0.493)(R 0.533, F 0.453)] [D acc: (0.656)(0.562, 0.750)] [G loss: 5.124] [G acc: 0.062]\n",
      "23784 [D loss: (0.516)(R 0.707, F 0.325)] [D acc: (0.781)(0.625, 0.938)] [G loss: 6.419] [G acc: 0.000]\n",
      "23785 [D loss: (0.502)(R 0.494, F 0.510)] [D acc: (0.844)(0.688, 1.000)] [G loss: 1.043] [G acc: 0.000]\n",
      "23786 [D loss: (0.533)(R 0.522, F 0.545)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.220] [G acc: 0.000]\n",
      "23787 [D loss: (0.451)(R 0.492, F 0.411)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.143] [G acc: 0.000]\n",
      "23788 [D loss: (0.618)(R 0.830, F 0.407)] [D acc: (0.688)(0.375, 1.000)] [G loss: 1.007] [G acc: 0.125]\n",
      "23789 [D loss: (0.513)(R 0.547, F 0.480)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.938] [G acc: 0.312]\n",
      "23790 [D loss: (0.366)(R 0.420, F 0.311)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.516] [G acc: 0.000]\n",
      "23791 [D loss: (0.460)(R 0.443, F 0.477)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.164] [G acc: 0.062]\n",
      "23792 [D loss: (0.398)(R 0.439, F 0.357)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.878] [G acc: 0.312]\n",
      "23793 [D loss: (0.388)(R 0.558, F 0.218)] [D acc: (0.844)(0.750, 0.938)] [G loss: 4.694] [G acc: 0.125]\n",
      "23794 [D loss: (0.325)(R 0.338, F 0.312)] [D acc: (0.812)(0.750, 0.875)] [G loss: 3.737] [G acc: 0.000]\n",
      "23795 [D loss: (0.394)(R 0.346, F 0.441)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.666] [G acc: 0.062]\n",
      "23796 [D loss: (0.355)(R 0.335, F 0.375)] [D acc: (0.812)(0.812, 0.812)] [G loss: 3.829] [G acc: 0.062]\n",
      "23797 [D loss: (0.322)(R 0.411, F 0.233)] [D acc: (0.875)(0.750, 1.000)] [G loss: 3.117] [G acc: 0.062]\n",
      "23798 [D loss: (0.425)(R 0.380, F 0.469)] [D acc: (0.812)(0.688, 0.938)] [G loss: 2.360] [G acc: 0.438]\n",
      "23799 [D loss: (0.588)(R 0.900, F 0.276)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.268] [G acc: 0.062]\n",
      "23800 [D loss: (0.680)(R 0.442, F 0.919)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.689] [G acc: 0.500]\n",
      "23801 [D loss: (0.599)(R 0.667, F 0.530)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.096] [G acc: 0.125]\n",
      "23802 [D loss: (0.394)(R 0.347, F 0.442)] [D acc: (0.906)(0.812, 1.000)] [G loss: 0.784] [G acc: 0.312]\n",
      "23803 [D loss: (0.858)(R 0.820, F 0.895)] [D acc: (0.594)(0.438, 0.750)] [G loss: 1.089] [G acc: 0.000]\n",
      "23804 [D loss: (0.403)(R 0.466, F 0.341)] [D acc: (0.844)(0.688, 1.000)] [G loss: 1.289] [G acc: 0.000]\n",
      "23805 [D loss: (0.509)(R 0.542, F 0.475)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.859] [G acc: 0.375]\n",
      "23806 [D loss: (0.410)(R 0.402, F 0.418)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.323] [G acc: 0.000]\n",
      "23807 [D loss: (0.711)(R 0.693, F 0.729)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.366] [G acc: 0.000]\n",
      "23808 [D loss: (0.411)(R 0.382, F 0.440)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.209] [G acc: 0.000]\n",
      "23809 [D loss: (0.503)(R 0.559, F 0.446)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.500] [G acc: 0.438]\n",
      "23810 [D loss: (0.329)(R 0.408, F 0.249)] [D acc: (0.844)(0.750, 0.938)] [G loss: 5.913] [G acc: 0.188]\n",
      "23811 [D loss: (0.266)(R 0.385, F 0.148)] [D acc: (0.844)(0.688, 1.000)] [G loss: 1.544] [G acc: 0.000]\n",
      "23812 [D loss: (0.436)(R 0.603, F 0.268)] [D acc: (0.781)(0.562, 1.000)] [G loss: 1.001] [G acc: 0.125]\n",
      "23813 [D loss: (0.637)(R 0.854, F 0.420)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.231] [G acc: 0.188]\n",
      "23814 [D loss: (0.492)(R 0.428, F 0.557)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.650] [G acc: 0.750]\n",
      "23815 [D loss: (1.121)(R 0.560, F 1.683)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.795] [G acc: 0.062]\n",
      "23816 [D loss: (0.265)(R 0.399, F 0.132)] [D acc: (0.812)(0.688, 0.938)] [G loss: 4.871] [G acc: 0.188]\n",
      "23817 [D loss: (0.494)(R 0.614, F 0.375)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.994] [G acc: 0.125]\n",
      "23818 [D loss: (0.466)(R 0.415, F 0.517)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.709] [G acc: 0.000]\n",
      "23819 [D loss: (0.613)(R 0.475, F 0.750)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.315] [G acc: 0.062]\n",
      "23820 [D loss: (0.452)(R 0.434, F 0.470)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.152] [G acc: 0.125]\n",
      "23821 [D loss: (0.480)(R 0.509, F 0.451)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.168] [G acc: 0.125]\n",
      "23822 [D loss: (0.449)(R 0.597, F 0.301)] [D acc: (0.781)(0.562, 1.000)] [G loss: 1.623] [G acc: 0.000]\n",
      "23823 [D loss: (0.366)(R 0.445, F 0.287)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.708] [G acc: 0.625]\n",
      "23824 [D loss: (0.695)(R 1.000, F 0.390)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.257] [G acc: 0.312]\n",
      "23825 [D loss: (0.930)(R 1.421, F 0.438)] [D acc: (0.594)(0.500, 0.688)] [G loss: 2.829] [G acc: 0.312]\n",
      "23826 [D loss: (0.385)(R 0.496, F 0.274)] [D acc: (0.750)(0.562, 0.938)] [G loss: 2.550] [G acc: 0.125]\n",
      "23827 [D loss: (0.945)(R 0.565, F 1.325)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.976] [G acc: 0.188]\n",
      "23828 [D loss: (0.478)(R 0.302, F 0.655)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.173] [G acc: 0.062]\n",
      "23829 [D loss: (0.442)(R 0.415, F 0.469)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.092] [G acc: 0.062]\n",
      "23830 [D loss: (0.441)(R 0.432, F 0.450)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.033] [G acc: 0.188]\n",
      "23831 [D loss: (0.654)(R 0.518, F 0.791)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.188] [G acc: 0.188]\n",
      "23832 [D loss: (0.291)(R 0.426, F 0.155)] [D acc: (0.875)(0.750, 1.000)] [G loss: 1.889] [G acc: 0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23833 [D loss: (0.536)(R 0.635, F 0.437)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.975] [G acc: 0.312]\n",
      "23834 [D loss: (0.659)(R 0.596, F 0.722)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.013] [G acc: 0.250]\n",
      "23835 [D loss: (0.490)(R 0.465, F 0.514)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.440] [G acc: 0.312]\n",
      "23836 [D loss: (0.422)(R 0.506, F 0.338)] [D acc: (0.719)(0.625, 0.812)] [G loss: 2.849] [G acc: 0.062]\n",
      "23837 [D loss: (0.319)(R 0.302, F 0.336)] [D acc: (0.844)(0.750, 0.938)] [G loss: 3.320] [G acc: 0.062]\n",
      "23838 [D loss: (0.421)(R 0.519, F 0.322)] [D acc: (0.750)(0.625, 0.875)] [G loss: 4.244] [G acc: 0.312]\n",
      "23839 [D loss: (0.640)(R 0.571, F 0.710)] [D acc: (0.562)(0.562, 0.562)] [G loss: 4.008] [G acc: 0.250]\n",
      "23840 [D loss: (0.724)(R 0.449, F 0.998)] [D acc: (0.688)(0.750, 0.625)] [G loss: 6.446] [G acc: 0.375]\n",
      "23841 [D loss: (0.615)(R 0.864, F 0.365)] [D acc: (0.656)(0.562, 0.750)] [G loss: 2.081] [G acc: 0.062]\n",
      "23842 [D loss: (0.607)(R 0.389, F 0.824)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.962] [G acc: 0.438]\n",
      "23843 [D loss: (0.321)(R 0.452, F 0.191)] [D acc: (0.812)(0.625, 1.000)] [G loss: 1.305] [G acc: 0.188]\n",
      "23844 [D loss: (0.495)(R 0.259, F 0.732)] [D acc: (0.844)(0.938, 0.750)] [G loss: 1.764] [G acc: 0.000]\n",
      "23845 [D loss: (0.536)(R 0.458, F 0.613)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.556] [G acc: 0.188]\n",
      "23846 [D loss: (0.460)(R 0.549, F 0.371)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.707] [G acc: 0.062]\n",
      "23847 [D loss: (0.692)(R 0.720, F 0.664)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.265] [G acc: 0.125]\n",
      "23848 [D loss: (0.450)(R 0.527, F 0.373)] [D acc: (0.906)(0.875, 0.938)] [G loss: 0.993] [G acc: 0.312]\n",
      "23849 [D loss: (0.561)(R 0.563, F 0.560)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.151] [G acc: 0.188]\n",
      "23850 [D loss: (0.487)(R 0.493, F 0.481)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.872] [G acc: 0.250]\n",
      "23851 [D loss: (0.351)(R 0.494, F 0.208)] [D acc: (0.781)(0.625, 0.938)] [G loss: 4.551] [G acc: 0.062]\n",
      "23852 [D loss: (0.910)(R 0.636, F 1.184)] [D acc: (0.625)(0.625, 0.625)] [G loss: 2.405] [G acc: 0.062]\n",
      "23853 [D loss: (0.512)(R 0.579, F 0.446)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.169] [G acc: 0.188]\n",
      "23854 [D loss: (0.496)(R 0.613, F 0.379)] [D acc: (0.688)(0.438, 0.938)] [G loss: 1.381] [G acc: 0.312]\n",
      "23855 [D loss: (0.544)(R 0.530, F 0.557)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.775] [G acc: 0.000]\n",
      "23856 [D loss: (0.431)(R 0.577, F 0.285)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.910] [G acc: 0.125]\n",
      "23857 [D loss: (0.809)(R 0.731, F 0.888)] [D acc: (0.562)(0.438, 0.688)] [G loss: 1.912] [G acc: 0.125]\n",
      "23858 [D loss: (0.432)(R 0.527, F 0.338)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.607] [G acc: 0.062]\n",
      "23859 [D loss: (0.444)(R 0.502, F 0.386)] [D acc: (0.812)(0.625, 1.000)] [G loss: 1.097] [G acc: 0.125]\n",
      "23860 [D loss: (0.415)(R 0.507, F 0.324)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.969] [G acc: 0.375]\n",
      "23861 [D loss: (0.430)(R 0.511, F 0.349)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.062] [G acc: 0.125]\n",
      "23862 [D loss: (0.552)(R 0.558, F 0.546)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.758] [G acc: 0.438]\n",
      "23863 [D loss: (0.430)(R 0.481, F 0.378)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.872] [G acc: 0.375]\n",
      "23864 [D loss: (0.594)(R 0.658, F 0.530)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.158] [G acc: 0.188]\n",
      "23865 [D loss: (0.581)(R 0.594, F 0.568)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.169] [G acc: 0.500]\n",
      "23866 [D loss: (0.622)(R 0.641, F 0.603)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.572] [G acc: 0.312]\n",
      "23867 [D loss: (0.533)(R 0.650, F 0.416)] [D acc: (0.781)(0.625, 0.938)] [G loss: 2.045] [G acc: 0.125]\n",
      "23868 [D loss: (0.547)(R 0.562, F 0.532)] [D acc: (0.750)(0.750, 0.750)] [G loss: 2.561] [G acc: 0.250]\n",
      "23869 [D loss: (0.322)(R 0.504, F 0.139)] [D acc: (0.906)(0.812, 1.000)] [G loss: 7.711] [G acc: 0.250]\n",
      "23870 [D loss: (0.476)(R 0.523, F 0.428)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.265] [G acc: 0.125]\n",
      "23871 [D loss: (0.411)(R 0.356, F 0.466)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.429] [G acc: 0.062]\n",
      "23872 [D loss: (0.544)(R 0.509, F 0.579)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.744] [G acc: 0.562]\n",
      "23873 [D loss: (0.881)(R 0.754, F 1.008)] [D acc: (0.531)(0.500, 0.562)] [G loss: 1.001] [G acc: 0.312]\n",
      "23874 [D loss: (0.434)(R 0.500, F 0.369)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.567] [G acc: 0.750]\n",
      "23875 [D loss: (0.719)(R 0.628, F 0.810)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.033] [G acc: 0.438]\n",
      "23876 [D loss: (0.618)(R 0.649, F 0.586)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.034] [G acc: 0.250]\n",
      "23877 [D loss: (0.959)(R 0.493, F 1.426)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.265] [G acc: 0.125]\n",
      "23878 [D loss: (0.626)(R 0.677, F 0.575)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.889] [G acc: 0.375]\n",
      "23879 [D loss: (0.876)(R 0.704, F 1.048)] [D acc: (0.562)(0.562, 0.562)] [G loss: 1.255] [G acc: 0.125]\n",
      "23880 [D loss: (0.401)(R 0.495, F 0.308)] [D acc: (0.844)(0.750, 0.938)] [G loss: 2.429] [G acc: 0.188]\n",
      "23881 [D loss: (0.590)(R 0.688, F 0.492)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.806] [G acc: 0.375]\n",
      "23882 [D loss: (0.289)(R 0.415, F 0.163)] [D acc: (0.875)(0.812, 0.938)] [G loss: 10.311] [G acc: 0.062]\n",
      "23883 [D loss: (0.402)(R 0.461, F 0.343)] [D acc: (0.781)(0.688, 0.875)] [G loss: 2.579] [G acc: 0.125]\n",
      "23884 [D loss: (0.475)(R 0.489, F 0.461)] [D acc: (0.875)(0.812, 0.938)] [G loss: 7.943] [G acc: 0.188]\n",
      "23885 [D loss: (0.690)(R 0.815, F 0.566)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.060] [G acc: 0.125]\n",
      "23886 [D loss: (0.988)(R 1.271, F 0.705)] [D acc: (0.562)(0.625, 0.500)] [G loss: 1.230] [G acc: 0.188]\n",
      "23887 [D loss: (0.617)(R 0.465, F 0.769)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.029] [G acc: 0.438]\n",
      "23888 [D loss: (0.541)(R 0.532, F 0.550)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.115] [G acc: 0.062]\n",
      "23889 [D loss: (0.730)(R 0.899, F 0.561)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.917] [G acc: 0.250]\n",
      "23890 [D loss: (0.589)(R 0.535, F 0.643)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.946] [G acc: 0.438]\n",
      "23891 [D loss: (0.535)(R 0.509, F 0.561)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.020] [G acc: 0.188]\n",
      "23892 [D loss: (0.611)(R 0.611, F 0.612)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.079] [G acc: 0.125]\n",
      "23893 [D loss: (0.609)(R 0.638, F 0.579)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.204] [G acc: 0.250]\n",
      "23894 [D loss: (0.460)(R 0.444, F 0.476)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.964] [G acc: 0.312]\n",
      "23895 [D loss: (0.592)(R 0.595, F 0.588)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.346] [G acc: 0.125]\n",
      "23896 [D loss: (0.535)(R 0.505, F 0.565)] [D acc: (0.781)(0.688, 0.875)] [G loss: 4.168] [G acc: 0.375]\n",
      "23897 [D loss: (0.755)(R 0.516, F 0.995)] [D acc: (0.656)(0.688, 0.625)] [G loss: 7.107] [G acc: 0.375]\n",
      "23898 [D loss: (0.418)(R 0.688, F 0.149)] [D acc: (0.750)(0.562, 0.938)] [G loss: 7.997] [G acc: 0.312]\n",
      "23899 [D loss: (0.418)(R 0.414, F 0.421)] [D acc: (0.781)(0.812, 0.750)] [G loss: 7.059] [G acc: 0.250]\n",
      "23900 [D loss: (0.499)(R 0.656, F 0.341)] [D acc: (0.750)(0.688, 0.812)] [G loss: 7.334] [G acc: 0.188]\n",
      "23901 [D loss: (0.618)(R 0.525, F 0.712)] [D acc: (0.656)(0.750, 0.562)] [G loss: 2.598] [G acc: 0.438]\n",
      "23902 [D loss: (0.499)(R 0.551, F 0.447)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.637] [G acc: 0.250]\n",
      "23903 [D loss: (0.605)(R 0.423, F 0.788)] [D acc: (0.719)(0.875, 0.562)] [G loss: 3.054] [G acc: 0.312]\n",
      "23904 [D loss: (0.492)(R 0.554, F 0.429)] [D acc: (0.656)(0.562, 0.750)] [G loss: 8.712] [G acc: 0.125]\n",
      "23905 [D loss: (0.495)(R 0.767, F 0.224)] [D acc: (0.844)(0.812, 0.875)] [G loss: 9.944] [G acc: 0.250]\n",
      "23906 [D loss: (0.342)(R 0.432, F 0.253)] [D acc: (0.844)(0.750, 0.938)] [G loss: 2.901] [G acc: 0.062]\n",
      "23907 [D loss: (1.479)(R 0.336, F 2.622)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.939] [G acc: 0.375]\n",
      "23908 [D loss: (0.926)(R 0.464, F 1.389)] [D acc: (0.625)(0.750, 0.500)] [G loss: 1.227] [G acc: 0.312]\n",
      "23909 [D loss: (0.693)(R 0.434, F 0.951)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.335] [G acc: 0.375]\n",
      "23910 [D loss: (0.472)(R 0.443, F 0.500)] [D acc: (0.906)(0.875, 0.938)] [G loss: 1.163] [G acc: 0.250]\n",
      "23911 [D loss: (0.454)(R 0.612, F 0.295)] [D acc: (0.781)(0.625, 0.938)] [G loss: 4.889] [G acc: 0.500]\n",
      "23912 [D loss: (0.481)(R 0.570, F 0.392)] [D acc: (0.781)(0.812, 0.750)] [G loss: 5.848] [G acc: 0.188]\n",
      "23913 [D loss: (0.476)(R 0.557, F 0.396)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.141] [G acc: 0.375]\n",
      "23914 [D loss: (0.560)(R 0.614, F 0.506)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.916] [G acc: 0.375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23915 [D loss: (0.631)(R 0.478, F 0.785)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.931] [G acc: 0.375]\n",
      "23916 [D loss: (0.479)(R 0.545, F 0.412)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.048] [G acc: 0.312]\n",
      "23917 [D loss: (0.517)(R 0.625, F 0.408)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.048] [G acc: 0.438]\n",
      "23918 [D loss: (0.577)(R 0.673, F 0.482)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.222] [G acc: 0.188]\n",
      "23919 [D loss: (0.740)(R 0.629, F 0.852)] [D acc: (0.562)(0.750, 0.375)] [G loss: 1.263] [G acc: 0.312]\n",
      "23920 [D loss: (0.504)(R 0.430, F 0.578)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.330] [G acc: 0.188]\n",
      "23921 [D loss: (0.529)(R 0.564, F 0.494)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.993] [G acc: 0.562]\n",
      "23922 [D loss: (0.338)(R 0.368, F 0.309)] [D acc: (0.875)(0.812, 0.938)] [G loss: 2.366] [G acc: 0.250]\n",
      "23923 [D loss: (0.374)(R 0.515, F 0.232)] [D acc: (0.875)(0.812, 0.938)] [G loss: 3.184] [G acc: 0.250]\n",
      "23924 [D loss: (0.563)(R 0.445, F 0.681)] [D acc: (0.688)(0.875, 0.500)] [G loss: 1.055] [G acc: 0.125]\n",
      "23925 [D loss: (0.517)(R 0.601, F 0.433)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.227] [G acc: 0.250]\n",
      "23926 [D loss: (0.465)(R 0.512, F 0.418)] [D acc: (0.781)(0.812, 0.750)] [G loss: 4.409] [G acc: 0.125]\n",
      "23927 [D loss: (0.507)(R 0.773, F 0.241)] [D acc: (0.781)(0.625, 0.938)] [G loss: 6.274] [G acc: 0.125]\n",
      "23928 [D loss: (0.500)(R 0.491, F 0.509)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.676] [G acc: 0.562]\n",
      "23929 [D loss: (0.446)(R 0.445, F 0.446)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.635] [G acc: 0.125]\n",
      "23930 [D loss: (0.663)(R 0.616, F 0.711)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.968] [G acc: 0.125]\n",
      "23931 [D loss: (0.541)(R 0.473, F 0.609)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.875] [G acc: 0.312]\n",
      "23932 [D loss: (0.447)(R 0.438, F 0.455)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.572] [G acc: 0.250]\n",
      "23933 [D loss: (0.644)(R 0.866, F 0.423)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.894] [G acc: 0.312]\n",
      "23934 [D loss: (0.499)(R 0.479, F 0.520)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.231] [G acc: 0.438]\n",
      "23935 [D loss: (0.506)(R 0.471, F 0.540)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.839] [G acc: 0.125]\n",
      "23936 [D loss: (0.408)(R 0.519, F 0.297)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.137] [G acc: 0.125]\n",
      "23937 [D loss: (0.445)(R 0.488, F 0.403)] [D acc: (0.750)(0.625, 0.875)] [G loss: 2.687] [G acc: 0.125]\n",
      "23938 [D loss: (0.342)(R 0.276, F 0.408)] [D acc: (0.844)(0.875, 0.812)] [G loss: 5.306] [G acc: 0.188]\n",
      "23939 [D loss: (0.446)(R 0.572, F 0.320)] [D acc: (0.812)(0.750, 0.875)] [G loss: 3.772] [G acc: 0.062]\n",
      "23940 [D loss: (0.493)(R 0.313, F 0.673)] [D acc: (0.781)(0.938, 0.625)] [G loss: 1.192] [G acc: 0.188]\n",
      "23941 [D loss: (0.462)(R 0.697, F 0.226)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.314] [G acc: 0.125]\n",
      "23942 [D loss: (0.603)(R 0.535, F 0.670)] [D acc: (0.750)(0.750, 0.750)] [G loss: 2.123] [G acc: 0.062]\n",
      "23943 [D loss: (0.354)(R 0.356, F 0.353)] [D acc: (0.812)(0.750, 0.875)] [G loss: 2.012] [G acc: 0.062]\n",
      "23944 [D loss: (0.547)(R 0.577, F 0.518)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.035] [G acc: 0.500]\n",
      "23945 [D loss: (0.476)(R 0.375, F 0.577)] [D acc: (0.750)(0.750, 0.750)] [G loss: 5.093] [G acc: 0.562]\n",
      "23946 [D loss: (0.544)(R 0.484, F 0.605)] [D acc: (0.812)(0.812, 0.812)] [G loss: 2.135] [G acc: 0.125]\n",
      "23947 [D loss: (1.667)(R 0.666, F 2.668)] [D acc: (0.500)(0.562, 0.438)] [G loss: 1.020] [G acc: 0.312]\n",
      "23948 [D loss: (0.897)(R 0.821, F 0.973)] [D acc: (0.469)(0.438, 0.500)] [G loss: 1.163] [G acc: 0.125]\n",
      "23949 [D loss: (0.686)(R 0.515, F 0.857)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.044] [G acc: 0.188]\n",
      "23950 [D loss: (0.790)(R 0.566, F 1.014)] [D acc: (0.781)(0.812, 0.750)] [G loss: 2.417] [G acc: 0.250]\n",
      "23951 [D loss: (0.662)(R 0.719, F 0.606)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.092] [G acc: 0.188]\n",
      "23952 [D loss: (0.504)(R 0.578, F 0.430)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.877] [G acc: 0.250]\n",
      "23953 [D loss: (0.629)(R 0.858, F 0.401)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.742] [G acc: 0.250]\n",
      "23954 [D loss: (0.388)(R 0.471, F 0.305)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.856] [G acc: 0.375]\n",
      "23955 [D loss: (0.576)(R 0.459, F 0.693)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.897] [G acc: 0.125]\n",
      "23956 [D loss: (0.688)(R 0.780, F 0.596)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.865] [G acc: 0.250]\n",
      "23957 [D loss: (0.663)(R 0.557, F 0.768)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.806] [G acc: 0.250]\n",
      "23958 [D loss: (0.591)(R 0.450, F 0.733)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.921] [G acc: 0.188]\n",
      "23959 [D loss: (0.543)(R 0.472, F 0.615)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.889] [G acc: 0.250]\n",
      "23960 [D loss: (0.790)(R 0.909, F 0.671)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.191] [G acc: 0.062]\n",
      "23961 [D loss: (0.530)(R 0.464, F 0.597)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.898] [G acc: 0.312]\n",
      "23962 [D loss: (0.606)(R 0.550, F 0.663)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.768] [G acc: 0.375]\n",
      "23963 [D loss: (0.578)(R 0.470, F 0.686)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.872] [G acc: 0.250]\n",
      "23964 [D loss: (0.605)(R 0.614, F 0.597)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.812] [G acc: 0.500]\n",
      "23965 [D loss: (0.471)(R 0.351, F 0.591)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.979] [G acc: 0.312]\n",
      "23966 [D loss: (0.699)(R 0.715, F 0.682)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.649] [G acc: 0.625]\n",
      "23967 [D loss: (0.513)(R 0.410, F 0.616)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.914] [G acc: 0.062]\n",
      "23968 [D loss: (0.560)(R 0.540, F 0.580)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.875] [G acc: 0.250]\n",
      "23969 [D loss: (0.553)(R 0.456, F 0.649)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.730] [G acc: 0.438]\n",
      "23970 [D loss: (0.506)(R 0.381, F 0.630)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.877] [G acc: 0.312]\n",
      "23971 [D loss: (0.734)(R 0.597, F 0.871)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.839] [G acc: 0.312]\n",
      "23972 [D loss: (0.575)(R 0.578, F 0.571)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.821] [G acc: 0.375]\n",
      "23973 [D loss: (0.894)(R 1.109, F 0.678)] [D acc: (0.438)(0.312, 0.562)] [G loss: 0.978] [G acc: 0.188]\n",
      "23974 [D loss: (0.566)(R 0.517, F 0.616)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.759] [G acc: 0.562]\n",
      "23975 [D loss: (0.545)(R 0.620, F 0.470)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.445] [G acc: 0.875]\n",
      "23976 [D loss: (0.813)(R 0.525, F 1.101)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.924] [G acc: 0.500]\n",
      "23977 [D loss: (0.849)(R 0.524, F 1.175)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.793] [G acc: 0.312]\n",
      "23978 [D loss: (0.716)(R 0.700, F 0.731)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.785] [G acc: 0.500]\n",
      "23979 [D loss: (0.736)(R 0.781, F 0.691)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.816] [G acc: 0.312]\n",
      "23980 [D loss: (1.003)(R 0.607, F 1.399)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.563] [G acc: 0.750]\n",
      "23981 [D loss: (0.673)(R 0.618, F 0.728)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.292] [G acc: 0.750]\n",
      "23982 [D loss: (0.881)(R 0.510, F 1.251)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.862] [G acc: 0.375]\n",
      "23983 [D loss: (0.693)(R 0.559, F 0.827)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.946] [G acc: 0.375]\n",
      "23984 [D loss: (0.684)(R 0.569, F 0.799)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.707] [G acc: 0.562]\n",
      "23985 [D loss: (0.950)(R 0.565, F 1.336)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.365] [G acc: 0.688]\n",
      "23986 [D loss: (0.946)(R 0.653, F 1.240)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.802] [G acc: 0.375]\n",
      "23987 [D loss: (0.648)(R 0.522, F 0.773)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.776] [G acc: 0.312]\n",
      "23988 [D loss: (0.930)(R 1.150, F 0.710)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.989] [G acc: 0.312]\n",
      "23989 [D loss: (0.652)(R 0.717, F 0.587)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.724] [G acc: 0.375]\n",
      "23990 [D loss: (0.741)(R 0.777, F 0.706)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.819] [G acc: 0.375]\n",
      "23991 [D loss: (0.840)(R 0.734, F 0.947)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.831] [G acc: 0.125]\n",
      "23992 [D loss: (0.814)(R 0.809, F 0.819)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.728] [G acc: 0.500]\n",
      "23993 [D loss: (0.627)(R 0.557, F 0.698)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.811] [G acc: 0.312]\n",
      "23994 [D loss: (0.677)(R 0.711, F 0.642)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.736] [G acc: 0.375]\n",
      "23995 [D loss: (0.741)(R 0.671, F 0.811)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.823] [G acc: 0.188]\n",
      "23996 [D loss: (0.716)(R 0.767, F 0.666)] [D acc: (0.375)(0.188, 0.562)] [G loss: 0.793] [G acc: 0.312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23997 [D loss: (0.676)(R 0.624, F 0.729)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.794] [G acc: 0.062]\n",
      "23998 [D loss: (0.714)(R 0.670, F 0.757)] [D acc: (0.438)(0.312, 0.562)] [G loss: 0.663] [G acc: 0.438]\n",
      "23999 [D loss: (0.929)(R 0.727, F 1.131)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.811] [G acc: 0.375]\n",
      "24000 [D loss: (0.718)(R 0.807, F 0.629)] [D acc: (0.500)(0.312, 0.688)] [G loss: 0.725] [G acc: 0.438]\n",
      "24001 [D loss: (0.822)(R 0.719, F 0.925)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.860] [G acc: 0.562]\n",
      "24002 [D loss: (0.859)(R 0.722, F 0.996)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.913] [G acc: 0.625]\n",
      "24003 [D loss: (0.782)(R 0.779, F 0.785)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.704] [G acc: 0.375]\n",
      "24004 [D loss: (0.922)(R 0.877, F 0.966)] [D acc: (0.312)(0.062, 0.562)] [G loss: 0.890] [G acc: 0.062]\n",
      "24005 [D loss: (0.683)(R 0.608, F 0.757)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.688] [G acc: 0.312]\n",
      "24006 [D loss: (0.726)(R 0.867, F 0.586)] [D acc: (0.531)(0.188, 0.875)] [G loss: 0.592] [G acc: 0.375]\n",
      "24007 [D loss: (0.811)(R 0.711, F 0.912)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.737] [G acc: 0.375]\n",
      "24008 [D loss: (1.027)(R 0.715, F 1.339)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.660] [G acc: 0.375]\n",
      "24009 [D loss: (0.753)(R 0.738, F 0.769)] [D acc: (0.406)(0.250, 0.562)] [G loss: 0.669] [G acc: 0.562]\n",
      "24010 [D loss: (0.908)(R 0.759, F 1.056)] [D acc: (0.438)(0.312, 0.562)] [G loss: 0.604] [G acc: 0.500]\n",
      "24011 [D loss: (0.912)(R 0.847, F 0.978)] [D acc: (0.344)(0.250, 0.438)] [G loss: 0.611] [G acc: 0.562]\n",
      "24012 [D loss: (1.145)(R 0.754, F 1.535)] [D acc: (0.375)(0.438, 0.312)] [G loss: 0.903] [G acc: 0.188]\n",
      "24013 [D loss: (0.894)(R 0.673, F 1.115)] [D acc: (0.438)(0.438, 0.438)] [G loss: 1.223] [G acc: 0.375]\n",
      "24014 [D loss: (0.699)(R 0.768, F 0.630)] [D acc: (0.531)(0.250, 0.812)] [G loss: 0.868] [G acc: 0.188]\n",
      "24015 [D loss: (0.688)(R 0.732, F 0.644)] [D acc: (0.500)(0.250, 0.750)] [G loss: 0.999] [G acc: 0.250]\n",
      "24016 [D loss: (0.640)(R 0.652, F 0.628)] [D acc: (0.656)(0.312, 1.000)] [G loss: 0.782] [G acc: 0.062]\n",
      "24017 [D loss: (0.680)(R 0.735, F 0.625)] [D acc: (0.688)(0.375, 1.000)] [G loss: 0.745] [G acc: 0.250]\n",
      "24018 [D loss: (0.681)(R 0.730, F 0.632)] [D acc: (0.562)(0.188, 0.938)] [G loss: 0.768] [G acc: 0.188]\n",
      "24019 [D loss: (0.724)(R 0.795, F 0.654)] [D acc: (0.562)(0.250, 0.875)] [G loss: 0.746] [G acc: 0.250]\n",
      "24020 [D loss: (0.723)(R 0.765, F 0.681)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.741] [G acc: 0.188]\n",
      "24021 [D loss: (0.707)(R 0.740, F 0.673)] [D acc: (0.500)(0.312, 0.688)] [G loss: 0.746] [G acc: 0.125]\n",
      "24022 [D loss: (0.697)(R 0.683, F 0.712)] [D acc: (0.500)(0.250, 0.750)] [G loss: 0.728] [G acc: 0.250]\n",
      "24023 [D loss: (0.648)(R 0.670, F 0.625)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.713] [G acc: 0.125]\n",
      "24024 [D loss: (0.619)(R 0.580, F 0.659)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.645] [G acc: 0.562]\n",
      "24025 [D loss: (0.743)(R 0.776, F 0.709)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.711] [G acc: 0.188]\n",
      "24026 [D loss: (0.699)(R 0.605, F 0.792)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.615] [G acc: 0.500]\n",
      "24027 [D loss: (0.771)(R 0.695, F 0.848)] [D acc: (0.406)(0.188, 0.625)] [G loss: 0.773] [G acc: 0.250]\n",
      "24028 [D loss: (0.907)(R 0.772, F 1.042)] [D acc: (0.438)(0.250, 0.625)] [G loss: 0.587] [G acc: 0.438]\n",
      "24029 [D loss: (0.787)(R 0.736, F 0.837)] [D acc: (0.469)(0.188, 0.750)] [G loss: 0.894] [G acc: 0.312]\n",
      "24030 [D loss: (0.647)(R 0.660, F 0.634)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.788] [G acc: 0.375]\n",
      "24031 [D loss: (0.784)(R 0.695, F 0.874)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.768] [G acc: 0.250]\n",
      "24032 [D loss: (0.684)(R 0.719, F 0.650)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.723] [G acc: 0.438]\n",
      "24033 [D loss: (0.694)(R 0.794, F 0.594)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.683] [G acc: 0.375]\n",
      "24034 [D loss: (0.644)(R 0.618, F 0.671)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.733] [G acc: 0.188]\n",
      "24035 [D loss: (0.777)(R 0.710, F 0.844)] [D acc: (0.406)(0.312, 0.500)] [G loss: 1.032] [G acc: 0.438]\n",
      "24036 [D loss: (1.314)(R 0.647, F 1.980)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.928] [G acc: 0.188]\n",
      "24037 [D loss: (0.656)(R 0.714, F 0.599)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.729] [G acc: 0.250]\n",
      "24038 [D loss: (0.669)(R 0.702, F 0.636)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.791] [G acc: 0.312]\n",
      "24039 [D loss: (0.664)(R 0.687, F 0.640)] [D acc: (0.594)(0.312, 0.875)] [G loss: 0.765] [G acc: 0.188]\n",
      "24040 [D loss: (0.661)(R 0.711, F 0.611)] [D acc: (0.594)(0.312, 0.875)] [G loss: 0.767] [G acc: 0.125]\n",
      "24041 [D loss: (0.644)(R 0.648, F 0.641)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.742] [G acc: 0.188]\n",
      "24042 [D loss: (0.636)(R 0.685, F 0.587)] [D acc: (0.719)(0.500, 0.938)] [G loss: 0.766] [G acc: 0.500]\n",
      "24043 [D loss: (0.685)(R 0.703, F 0.666)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.732] [G acc: 0.188]\n",
      "24044 [D loss: (0.666)(R 0.678, F 0.653)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.697] [G acc: 0.438]\n",
      "24045 [D loss: (0.740)(R 0.646, F 0.833)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.828] [G acc: 0.250]\n",
      "24046 [D loss: (0.693)(R 0.714, F 0.673)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.634] [G acc: 0.438]\n",
      "24047 [D loss: (0.735)(R 0.748, F 0.723)] [D acc: (0.375)(0.188, 0.562)] [G loss: 0.751] [G acc: 0.250]\n",
      "24048 [D loss: (0.716)(R 0.705, F 0.726)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.896] [G acc: 0.188]\n",
      "24049 [D loss: (0.657)(R 0.675, F 0.639)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.747] [G acc: 0.188]\n",
      "24050 [D loss: (0.625)(R 0.615, F 0.636)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.840] [G acc: 0.000]\n",
      "24051 [D loss: (0.748)(R 0.800, F 0.696)] [D acc: (0.406)(0.125, 0.688)] [G loss: 0.785] [G acc: 0.188]\n",
      "24052 [D loss: (0.725)(R 0.801, F 0.648)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.754] [G acc: 0.188]\n",
      "24053 [D loss: (0.671)(R 0.684, F 0.657)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.765] [G acc: 0.250]\n",
      "24054 [D loss: (0.718)(R 0.740, F 0.697)] [D acc: (0.375)(0.312, 0.438)] [G loss: 0.757] [G acc: 0.125]\n",
      "24055 [D loss: (0.676)(R 0.711, F 0.640)] [D acc: (0.500)(0.250, 0.750)] [G loss: 0.762] [G acc: 0.125]\n",
      "24056 [D loss: (0.660)(R 0.660, F 0.660)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.765] [G acc: 0.125]\n",
      "24057 [D loss: (0.696)(R 0.738, F 0.654)] [D acc: (0.531)(0.312, 0.750)] [G loss: 1.032] [G acc: 0.312]\n",
      "24058 [D loss: (0.642)(R 0.674, F 0.610)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.708] [G acc: 0.375]\n",
      "24059 [D loss: (0.755)(R 0.700, F 0.811)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.667] [G acc: 0.438]\n",
      "24060 [D loss: (0.805)(R 0.734, F 0.877)] [D acc: (0.562)(0.500, 0.625)] [G loss: 1.177] [G acc: 0.312]\n",
      "24061 [D loss: (0.711)(R 0.793, F 0.630)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.810] [G acc: 0.250]\n",
      "24062 [D loss: (0.663)(R 0.690, F 0.636)] [D acc: (0.562)(0.312, 0.812)] [G loss: 0.817] [G acc: 0.188]\n",
      "24063 [D loss: (0.654)(R 0.666, F 0.643)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.756] [G acc: 0.312]\n",
      "24064 [D loss: (0.665)(R 0.700, F 0.631)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.800] [G acc: 0.250]\n",
      "24065 [D loss: (0.683)(R 0.680, F 0.686)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.885] [G acc: 0.250]\n",
      "24066 [D loss: (0.625)(R 0.666, F 0.585)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.767] [G acc: 0.250]\n",
      "24067 [D loss: (0.590)(R 0.606, F 0.574)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.849] [G acc: 0.312]\n",
      "24068 [D loss: (0.656)(R 0.690, F 0.622)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.719] [G acc: 0.438]\n",
      "24069 [D loss: (0.644)(R 0.693, F 0.595)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.653] [G acc: 0.500]\n",
      "24070 [D loss: (0.672)(R 0.698, F 0.646)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.865] [G acc: 0.312]\n",
      "24071 [D loss: (0.651)(R 0.647, F 0.654)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.734] [G acc: 0.375]\n",
      "24072 [D loss: (0.634)(R 0.636, F 0.633)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.762] [G acc: 0.188]\n",
      "24073 [D loss: (0.633)(R 0.633, F 0.634)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.754] [G acc: 0.375]\n",
      "24074 [D loss: (0.665)(R 0.657, F 0.673)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.783] [G acc: 0.188]\n",
      "24075 [D loss: (0.710)(R 0.710, F 0.709)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.615] [G acc: 0.562]\n",
      "24076 [D loss: (0.680)(R 0.657, F 0.703)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.820] [G acc: 0.375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24077 [D loss: (1.351)(R 0.612, F 2.089)] [D acc: (0.531)(0.438, 0.625)] [G loss: 2.674] [G acc: 0.312]\n",
      "24078 [D loss: (0.695)(R 0.670, F 0.720)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.944] [G acc: 0.000]\n",
      "24079 [D loss: (0.943)(R 1.303, F 0.582)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.010] [G acc: 0.312]\n",
      "24080 [D loss: (0.752)(R 0.800, F 0.703)] [D acc: (0.281)(0.125, 0.438)] [G loss: 0.931] [G acc: 0.125]\n",
      "24081 [D loss: (0.644)(R 0.623, F 0.665)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.796] [G acc: 0.312]\n",
      "24082 [D loss: (0.645)(R 0.641, F 0.650)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.787] [G acc: 0.375]\n",
      "24083 [D loss: (0.692)(R 0.734, F 0.650)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.782] [G acc: 0.438]\n",
      "24084 [D loss: (0.737)(R 0.705, F 0.768)] [D acc: (0.562)(0.562, 0.562)] [G loss: 1.108] [G acc: 0.250]\n",
      "24085 [D loss: (0.613)(R 0.579, F 0.648)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.816] [G acc: 0.125]\n",
      "24086 [D loss: (0.634)(R 0.647, F 0.622)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.729] [G acc: 0.312]\n",
      "24087 [D loss: (0.607)(R 0.582, F 0.632)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.793] [G acc: 0.188]\n",
      "24088 [D loss: (0.583)(R 0.531, F 0.635)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.686] [G acc: 0.625]\n",
      "24089 [D loss: (0.730)(R 0.622, F 0.838)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.702] [G acc: 0.312]\n",
      "24090 [D loss: (0.714)(R 0.695, F 0.733)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.760] [G acc: 0.438]\n",
      "24091 [D loss: (0.742)(R 0.746, F 0.738)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.901] [G acc: 0.375]\n",
      "24092 [D loss: (0.767)(R 0.754, F 0.779)] [D acc: (0.375)(0.375, 0.375)] [G loss: 0.719] [G acc: 0.188]\n",
      "24093 [D loss: (0.656)(R 0.661, F 0.651)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.767] [G acc: 0.312]\n",
      "24094 [D loss: (0.565)(R 0.503, F 0.628)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.672] [G acc: 0.500]\n",
      "24095 [D loss: (0.737)(R 0.756, F 0.718)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.601] [G acc: 0.750]\n",
      "24096 [D loss: (0.731)(R 0.686, F 0.777)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.652] [G acc: 0.688]\n",
      "24097 [D loss: (0.713)(R 0.637, F 0.788)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.815] [G acc: 0.312]\n",
      "24098 [D loss: (0.725)(R 0.741, F 0.709)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.725] [G acc: 0.375]\n",
      "24099 [D loss: (0.762)(R 0.758, F 0.767)] [D acc: (0.375)(0.375, 0.375)] [G loss: 0.803] [G acc: 0.375]\n",
      "24100 [D loss: (0.733)(R 0.755, F 0.710)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.828] [G acc: 0.312]\n",
      "24101 [D loss: (0.693)(R 0.698, F 0.687)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.657] [G acc: 0.562]\n",
      "24102 [D loss: (0.649)(R 0.718, F 0.579)] [D acc: (0.531)(0.312, 0.750)] [G loss: 1.086] [G acc: 0.188]\n",
      "24103 [D loss: (0.698)(R 0.720, F 0.676)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.743] [G acc: 0.438]\n",
      "24104 [D loss: (0.675)(R 0.700, F 0.651)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.715] [G acc: 0.438]\n",
      "24105 [D loss: (0.706)(R 0.732, F 0.679)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.712] [G acc: 0.500]\n",
      "24106 [D loss: (0.656)(R 0.673, F 0.639)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.738] [G acc: 0.500]\n",
      "24107 [D loss: (0.733)(R 0.686, F 0.780)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.697] [G acc: 0.500]\n",
      "24108 [D loss: (0.691)(R 0.590, F 0.792)] [D acc: (0.375)(0.500, 0.250)] [G loss: 0.775] [G acc: 0.375]\n",
      "24109 [D loss: (0.734)(R 0.733, F 0.736)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.630] [G acc: 0.688]\n",
      "24110 [D loss: (0.714)(R 0.700, F 0.727)] [D acc: (0.438)(0.312, 0.562)] [G loss: 0.686] [G acc: 0.562]\n",
      "24111 [D loss: (0.723)(R 0.712, F 0.734)] [D acc: (0.375)(0.375, 0.375)] [G loss: 0.740] [G acc: 0.438]\n",
      "24112 [D loss: (0.712)(R 0.720, F 0.704)] [D acc: (0.375)(0.312, 0.438)] [G loss: 0.630] [G acc: 0.688]\n",
      "24113 [D loss: (0.695)(R 0.616, F 0.773)] [D acc: (0.344)(0.375, 0.312)] [G loss: 0.830] [G acc: 0.250]\n",
      "24114 [D loss: (0.705)(R 0.695, F 0.716)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.875] [G acc: 0.188]\n",
      "24115 [D loss: (0.644)(R 0.739, F 0.550)] [D acc: (0.500)(0.250, 0.750)] [G loss: 0.871] [G acc: 0.188]\n",
      "24116 [D loss: (0.650)(R 0.620, F 0.679)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.669] [G acc: 0.438]\n",
      "24117 [D loss: (0.747)(R 0.696, F 0.798)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.992] [G acc: 0.312]\n",
      "24118 [D loss: (0.747)(R 0.820, F 0.674)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.896] [G acc: 0.250]\n",
      "24119 [D loss: (0.672)(R 0.705, F 0.639)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.744] [G acc: 0.500]\n",
      "24120 [D loss: (0.589)(R 0.615, F 0.563)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.718] [G acc: 0.375]\n",
      "24121 [D loss: (0.652)(R 0.712, F 0.593)] [D acc: (0.406)(0.125, 0.688)] [G loss: 0.702] [G acc: 0.625]\n",
      "24122 [D loss: (0.700)(R 0.617, F 0.783)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.676] [G acc: 0.562]\n",
      "24123 [D loss: (0.572)(R 0.683, F 0.460)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.862] [G acc: 0.438]\n",
      "24124 [D loss: (0.530)(R 0.687, F 0.374)] [D acc: (0.594)(0.438, 0.750)] [G loss: 1.099] [G acc: 0.312]\n",
      "24125 [D loss: (0.704)(R 0.640, F 0.767)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.714] [G acc: 0.562]\n",
      "24126 [D loss: (0.771)(R 0.706, F 0.837)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.623] [G acc: 0.562]\n",
      "24127 [D loss: (0.693)(R 0.659, F 0.726)] [D acc: (0.531)(0.375, 0.688)] [G loss: 2.206] [G acc: 0.188]\n",
      "24128 [D loss: (0.547)(R 0.725, F 0.369)] [D acc: (0.531)(0.312, 0.750)] [G loss: 5.296] [G acc: 0.125]\n",
      "24129 [D loss: (0.652)(R 0.738, F 0.566)] [D acc: (0.531)(0.375, 0.688)] [G loss: 1.092] [G acc: 0.312]\n",
      "24130 [D loss: (0.563)(R 0.632, F 0.494)] [D acc: (0.656)(0.625, 0.688)] [G loss: 2.325] [G acc: 0.250]\n",
      "24131 [D loss: (0.566)(R 0.709, F 0.423)] [D acc: (0.469)(0.312, 0.625)] [G loss: 1.098] [G acc: 0.188]\n",
      "24132 [D loss: (0.574)(R 0.790, F 0.358)] [D acc: (0.594)(0.438, 0.750)] [G loss: 1.794] [G acc: 0.250]\n",
      "24133 [D loss: (0.797)(R 0.689, F 0.906)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.857] [G acc: 0.312]\n",
      "24134 [D loss: (0.532)(R 0.548, F 0.516)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.883] [G acc: 0.312]\n",
      "24135 [D loss: (0.772)(R 0.735, F 0.809)] [D acc: (0.375)(0.500, 0.250)] [G loss: 0.780] [G acc: 0.500]\n",
      "24136 [D loss: (0.651)(R 0.639, F 0.664)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.691] [G acc: 0.500]\n",
      "24137 [D loss: (0.627)(R 0.652, F 0.603)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.821] [G acc: 0.312]\n",
      "24138 [D loss: (0.663)(R 0.652, F 0.675)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.845] [G acc: 0.375]\n",
      "24139 [D loss: (0.685)(R 0.660, F 0.709)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.851] [G acc: 0.312]\n",
      "24140 [D loss: (0.489)(R 0.700, F 0.278)] [D acc: (0.656)(0.500, 0.812)] [G loss: 2.172] [G acc: 0.250]\n",
      "24141 [D loss: (0.706)(R 1.146, F 0.265)] [D acc: (0.594)(0.312, 0.875)] [G loss: 6.696] [G acc: 0.125]\n",
      "24142 [D loss: (0.646)(R 0.706, F 0.587)] [D acc: (0.438)(0.312, 0.562)] [G loss: 0.889] [G acc: 0.500]\n",
      "24143 [D loss: (0.630)(R 0.635, F 0.626)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.682] [G acc: 0.500]\n",
      "24144 [D loss: (0.661)(R 0.663, F 0.659)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.823] [G acc: 0.375]\n",
      "24145 [D loss: (0.680)(R 0.674, F 0.685)] [D acc: (0.375)(0.312, 0.438)] [G loss: 0.960] [G acc: 0.250]\n",
      "24146 [D loss: (0.713)(R 0.837, F 0.588)] [D acc: (0.438)(0.250, 0.625)] [G loss: 0.689] [G acc: 0.500]\n",
      "24147 [D loss: (0.672)(R 0.708, F 0.637)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.815] [G acc: 0.312]\n",
      "24148 [D loss: (0.654)(R 0.705, F 0.604)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.762] [G acc: 0.312]\n",
      "24149 [D loss: (0.614)(R 0.595, F 0.633)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.801] [G acc: 0.438]\n",
      "24150 [D loss: (0.593)(R 0.612, F 0.574)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.068] [G acc: 0.062]\n",
      "24151 [D loss: (0.623)(R 0.636, F 0.609)] [D acc: (0.562)(0.438, 0.688)] [G loss: 1.583] [G acc: 0.125]\n",
      "24152 [D loss: (0.581)(R 0.731, F 0.432)] [D acc: (0.688)(0.375, 1.000)] [G loss: 1.150] [G acc: 0.188]\n",
      "24153 [D loss: (0.633)(R 0.672, F 0.594)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.803] [G acc: 0.500]\n",
      "24154 [D loss: (0.566)(R 0.557, F 0.574)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.418] [G acc: 0.188]\n",
      "24155 [D loss: (0.623)(R 0.726, F 0.520)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.183] [G acc: 0.188]\n",
      "24156 [D loss: (0.561)(R 0.685, F 0.436)] [D acc: (0.625)(0.438, 0.812)] [G loss: 3.227] [G acc: 0.062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24157 [D loss: (0.406)(R 0.666, F 0.146)] [D acc: (0.812)(0.625, 1.000)] [G loss: 6.228] [G acc: 0.000]\n",
      "24158 [D loss: (0.518)(R 0.709, F 0.327)] [D acc: (0.656)(0.438, 0.875)] [G loss: 2.791] [G acc: 0.000]\n",
      "24159 [D loss: (0.691)(R 0.629, F 0.753)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.983] [G acc: 0.438]\n",
      "24160 [D loss: (0.546)(R 0.673, F 0.419)] [D acc: (0.625)(0.438, 0.812)] [G loss: 1.696] [G acc: 0.062]\n",
      "24161 [D loss: (0.554)(R 0.585, F 0.524)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.587] [G acc: 0.188]\n",
      "24162 [D loss: (0.532)(R 0.549, F 0.514)] [D acc: (0.875)(0.938, 0.812)] [G loss: 2.041] [G acc: 0.250]\n",
      "24163 [D loss: (0.636)(R 0.627, F 0.646)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.280] [G acc: 0.312]\n",
      "24164 [D loss: (0.815)(R 1.104, F 0.527)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.828] [G acc: 0.312]\n",
      "24165 [D loss: (0.663)(R 0.619, F 0.706)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.641] [G acc: 0.688]\n",
      "24166 [D loss: (0.639)(R 0.566, F 0.712)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.740] [G acc: 0.500]\n",
      "24167 [D loss: (0.892)(R 1.028, F 0.756)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.436] [G acc: 0.812]\n",
      "24168 [D loss: (0.692)(R 0.648, F 0.737)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.678] [G acc: 0.375]\n",
      "24169 [D loss: (0.599)(R 0.531, F 0.667)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.742] [G acc: 0.375]\n",
      "24170 [D loss: (0.597)(R 0.483, F 0.712)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.768] [G acc: 0.125]\n",
      "24171 [D loss: (0.673)(R 0.624, F 0.723)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.685] [G acc: 0.438]\n",
      "24172 [D loss: (0.633)(R 0.596, F 0.670)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.788] [G acc: 0.438]\n",
      "24173 [D loss: (0.575)(R 0.497, F 0.654)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.766] [G acc: 0.188]\n",
      "24174 [D loss: (0.576)(R 0.538, F 0.614)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.774] [G acc: 0.625]\n",
      "24175 [D loss: (0.586)(R 0.584, F 0.589)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.215] [G acc: 0.188]\n",
      "24176 [D loss: (0.503)(R 0.549, F 0.457)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.240] [G acc: 0.312]\n",
      "24177 [D loss: (0.440)(R 0.507, F 0.373)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.490] [G acc: 0.062]\n",
      "24178 [D loss: (0.580)(R 0.511, F 0.649)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.789] [G acc: 0.125]\n",
      "24179 [D loss: (0.642)(R 0.669, F 0.616)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.842] [G acc: 0.125]\n",
      "24180 [D loss: (0.586)(R 0.547, F 0.624)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.135] [G acc: 0.062]\n",
      "24181 [D loss: (0.462)(R 0.491, F 0.432)] [D acc: (0.750)(0.875, 0.625)] [G loss: 0.849] [G acc: 0.375]\n",
      "24182 [D loss: (0.524)(R 0.410, F 0.638)] [D acc: (0.719)(0.875, 0.562)] [G loss: 3.512] [G acc: 0.312]\n",
      "24183 [D loss: (0.500)(R 0.486, F 0.514)] [D acc: (0.688)(0.688, 0.688)] [G loss: 8.800] [G acc: 0.438]\n",
      "24184 [D loss: (0.983)(R 0.463, F 1.502)] [D acc: (0.594)(0.812, 0.375)] [G loss: 5.460] [G acc: 0.375]\n",
      "24185 [D loss: (0.535)(R 0.477, F 0.593)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.748] [G acc: 0.375]\n",
      "24186 [D loss: (0.569)(R 0.463, F 0.675)] [D acc: (0.750)(0.938, 0.562)] [G loss: 0.993] [G acc: 0.188]\n",
      "24187 [D loss: (0.651)(R 0.646, F 0.657)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.792] [G acc: 0.562]\n",
      "24188 [D loss: (0.645)(R 0.609, F 0.681)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.997] [G acc: 0.312]\n",
      "24189 [D loss: (0.605)(R 0.536, F 0.673)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.217] [G acc: 0.125]\n",
      "24190 [D loss: (0.626)(R 0.755, F 0.496)] [D acc: (0.594)(0.500, 0.688)] [G loss: 1.041] [G acc: 0.125]\n",
      "24191 [D loss: (0.547)(R 0.574, F 0.520)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.197] [G acc: 0.125]\n",
      "24192 [D loss: (0.670)(R 0.627, F 0.713)] [D acc: (0.562)(0.625, 0.500)] [G loss: 1.093] [G acc: 0.250]\n",
      "24193 [D loss: (0.537)(R 0.507, F 0.567)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.236] [G acc: 0.188]\n",
      "24194 [D loss: (0.459)(R 0.553, F 0.365)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.074] [G acc: 0.438]\n",
      "24195 [D loss: (0.439)(R 0.511, F 0.368)] [D acc: (0.812)(0.688, 0.938)] [G loss: 2.789] [G acc: 0.250]\n",
      "24196 [D loss: (0.561)(R 0.711, F 0.412)] [D acc: (0.688)(0.688, 0.688)] [G loss: 2.388] [G acc: 0.438]\n",
      "24197 [D loss: (0.379)(R 0.469, F 0.288)] [D acc: (0.875)(0.750, 1.000)] [G loss: 2.253] [G acc: 0.438]\n",
      "24198 [D loss: (0.682)(R 0.524, F 0.840)] [D acc: (0.656)(0.750, 0.562)] [G loss: 2.416] [G acc: 0.312]\n",
      "24199 [D loss: (0.615)(R 0.479, F 0.751)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.955] [G acc: 0.438]\n",
      "24200 [D loss: (0.669)(R 0.609, F 0.729)] [D acc: (0.562)(0.750, 0.375)] [G loss: 3.517] [G acc: 0.250]\n",
      "24201 [D loss: (0.408)(R 0.577, F 0.238)] [D acc: (0.812)(0.688, 0.938)] [G loss: 2.441] [G acc: 0.125]\n",
      "24202 [D loss: (0.728)(R 0.579, F 0.877)] [D acc: (0.469)(0.562, 0.375)] [G loss: 4.660] [G acc: 0.250]\n",
      "24203 [D loss: (1.110)(R 0.557, F 1.664)] [D acc: (0.625)(0.625, 0.625)] [G loss: 6.018] [G acc: 0.312]\n",
      "24204 [D loss: (0.705)(R 0.584, F 0.826)] [D acc: (0.562)(0.562, 0.562)] [G loss: 3.396] [G acc: 0.188]\n",
      "24205 [D loss: (0.611)(R 0.797, F 0.425)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.268] [G acc: 0.125]\n",
      "24206 [D loss: (0.621)(R 0.602, F 0.639)] [D acc: (0.688)(0.750, 0.625)] [G loss: 2.069] [G acc: 0.375]\n",
      "24207 [D loss: (0.549)(R 0.638, F 0.460)] [D acc: (0.719)(0.562, 0.875)] [G loss: 2.422] [G acc: 0.188]\n",
      "24208 [D loss: (0.603)(R 0.546, F 0.659)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.178] [G acc: 0.125]\n",
      "24209 [D loss: (0.417)(R 0.454, F 0.381)] [D acc: (0.812)(0.750, 0.875)] [G loss: 3.178] [G acc: 0.250]\n",
      "24210 [D loss: (0.528)(R 0.699, F 0.358)] [D acc: (0.625)(0.562, 0.688)] [G loss: 4.880] [G acc: 0.062]\n",
      "24211 [D loss: (0.539)(R 0.611, F 0.467)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.612] [G acc: 0.125]\n",
      "24212 [D loss: (0.532)(R 0.551, F 0.512)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.423] [G acc: 0.250]\n",
      "24213 [D loss: (0.594)(R 0.588, F 0.599)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.044] [G acc: 0.500]\n",
      "24214 [D loss: (0.498)(R 0.516, F 0.480)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.433] [G acc: 0.125]\n",
      "24215 [D loss: (0.604)(R 0.650, F 0.558)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.338] [G acc: 0.250]\n",
      "24216 [D loss: (0.756)(R 0.833, F 0.679)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.990] [G acc: 0.125]\n",
      "24217 [D loss: (0.568)(R 0.568, F 0.569)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.955] [G acc: 0.062]\n",
      "24218 [D loss: (0.586)(R 0.577, F 0.595)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.071] [G acc: 0.125]\n",
      "24219 [D loss: (0.653)(R 0.689, F 0.617)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.838] [G acc: 0.125]\n",
      "24220 [D loss: (0.612)(R 0.646, F 0.579)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.674] [G acc: 0.500]\n",
      "24221 [D loss: (0.539)(R 0.447, F 0.631)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.843] [G acc: 0.188]\n",
      "24222 [D loss: (0.595)(R 0.568, F 0.622)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.716] [G acc: 0.438]\n",
      "24223 [D loss: (0.498)(R 0.505, F 0.492)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.693] [G acc: 0.500]\n",
      "24224 [D loss: (0.574)(R 0.521, F 0.627)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.981] [G acc: 0.250]\n",
      "24225 [D loss: (0.622)(R 0.676, F 0.568)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.746] [G acc: 0.375]\n",
      "24226 [D loss: (0.610)(R 0.602, F 0.618)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.827] [G acc: 0.188]\n",
      "24227 [D loss: (0.679)(R 0.659, F 0.700)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.839] [G acc: 0.250]\n",
      "24228 [D loss: (0.632)(R 0.627, F 0.638)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.791] [G acc: 0.188]\n",
      "24229 [D loss: (0.433)(R 0.464, F 0.403)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.462] [G acc: 0.062]\n",
      "24230 [D loss: (0.699)(R 0.571, F 0.827)] [D acc: (0.562)(0.625, 0.500)] [G loss: 1.280] [G acc: 0.125]\n",
      "24231 [D loss: (0.403)(R 0.615, F 0.191)] [D acc: (0.656)(0.438, 0.875)] [G loss: 7.459] [G acc: 0.062]\n",
      "24232 [D loss: (0.618)(R 0.664, F 0.573)] [D acc: (0.750)(0.688, 0.812)] [G loss: 5.681] [G acc: 0.188]\n",
      "24233 [D loss: (0.514)(R 0.496, F 0.531)] [D acc: (0.875)(0.812, 0.938)] [G loss: 0.935] [G acc: 0.250]\n",
      "24234 [D loss: (0.555)(R 0.472, F 0.638)] [D acc: (0.781)(0.938, 0.625)] [G loss: 0.724] [G acc: 0.438]\n",
      "24235 [D loss: (0.812)(R 0.954, F 0.671)] [D acc: (0.500)(0.500, 0.500)] [G loss: 1.157] [G acc: 0.250]\n",
      "24236 [D loss: (0.607)(R 0.548, F 0.666)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.954] [G acc: 0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24237 [D loss: (0.578)(R 0.599, F 0.557)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.381] [G acc: 0.125]\n",
      "24238 [D loss: (0.493)(R 0.511, F 0.476)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.142] [G acc: 0.062]\n",
      "24239 [D loss: (0.549)(R 0.482, F 0.616)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.899] [G acc: 0.250]\n",
      "24240 [D loss: (0.557)(R 0.459, F 0.654)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.875] [G acc: 0.188]\n",
      "24241 [D loss: (0.890)(R 1.203, F 0.577)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.833] [G acc: 0.312]\n",
      "24242 [D loss: (0.581)(R 0.485, F 0.677)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.795] [G acc: 0.312]\n",
      "24243 [D loss: (0.686)(R 0.521, F 0.851)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.821] [G acc: 0.125]\n",
      "24244 [D loss: (0.482)(R 0.391, F 0.572)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.675] [G acc: 0.438]\n",
      "24245 [D loss: (1.171)(R 1.663, F 0.679)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.818] [G acc: 0.562]\n",
      "24246 [D loss: (0.484)(R 0.568, F 0.400)] [D acc: (0.750)(0.688, 0.812)] [G loss: 2.978] [G acc: 0.250]\n",
      "24247 [D loss: (0.500)(R 0.523, F 0.477)] [D acc: (0.750)(0.688, 0.812)] [G loss: 3.682] [G acc: 0.188]\n",
      "24248 [D loss: (0.530)(R 0.376, F 0.683)] [D acc: (0.781)(0.875, 0.688)] [G loss: 1.148] [G acc: 0.438]\n",
      "24249 [D loss: (0.496)(R 0.566, F 0.427)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.269] [G acc: 0.312]\n",
      "24250 [D loss: (0.489)(R 0.460, F 0.518)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.901] [G acc: 0.250]\n",
      "24251 [D loss: (0.773)(R 0.734, F 0.813)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.888] [G acc: 0.250]\n",
      "24252 [D loss: (0.659)(R 0.528, F 0.790)] [D acc: (0.562)(0.688, 0.438)] [G loss: 1.225] [G acc: 0.125]\n",
      "24253 [D loss: (0.563)(R 0.654, F 0.471)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.102] [G acc: 0.062]\n",
      "24254 [D loss: (0.487)(R 0.454, F 0.519)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.388] [G acc: 0.062]\n",
      "24255 [D loss: (0.990)(R 1.350, F 0.630)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.790] [G acc: 0.125]\n",
      "24256 [D loss: (0.639)(R 0.614, F 0.664)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.722] [G acc: 0.250]\n",
      "24257 [D loss: (0.588)(R 0.544, F 0.632)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.872] [G acc: 0.062]\n",
      "24258 [D loss: (0.565)(R 0.470, F 0.659)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.066] [G acc: 0.125]\n",
      "24259 [D loss: (0.492)(R 0.647, F 0.337)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.050] [G acc: 0.062]\n",
      "24260 [D loss: (0.548)(R 0.443, F 0.652)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.803] [G acc: 0.250]\n",
      "24261 [D loss: (0.626)(R 0.570, F 0.682)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.561] [G acc: 0.500]\n",
      "24262 [D loss: (0.726)(R 1.137, F 0.316)] [D acc: (0.844)(0.812, 0.875)] [G loss: 7.912] [G acc: 0.250]\n",
      "24263 [D loss: (0.735)(R 0.450, F 1.019)] [D acc: (0.562)(0.625, 0.500)] [G loss: 1.827] [G acc: 0.500]\n",
      "24264 [D loss: (0.434)(R 0.566, F 0.303)] [D acc: (0.719)(0.625, 0.812)] [G loss: 2.235] [G acc: 0.188]\n",
      "24265 [D loss: (1.333)(R 1.544, F 1.122)] [D acc: (0.625)(0.688, 0.562)] [G loss: 2.981] [G acc: 0.562]\n",
      "24266 [D loss: (0.814)(R 0.670, F 0.958)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.095] [G acc: 0.312]\n",
      "24267 [D loss: (0.566)(R 0.519, F 0.612)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.119] [G acc: 0.375]\n",
      "24268 [D loss: (0.616)(R 0.582, F 0.649)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.790] [G acc: 0.188]\n",
      "24269 [D loss: (1.858)(R 3.054, F 0.663)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.797] [G acc: 0.188]\n",
      "24270 [D loss: (0.573)(R 0.584, F 0.561)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.873] [G acc: 0.250]\n",
      "24271 [D loss: (0.714)(R 0.643, F 0.786)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.895] [G acc: 0.125]\n",
      "24272 [D loss: (0.520)(R 0.485, F 0.554)] [D acc: (0.938)(0.875, 1.000)] [G loss: 0.794] [G acc: 0.312]\n",
      "24273 [D loss: (0.562)(R 0.611, F 0.514)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.046] [G acc: 0.188]\n",
      "24274 [D loss: (0.545)(R 0.409, F 0.682)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.872] [G acc: 0.250]\n",
      "24275 [D loss: (0.640)(R 0.628, F 0.652)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.573] [G acc: 0.688]\n",
      "24276 [D loss: (0.584)(R 0.525, F 0.644)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.832] [G acc: 0.188]\n",
      "24277 [D loss: (0.749)(R 0.805, F 0.693)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.879] [G acc: 0.188]\n",
      "24278 [D loss: (0.593)(R 0.633, F 0.553)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.764] [G acc: 0.375]\n",
      "24279 [D loss: (0.610)(R 0.538, F 0.681)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.976] [G acc: 0.250]\n",
      "24280 [D loss: (0.871)(R 0.779, F 0.964)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.775] [G acc: 0.250]\n",
      "24281 [D loss: (0.635)(R 0.571, F 0.700)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.892] [G acc: 0.125]\n",
      "24282 [D loss: (0.640)(R 0.625, F 0.654)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.579] [G acc: 0.562]\n",
      "24283 [D loss: (0.713)(R 0.778, F 0.647)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.971] [G acc: 0.062]\n",
      "24284 [D loss: (0.659)(R 0.659, F 0.659)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.789] [G acc: 0.312]\n",
      "24285 [D loss: (0.620)(R 0.800, F 0.441)] [D acc: (0.719)(0.625, 0.812)] [G loss: 2.041] [G acc: 0.062]\n",
      "24286 [D loss: (0.510)(R 0.673, F 0.348)] [D acc: (0.719)(0.562, 0.875)] [G loss: 4.113] [G acc: 0.062]\n",
      "24287 [D loss: (0.550)(R 0.511, F 0.588)] [D acc: (0.719)(0.750, 0.688)] [G loss: 5.089] [G acc: 0.188]\n",
      "24288 [D loss: (0.561)(R 0.550, F 0.571)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.022] [G acc: 0.000]\n",
      "24289 [D loss: (0.526)(R 0.488, F 0.564)] [D acc: (0.844)(0.750, 0.938)] [G loss: 0.839] [G acc: 0.250]\n",
      "24290 [D loss: (0.619)(R 0.671, F 0.568)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.793] [G acc: 0.312]\n",
      "24291 [D loss: (0.536)(R 0.482, F 0.589)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.909] [G acc: 0.188]\n",
      "24292 [D loss: (0.597)(R 0.767, F 0.426)] [D acc: (0.750)(0.500, 1.000)] [G loss: 0.709] [G acc: 0.375]\n",
      "24293 [D loss: (0.476)(R 0.584, F 0.369)] [D acc: (0.781)(0.562, 1.000)] [G loss: 0.964] [G acc: 0.188]\n",
      "24294 [D loss: (0.539)(R 0.551, F 0.527)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.911] [G acc: 0.125]\n",
      "24295 [D loss: (0.619)(R 0.745, F 0.493)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.658] [G acc: 0.562]\n",
      "24296 [D loss: (0.449)(R 0.466, F 0.431)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.229] [G acc: 0.250]\n",
      "24297 [D loss: (0.614)(R 0.723, F 0.505)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.412] [G acc: 0.188]\n",
      "24298 [D loss: (0.671)(R 0.729, F 0.613)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.009] [G acc: 0.188]\n",
      "24299 [D loss: (0.578)(R 0.617, F 0.538)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.942] [G acc: 0.125]\n",
      "24300 [D loss: (0.624)(R 0.643, F 0.604)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.979] [G acc: 0.188]\n",
      "24301 [D loss: (0.501)(R 0.457, F 0.544)] [D acc: (0.781)(0.875, 0.688)] [G loss: 0.952] [G acc: 0.125]\n",
      "24302 [D loss: (0.495)(R 0.467, F 0.523)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.979] [G acc: 0.062]\n",
      "24303 [D loss: (0.620)(R 0.730, F 0.510)] [D acc: (0.625)(0.438, 0.812)] [G loss: 1.028] [G acc: 0.000]\n",
      "24304 [D loss: (0.509)(R 0.538, F 0.480)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.958] [G acc: 0.125]\n",
      "24305 [D loss: (0.592)(R 0.529, F 0.655)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.900] [G acc: 0.250]\n",
      "24306 [D loss: (0.492)(R 0.575, F 0.408)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.674] [G acc: 0.125]\n",
      "24307 [D loss: (0.409)(R 0.682, F 0.136)] [D acc: (0.812)(0.625, 1.000)] [G loss: 2.142] [G acc: 0.062]\n",
      "24308 [D loss: (0.556)(R 0.494, F 0.619)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.940] [G acc: 0.188]\n",
      "24309 [D loss: (0.496)(R 0.427, F 0.566)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.195] [G acc: 0.250]\n",
      "24310 [D loss: (0.500)(R 0.630, F 0.371)] [D acc: (0.719)(0.500, 0.938)] [G loss: 1.472] [G acc: 0.125]\n",
      "24311 [D loss: (0.528)(R 0.519, F 0.536)] [D acc: (0.688)(0.562, 0.812)] [G loss: 2.967] [G acc: 0.375]\n",
      "24312 [D loss: (0.397)(R 0.550, F 0.245)] [D acc: (0.719)(0.562, 0.875)] [G loss: 6.914] [G acc: 0.125]\n",
      "24313 [D loss: (0.609)(R 0.711, F 0.507)] [D acc: (0.656)(0.438, 0.875)] [G loss: 1.497] [G acc: 0.062]\n",
      "24314 [D loss: (0.420)(R 0.508, F 0.332)] [D acc: (0.719)(0.625, 0.812)] [G loss: 2.015] [G acc: 0.375]\n",
      "24315 [D loss: (0.368)(R 0.439, F 0.296)] [D acc: (0.781)(0.688, 0.875)] [G loss: 4.265] [G acc: 0.125]\n",
      "24316 [D loss: (0.619)(R 0.602, F 0.636)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.858] [G acc: 0.500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24317 [D loss: (0.514)(R 0.522, F 0.506)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.247] [G acc: 0.250]\n",
      "24318 [D loss: (0.631)(R 0.481, F 0.781)] [D acc: (0.594)(0.688, 0.500)] [G loss: 1.101] [G acc: 0.125]\n",
      "24319 [D loss: (0.770)(R 1.038, F 0.501)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.994] [G acc: 0.062]\n",
      "24320 [D loss: (0.502)(R 0.536, F 0.468)] [D acc: (0.719)(0.500, 0.938)] [G loss: 1.044] [G acc: 0.312]\n",
      "24321 [D loss: (0.566)(R 0.621, F 0.511)] [D acc: (0.688)(0.500, 0.875)] [G loss: 1.009] [G acc: 0.125]\n",
      "24322 [D loss: (0.745)(R 0.754, F 0.735)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.047] [G acc: 0.250]\n",
      "24323 [D loss: (0.519)(R 0.554, F 0.485)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.093] [G acc: 0.125]\n",
      "24324 [D loss: (0.863)(R 1.172, F 0.554)] [D acc: (0.688)(0.500, 0.875)] [G loss: 1.048] [G acc: 0.250]\n",
      "24325 [D loss: (0.549)(R 0.573, F 0.524)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.961] [G acc: 0.312]\n",
      "24326 [D loss: (0.624)(R 0.589, F 0.659)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.899] [G acc: 0.125]\n",
      "24327 [D loss: (0.585)(R 0.537, F 0.633)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.854] [G acc: 0.125]\n",
      "24328 [D loss: (0.571)(R 0.514, F 0.628)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.912] [G acc: 0.188]\n",
      "24329 [D loss: (0.595)(R 0.514, F 0.675)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.864] [G acc: 0.125]\n",
      "24330 [D loss: (0.525)(R 0.498, F 0.552)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.022] [G acc: 0.312]\n",
      "24331 [D loss: (0.637)(R 0.633, F 0.641)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.844] [G acc: 0.312]\n",
      "24332 [D loss: (0.716)(R 0.511, F 0.921)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.543] [G acc: 0.625]\n",
      "24333 [D loss: (0.609)(R 0.597, F 0.622)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.499] [G acc: 0.688]\n",
      "24334 [D loss: (0.629)(R 0.517, F 0.740)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.829] [G acc: 0.125]\n",
      "24335 [D loss: (0.758)(R 0.601, F 0.914)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.876] [G acc: 0.250]\n",
      "24336 [D loss: (0.773)(R 0.729, F 0.818)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.836] [G acc: 0.250]\n",
      "24337 [D loss: (0.650)(R 0.631, F 0.669)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.717] [G acc: 0.500]\n",
      "24338 [D loss: (0.666)(R 0.732, F 0.599)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.542] [G acc: 0.625]\n",
      "24339 [D loss: (0.641)(R 0.525, F 0.758)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.647] [G acc: 0.500]\n",
      "24340 [D loss: (0.680)(R 0.663, F 0.697)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.517] [G acc: 0.562]\n",
      "24341 [D loss: (0.756)(R 0.488, F 1.024)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.832] [G acc: 0.312]\n",
      "24342 [D loss: (0.742)(R 0.740, F 0.745)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.902] [G acc: 0.250]\n",
      "24343 [D loss: (0.596)(R 0.574, F 0.618)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.757] [G acc: 0.500]\n",
      "24344 [D loss: (0.671)(R 0.635, F 0.707)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.929] [G acc: 0.125]\n",
      "24345 [D loss: (0.592)(R 0.547, F 0.637)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.864] [G acc: 0.250]\n",
      "24346 [D loss: (0.704)(R 0.800, F 0.609)] [D acc: (0.406)(0.250, 0.562)] [G loss: 0.703] [G acc: 0.562]\n",
      "24347 [D loss: (0.692)(R 0.811, F 0.573)] [D acc: (0.562)(0.250, 0.875)] [G loss: 0.799] [G acc: 0.312]\n",
      "24348 [D loss: (0.775)(R 0.790, F 0.761)] [D acc: (0.406)(0.312, 0.500)] [G loss: 0.712] [G acc: 0.438]\n",
      "24349 [D loss: (0.813)(R 0.644, F 0.982)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.616] [G acc: 0.500]\n",
      "24350 [D loss: (0.712)(R 0.620, F 0.804)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.827] [G acc: 0.438]\n",
      "24351 [D loss: (0.855)(R 0.692, F 1.019)] [D acc: (0.375)(0.312, 0.438)] [G loss: 0.816] [G acc: 0.250]\n",
      "24352 [D loss: (0.814)(R 0.864, F 0.765)] [D acc: (0.344)(0.125, 0.562)] [G loss: 0.603] [G acc: 0.500]\n",
      "24353 [D loss: (0.740)(R 0.696, F 0.784)] [D acc: (0.406)(0.250, 0.562)] [G loss: 0.646] [G acc: 0.438]\n",
      "24354 [D loss: (0.747)(R 0.634, F 0.859)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.848] [G acc: 0.188]\n",
      "24355 [D loss: (0.752)(R 0.670, F 0.834)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.916] [G acc: 0.188]\n",
      "24356 [D loss: (0.837)(R 0.691, F 0.982)] [D acc: (0.438)(0.312, 0.562)] [G loss: 0.901] [G acc: 0.438]\n",
      "24357 [D loss: (0.753)(R 0.621, F 0.885)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.742] [G acc: 0.250]\n",
      "24358 [D loss: (0.735)(R 0.547, F 0.922)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.731] [G acc: 0.375]\n",
      "24359 [D loss: (0.679)(R 0.678, F 0.680)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.744] [G acc: 0.312]\n",
      "24360 [D loss: (0.783)(R 0.748, F 0.818)] [D acc: (0.375)(0.250, 0.500)] [G loss: 0.555] [G acc: 0.688]\n",
      "24361 [D loss: (0.701)(R 0.665, F 0.738)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.757] [G acc: 0.250]\n",
      "24362 [D loss: (0.809)(R 0.783, F 0.836)] [D acc: (0.188)(0.125, 0.250)] [G loss: 0.673] [G acc: 0.438]\n",
      "24363 [D loss: (0.683)(R 0.557, F 0.809)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.675] [G acc: 0.375]\n",
      "24364 [D loss: (0.736)(R 0.708, F 0.764)] [D acc: (0.469)(0.250, 0.688)] [G loss: 0.711] [G acc: 0.375]\n",
      "24365 [D loss: (0.821)(R 0.741, F 0.901)] [D acc: (0.438)(0.312, 0.562)] [G loss: 0.596] [G acc: 0.500]\n",
      "24366 [D loss: (0.759)(R 0.629, F 0.889)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.693] [G acc: 0.375]\n",
      "24367 [D loss: (0.704)(R 0.544, F 0.863)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.638] [G acc: 0.375]\n",
      "24368 [D loss: (0.833)(R 0.799, F 0.868)] [D acc: (0.500)(0.250, 0.750)] [G loss: 0.741] [G acc: 0.188]\n",
      "24369 [D loss: (0.765)(R 0.715, F 0.814)] [D acc: (0.375)(0.375, 0.375)] [G loss: 0.695] [G acc: 0.312]\n",
      "24370 [D loss: (0.770)(R 0.747, F 0.793)] [D acc: (0.312)(0.188, 0.438)] [G loss: 0.570] [G acc: 0.438]\n",
      "24371 [D loss: (0.735)(R 0.622, F 0.848)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.678] [G acc: 0.375]\n",
      "24372 [D loss: (0.855)(R 0.610, F 1.101)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.753] [G acc: 0.188]\n",
      "24373 [D loss: (0.705)(R 0.644, F 0.767)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.664] [G acc: 0.250]\n",
      "24374 [D loss: (0.771)(R 0.665, F 0.877)] [D acc: (0.438)(0.250, 0.625)] [G loss: 0.640] [G acc: 0.250]\n",
      "24375 [D loss: (0.809)(R 0.647, F 0.971)] [D acc: (0.406)(0.250, 0.562)] [G loss: 0.761] [G acc: 0.125]\n",
      "24376 [D loss: (0.750)(R 0.629, F 0.871)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.421] [G acc: 0.625]\n",
      "24377 [D loss: (0.939)(R 0.661, F 1.218)] [D acc: (0.469)(0.188, 0.750)] [G loss: 0.591] [G acc: 0.500]\n",
      "24378 [D loss: (0.644)(R 0.690, F 0.599)] [D acc: (0.406)(0.125, 0.688)] [G loss: 0.856] [G acc: 0.375]\n",
      "24379 [D loss: (0.719)(R 0.714, F 0.724)] [D acc: (0.500)(0.188, 0.812)] [G loss: 1.009] [G acc: 0.312]\n",
      "24380 [D loss: (0.761)(R 0.694, F 0.829)] [D acc: (0.469)(0.250, 0.688)] [G loss: 0.636] [G acc: 0.562]\n",
      "24381 [D loss: (0.926)(R 0.722, F 1.130)] [D acc: (0.281)(0.125, 0.438)] [G loss: 0.750] [G acc: 0.188]\n",
      "24382 [D loss: (0.732)(R 0.729, F 0.736)] [D acc: (0.469)(0.250, 0.688)] [G loss: 0.599] [G acc: 0.312]\n",
      "24383 [D loss: (0.802)(R 0.695, F 0.910)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.748] [G acc: 0.312]\n",
      "24384 [D loss: (0.713)(R 0.683, F 0.742)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.781] [G acc: 0.062]\n",
      "24385 [D loss: (0.689)(R 0.619, F 0.759)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.650] [G acc: 0.438]\n",
      "24386 [D loss: (0.743)(R 0.707, F 0.778)] [D acc: (0.562)(0.312, 0.812)] [G loss: 0.795] [G acc: 0.125]\n",
      "24387 [D loss: (0.618)(R 0.665, F 0.571)] [D acc: (0.594)(0.250, 0.938)] [G loss: 0.723] [G acc: 0.375]\n",
      "24388 [D loss: (0.671)(R 0.625, F 0.717)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.823] [G acc: 0.188]\n",
      "24389 [D loss: (0.709)(R 0.604, F 0.813)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.805] [G acc: 0.125]\n",
      "24390 [D loss: (0.764)(R 0.567, F 0.961)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.880] [G acc: 0.062]\n",
      "24391 [D loss: (0.638)(R 0.689, F 0.587)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.959] [G acc: 0.250]\n",
      "24392 [D loss: (0.616)(R 0.671, F 0.561)] [D acc: (0.562)(0.188, 0.938)] [G loss: 0.812] [G acc: 0.062]\n",
      "24393 [D loss: (0.637)(R 0.680, F 0.594)] [D acc: (0.594)(0.250, 0.938)] [G loss: 0.710] [G acc: 0.312]\n",
      "24394 [D loss: (0.664)(R 0.713, F 0.614)] [D acc: (0.625)(0.250, 1.000)] [G loss: 0.824] [G acc: 0.062]\n",
      "24395 [D loss: (0.613)(R 0.602, F 0.624)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.751] [G acc: 0.250]\n",
      "24396 [D loss: (0.606)(R 0.600, F 0.611)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.788] [G acc: 0.188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24397 [D loss: (0.608)(R 0.564, F 0.651)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.809] [G acc: 0.062]\n",
      "24398 [D loss: (0.650)(R 0.695, F 0.604)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.841] [G acc: 0.062]\n",
      "24399 [D loss: (0.645)(R 0.599, F 0.691)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.783] [G acc: 0.188]\n",
      "24400 [D loss: (0.733)(R 0.638, F 0.829)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.828] [G acc: 0.188]\n",
      "24401 [D loss: (0.531)(R 0.452, F 0.611)] [D acc: (0.719)(0.500, 0.938)] [G loss: 0.839] [G acc: 0.188]\n",
      "24402 [D loss: (0.611)(R 0.652, F 0.570)] [D acc: (0.719)(0.500, 0.938)] [G loss: 0.919] [G acc: 0.125]\n",
      "24403 [D loss: (0.643)(R 0.635, F 0.651)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.796] [G acc: 0.125]\n",
      "24404 [D loss: (0.597)(R 0.612, F 0.582)] [D acc: (0.656)(0.312, 1.000)] [G loss: 0.577] [G acc: 0.625]\n",
      "24405 [D loss: (0.580)(R 0.459, F 0.700)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.789] [G acc: 0.312]\n",
      "24406 [D loss: (0.504)(R 0.438, F 0.571)] [D acc: (0.812)(0.625, 1.000)] [G loss: 0.852] [G acc: 0.125]\n",
      "24407 [D loss: (0.535)(R 0.455, F 0.616)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.700] [G acc: 0.312]\n",
      "24408 [D loss: (0.528)(R 0.477, F 0.579)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.867] [G acc: 0.062]\n",
      "24409 [D loss: (0.568)(R 0.546, F 0.591)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.820] [G acc: 0.062]\n",
      "24410 [D loss: (0.509)(R 0.435, F 0.583)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.751] [G acc: 0.312]\n",
      "24411 [D loss: (0.925)(R 0.615, F 1.234)] [D acc: (0.625)(0.438, 0.812)] [G loss: 5.228] [G acc: 0.250]\n",
      "24412 [D loss: (0.564)(R 0.615, F 0.514)] [D acc: (0.688)(0.500, 0.875)] [G loss: 2.061] [G acc: 0.062]\n",
      "24413 [D loss: (0.650)(R 0.594, F 0.707)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.720] [G acc: 0.562]\n",
      "24414 [D loss: (0.882)(R 0.553, F 1.210)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.970] [G acc: 0.312]\n",
      "24415 [D loss: (0.534)(R 0.590, F 0.477)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.942] [G acc: 0.188]\n",
      "24416 [D loss: (0.466)(R 0.596, F 0.337)] [D acc: (0.781)(0.562, 1.000)] [G loss: 1.008] [G acc: 0.375]\n",
      "24417 [D loss: (0.693)(R 0.672, F 0.714)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.668] [G acc: 0.500]\n",
      "24418 [D loss: (0.481)(R 0.539, F 0.422)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.416] [G acc: 0.312]\n",
      "24419 [D loss: (0.502)(R 0.577, F 0.428)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.344] [G acc: 0.125]\n",
      "24420 [D loss: (0.390)(R 0.525, F 0.255)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.966] [G acc: 0.062]\n",
      "24421 [D loss: (0.416)(R 0.641, F 0.191)] [D acc: (0.750)(0.500, 1.000)] [G loss: 1.491] [G acc: 0.125]\n",
      "24422 [D loss: (0.507)(R 0.408, F 0.605)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.319] [G acc: 0.125]\n",
      "24423 [D loss: (0.436)(R 0.520, F 0.352)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.925] [G acc: 0.062]\n",
      "24424 [D loss: (0.496)(R 0.441, F 0.550)] [D acc: (0.719)(0.562, 0.875)] [G loss: 2.758] [G acc: 0.062]\n",
      "24425 [D loss: (0.378)(R 0.611, F 0.144)] [D acc: (0.750)(0.500, 1.000)] [G loss: 1.486] [G acc: 0.188]\n",
      "24426 [D loss: (0.504)(R 0.525, F 0.482)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.846] [G acc: 0.312]\n",
      "24427 [D loss: (0.498)(R 0.544, F 0.451)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.554] [G acc: 0.125]\n",
      "24428 [D loss: (0.394)(R 0.292, F 0.496)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.795] [G acc: 0.125]\n",
      "24429 [D loss: (0.402)(R 0.484, F 0.320)] [D acc: (0.812)(0.688, 0.938)] [G loss: 3.237] [G acc: 0.375]\n",
      "24430 [D loss: (0.888)(R 0.569, F 1.207)] [D acc: (0.656)(0.562, 0.750)] [G loss: 5.332] [G acc: 0.000]\n",
      "24431 [D loss: (0.576)(R 0.602, F 0.550)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.871] [G acc: 0.188]\n",
      "24432 [D loss: (0.516)(R 0.565, F 0.467)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.978] [G acc: 0.188]\n",
      "24433 [D loss: (0.719)(R 0.934, F 0.505)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.943] [G acc: 0.000]\n",
      "24434 [D loss: (0.546)(R 0.597, F 0.495)] [D acc: (0.719)(0.500, 0.938)] [G loss: 0.874] [G acc: 0.125]\n",
      "24435 [D loss: (0.507)(R 0.515, F 0.499)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.920] [G acc: 0.062]\n",
      "24436 [D loss: (0.546)(R 0.466, F 0.627)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.927] [G acc: 0.125]\n",
      "24437 [D loss: (0.456)(R 0.401, F 0.510)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.161] [G acc: 0.000]\n",
      "24438 [D loss: (0.534)(R 0.534, F 0.535)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.120] [G acc: 0.125]\n",
      "24439 [D loss: (0.483)(R 0.492, F 0.474)] [D acc: (0.812)(0.625, 1.000)] [G loss: 1.121] [G acc: 0.188]\n",
      "24440 [D loss: (0.741)(R 0.983, F 0.499)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.025] [G acc: 0.000]\n",
      "24441 [D loss: (0.488)(R 0.543, F 0.434)] [D acc: (0.844)(0.688, 1.000)] [G loss: 1.228] [G acc: 0.062]\n",
      "24442 [D loss: (0.565)(R 0.644, F 0.485)] [D acc: (0.688)(0.500, 0.875)] [G loss: 0.982] [G acc: 0.188]\n",
      "24443 [D loss: (0.486)(R 0.513, F 0.460)] [D acc: (0.875)(0.750, 1.000)] [G loss: 1.002] [G acc: 0.250]\n",
      "24444 [D loss: (0.479)(R 0.523, F 0.435)] [D acc: (0.781)(0.562, 1.000)] [G loss: 0.980] [G acc: 0.188]\n",
      "24445 [D loss: (0.508)(R 0.450, F 0.567)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.974] [G acc: 0.125]\n",
      "24446 [D loss: (0.408)(R 0.341, F 0.475)] [D acc: (0.906)(0.875, 0.938)] [G loss: 1.083] [G acc: 0.125]\n",
      "24447 [D loss: (0.453)(R 0.319, F 0.587)] [D acc: (0.844)(0.875, 0.812)] [G loss: 0.821] [G acc: 0.375]\n",
      "24448 [D loss: (0.507)(R 0.379, F 0.635)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.018] [G acc: 0.062]\n",
      "24449 [D loss: (0.458)(R 0.410, F 0.507)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.286] [G acc: 0.188]\n",
      "24450 [D loss: (0.312)(R 0.273, F 0.352)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.029] [G acc: 0.062]\n",
      "24451 [D loss: (0.522)(R 0.503, F 0.541)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.148] [G acc: 0.000]\n",
      "24452 [D loss: (0.540)(R 0.523, F 0.558)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.951] [G acc: 0.125]\n",
      "24453 [D loss: (0.564)(R 0.276, F 0.852)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.008] [G acc: 0.125]\n",
      "24454 [D loss: (0.529)(R 0.395, F 0.663)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.994] [G acc: 0.125]\n",
      "24455 [D loss: (0.821)(R 0.882, F 0.760)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.943] [G acc: 0.250]\n",
      "24456 [D loss: (0.549)(R 0.354, F 0.745)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.999] [G acc: 0.250]\n",
      "24457 [D loss: (0.713)(R 0.703, F 0.723)] [D acc: (0.562)(0.438, 0.688)] [G loss: 1.053] [G acc: 0.188]\n",
      "24458 [D loss: (0.699)(R 0.662, F 0.736)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.811] [G acc: 0.250]\n",
      "24459 [D loss: (0.595)(R 0.450, F 0.741)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.987] [G acc: 0.125]\n",
      "24460 [D loss: (0.603)(R 0.594, F 0.612)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.840] [G acc: 0.375]\n",
      "24461 [D loss: (0.638)(R 0.739, F 0.538)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.910] [G acc: 0.188]\n",
      "24462 [D loss: (0.607)(R 0.665, F 0.549)] [D acc: (0.688)(0.500, 0.875)] [G loss: 1.638] [G acc: 0.250]\n",
      "24463 [D loss: (0.253)(R 0.454, F 0.053)] [D acc: (0.875)(0.750, 1.000)] [G loss: 7.198] [G acc: 0.125]\n",
      "24464 [D loss: (0.884)(R 1.230, F 0.537)] [D acc: (0.594)(0.312, 0.875)] [G loss: 1.073] [G acc: 0.250]\n",
      "24465 [D loss: (0.628)(R 0.645, F 0.611)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.743] [G acc: 0.312]\n",
      "24466 [D loss: (0.440)(R 0.335, F 0.545)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.757] [G acc: 0.438]\n",
      "24467 [D loss: (0.608)(R 0.459, F 0.757)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.112] [G acc: 0.562]\n",
      "24468 [D loss: (0.451)(R 0.323, F 0.578)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.925] [G acc: 0.125]\n",
      "24469 [D loss: (0.473)(R 0.421, F 0.524)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.852] [G acc: 0.312]\n",
      "24470 [D loss: (0.604)(R 0.686, F 0.522)] [D acc: (0.719)(0.500, 0.938)] [G loss: 1.381] [G acc: 0.500]\n",
      "24471 [D loss: (0.666)(R 0.862, F 0.470)] [D acc: (0.719)(0.438, 1.000)] [G loss: 1.183] [G acc: 0.062]\n",
      "24472 [D loss: (0.568)(R 0.400, F 0.735)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.992] [G acc: 0.000]\n",
      "24473 [D loss: (0.642)(R 0.589, F 0.695)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.892] [G acc: 0.125]\n",
      "24474 [D loss: (0.443)(R 0.413, F 0.474)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.911] [G acc: 0.188]\n",
      "24475 [D loss: (0.575)(R 0.600, F 0.551)] [D acc: (0.719)(0.500, 0.938)] [G loss: 0.708] [G acc: 0.438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24476 [D loss: (0.663)(R 0.610, F 0.716)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.932] [G acc: 0.125]\n",
      "24477 [D loss: (0.665)(R 0.519, F 0.811)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.593] [G acc: 0.562]\n",
      "24478 [D loss: (0.542)(R 0.397, F 0.687)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.707] [G acc: 0.438]\n",
      "24479 [D loss: (0.608)(R 0.623, F 0.593)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.257] [G acc: 0.250]\n",
      "24480 [D loss: (0.454)(R 0.581, F 0.328)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.256] [G acc: 0.062]\n",
      "24481 [D loss: (0.372)(R 0.447, F 0.298)] [D acc: (0.844)(0.688, 1.000)] [G loss: 1.019] [G acc: 0.062]\n",
      "24482 [D loss: (0.618)(R 0.438, F 0.797)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.105] [G acc: 0.000]\n",
      "24483 [D loss: (0.683)(R 0.564, F 0.802)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.951] [G acc: 0.188]\n",
      "24484 [D loss: (0.517)(R 0.366, F 0.669)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.283] [G acc: 0.500]\n",
      "24485 [D loss: (0.482)(R 0.597, F 0.367)] [D acc: (0.781)(0.562, 1.000)] [G loss: 1.842] [G acc: 0.125]\n",
      "24486 [D loss: (0.490)(R 0.637, F 0.344)] [D acc: (0.781)(0.562, 1.000)] [G loss: 2.001] [G acc: 0.125]\n",
      "24487 [D loss: (0.699)(R 0.757, F 0.642)] [D acc: (0.594)(0.500, 0.688)] [G loss: 9.384] [G acc: 0.188]\n",
      "24488 [D loss: (0.380)(R 0.429, F 0.331)] [D acc: (0.844)(0.750, 0.938)] [G loss: 3.504] [G acc: 0.188]\n",
      "24489 [D loss: (0.602)(R 0.569, F 0.635)] [D acc: (0.625)(0.562, 0.688)] [G loss: 2.055] [G acc: 0.000]\n",
      "24490 [D loss: (0.492)(R 0.587, F 0.397)] [D acc: (0.719)(0.500, 0.938)] [G loss: 0.943] [G acc: 0.125]\n",
      "24491 [D loss: (0.619)(R 0.687, F 0.550)] [D acc: (0.594)(0.375, 0.812)] [G loss: 2.998] [G acc: 0.000]\n",
      "24492 [D loss: (0.440)(R 0.657, F 0.223)] [D acc: (0.625)(0.375, 0.875)] [G loss: 1.612] [G acc: 0.188]\n",
      "24493 [D loss: (0.554)(R 0.574, F 0.534)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.003] [G acc: 0.125]\n",
      "24494 [D loss: (0.686)(R 0.809, F 0.563)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.745] [G acc: 0.250]\n",
      "24495 [D loss: (0.532)(R 0.436, F 0.629)] [D acc: (0.812)(0.812, 0.812)] [G loss: 0.802] [G acc: 0.250]\n",
      "24496 [D loss: (0.618)(R 0.648, F 0.587)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.874] [G acc: 0.312]\n",
      "24497 [D loss: (0.504)(R 0.438, F 0.571)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.806] [G acc: 0.188]\n",
      "24498 [D loss: (0.614)(R 0.636, F 0.592)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.793] [G acc: 0.250]\n",
      "24499 [D loss: (0.484)(R 0.370, F 0.598)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.728] [G acc: 0.500]\n",
      "24500 [D loss: (0.630)(R 0.512, F 0.748)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.651] [G acc: 0.500]\n",
      "24501 [D loss: (0.652)(R 0.701, F 0.603)] [D acc: (0.500)(0.312, 0.688)] [G loss: 1.033] [G acc: 0.125]\n",
      "24502 [D loss: (0.626)(R 0.604, F 0.648)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.918] [G acc: 0.250]\n",
      "24503 [D loss: (0.605)(R 0.435, F 0.774)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.593] [G acc: 0.625]\n",
      "24504 [D loss: (0.537)(R 0.505, F 0.568)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.186] [G acc: 0.000]\n",
      "24505 [D loss: (0.514)(R 0.516, F 0.511)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.978] [G acc: 0.188]\n",
      "24506 [D loss: (0.694)(R 0.587, F 0.800)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.082] [G acc: 0.125]\n",
      "24507 [D loss: (0.647)(R 0.720, F 0.575)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.974] [G acc: 0.250]\n",
      "24508 [D loss: (0.575)(R 0.479, F 0.671)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.167] [G acc: 0.062]\n",
      "24509 [D loss: (0.614)(R 0.584, F 0.644)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.040] [G acc: 0.188]\n",
      "24510 [D loss: (0.526)(R 0.574, F 0.478)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.064] [G acc: 0.062]\n",
      "24511 [D loss: (0.780)(R 0.790, F 0.771)] [D acc: (0.656)(0.438, 0.875)] [G loss: 2.092] [G acc: 0.375]\n",
      "24512 [D loss: (0.521)(R 0.657, F 0.386)] [D acc: (0.719)(0.562, 0.875)] [G loss: 7.300] [G acc: 0.125]\n",
      "24513 [D loss: (0.397)(R 0.518, F 0.275)] [D acc: (0.719)(0.562, 0.875)] [G loss: 4.156] [G acc: 0.188]\n",
      "24514 [D loss: (0.660)(R 0.790, F 0.530)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.934] [G acc: 0.188]\n",
      "24515 [D loss: (0.436)(R 0.510, F 0.363)] [D acc: (0.844)(0.688, 1.000)] [G loss: 1.035] [G acc: 0.125]\n",
      "24516 [D loss: (0.580)(R 0.599, F 0.560)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.042] [G acc: 0.125]\n",
      "24517 [D loss: (0.492)(R 0.461, F 0.523)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.133] [G acc: 0.062]\n",
      "24518 [D loss: (0.444)(R 0.416, F 0.473)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.059] [G acc: 0.125]\n",
      "24519 [D loss: (0.544)(R 0.593, F 0.496)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.129] [G acc: 0.000]\n",
      "24520 [D loss: (0.596)(R 0.623, F 0.569)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.171] [G acc: 0.188]\n",
      "24521 [D loss: (0.628)(R 0.718, F 0.538)] [D acc: (0.562)(0.375, 0.750)] [G loss: 1.105] [G acc: 0.062]\n",
      "24522 [D loss: (0.533)(R 0.559, F 0.507)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.248] [G acc: 0.062]\n",
      "24523 [D loss: (0.578)(R 0.582, F 0.574)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.977] [G acc: 0.125]\n",
      "24524 [D loss: (0.436)(R 0.386, F 0.486)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.111] [G acc: 0.250]\n",
      "24525 [D loss: (0.393)(R 0.318, F 0.468)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.183] [G acc: 0.125]\n",
      "24526 [D loss: (0.430)(R 0.382, F 0.479)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.230] [G acc: 0.062]\n",
      "24527 [D loss: (0.464)(R 0.554, F 0.374)] [D acc: (0.781)(0.562, 1.000)] [G loss: 1.202] [G acc: 0.125]\n",
      "24528 [D loss: (0.521)(R 0.477, F 0.565)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.463] [G acc: 0.188]\n",
      "24529 [D loss: (0.597)(R 0.597, F 0.596)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.071] [G acc: 0.312]\n",
      "24530 [D loss: (0.592)(R 0.575, F 0.609)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.919] [G acc: 0.312]\n",
      "24531 [D loss: (0.543)(R 0.620, F 0.466)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.103] [G acc: 0.188]\n",
      "24532 [D loss: (0.523)(R 0.609, F 0.437)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.917] [G acc: 0.375]\n",
      "24533 [D loss: (0.453)(R 0.561, F 0.345)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.249] [G acc: 0.188]\n",
      "24534 [D loss: (0.416)(R 0.544, F 0.288)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.622] [G acc: 0.375]\n",
      "24535 [D loss: (0.177)(R 0.209, F 0.146)] [D acc: (0.906)(0.938, 0.875)] [G loss: 7.621] [G acc: 0.250]\n",
      "24536 [D loss: (0.468)(R 0.541, F 0.395)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.112] [G acc: 0.188]\n",
      "24537 [D loss: (0.655)(R 0.777, F 0.533)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.651] [G acc: 0.188]\n",
      "24538 [D loss: (0.519)(R 0.584, F 0.454)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.324] [G acc: 0.250]\n",
      "24539 [D loss: (0.542)(R 0.585, F 0.498)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.181] [G acc: 0.062]\n",
      "24540 [D loss: (0.513)(R 0.462, F 0.565)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.287] [G acc: 0.188]\n",
      "24541 [D loss: (0.460)(R 0.554, F 0.367)] [D acc: (0.812)(0.750, 0.875)] [G loss: 4.402] [G acc: 0.438]\n",
      "24542 [D loss: (0.588)(R 0.388, F 0.788)] [D acc: (0.688)(0.688, 0.688)] [G loss: 5.201] [G acc: 0.188]\n",
      "24543 [D loss: (0.376)(R 0.510, F 0.242)] [D acc: (0.844)(0.688, 1.000)] [G loss: 1.779] [G acc: 0.062]\n",
      "24544 [D loss: (0.482)(R 0.582, F 0.382)] [D acc: (0.688)(0.500, 0.875)] [G loss: 1.183] [G acc: 0.125]\n",
      "24545 [D loss: (0.445)(R 0.404, F 0.487)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.606] [G acc: 0.375]\n",
      "24546 [D loss: (0.460)(R 0.593, F 0.326)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.081] [G acc: 0.375]\n",
      "24547 [D loss: (0.663)(R 0.846, F 0.479)] [D acc: (0.531)(0.375, 0.688)] [G loss: 1.021] [G acc: 0.250]\n",
      "24548 [D loss: (0.480)(R 0.398, F 0.563)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.558] [G acc: 0.125]\n",
      "24549 [D loss: (0.440)(R 0.503, F 0.376)] [D acc: (0.719)(0.688, 0.750)] [G loss: 3.616] [G acc: 0.062]\n",
      "24550 [D loss: (0.454)(R 0.631, F 0.277)] [D acc: (0.750)(0.562, 0.938)] [G loss: 2.428] [G acc: 0.312]\n",
      "24551 [D loss: (0.464)(R 0.420, F 0.507)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.939] [G acc: 0.125]\n",
      "24552 [D loss: (0.524)(R 0.622, F 0.426)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.307] [G acc: 0.125]\n",
      "24553 [D loss: (0.754)(R 0.973, F 0.535)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.451] [G acc: 0.250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24554 [D loss: (0.460)(R 0.397, F 0.523)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.328] [G acc: 0.188]\n",
      "24555 [D loss: (0.739)(R 0.547, F 0.931)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.124] [G acc: 0.375]\n",
      "24556 [D loss: (0.545)(R 0.655, F 0.435)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.464] [G acc: 0.125]\n",
      "24557 [D loss: (0.531)(R 0.672, F 0.391)] [D acc: (0.844)(0.750, 0.938)] [G loss: 0.911] [G acc: 0.375]\n",
      "24558 [D loss: (0.544)(R 0.313, F 0.774)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.662] [G acc: 0.312]\n",
      "24559 [D loss: (0.423)(R 0.522, F 0.324)] [D acc: (0.781)(0.750, 0.812)] [G loss: 2.392] [G acc: 0.000]\n",
      "24560 [D loss: (0.489)(R 0.640, F 0.339)] [D acc: (0.750)(0.625, 0.875)] [G loss: 5.500] [G acc: 0.125]\n",
      "24561 [D loss: (0.231)(R 0.291, F 0.171)] [D acc: (0.938)(0.875, 1.000)] [G loss: 2.170] [G acc: 0.250]\n",
      "24562 [D loss: (0.628)(R 0.752, F 0.504)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.924] [G acc: 0.250]\n",
      "24563 [D loss: (0.493)(R 0.432, F 0.554)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.055] [G acc: 0.375]\n",
      "24564 [D loss: (0.498)(R 0.427, F 0.568)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.224] [G acc: 0.312]\n",
      "24565 [D loss: (0.609)(R 0.560, F 0.659)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.386] [G acc: 0.188]\n",
      "24566 [D loss: (0.492)(R 0.574, F 0.411)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.333] [G acc: 0.062]\n",
      "24567 [D loss: (0.478)(R 0.383, F 0.573)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.274] [G acc: 0.250]\n",
      "24568 [D loss: (0.446)(R 0.406, F 0.485)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.480] [G acc: 0.312]\n",
      "24569 [D loss: (0.392)(R 0.343, F 0.441)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.088] [G acc: 0.125]\n",
      "24570 [D loss: (0.545)(R 0.558, F 0.531)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.047] [G acc: 0.188]\n",
      "24571 [D loss: (0.501)(R 0.289, F 0.713)] [D acc: (0.812)(1.000, 0.625)] [G loss: 1.283] [G acc: 0.312]\n",
      "24572 [D loss: (0.511)(R 0.628, F 0.393)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.270] [G acc: 0.312]\n",
      "24573 [D loss: (0.404)(R 0.358, F 0.450)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.302] [G acc: 0.188]\n",
      "24574 [D loss: (0.574)(R 0.575, F 0.573)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.331] [G acc: 0.312]\n",
      "24575 [D loss: (0.544)(R 0.657, F 0.430)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.506] [G acc: 0.250]\n",
      "24576 [D loss: (0.342)(R 0.365, F 0.319)] [D acc: (0.875)(0.875, 0.875)] [G loss: 1.012] [G acc: 0.375]\n",
      "24577 [D loss: (0.529)(R 0.655, F 0.404)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.070] [G acc: 0.125]\n",
      "24578 [D loss: (0.741)(R 0.935, F 0.547)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.539] [G acc: 0.188]\n",
      "24579 [D loss: (0.751)(R 0.814, F 0.689)] [D acc: (0.562)(0.438, 0.688)] [G loss: 1.120] [G acc: 0.250]\n",
      "24580 [D loss: (0.498)(R 0.439, F 0.558)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.376] [G acc: 0.125]\n",
      "24581 [D loss: (0.744)(R 0.819, F 0.669)] [D acc: (0.562)(0.500, 0.625)] [G loss: 1.122] [G acc: 0.438]\n",
      "24582 [D loss: (0.483)(R 0.444, F 0.523)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.996] [G acc: 0.375]\n",
      "24583 [D loss: (0.714)(R 0.891, F 0.536)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.303] [G acc: 0.250]\n",
      "24584 [D loss: (0.571)(R 0.637, F 0.506)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.239] [G acc: 0.250]\n",
      "24585 [D loss: (0.539)(R 0.478, F 0.599)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.104] [G acc: 0.125]\n",
      "24586 [D loss: (0.633)(R 0.505, F 0.761)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.990] [G acc: 0.312]\n",
      "24587 [D loss: (0.659)(R 0.613, F 0.705)] [D acc: (0.531)(0.625, 0.438)] [G loss: 1.322] [G acc: 0.188]\n",
      "24588 [D loss: (0.764)(R 0.437, F 1.091)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.883] [G acc: 0.562]\n",
      "24589 [D loss: (0.307)(R 0.432, F 0.182)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.461] [G acc: 0.062]\n",
      "24590 [D loss: (0.649)(R 0.488, F 0.809)] [D acc: (0.531)(0.750, 0.312)] [G loss: 1.034] [G acc: 0.375]\n",
      "24591 [D loss: (0.523)(R 0.523, F 0.522)] [D acc: (0.781)(0.812, 0.750)] [G loss: 0.959] [G acc: 0.500]\n",
      "24592 [D loss: (0.650)(R 0.711, F 0.589)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.775] [G acc: 0.375]\n",
      "24593 [D loss: (0.866)(R 0.543, F 1.189)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.528] [G acc: 0.250]\n",
      "24594 [D loss: (0.646)(R 0.774, F 0.518)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.917] [G acc: 0.438]\n",
      "24595 [D loss: (1.114)(R 1.613, F 0.615)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.005] [G acc: 0.125]\n",
      "24596 [D loss: (0.510)(R 0.537, F 0.484)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.968] [G acc: 0.188]\n",
      "24597 [D loss: (0.463)(R 0.425, F 0.502)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.860] [G acc: 0.438]\n",
      "24598 [D loss: (0.586)(R 0.417, F 0.755)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.730] [G acc: 0.562]\n",
      "24599 [D loss: (0.577)(R 0.400, F 0.753)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.875] [G acc: 0.500]\n",
      "24600 [D loss: (0.805)(R 0.608, F 1.001)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.666] [G acc: 0.625]\n",
      "24601 [D loss: (1.080)(R 0.725, F 1.436)] [D acc: (0.594)(0.688, 0.500)] [G loss: 1.312] [G acc: 0.312]\n",
      "24602 [D loss: (0.578)(R 0.843, F 0.313)] [D acc: (0.656)(0.500, 0.812)] [G loss: 2.136] [G acc: 0.125]\n",
      "24603 [D loss: (0.787)(R 0.562, F 1.012)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.675] [G acc: 0.688]\n",
      "24604 [D loss: (0.807)(R 0.509, F 1.105)] [D acc: (0.562)(0.688, 0.438)] [G loss: 1.488] [G acc: 0.312]\n",
      "24605 [D loss: (0.617)(R 0.635, F 0.599)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.069] [G acc: 0.375]\n",
      "24606 [D loss: (0.580)(R 0.369, F 0.791)] [D acc: (0.719)(0.875, 0.562)] [G loss: 0.855] [G acc: 0.250]\n",
      "24607 [D loss: (0.781)(R 0.928, F 0.633)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.856] [G acc: 0.500]\n",
      "24608 [D loss: (0.548)(R 0.515, F 0.581)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.365] [G acc: 0.312]\n",
      "24609 [D loss: (0.671)(R 0.727, F 0.615)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.808] [G acc: 0.438]\n",
      "24610 [D loss: (0.567)(R 0.541, F 0.594)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.297] [G acc: 0.250]\n",
      "24611 [D loss: (0.577)(R 0.582, F 0.571)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.182] [G acc: 0.125]\n",
      "24612 [D loss: (0.591)(R 0.515, F 0.667)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.797] [G acc: 0.500]\n",
      "24613 [D loss: (0.685)(R 0.645, F 0.724)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.631] [G acc: 0.625]\n",
      "24614 [D loss: (0.504)(R 0.575, F 0.433)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.138] [G acc: 0.188]\n",
      "24615 [D loss: (0.519)(R 0.510, F 0.528)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.011] [G acc: 0.375]\n",
      "24616 [D loss: (0.829)(R 0.833, F 0.826)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.139] [G acc: 0.562]\n",
      "24617 [D loss: (0.694)(R 0.632, F 0.755)] [D acc: (0.531)(0.750, 0.312)] [G loss: 1.133] [G acc: 0.188]\n",
      "24618 [D loss: (0.787)(R 0.426, F 1.148)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.731] [G acc: 0.562]\n",
      "24619 [D loss: (0.572)(R 0.457, F 0.687)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.180] [G acc: 0.375]\n",
      "24620 [D loss: (0.614)(R 0.691, F 0.538)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.905] [G acc: 0.375]\n",
      "24621 [D loss: (0.484)(R 0.492, F 0.476)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.867] [G acc: 0.438]\n",
      "24622 [D loss: (0.550)(R 0.509, F 0.592)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.976] [G acc: 0.375]\n",
      "24623 [D loss: (0.720)(R 0.757, F 0.683)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.961] [G acc: 0.188]\n",
      "24624 [D loss: (0.582)(R 0.528, F 0.636)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.704] [G acc: 0.625]\n",
      "24625 [D loss: (0.749)(R 0.774, F 0.725)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.768] [G acc: 0.375]\n",
      "24626 [D loss: (0.575)(R 0.484, F 0.666)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.738] [G acc: 0.562]\n",
      "24627 [D loss: (0.726)(R 0.810, F 0.642)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.925] [G acc: 0.375]\n",
      "24628 [D loss: (0.553)(R 0.543, F 0.563)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.876] [G acc: 0.500]\n",
      "24629 [D loss: (0.610)(R 0.532, F 0.688)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.813] [G acc: 0.250]\n",
      "24630 [D loss: (0.576)(R 0.513, F 0.639)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.102] [G acc: 0.062]\n",
      "24631 [D loss: (0.538)(R 0.613, F 0.464)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.958] [G acc: 0.438]\n",
      "24632 [D loss: (0.600)(R 0.563, F 0.637)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.871] [G acc: 0.250]\n",
      "24633 [D loss: (0.560)(R 0.599, F 0.520)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.882] [G acc: 0.562]\n",
      "24634 [D loss: (0.634)(R 0.569, F 0.698)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.704] [G acc: 0.500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24635 [D loss: (0.566)(R 0.566, F 0.567)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.686] [G acc: 0.688]\n",
      "24636 [D loss: (0.637)(R 0.572, F 0.702)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.198] [G acc: 0.438]\n",
      "24637 [D loss: (0.533)(R 0.619, F 0.446)] [D acc: (0.719)(0.562, 0.875)] [G loss: 3.778] [G acc: 0.125]\n",
      "24638 [D loss: (0.643)(R 0.579, F 0.706)] [D acc: (0.688)(0.688, 0.688)] [G loss: 4.059] [G acc: 0.188]\n",
      "24639 [D loss: (0.640)(R 0.693, F 0.586)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.868] [G acc: 0.250]\n",
      "24640 [D loss: (0.629)(R 0.622, F 0.636)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.678] [G acc: 0.562]\n",
      "24641 [D loss: (0.733)(R 0.734, F 0.733)] [D acc: (0.531)(0.500, 0.562)] [G loss: 0.628] [G acc: 0.688]\n",
      "24642 [D loss: (0.638)(R 0.391, F 0.885)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.953] [G acc: 0.375]\n",
      "24643 [D loss: (0.684)(R 0.595, F 0.772)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.806] [G acc: 0.500]\n",
      "24644 [D loss: (0.616)(R 0.586, F 0.647)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.933] [G acc: 0.375]\n",
      "24645 [D loss: (0.604)(R 0.604, F 0.604)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.949] [G acc: 0.500]\n",
      "24646 [D loss: (0.748)(R 0.814, F 0.682)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.864] [G acc: 0.375]\n",
      "24647 [D loss: (0.652)(R 0.569, F 0.734)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.871] [G acc: 0.688]\n",
      "24648 [D loss: (0.806)(R 0.614, F 0.998)] [D acc: (0.562)(0.625, 0.500)] [G loss: 1.066] [G acc: 0.375]\n",
      "24649 [D loss: (0.673)(R 0.679, F 0.668)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.533] [G acc: 0.500]\n",
      "24650 [D loss: (0.565)(R 0.755, F 0.375)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.244] [G acc: 0.062]\n",
      "24651 [D loss: (0.542)(R 0.477, F 0.608)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.024] [G acc: 0.312]\n",
      "24652 [D loss: (0.527)(R 0.556, F 0.499)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.099] [G acc: 0.250]\n",
      "24653 [D loss: (0.568)(R 0.717, F 0.420)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.820] [G acc: 0.688]\n",
      "24654 [D loss: (0.616)(R 0.728, F 0.505)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.927] [G acc: 0.312]\n",
      "24655 [D loss: (0.416)(R 0.671, F 0.162)] [D acc: (0.719)(0.562, 0.875)] [G loss: 8.584] [G acc: 0.062]\n",
      "24656 [D loss: (1.222)(R 0.721, F 1.722)] [D acc: (0.469)(0.500, 0.438)] [G loss: 2.109] [G acc: 0.312]\n",
      "24657 [D loss: (0.710)(R 0.551, F 0.868)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.647] [G acc: 0.312]\n",
      "24658 [D loss: (0.376)(R 0.586, F 0.166)] [D acc: (0.812)(0.688, 0.938)] [G loss: 9.123] [G acc: 0.188]\n",
      "24659 [D loss: (0.583)(R 0.600, F 0.566)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.465] [G acc: 0.125]\n",
      "24660 [D loss: (0.542)(R 0.646, F 0.439)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.702] [G acc: 0.312]\n",
      "24661 [D loss: (0.439)(R 0.581, F 0.297)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.686] [G acc: 0.125]\n",
      "24662 [D loss: (0.495)(R 0.544, F 0.446)] [D acc: (0.875)(0.812, 0.938)] [G loss: 1.326] [G acc: 0.062]\n",
      "24663 [D loss: (0.666)(R 0.612, F 0.719)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.812] [G acc: 0.375]\n",
      "24664 [D loss: (0.636)(R 0.657, F 0.614)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.149] [G acc: 0.188]\n",
      "24665 [D loss: (0.587)(R 0.695, F 0.479)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.931] [G acc: 0.188]\n",
      "24666 [D loss: (0.551)(R 0.570, F 0.533)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.892] [G acc: 0.500]\n",
      "24667 [D loss: (0.573)(R 0.466, F 0.680)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.307] [G acc: 0.062]\n",
      "24668 [D loss: (0.722)(R 0.740, F 0.704)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.097] [G acc: 0.062]\n",
      "24669 [D loss: (0.655)(R 0.782, F 0.528)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.229] [G acc: 0.062]\n",
      "24670 [D loss: (0.508)(R 0.583, F 0.433)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.225] [G acc: 0.250]\n",
      "24671 [D loss: (0.654)(R 0.785, F 0.523)] [D acc: (0.656)(0.375, 0.938)] [G loss: 1.219] [G acc: 0.062]\n",
      "24672 [D loss: (0.699)(R 0.960, F 0.439)] [D acc: (0.625)(0.375, 0.875)] [G loss: 1.628] [G acc: 0.188]\n",
      "24673 [D loss: (0.561)(R 0.676, F 0.447)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.523] [G acc: 0.188]\n",
      "24674 [D loss: (0.554)(R 0.649, F 0.459)] [D acc: (0.719)(0.750, 0.688)] [G loss: 3.106] [G acc: 0.188]\n",
      "24675 [D loss: (0.518)(R 0.551, F 0.485)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.752] [G acc: 0.250]\n",
      "24676 [D loss: (0.641)(R 0.653, F 0.629)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.252] [G acc: 0.250]\n",
      "24677 [D loss: (0.476)(R 0.547, F 0.405)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.617] [G acc: 0.188]\n",
      "24678 [D loss: (0.590)(R 0.601, F 0.579)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.683] [G acc: 0.250]\n",
      "24679 [D loss: (0.501)(R 0.494, F 0.509)] [D acc: (0.781)(0.938, 0.625)] [G loss: 0.727] [G acc: 0.375]\n",
      "24680 [D loss: (0.726)(R 0.988, F 0.464)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.807] [G acc: 0.188]\n",
      "24681 [D loss: (0.583)(R 0.677, F 0.489)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.057] [G acc: 0.500]\n",
      "24682 [D loss: (0.585)(R 0.568, F 0.602)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.863] [G acc: 0.438]\n",
      "24683 [D loss: (0.557)(R 0.536, F 0.578)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.724] [G acc: 0.500]\n",
      "24684 [D loss: (0.656)(R 0.663, F 0.649)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.849] [G acc: 0.375]\n",
      "24685 [D loss: (0.673)(R 0.716, F 0.629)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.740] [G acc: 0.500]\n",
      "24686 [D loss: (0.562)(R 0.522, F 0.603)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.784] [G acc: 0.438]\n",
      "24687 [D loss: (0.703)(R 0.669, F 0.737)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.926] [G acc: 0.500]\n",
      "24688 [D loss: (0.701)(R 0.490, F 0.911)] [D acc: (0.594)(0.750, 0.438)] [G loss: 1.210] [G acc: 0.500]\n",
      "24689 [D loss: (0.578)(R 0.594, F 0.562)] [D acc: (0.656)(0.750, 0.562)] [G loss: 2.163] [G acc: 0.125]\n",
      "24690 [D loss: (0.282)(R 0.440, F 0.124)] [D acc: (0.906)(0.875, 0.938)] [G loss: 7.451] [G acc: 0.125]\n",
      "24691 [D loss: (0.632)(R 0.625, F 0.640)] [D acc: (0.594)(0.688, 0.500)] [G loss: 1.197] [G acc: 0.125]\n",
      "24692 [D loss: (0.367)(R 0.490, F 0.244)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.935] [G acc: 0.250]\n",
      "24693 [D loss: (0.463)(R 0.555, F 0.372)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.710] [G acc: 0.500]\n",
      "24694 [D loss: (0.706)(R 0.573, F 0.839)] [D acc: (0.500)(0.688, 0.312)] [G loss: 0.850] [G acc: 0.375]\n",
      "24695 [D loss: (0.558)(R 0.524, F 0.592)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.719] [G acc: 0.562]\n",
      "24696 [D loss: (0.610)(R 0.588, F 0.633)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.741] [G acc: 0.688]\n",
      "24697 [D loss: (0.666)(R 0.633, F 0.698)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.871] [G acc: 0.500]\n",
      "24698 [D loss: (0.726)(R 0.593, F 0.859)] [D acc: (0.562)(0.625, 0.500)] [G loss: 2.232] [G acc: 0.125]\n",
      "24699 [D loss: (0.582)(R 0.692, F 0.472)] [D acc: (0.656)(0.750, 0.562)] [G loss: 2.045] [G acc: 0.250]\n",
      "24700 [D loss: (0.586)(R 0.592, F 0.581)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.787] [G acc: 0.625]\n",
      "24701 [D loss: (0.900)(R 0.996, F 0.804)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.611] [G acc: 0.688]\n",
      "24702 [D loss: (0.789)(R 0.729, F 0.849)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.745] [G acc: 0.375]\n",
      "24703 [D loss: (0.595)(R 0.508, F 0.682)] [D acc: (0.719)(0.812, 0.625)] [G loss: 0.714] [G acc: 0.500]\n",
      "24704 [D loss: (0.761)(R 0.569, F 0.953)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.575] [G acc: 0.562]\n",
      "24705 [D loss: (0.647)(R 0.581, F 0.712)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.667] [G acc: 0.688]\n",
      "24706 [D loss: (0.731)(R 0.609, F 0.854)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.567] [G acc: 0.688]\n",
      "24707 [D loss: (0.620)(R 0.498, F 0.741)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.585] [G acc: 0.688]\n",
      "24708 [D loss: (0.706)(R 0.638, F 0.774)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.615] [G acc: 0.625]\n",
      "24709 [D loss: (0.725)(R 0.536, F 0.914)] [D acc: (0.469)(0.750, 0.188)] [G loss: 0.673] [G acc: 0.500]\n",
      "24710 [D loss: (0.636)(R 0.509, F 0.763)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.721] [G acc: 0.500]\n",
      "24711 [D loss: (0.636)(R 0.481, F 0.792)] [D acc: (0.438)(0.625, 0.250)] [G loss: 0.832] [G acc: 0.625]\n",
      "24712 [D loss: (0.671)(R 0.582, F 0.760)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.794] [G acc: 0.562]\n",
      "24713 [D loss: (0.620)(R 0.517, F 0.723)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.477] [G acc: 0.812]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24714 [D loss: (0.646)(R 0.504, F 0.787)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.621] [G acc: 0.688]\n",
      "24715 [D loss: (0.823)(R 0.814, F 0.832)] [D acc: (0.312)(0.250, 0.375)] [G loss: 0.576] [G acc: 0.812]\n",
      "24716 [D loss: (0.645)(R 0.574, F 0.717)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.590] [G acc: 0.500]\n",
      "24717 [D loss: (0.816)(R 0.518, F 1.113)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.779] [G acc: 0.688]\n",
      "24718 [D loss: (0.644)(R 0.533, F 0.755)] [D acc: (0.500)(0.750, 0.250)] [G loss: 0.684] [G acc: 0.562]\n",
      "24719 [D loss: (0.601)(R 0.586, F 0.617)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.909] [G acc: 0.188]\n",
      "24720 [D loss: (0.673)(R 0.624, F 0.723)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.167] [G acc: 0.188]\n",
      "24721 [D loss: (0.599)(R 0.604, F 0.594)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.610] [G acc: 0.438]\n",
      "24722 [D loss: (0.609)(R 0.499, F 0.719)] [D acc: (0.562)(0.688, 0.438)] [G loss: 2.819] [G acc: 0.250]\n",
      "24723 [D loss: (0.438)(R 0.500, F 0.376)] [D acc: (0.812)(0.750, 0.875)] [G loss: 3.616] [G acc: 0.250]\n",
      "24724 [D loss: (0.512)(R 0.585, F 0.440)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.502] [G acc: 0.188]\n",
      "24725 [D loss: (0.712)(R 0.609, F 0.816)] [D acc: (0.625)(0.812, 0.438)] [G loss: 0.879] [G acc: 0.438]\n",
      "24726 [D loss: (0.621)(R 0.582, F 0.659)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.212] [G acc: 0.312]\n",
      "24727 [D loss: (0.636)(R 0.569, F 0.704)] [D acc: (0.688)(0.812, 0.562)] [G loss: 0.641] [G acc: 0.625]\n",
      "24728 [D loss: (0.780)(R 0.657, F 0.902)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.911] [G acc: 0.312]\n",
      "24729 [D loss: (0.582)(R 0.567, F 0.597)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.240] [G acc: 0.375]\n",
      "24730 [D loss: (0.690)(R 0.710, F 0.670)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.913] [G acc: 0.188]\n",
      "24731 [D loss: (0.549)(R 0.541, F 0.556)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.853] [G acc: 0.250]\n",
      "24732 [D loss: (0.696)(R 0.824, F 0.568)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.720] [G acc: 0.688]\n",
      "24733 [D loss: (0.574)(R 0.528, F 0.620)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.915] [G acc: 0.250]\n",
      "24734 [D loss: (0.671)(R 0.702, F 0.640)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.832] [G acc: 0.375]\n",
      "24735 [D loss: (0.665)(R 0.598, F 0.732)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.873] [G acc: 0.250]\n",
      "24736 [D loss: (0.671)(R 0.770, F 0.571)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.689] [G acc: 0.375]\n",
      "24737 [D loss: (0.614)(R 0.569, F 0.659)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.903] [G acc: 0.250]\n",
      "24738 [D loss: (0.725)(R 0.756, F 0.695)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.897] [G acc: 0.188]\n",
      "24739 [D loss: (0.644)(R 0.701, F 0.587)] [D acc: (0.594)(0.312, 0.875)] [G loss: 1.015] [G acc: 0.375]\n",
      "24740 [D loss: (0.527)(R 0.534, F 0.520)] [D acc: (0.844)(0.750, 0.938)] [G loss: 0.929] [G acc: 0.438]\n",
      "24741 [D loss: (0.573)(R 0.643, F 0.504)] [D acc: (0.844)(0.688, 1.000)] [G loss: 0.919] [G acc: 0.250]\n",
      "24742 [D loss: (0.671)(R 0.704, F 0.637)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.939] [G acc: 0.188]\n",
      "24743 [D loss: (0.713)(R 0.774, F 0.653)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.923] [G acc: 0.125]\n",
      "24744 [D loss: (0.518)(R 0.512, F 0.524)] [D acc: (0.875)(0.812, 0.938)] [G loss: 0.483] [G acc: 0.750]\n",
      "24745 [D loss: (0.627)(R 0.658, F 0.596)] [D acc: (0.594)(0.438, 0.750)] [G loss: 1.041] [G acc: 0.188]\n",
      "24746 [D loss: (0.531)(R 0.514, F 0.548)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.976] [G acc: 0.375]\n",
      "24747 [D loss: (0.564)(R 0.549, F 0.579)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.504] [G acc: 0.750]\n",
      "24748 [D loss: (0.707)(R 0.645, F 0.769)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.802] [G acc: 0.250]\n",
      "24749 [D loss: (0.670)(R 0.487, F 0.853)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.957] [G acc: 0.250]\n",
      "24750 [D loss: (0.651)(R 0.569, F 0.733)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.661] [G acc: 0.562]\n",
      "24751 [D loss: (0.719)(R 0.679, F 0.758)] [D acc: (0.562)(0.625, 0.500)] [G loss: 1.415] [G acc: 0.188]\n",
      "24752 [D loss: (0.494)(R 0.620, F 0.367)] [D acc: (0.688)(0.625, 0.750)] [G loss: 2.838] [G acc: 0.000]\n",
      "24753 [D loss: (1.107)(R 0.628, F 1.586)] [D acc: (0.719)(0.750, 0.688)] [G loss: 3.181] [G acc: 0.125]\n",
      "24754 [D loss: (0.492)(R 0.608, F 0.376)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.423] [G acc: 0.312]\n",
      "24755 [D loss: (0.484)(R 0.617, F 0.352)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.869] [G acc: 0.375]\n",
      "24756 [D loss: (0.856)(R 0.579, F 1.134)] [D acc: (0.562)(0.562, 0.562)] [G loss: 1.107] [G acc: 0.312]\n",
      "24757 [D loss: (0.467)(R 0.568, F 0.366)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.087] [G acc: 0.500]\n",
      "24758 [D loss: (0.609)(R 0.712, F 0.506)] [D acc: (0.594)(0.500, 0.688)] [G loss: 1.245] [G acc: 0.312]\n",
      "24759 [D loss: (0.574)(R 0.659, F 0.489)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.211] [G acc: 0.312]\n",
      "24760 [D loss: (0.509)(R 0.514, F 0.505)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.739] [G acc: 0.500]\n",
      "24761 [D loss: (0.554)(R 0.599, F 0.510)] [D acc: (0.719)(0.688, 0.750)] [G loss: 4.199] [G acc: 0.062]\n",
      "24762 [D loss: (0.587)(R 0.762, F 0.411)] [D acc: (0.562)(0.375, 0.750)] [G loss: 2.361] [G acc: 0.250]\n",
      "24763 [D loss: (0.603)(R 0.572, F 0.634)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.852] [G acc: 0.375]\n",
      "24764 [D loss: (0.686)(R 0.603, F 0.770)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.950] [G acc: 0.500]\n",
      "24765 [D loss: (0.517)(R 0.507, F 0.527)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.162] [G acc: 0.375]\n",
      "24766 [D loss: (0.623)(R 0.607, F 0.638)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.715] [G acc: 0.688]\n",
      "24767 [D loss: (0.593)(R 0.453, F 0.733)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.379] [G acc: 0.125]\n",
      "24768 [D loss: (0.561)(R 0.591, F 0.531)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.128] [G acc: 0.188]\n",
      "24769 [D loss: (0.813)(R 1.038, F 0.588)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.818] [G acc: 0.375]\n",
      "24770 [D loss: (0.590)(R 0.578, F 0.602)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.061] [G acc: 0.312]\n",
      "24771 [D loss: (0.668)(R 0.686, F 0.650)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.204] [G acc: 0.062]\n",
      "24772 [D loss: (0.567)(R 0.537, F 0.597)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.790] [G acc: 0.250]\n",
      "24773 [D loss: (0.757)(R 0.883, F 0.632)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.942] [G acc: 0.125]\n",
      "24774 [D loss: (0.664)(R 0.747, F 0.581)] [D acc: (0.688)(0.438, 0.938)] [G loss: 0.759] [G acc: 0.562]\n",
      "24775 [D loss: (0.695)(R 0.716, F 0.674)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.863] [G acc: 0.250]\n",
      "24776 [D loss: (0.580)(R 0.521, F 0.639)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.913] [G acc: 0.375]\n",
      "24777 [D loss: (0.558)(R 0.560, F 0.557)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.833] [G acc: 0.562]\n",
      "24778 [D loss: (0.646)(R 0.608, F 0.684)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.774] [G acc: 0.500]\n",
      "24779 [D loss: (0.501)(R 0.463, F 0.539)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.912] [G acc: 0.062]\n",
      "24780 [D loss: (0.520)(R 0.479, F 0.562)] [D acc: (0.844)(0.750, 0.938)] [G loss: 0.818] [G acc: 0.438]\n",
      "24781 [D loss: (0.690)(R 0.797, F 0.583)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.777] [G acc: 0.500]\n",
      "24782 [D loss: (0.573)(R 0.444, F 0.702)] [D acc: (0.688)(0.875, 0.500)] [G loss: 0.681] [G acc: 0.562]\n",
      "24783 [D loss: (0.638)(R 0.598, F 0.679)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.911] [G acc: 0.062]\n",
      "24784 [D loss: (0.731)(R 0.652, F 0.809)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.450] [G acc: 0.812]\n",
      "24785 [D loss: (0.614)(R 0.636, F 0.593)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.708] [G acc: 0.625]\n",
      "24786 [D loss: (0.705)(R 0.806, F 0.604)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.634] [G acc: 0.562]\n",
      "24787 [D loss: (1.058)(R 1.065, F 1.051)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.880] [G acc: 0.250]\n",
      "24788 [D loss: (0.611)(R 0.600, F 0.623)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.032] [G acc: 0.188]\n",
      "24789 [D loss: (0.762)(R 0.750, F 0.773)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.849] [G acc: 0.375]\n",
      "24790 [D loss: (0.691)(R 0.606, F 0.776)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.856] [G acc: 0.562]\n",
      "24791 [D loss: (0.561)(R 0.608, F 0.514)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.806] [G acc: 0.438]\n",
      "24792 [D loss: (0.514)(R 0.384, F 0.645)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.228] [G acc: 0.250]\n",
      "24793 [D loss: (0.494)(R 0.484, F 0.504)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.673] [G acc: 0.500]\n",
      "24794 [D loss: (0.617)(R 0.594, F 0.640)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.801] [G acc: 0.375]\n",
      "24795 [D loss: (0.525)(R 0.496, F 0.555)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.545] [G acc: 0.625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24796 [D loss: (0.692)(R 0.769, F 0.615)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.918] [G acc: 0.250]\n",
      "24797 [D loss: (0.515)(R 0.547, F 0.484)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.725] [G acc: 0.375]\n",
      "24798 [D loss: (0.612)(R 0.567, F 0.657)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.763] [G acc: 0.375]\n",
      "24799 [D loss: (0.667)(R 0.533, F 0.802)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.788] [G acc: 0.562]\n",
      "24800 [D loss: (0.662)(R 0.676, F 0.648)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.883] [G acc: 0.562]\n",
      "24801 [D loss: (0.691)(R 0.649, F 0.732)] [D acc: (0.594)(0.500, 0.688)] [G loss: 3.012] [G acc: 0.438]\n",
      "24802 [D loss: (0.776)(R 0.681, F 0.872)] [D acc: (0.688)(0.625, 0.750)] [G loss: 3.852] [G acc: 0.250]\n",
      "24803 [D loss: (0.513)(R 0.760, F 0.265)] [D acc: (0.656)(0.438, 0.875)] [G loss: 1.034] [G acc: 0.562]\n",
      "24804 [D loss: (0.613)(R 0.724, F 0.503)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.644] [G acc: 0.562]\n",
      "24805 [D loss: (0.808)(R 0.632, F 0.984)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.924] [G acc: 0.188]\n",
      "24806 [D loss: (0.694)(R 0.619, F 0.768)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.922] [G acc: 0.188]\n",
      "24807 [D loss: (0.657)(R 0.575, F 0.739)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.670] [G acc: 0.625]\n",
      "24808 [D loss: (0.611)(R 0.642, F 0.581)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.243] [G acc: 0.500]\n",
      "24809 [D loss: (0.591)(R 0.531, F 0.650)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.092] [G acc: 0.062]\n",
      "24810 [D loss: (0.768)(R 0.514, F 1.022)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.884] [G acc: 0.188]\n",
      "24811 [D loss: (0.534)(R 0.605, F 0.464)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.879] [G acc: 0.250]\n",
      "24812 [D loss: (0.669)(R 0.645, F 0.692)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.948] [G acc: 0.188]\n",
      "24813 [D loss: (0.780)(R 1.044, F 0.517)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.792] [G acc: 0.562]\n",
      "24814 [D loss: (0.688)(R 0.764, F 0.613)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.676] [G acc: 0.562]\n",
      "24815 [D loss: (0.588)(R 0.591, F 0.585)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.904] [G acc: 0.250]\n",
      "24816 [D loss: (0.503)(R 0.505, F 0.502)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.064] [G acc: 0.250]\n",
      "24817 [D loss: (0.487)(R 0.644, F 0.330)] [D acc: (0.812)(0.625, 1.000)] [G loss: 1.133] [G acc: 0.188]\n",
      "24818 [D loss: (0.634)(R 0.778, F 0.490)] [D acc: (0.625)(0.562, 0.688)] [G loss: 2.541] [G acc: 0.188]\n",
      "24819 [D loss: (0.543)(R 0.687, F 0.400)] [D acc: (0.719)(0.688, 0.750)] [G loss: 5.239] [G acc: 0.125]\n",
      "24820 [D loss: (0.624)(R 0.673, F 0.575)] [D acc: (0.656)(0.438, 0.875)] [G loss: 1.972] [G acc: 0.250]\n",
      "24821 [D loss: (0.417)(R 0.505, F 0.330)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.820] [G acc: 0.500]\n",
      "24822 [D loss: (0.519)(R 0.632, F 0.406)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.662] [G acc: 0.688]\n",
      "24823 [D loss: (0.489)(R 0.533, F 0.445)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.663] [G acc: 0.500]\n",
      "24824 [D loss: (0.658)(R 0.670, F 0.646)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.720] [G acc: 0.625]\n",
      "24825 [D loss: (0.629)(R 0.602, F 0.656)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.646] [G acc: 0.625]\n",
      "24826 [D loss: (0.721)(R 0.749, F 0.694)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.815] [G acc: 0.312]\n",
      "24827 [D loss: (0.591)(R 0.573, F 0.609)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.763] [G acc: 0.188]\n",
      "24828 [D loss: (0.544)(R 0.481, F 0.606)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.770] [G acc: 0.312]\n",
      "24829 [D loss: (0.621)(R 0.556, F 0.685)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.718] [G acc: 0.250]\n",
      "24830 [D loss: (0.620)(R 0.571, F 0.670)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.799] [G acc: 0.312]\n",
      "24831 [D loss: (0.590)(R 0.523, F 0.657)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.712] [G acc: 0.312]\n",
      "24832 [D loss: (0.680)(R 0.721, F 0.639)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.898] [G acc: 0.062]\n",
      "24833 [D loss: (0.641)(R 0.543, F 0.738)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.876] [G acc: 0.062]\n",
      "24834 [D loss: (0.560)(R 0.515, F 0.606)] [D acc: (0.844)(0.750, 0.938)] [G loss: 0.692] [G acc: 0.375]\n",
      "24835 [D loss: (0.609)(R 0.597, F 0.622)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.789] [G acc: 0.500]\n",
      "24836 [D loss: (0.611)(R 0.560, F 0.661)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.641] [G acc: 0.562]\n",
      "24837 [D loss: (0.631)(R 0.518, F 0.744)] [D acc: (0.656)(0.750, 0.562)] [G loss: 1.000] [G acc: 0.125]\n",
      "24838 [D loss: (0.647)(R 0.624, F 0.670)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.668] [G acc: 0.562]\n",
      "24839 [D loss: (1.712)(R 0.692, F 2.732)] [D acc: (0.375)(0.500, 0.250)] [G loss: 0.633] [G acc: 0.562]\n",
      "24840 [D loss: (0.895)(R 0.553, F 1.237)] [D acc: (0.625)(0.750, 0.500)] [G loss: 1.167] [G acc: 0.312]\n",
      "24841 [D loss: (0.537)(R 0.496, F 0.577)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.219] [G acc: 0.188]\n",
      "24842 [D loss: (0.855)(R 0.729, F 0.981)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.867] [G acc: 0.688]\n",
      "24843 [D loss: (0.504)(R 0.659, F 0.350)] [D acc: (0.656)(0.500, 0.812)] [G loss: 5.106] [G acc: 0.062]\n",
      "24844 [D loss: (1.116)(R 0.639, F 1.592)] [D acc: (0.531)(0.500, 0.562)] [G loss: 1.691] [G acc: 0.438]\n",
      "24845 [D loss: (0.458)(R 0.553, F 0.363)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.024] [G acc: 0.188]\n",
      "24846 [D loss: (1.269)(R 0.582, F 1.956)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.781] [G acc: 0.500]\n",
      "24847 [D loss: (0.992)(R 0.668, F 1.316)] [D acc: (0.406)(0.375, 0.438)] [G loss: 0.733] [G acc: 0.625]\n",
      "24848 [D loss: (0.869)(R 0.681, F 1.058)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.995] [G acc: 0.125]\n",
      "24849 [D loss: (0.523)(R 0.654, F 0.392)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.981] [G acc: 0.125]\n",
      "24850 [D loss: (0.666)(R 0.799, F 0.534)] [D acc: (0.625)(0.375, 0.875)] [G loss: 0.930] [G acc: 0.250]\n",
      "24851 [D loss: (0.648)(R 0.724, F 0.571)] [D acc: (0.562)(0.375, 0.750)] [G loss: 1.021] [G acc: 0.312]\n",
      "24852 [D loss: (0.607)(R 0.630, F 0.585)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.785] [G acc: 0.438]\n",
      "24853 [D loss: (0.725)(R 0.808, F 0.642)] [D acc: (0.438)(0.312, 0.562)] [G loss: 0.840] [G acc: 0.312]\n",
      "24854 [D loss: (0.697)(R 0.605, F 0.789)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.911] [G acc: 0.250]\n",
      "24855 [D loss: (0.630)(R 0.736, F 0.523)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.904] [G acc: 0.250]\n",
      "24856 [D loss: (0.620)(R 0.637, F 0.602)] [D acc: (0.594)(0.500, 0.688)] [G loss: 1.207] [G acc: 0.188]\n",
      "24857 [D loss: (0.594)(R 0.577, F 0.611)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.933] [G acc: 0.250]\n",
      "24858 [D loss: (0.635)(R 0.712, F 0.558)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.933] [G acc: 0.250]\n",
      "24859 [D loss: (0.733)(R 0.887, F 0.579)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.917] [G acc: 0.500]\n",
      "24860 [D loss: (0.635)(R 0.659, F 0.612)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.231] [G acc: 0.438]\n",
      "24861 [D loss: (0.645)(R 0.601, F 0.690)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.873] [G acc: 0.500]\n",
      "24862 [D loss: (0.693)(R 0.737, F 0.649)] [D acc: (0.656)(0.375, 0.938)] [G loss: 0.790] [G acc: 0.062]\n",
      "24863 [D loss: (0.651)(R 0.633, F 0.669)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.786] [G acc: 0.125]\n",
      "24864 [D loss: (0.715)(R 0.855, F 0.575)] [D acc: (0.531)(0.188, 0.875)] [G loss: 0.821] [G acc: 0.125]\n",
      "24865 [D loss: (0.637)(R 0.662, F 0.611)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.854] [G acc: 0.250]\n",
      "24866 [D loss: (0.743)(R 0.828, F 0.659)] [D acc: (0.438)(0.250, 0.625)] [G loss: 0.803] [G acc: 0.188]\n",
      "24867 [D loss: (0.631)(R 0.591, F 0.670)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.797] [G acc: 0.188]\n",
      "24868 [D loss: (0.705)(R 0.582, F 0.828)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.831] [G acc: 0.125]\n",
      "24869 [D loss: (0.713)(R 0.732, F 0.695)] [D acc: (0.438)(0.250, 0.625)] [G loss: 0.719] [G acc: 0.375]\n",
      "24870 [D loss: (0.724)(R 0.744, F 0.703)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.685] [G acc: 0.312]\n",
      "24871 [D loss: (0.714)(R 0.773, F 0.655)] [D acc: (0.438)(0.125, 0.750)] [G loss: 0.696] [G acc: 0.312]\n",
      "24872 [D loss: (0.701)(R 0.540, F 0.863)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.802] [G acc: 0.250]\n",
      "24873 [D loss: (0.788)(R 0.630, F 0.945)] [D acc: (0.594)(0.500, 0.688)] [G loss: 0.842] [G acc: 0.500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24874 [D loss: (0.684)(R 0.720, F 0.649)] [D acc: (0.625)(0.312, 0.938)] [G loss: 0.787] [G acc: 0.375]\n",
      "24875 [D loss: (1.225)(R 0.662, F 1.788)] [D acc: (0.344)(0.375, 0.312)] [G loss: 0.958] [G acc: 0.312]\n",
      "24876 [D loss: (1.050)(R 0.765, F 1.335)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.894] [G acc: 0.250]\n",
      "24877 [D loss: (0.747)(R 0.869, F 0.625)] [D acc: (0.500)(0.188, 0.812)] [G loss: 0.846] [G acc: 0.188]\n",
      "24878 [D loss: (0.658)(R 0.686, F 0.631)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.786] [G acc: 0.062]\n",
      "24879 [D loss: (0.643)(R 0.699, F 0.587)] [D acc: (0.625)(0.312, 0.938)] [G loss: 0.795] [G acc: 0.188]\n",
      "24880 [D loss: (0.712)(R 0.693, F 0.731)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.464] [G acc: 0.625]\n",
      "24881 [D loss: (0.661)(R 0.640, F 0.681)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.717] [G acc: 0.250]\n",
      "24882 [D loss: (0.733)(R 0.677, F 0.790)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.880] [G acc: 0.375]\n",
      "24883 [D loss: (0.979)(R 0.788, F 1.171)] [D acc: (0.281)(0.188, 0.375)] [G loss: 0.889] [G acc: 0.500]\n",
      "24884 [D loss: (0.737)(R 0.835, F 0.640)] [D acc: (0.438)(0.125, 0.750)] [G loss: 0.905] [G acc: 0.250]\n",
      "24885 [D loss: (0.728)(R 0.826, F 0.629)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.741] [G acc: 0.250]\n",
      "24886 [D loss: (0.683)(R 0.735, F 0.631)] [D acc: (0.531)(0.188, 0.875)] [G loss: 1.039] [G acc: 0.312]\n",
      "24887 [D loss: (0.665)(R 0.732, F 0.598)] [D acc: (0.656)(0.375, 0.938)] [G loss: 0.914] [G acc: 0.062]\n",
      "24888 [D loss: (0.688)(R 0.712, F 0.664)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.787] [G acc: 0.250]\n",
      "24889 [D loss: (0.662)(R 0.692, F 0.632)] [D acc: (0.594)(0.312, 0.875)] [G loss: 0.798] [G acc: 0.125]\n",
      "24890 [D loss: (0.688)(R 0.754, F 0.622)] [D acc: (0.531)(0.312, 0.750)] [G loss: 0.764] [G acc: 0.062]\n",
      "24891 [D loss: (0.654)(R 0.622, F 0.686)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.664] [G acc: 0.375]\n",
      "24892 [D loss: (0.620)(R 0.635, F 0.606)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.804] [G acc: 0.125]\n",
      "24893 [D loss: (0.905)(R 0.828, F 0.981)] [D acc: (0.438)(0.188, 0.688)] [G loss: 0.816] [G acc: 0.250]\n",
      "24894 [D loss: (0.790)(R 0.764, F 0.816)] [D acc: (0.469)(0.375, 0.562)] [G loss: 0.721] [G acc: 0.500]\n",
      "24895 [D loss: (0.677)(R 0.741, F 0.613)] [D acc: (0.656)(0.375, 0.938)] [G loss: 0.803] [G acc: 0.062]\n",
      "24896 [D loss: (0.678)(R 0.709, F 0.646)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.805] [G acc: 0.125]\n",
      "24897 [D loss: (0.654)(R 0.688, F 0.621)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.785] [G acc: 0.125]\n",
      "24898 [D loss: (0.658)(R 0.664, F 0.653)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.757] [G acc: 0.250]\n",
      "24899 [D loss: (0.616)(R 0.637, F 0.595)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.792] [G acc: 0.188]\n",
      "24900 [D loss: (0.623)(R 0.656, F 0.591)] [D acc: (0.719)(0.500, 0.938)] [G loss: 0.736] [G acc: 0.250]\n",
      "24901 [D loss: (0.596)(R 0.556, F 0.637)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.794] [G acc: 0.125]\n",
      "24902 [D loss: (0.580)(R 0.519, F 0.640)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.744] [G acc: 0.250]\n",
      "24903 [D loss: (0.682)(R 0.689, F 0.676)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.725] [G acc: 0.250]\n",
      "24904 [D loss: (0.651)(R 0.704, F 0.599)] [D acc: (0.750)(0.500, 1.000)] [G loss: 0.748] [G acc: 0.125]\n",
      "24905 [D loss: (0.580)(R 0.471, F 0.690)] [D acc: (0.719)(0.750, 0.688)] [G loss: 0.799] [G acc: 0.125]\n",
      "24906 [D loss: (0.647)(R 0.595, F 0.698)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.850] [G acc: 0.188]\n",
      "24907 [D loss: (0.623)(R 0.429, F 0.816)] [D acc: (0.750)(0.812, 0.688)] [G loss: 1.110] [G acc: 0.062]\n",
      "24908 [D loss: (0.474)(R 0.617, F 0.330)] [D acc: (0.719)(0.562, 0.875)] [G loss: 4.063] [G acc: 0.188]\n",
      "24909 [D loss: (0.621)(R 0.555, F 0.687)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.847] [G acc: 0.375]\n",
      "24910 [D loss: (0.720)(R 0.702, F 0.738)] [D acc: (0.469)(0.438, 0.500)] [G loss: 0.857] [G acc: 0.188]\n",
      "24911 [D loss: (0.669)(R 0.487, F 0.852)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.741] [G acc: 0.375]\n",
      "24912 [D loss: (0.688)(R 0.717, F 0.658)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.819] [G acc: 0.188]\n",
      "24913 [D loss: (0.632)(R 0.683, F 0.580)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.820] [G acc: 0.312]\n",
      "24914 [D loss: (0.640)(R 0.632, F 0.647)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.876] [G acc: 0.125]\n",
      "24915 [D loss: (0.653)(R 0.710, F 0.597)] [D acc: (0.594)(0.375, 0.812)] [G loss: 0.863] [G acc: 0.250]\n",
      "24916 [D loss: (0.634)(R 0.680, F 0.588)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.844] [G acc: 0.188]\n",
      "24917 [D loss: (0.529)(R 0.508, F 0.550)] [D acc: (0.969)(0.938, 1.000)] [G loss: 0.742] [G acc: 0.312]\n",
      "24918 [D loss: (0.526)(R 0.493, F 0.559)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.826] [G acc: 0.188]\n",
      "24919 [D loss: (0.637)(R 0.649, F 0.625)] [D acc: (0.594)(0.438, 0.750)] [G loss: 0.715] [G acc: 0.312]\n",
      "24920 [D loss: (0.673)(R 0.589, F 0.758)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.950] [G acc: 0.438]\n",
      "24921 [D loss: (1.072)(R 0.655, F 1.489)] [D acc: (0.406)(0.438, 0.375)] [G loss: 0.288] [G acc: 0.750]\n",
      "24922 [D loss: (0.688)(R 0.672, F 0.703)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.866] [G acc: 0.312]\n",
      "24923 [D loss: (0.929)(R 0.753, F 1.105)] [D acc: (0.531)(0.438, 0.625)] [G loss: 0.743] [G acc: 0.625]\n",
      "24924 [D loss: (0.607)(R 0.589, F 0.624)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.533] [G acc: 0.625]\n",
      "24925 [D loss: (0.614)(R 0.645, F 0.583)] [D acc: (0.625)(0.562, 0.688)] [G loss: 2.714] [G acc: 0.062]\n",
      "24926 [D loss: (0.561)(R 0.680, F 0.442)] [D acc: (0.656)(0.438, 0.875)] [G loss: 1.022] [G acc: 0.062]\n",
      "24927 [D loss: (0.564)(R 0.618, F 0.509)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.899] [G acc: 0.125]\n",
      "24928 [D loss: (0.525)(R 0.517, F 0.534)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.931] [G acc: 0.188]\n",
      "24929 [D loss: (0.588)(R 0.654, F 0.523)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.117] [G acc: 0.250]\n",
      "24930 [D loss: (0.531)(R 0.545, F 0.516)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.874] [G acc: 0.062]\n",
      "24931 [D loss: (0.622)(R 0.729, F 0.514)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.679] [G acc: 0.438]\n",
      "24932 [D loss: (0.646)(R 0.657, F 0.635)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.041] [G acc: 0.312]\n",
      "24933 [D loss: (0.709)(R 0.684, F 0.735)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.910] [G acc: 0.062]\n",
      "24934 [D loss: (0.637)(R 0.638, F 0.637)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.824] [G acc: 0.438]\n",
      "24935 [D loss: (0.806)(R 1.047, F 0.565)] [D acc: (0.531)(0.375, 0.688)] [G loss: 0.961] [G acc: 0.312]\n",
      "24936 [D loss: (0.592)(R 0.646, F 0.538)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.976] [G acc: 0.125]\n",
      "24937 [D loss: (0.587)(R 0.572, F 0.602)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.885] [G acc: 0.188]\n",
      "24938 [D loss: (0.580)(R 0.631, F 0.529)] [D acc: (0.719)(0.500, 0.938)] [G loss: 0.939] [G acc: 0.188]\n",
      "24939 [D loss: (0.606)(R 0.625, F 0.587)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.894] [G acc: 0.188]\n",
      "24940 [D loss: (0.578)(R 0.529, F 0.627)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.068] [G acc: 0.188]\n",
      "24941 [D loss: (0.563)(R 0.572, F 0.554)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.916] [G acc: 0.250]\n",
      "24942 [D loss: (0.585)(R 0.585, F 0.585)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.881] [G acc: 0.125]\n",
      "24943 [D loss: (0.569)(R 0.550, F 0.588)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.051] [G acc: 0.188]\n",
      "24944 [D loss: (0.644)(R 0.633, F 0.655)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.368] [G acc: 0.750]\n",
      "24945 [D loss: (0.539)(R 0.459, F 0.619)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.706] [G acc: 0.500]\n",
      "24946 [D loss: (0.844)(R 0.420, F 1.267)] [D acc: (0.656)(0.875, 0.438)] [G loss: 0.812] [G acc: 0.438]\n",
      "24947 [D loss: (0.890)(R 0.723, F 1.057)] [D acc: (0.438)(0.500, 0.375)] [G loss: 1.886] [G acc: 0.438]\n",
      "24948 [D loss: (0.636)(R 0.647, F 0.625)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.487] [G acc: 0.125]\n",
      "24949 [D loss: (0.543)(R 0.669, F 0.418)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.988] [G acc: 0.125]\n",
      "24950 [D loss: (0.580)(R 0.605, F 0.554)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.869] [G acc: 0.188]\n",
      "24951 [D loss: (0.601)(R 0.640, F 0.562)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.988] [G acc: 0.188]\n",
      "24952 [D loss: (0.558)(R 0.592, F 0.524)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.869] [G acc: 0.125]\n",
      "24953 [D loss: (0.664)(R 0.647, F 0.682)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.798] [G acc: 0.438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24954 [D loss: (0.537)(R 0.548, F 0.527)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.881] [G acc: 0.375]\n",
      "24955 [D loss: (0.615)(R 0.685, F 0.546)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.034] [G acc: 0.125]\n",
      "24956 [D loss: (0.614)(R 0.624, F 0.604)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.778] [G acc: 0.438]\n",
      "24957 [D loss: (0.501)(R 0.510, F 0.492)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.032] [G acc: 0.438]\n",
      "24958 [D loss: (0.747)(R 0.772, F 0.722)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.850] [G acc: 0.188]\n",
      "24959 [D loss: (0.581)(R 0.496, F 0.666)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.817] [G acc: 0.250]\n",
      "24960 [D loss: (0.554)(R 0.538, F 0.571)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.749] [G acc: 0.375]\n",
      "24961 [D loss: (0.734)(R 0.629, F 0.839)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.729] [G acc: 0.562]\n",
      "24962 [D loss: (0.588)(R 0.505, F 0.671)] [D acc: (0.688)(0.750, 0.625)] [G loss: 2.896] [G acc: 0.438]\n",
      "24963 [D loss: (0.503)(R 0.710, F 0.295)] [D acc: (0.750)(0.500, 1.000)] [G loss: 5.831] [G acc: 0.000]\n",
      "24964 [D loss: (0.629)(R 0.727, F 0.531)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.447] [G acc: 0.812]\n",
      "24965 [D loss: (0.586)(R 0.581, F 0.592)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.771] [G acc: 0.375]\n",
      "24966 [D loss: (0.643)(R 0.719, F 0.566)] [D acc: (0.656)(0.500, 0.812)] [G loss: 0.865] [G acc: 0.375]\n",
      "24967 [D loss: (0.545)(R 0.493, F 0.597)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.862] [G acc: 0.375]\n",
      "24968 [D loss: (0.641)(R 0.758, F 0.524)] [D acc: (0.594)(0.312, 0.875)] [G loss: 0.684] [G acc: 0.562]\n",
      "24969 [D loss: (0.543)(R 0.568, F 0.519)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.860] [G acc: 0.312]\n",
      "24970 [D loss: (0.642)(R 0.622, F 0.661)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.862] [G acc: 0.250]\n",
      "24971 [D loss: (0.659)(R 0.652, F 0.666)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.801] [G acc: 0.312]\n",
      "24972 [D loss: (0.739)(R 0.756, F 0.723)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.772] [G acc: 0.375]\n",
      "24973 [D loss: (0.749)(R 0.663, F 0.835)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.930] [G acc: 0.188]\n",
      "24974 [D loss: (0.643)(R 0.565, F 0.722)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.847] [G acc: 0.250]\n",
      "24975 [D loss: (0.665)(R 0.667, F 0.662)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.795] [G acc: 0.562]\n",
      "24976 [D loss: (0.591)(R 0.575, F 0.606)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.767] [G acc: 0.375]\n",
      "24977 [D loss: (0.596)(R 0.624, F 0.569)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.754] [G acc: 0.312]\n",
      "24978 [D loss: (0.632)(R 0.556, F 0.707)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.706] [G acc: 0.625]\n",
      "24979 [D loss: (0.696)(R 0.595, F 0.796)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.610] [G acc: 0.562]\n",
      "24980 [D loss: (0.643)(R 0.680, F 0.606)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.753] [G acc: 0.500]\n",
      "24981 [D loss: (0.718)(R 0.657, F 0.779)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.982] [G acc: 0.250]\n",
      "24982 [D loss: (0.526)(R 0.567, F 0.484)] [D acc: (0.875)(0.750, 1.000)] [G loss: 0.835] [G acc: 0.250]\n",
      "24983 [D loss: (0.682)(R 0.618, F 0.745)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.860] [G acc: 0.250]\n",
      "24984 [D loss: (0.534)(R 0.528, F 0.541)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.958] [G acc: 0.250]\n",
      "24985 [D loss: (0.547)(R 0.544, F 0.551)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.023] [G acc: 0.062]\n",
      "24986 [D loss: (0.631)(R 0.674, F 0.588)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.040] [G acc: 0.062]\n",
      "24987 [D loss: (0.562)(R 0.542, F 0.581)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.981] [G acc: 0.062]\n",
      "24988 [D loss: (0.629)(R 0.736, F 0.521)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.009] [G acc: 0.188]\n",
      "24989 [D loss: (0.564)(R 0.526, F 0.601)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.997] [G acc: 0.188]\n",
      "24990 [D loss: (0.645)(R 0.749, F 0.541)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.065] [G acc: 0.125]\n",
      "24991 [D loss: (0.667)(R 0.760, F 0.574)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.887] [G acc: 0.125]\n",
      "24992 [D loss: (0.561)(R 0.610, F 0.513)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.850] [G acc: 0.375]\n",
      "24993 [D loss: (0.691)(R 0.762, F 0.619)] [D acc: (0.500)(0.375, 0.625)] [G loss: 1.002] [G acc: 0.312]\n",
      "24994 [D loss: (0.661)(R 0.806, F 0.516)] [D acc: (0.562)(0.375, 0.750)] [G loss: 0.936] [G acc: 0.250]\n",
      "24995 [D loss: (0.665)(R 0.704, F 0.627)] [D acc: (0.531)(0.500, 0.562)] [G loss: 1.455] [G acc: 0.188]\n",
      "24996 [D loss: (0.391)(R 0.552, F 0.231)] [D acc: (0.812)(0.750, 0.875)] [G loss: 8.388] [G acc: 0.125]\n",
      "24997 [D loss: (0.587)(R 0.634, F 0.541)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.826] [G acc: 0.125]\n",
      "24998 [D loss: (0.576)(R 0.592, F 0.560)] [D acc: (0.625)(0.500, 0.750)] [G loss: 0.930] [G acc: 0.312]\n",
      "24999 [D loss: (0.682)(R 0.762, F 0.602)] [D acc: (0.594)(0.438, 0.750)] [G loss: 1.029] [G acc: 0.000]\n",
      "25000 [D loss: (0.702)(R 0.759, F 0.646)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.850] [G acc: 0.375]\n",
      "25001 [D loss: (0.685)(R 0.750, F 0.619)] [D acc: (0.625)(0.438, 0.812)] [G loss: 0.784] [G acc: 0.250]\n",
      "25002 [D loss: (0.535)(R 0.512, F 0.558)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.829] [G acc: 0.312]\n",
      "25003 [D loss: (0.522)(R 0.433, F 0.612)] [D acc: (0.812)(0.875, 0.750)] [G loss: 0.760] [G acc: 0.500]\n",
      "25004 [D loss: (0.628)(R 0.561, F 0.695)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.858] [G acc: 0.438]\n",
      "25005 [D loss: (0.613)(R 0.716, F 0.510)] [D acc: (0.719)(0.438, 1.000)] [G loss: 0.452] [G acc: 0.875]\n",
      "25006 [D loss: (0.600)(R 0.592, F 0.607)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.629] [G acc: 0.062]\n",
      "25007 [D loss: (0.581)(R 0.873, F 0.288)] [D acc: (0.781)(0.625, 0.938)] [G loss: 2.269] [G acc: 0.062]\n",
      "25008 [D loss: (0.555)(R 0.615, F 0.495)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.821] [G acc: 0.375]\n",
      "25009 [D loss: (0.502)(R 0.586, F 0.417)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.847] [G acc: 0.250]\n",
      "25010 [D loss: (0.629)(R 0.617, F 0.641)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.972] [G acc: 0.375]\n",
      "25011 [D loss: (0.593)(R 0.623, F 0.563)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.890] [G acc: 0.188]\n",
      "25012 [D loss: (0.461)(R 0.481, F 0.441)] [D acc: (0.844)(0.875, 0.812)] [G loss: 0.859] [G acc: 0.250]\n",
      "25013 [D loss: (0.525)(R 0.455, F 0.596)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.887] [G acc: 0.312]\n",
      "25014 [D loss: (0.557)(R 0.796, F 0.317)] [D acc: (0.656)(0.438, 0.875)] [G loss: 0.954] [G acc: 0.312]\n",
      "25015 [D loss: (0.628)(R 0.600, F 0.655)] [D acc: (0.656)(0.625, 0.688)] [G loss: 2.494] [G acc: 0.125]\n",
      "25016 [D loss: (0.419)(R 0.630, F 0.208)] [D acc: (0.781)(0.562, 1.000)] [G loss: 5.209] [G acc: 0.125]\n",
      "25017 [D loss: (0.834)(R 0.661, F 1.007)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.986] [G acc: 0.312]\n",
      "25018 [D loss: (0.742)(R 0.632, F 0.851)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.838] [G acc: 0.500]\n",
      "25019 [D loss: (0.723)(R 0.686, F 0.761)] [D acc: (0.531)(0.562, 0.500)] [G loss: 1.049] [G acc: 0.438]\n",
      "25020 [D loss: (0.775)(R 0.672, F 0.878)] [D acc: (0.469)(0.500, 0.438)] [G loss: 0.937] [G acc: 0.188]\n",
      "25021 [D loss: (0.607)(R 0.681, F 0.534)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.013] [G acc: 0.250]\n",
      "25022 [D loss: (0.622)(R 0.562, F 0.681)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.294] [G acc: 0.250]\n",
      "25023 [D loss: (0.606)(R 0.580, F 0.631)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.215] [G acc: 0.188]\n",
      "25024 [D loss: (0.451)(R 0.548, F 0.354)] [D acc: (0.812)(0.750, 0.875)] [G loss: 0.858] [G acc: 0.375]\n",
      "25025 [D loss: (0.566)(R 0.671, F 0.462)] [D acc: (0.562)(0.438, 0.688)] [G loss: 2.313] [G acc: 0.125]\n",
      "25026 [D loss: (0.600)(R 0.501, F 0.698)] [D acc: (0.719)(0.812, 0.625)] [G loss: 2.712] [G acc: 0.312]\n",
      "25027 [D loss: (0.475)(R 0.512, F 0.438)] [D acc: (0.719)(0.688, 0.750)] [G loss: 7.286] [G acc: 0.125]\n",
      "25028 [D loss: (0.406)(R 0.535, F 0.276)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.862] [G acc: 0.250]\n",
      "25029 [D loss: (0.600)(R 0.547, F 0.653)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.808] [G acc: 0.500]\n",
      "25030 [D loss: (0.640)(R 0.559, F 0.720)] [D acc: (0.594)(0.688, 0.500)] [G loss: 1.182] [G acc: 0.125]\n",
      "25031 [D loss: (0.636)(R 0.740, F 0.532)] [D acc: (0.750)(0.625, 0.875)] [G loss: 0.789] [G acc: 0.312]\n",
      "25032 [D loss: (0.684)(R 0.779, F 0.589)] [D acc: (0.594)(0.438, 0.750)] [G loss: 1.036] [G acc: 0.312]\n",
      "25033 [D loss: (0.732)(R 1.023, F 0.442)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.915] [G acc: 0.062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25034 [D loss: (0.588)(R 0.579, F 0.597)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.969] [G acc: 0.188]\n",
      "25035 [D loss: (0.403)(R 0.489, F 0.316)] [D acc: (0.875)(0.750, 1.000)] [G loss: 1.599] [G acc: 0.438]\n",
      "25036 [D loss: (0.470)(R 0.514, F 0.426)] [D acc: (0.812)(0.812, 0.812)] [G loss: 2.873] [G acc: 0.125]\n",
      "25037 [D loss: (0.535)(R 0.441, F 0.629)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.826] [G acc: 0.438]\n",
      "25038 [D loss: (0.620)(R 0.712, F 0.528)] [D acc: (0.781)(0.625, 0.938)] [G loss: 0.910] [G acc: 0.312]\n",
      "25039 [D loss: (0.579)(R 0.683, F 0.476)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.011] [G acc: 0.125]\n",
      "25040 [D loss: (0.529)(R 0.509, F 0.549)] [D acc: (0.781)(0.750, 0.812)] [G loss: 0.735] [G acc: 0.312]\n",
      "25041 [D loss: (0.431)(R 0.390, F 0.473)] [D acc: (0.844)(0.812, 0.875)] [G loss: 0.895] [G acc: 0.188]\n",
      "25042 [D loss: (0.775)(R 0.930, F 0.619)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.587] [G acc: 0.750]\n",
      "25043 [D loss: (0.530)(R 0.581, F 0.478)] [D acc: (0.844)(0.812, 0.875)] [G loss: 4.155] [G acc: 0.188]\n",
      "25044 [D loss: (0.712)(R 0.435, F 0.989)] [D acc: (0.625)(0.688, 0.562)] [G loss: 3.829] [G acc: 0.500]\n",
      "25045 [D loss: (0.359)(R 0.408, F 0.310)] [D acc: (0.812)(0.812, 0.812)] [G loss: 4.442] [G acc: 0.250]\n",
      "25046 [D loss: (0.460)(R 0.624, F 0.297)] [D acc: (0.688)(0.438, 0.938)] [G loss: 4.126] [G acc: 0.188]\n",
      "25047 [D loss: (0.432)(R 0.420, F 0.445)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.098] [G acc: 0.062]\n",
      "25048 [D loss: (0.625)(R 0.381, F 0.869)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.523] [G acc: 0.625]\n",
      "25049 [D loss: (0.674)(R 0.566, F 0.781)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.759] [G acc: 0.438]\n",
      "25050 [D loss: (0.697)(R 0.533, F 0.861)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.759] [G acc: 0.500]\n",
      "25051 [D loss: (0.602)(R 0.642, F 0.562)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.083] [G acc: 0.312]\n",
      "25052 [D loss: (0.639)(R 0.634, F 0.645)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.911] [G acc: 0.250]\n",
      "25053 [D loss: (0.716)(R 0.797, F 0.635)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.233] [G acc: 0.250]\n",
      "25054 [D loss: (0.568)(R 0.541, F 0.594)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.784] [G acc: 0.188]\n",
      "25055 [D loss: (0.529)(R 0.527, F 0.531)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.158] [G acc: 0.000]\n",
      "25056 [D loss: (0.631)(R 0.801, F 0.460)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.776] [G acc: 0.312]\n",
      "25057 [D loss: (0.544)(R 0.521, F 0.566)] [D acc: (0.719)(0.812, 0.625)] [G loss: 2.552] [G acc: 0.312]\n",
      "25058 [D loss: (0.405)(R 0.477, F 0.334)] [D acc: (0.844)(0.750, 0.938)] [G loss: 1.613] [G acc: 0.125]\n",
      "25059 [D loss: (0.510)(R 0.650, F 0.370)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.900] [G acc: 0.188]\n",
      "25060 [D loss: (0.581)(R 0.478, F 0.684)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.985] [G acc: 0.500]\n",
      "25061 [D loss: (0.441)(R 0.472, F 0.411)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.246] [G acc: 0.188]\n",
      "25062 [D loss: (0.616)(R 0.907, F 0.326)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.141] [G acc: 0.125]\n",
      "25063 [D loss: (0.501)(R 0.455, F 0.548)] [D acc: (0.781)(0.688, 0.875)] [G loss: 0.946] [G acc: 0.312]\n",
      "25064 [D loss: (0.542)(R 0.607, F 0.477)] [D acc: (0.688)(0.562, 0.812)] [G loss: 0.742] [G acc: 0.562]\n",
      "25065 [D loss: (0.513)(R 0.581, F 0.446)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.266] [G acc: 0.312]\n",
      "25066 [D loss: (0.562)(R 0.526, F 0.599)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.391] [G acc: 0.375]\n",
      "25067 [D loss: (0.454)(R 0.433, F 0.474)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.347] [G acc: 0.062]\n",
      "25068 [D loss: (0.639)(R 0.655, F 0.624)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.736] [G acc: 0.500]\n",
      "25069 [D loss: (0.609)(R 0.533, F 0.685)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.951] [G acc: 0.188]\n",
      "25070 [D loss: (0.531)(R 0.556, F 0.505)] [D acc: (0.812)(0.688, 0.938)] [G loss: 0.711] [G acc: 0.625]\n",
      "25071 [D loss: (0.609)(R 0.561, F 0.658)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.966] [G acc: 0.312]\n",
      "25072 [D loss: (0.637)(R 0.613, F 0.662)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.069] [G acc: 0.312]\n",
      "25073 [D loss: (0.587)(R 0.425, F 0.749)] [D acc: (0.625)(0.812, 0.438)] [G loss: 1.478] [G acc: 0.312]\n",
      "25074 [D loss: (0.497)(R 0.579, F 0.414)] [D acc: (0.719)(0.625, 0.812)] [G loss: 2.172] [G acc: 0.125]\n",
      "25075 [D loss: (0.421)(R 0.448, F 0.394)] [D acc: (0.781)(0.688, 0.875)] [G loss: 3.636] [G acc: 0.188]\n",
      "25076 [D loss: (0.390)(R 0.374, F 0.406)] [D acc: (0.844)(0.875, 0.812)] [G loss: 1.978] [G acc: 0.062]\n",
      "25077 [D loss: (0.651)(R 0.533, F 0.770)] [D acc: (0.594)(0.562, 0.625)] [G loss: 3.198] [G acc: 0.250]\n",
      "25078 [D loss: (0.393)(R 0.633, F 0.154)] [D acc: (0.688)(0.438, 0.938)] [G loss: 2.569] [G acc: 0.125]\n",
      "25079 [D loss: (0.624)(R 0.603, F 0.646)] [D acc: (0.719)(0.625, 0.812)] [G loss: 0.851] [G acc: 0.312]\n",
      "25080 [D loss: (0.571)(R 0.588, F 0.553)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.678] [G acc: 0.500]\n",
      "25081 [D loss: (0.601)(R 0.687, F 0.514)] [D acc: (0.750)(0.562, 0.938)] [G loss: 1.202] [G acc: 0.062]\n",
      "25082 [D loss: (0.524)(R 0.447, F 0.601)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.998] [G acc: 0.188]\n",
      "25083 [D loss: (0.642)(R 0.624, F 0.661)] [D acc: (0.531)(0.500, 0.562)] [G loss: 1.268] [G acc: 0.125]\n",
      "25084 [D loss: (0.494)(R 0.503, F 0.484)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.041] [G acc: 0.188]\n",
      "25085 [D loss: (0.517)(R 0.565, F 0.469)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.261] [G acc: 0.188]\n",
      "25086 [D loss: (0.502)(R 0.452, F 0.551)] [D acc: (0.750)(0.688, 0.812)] [G loss: 0.873] [G acc: 0.375]\n",
      "25087 [D loss: (0.679)(R 0.948, F 0.411)] [D acc: (0.688)(0.375, 1.000)] [G loss: 0.872] [G acc: 0.250]\n",
      "25088 [D loss: (0.606)(R 0.562, F 0.651)] [D acc: (0.562)(0.500, 0.625)] [G loss: 1.298] [G acc: 0.438]\n",
      "25089 [D loss: (0.656)(R 0.661, F 0.650)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.114] [G acc: 0.062]\n",
      "25090 [D loss: (0.604)(R 0.571, F 0.636)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.768] [G acc: 0.438]\n",
      "25091 [D loss: (0.579)(R 0.555, F 0.604)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.694] [G acc: 0.500]\n",
      "25092 [D loss: (0.567)(R 0.455, F 0.678)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.013] [G acc: 0.188]\n",
      "25093 [D loss: (0.453)(R 0.442, F 0.465)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.133] [G acc: 0.250]\n",
      "25094 [D loss: (0.573)(R 0.519, F 0.628)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.036] [G acc: 0.250]\n",
      "25095 [D loss: (0.497)(R 0.540, F 0.453)] [D acc: (0.719)(0.562, 0.875)] [G loss: 0.969] [G acc: 0.312]\n",
      "25096 [D loss: (0.629)(R 0.487, F 0.772)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.696] [G acc: 0.500]\n",
      "25097 [D loss: (0.778)(R 0.830, F 0.727)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.796] [G acc: 0.438]\n",
      "25098 [D loss: (0.874)(R 0.827, F 0.921)] [D acc: (0.469)(0.312, 0.625)] [G loss: 0.764] [G acc: 0.312]\n",
      "25099 [D loss: (0.500)(R 0.375, F 0.626)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.809] [G acc: 0.375]\n",
      "25100 [D loss: (0.555)(R 0.463, F 0.647)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.943] [G acc: 0.312]\n",
      "25101 [D loss: (0.624)(R 0.454, F 0.794)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.932] [G acc: 0.062]\n",
      "25102 [D loss: (0.500)(R 0.411, F 0.588)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.018] [G acc: 0.188]\n",
      "25103 [D loss: (0.686)(R 0.541, F 0.831)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.877] [G acc: 0.438]\n",
      "25104 [D loss: (0.708)(R 0.537, F 0.878)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.817] [G acc: 0.500]\n",
      "25105 [D loss: (0.726)(R 0.788, F 0.664)] [D acc: (0.500)(0.438, 0.562)] [G loss: 0.781] [G acc: 0.312]\n",
      "25106 [D loss: (0.738)(R 0.695, F 0.780)] [D acc: (0.406)(0.375, 0.438)] [G loss: 0.977] [G acc: 0.062]\n",
      "25107 [D loss: (0.780)(R 0.825, F 0.735)] [D acc: (0.281)(0.250, 0.312)] [G loss: 0.869] [G acc: 0.312]\n",
      "25108 [D loss: (0.793)(R 0.835, F 0.751)] [D acc: (0.500)(0.625, 0.375)] [G loss: 0.906] [G acc: 0.312]\n",
      "25109 [D loss: (1.208)(R 0.671, F 1.745)] [D acc: (0.375)(0.375, 0.375)] [G loss: 0.719] [G acc: 0.438]\n",
      "25110 [D loss: (0.621)(R 0.470, F 0.771)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.706] [G acc: 0.438]\n",
      "25111 [D loss: (0.705)(R 0.495, F 0.915)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.743] [G acc: 0.562]\n",
      "25112 [D loss: (0.848)(R 0.746, F 0.949)] [D acc: (0.344)(0.312, 0.375)] [G loss: 0.717] [G acc: 0.438]\n",
      "25113 [D loss: (0.692)(R 0.490, F 0.893)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.761] [G acc: 0.375]\n",
      "25114 [D loss: (0.797)(R 0.747, F 0.847)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.682] [G acc: 0.438]\n",
      "25115 [D loss: (0.760)(R 0.699, F 0.822)] [D acc: (0.406)(0.375, 0.438)] [G loss: 0.644] [G acc: 0.500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25116 [D loss: (0.927)(R 0.683, F 1.172)] [D acc: (0.500)(0.500, 0.500)] [G loss: 0.476] [G acc: 0.750]\n",
      "25117 [D loss: (0.765)(R 0.705, F 0.825)] [D acc: (0.406)(0.250, 0.562)] [G loss: 0.742] [G acc: 0.438]\n",
      "25118 [D loss: (0.742)(R 0.545, F 0.940)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.576] [G acc: 0.812]\n",
      "25119 [D loss: (1.247)(R 0.634, F 1.860)] [D acc: (0.438)(0.500, 0.375)] [G loss: 0.787] [G acc: 0.500]\n",
      "25120 [D loss: (0.898)(R 0.558, F 1.238)] [D acc: (0.594)(0.562, 0.625)] [G loss: 2.110] [G acc: 0.250]\n",
      "25121 [D loss: (0.765)(R 0.731, F 0.798)] [D acc: (0.500)(0.312, 0.688)] [G loss: 2.988] [G acc: 0.375]\n",
      "25122 [D loss: (0.626)(R 0.534, F 0.717)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.592] [G acc: 0.438]\n",
      "25123 [D loss: (1.150)(R 0.646, F 1.653)] [D acc: (0.469)(0.375, 0.562)] [G loss: 1.198] [G acc: 0.312]\n",
      "25124 [D loss: (0.567)(R 0.580, F 0.554)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.791] [G acc: 0.438]\n",
      "25125 [D loss: (1.217)(R 0.644, F 1.791)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.734] [G acc: 0.625]\n",
      "25126 [D loss: (0.684)(R 0.729, F 0.638)] [D acc: (0.531)(0.312, 0.750)] [G loss: 1.076] [G acc: 0.500]\n",
      "25127 [D loss: (0.953)(R 0.704, F 1.202)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.905] [G acc: 0.438]\n",
      "25128 [D loss: (0.685)(R 0.642, F 0.728)] [D acc: (0.594)(0.500, 0.688)] [G loss: 1.310] [G acc: 0.438]\n",
      "25129 [D loss: (0.868)(R 0.516, F 1.220)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.776] [G acc: 0.438]\n",
      "25130 [D loss: (0.675)(R 0.724, F 0.625)] [D acc: (0.500)(0.375, 0.625)] [G loss: 1.413] [G acc: 0.438]\n",
      "25131 [D loss: (0.809)(R 0.759, F 0.859)] [D acc: (0.562)(0.562, 0.562)] [G loss: 1.553] [G acc: 0.188]\n",
      "25132 [D loss: (1.241)(R 0.761, F 1.721)] [D acc: (0.438)(0.438, 0.438)] [G loss: 0.824] [G acc: 0.562]\n",
      "25133 [D loss: (0.796)(R 0.864, F 0.728)] [D acc: (0.500)(0.438, 0.562)] [G loss: 1.270] [G acc: 0.438]\n",
      "25134 [D loss: (0.616)(R 0.525, F 0.706)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.362] [G acc: 0.188]\n",
      "25135 [D loss: (0.650)(R 0.619, F 0.682)] [D acc: (0.500)(0.500, 0.500)] [G loss: 1.308] [G acc: 0.188]\n",
      "25136 [D loss: (0.682)(R 0.755, F 0.609)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.709] [G acc: 0.375]\n",
      "25137 [D loss: (0.690)(R 0.526, F 0.855)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.816] [G acc: 0.500]\n",
      "25138 [D loss: (0.849)(R 0.723, F 0.975)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.843] [G acc: 0.625]\n",
      "25139 [D loss: (0.732)(R 0.670, F 0.793)] [D acc: (0.469)(0.562, 0.375)] [G loss: 0.752] [G acc: 0.500]\n",
      "25140 [D loss: (0.558)(R 0.571, F 0.544)] [D acc: (0.719)(0.688, 0.750)] [G loss: 0.940] [G acc: 0.250]\n",
      "25141 [D loss: (0.600)(R 0.604, F 0.597)] [D acc: (0.562)(0.500, 0.625)] [G loss: 1.234] [G acc: 0.312]\n",
      "25142 [D loss: (0.713)(R 0.775, F 0.650)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.964] [G acc: 0.312]\n",
      "25143 [D loss: (0.674)(R 0.631, F 0.717)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.761] [G acc: 0.562]\n",
      "25144 [D loss: (0.677)(R 0.708, F 0.646)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.773] [G acc: 0.375]\n",
      "25145 [D loss: (0.615)(R 0.602, F 0.628)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.859] [G acc: 0.500]\n",
      "25146 [D loss: (0.763)(R 0.716, F 0.809)] [D acc: (0.469)(0.438, 0.500)] [G loss: 1.686] [G acc: 0.250]\n",
      "25147 [D loss: (0.433)(R 0.633, F 0.233)] [D acc: (0.781)(0.562, 1.000)] [G loss: 1.157] [G acc: 0.062]\n",
      "25148 [D loss: (0.677)(R 0.679, F 0.674)] [D acc: (0.500)(0.375, 0.625)] [G loss: 0.788] [G acc: 0.375]\n",
      "25149 [D loss: (0.590)(R 0.520, F 0.660)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.854] [G acc: 0.375]\n",
      "25150 [D loss: (0.601)(R 0.544, F 0.658)] [D acc: (0.656)(0.812, 0.500)] [G loss: 0.629] [G acc: 0.438]\n",
      "25151 [D loss: (0.636)(R 0.616, F 0.655)] [D acc: (0.750)(0.750, 0.750)] [G loss: 0.840] [G acc: 0.312]\n",
      "25152 [D loss: (0.675)(R 0.548, F 0.802)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.732] [G acc: 0.438]\n",
      "25153 [D loss: (0.548)(R 0.520, F 0.576)] [D acc: (0.812)(0.875, 0.750)] [G loss: 1.131] [G acc: 0.250]\n",
      "25154 [D loss: (0.823)(R 0.713, F 0.933)] [D acc: (0.344)(0.438, 0.250)] [G loss: 0.526] [G acc: 0.562]\n",
      "25155 [D loss: (0.822)(R 0.626, F 1.018)] [D acc: (0.469)(0.688, 0.250)] [G loss: 2.427] [G acc: 0.312]\n",
      "25156 [D loss: (0.413)(R 0.649, F 0.178)] [D acc: (0.688)(0.500, 0.875)] [G loss: 7.655] [G acc: 0.250]\n",
      "25157 [D loss: (0.816)(R 0.678, F 0.954)] [D acc: (0.438)(0.562, 0.312)] [G loss: 0.983] [G acc: 0.500]"
     ]
    }
   ],
   "source": [
    "gan.train(     \n",
    "    y_train\n",
    "    , batch_size = BATCH_SIZE\n",
    "    , epochs = EPOCHS\n",
    "    , run_folder = RUN_FOLDER\n",
    "    , print_every_n_batches = PRINT_EVERY_N_BATCHES\n",
    ")\n",
    "\n",
    "gan.save(RUN_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x[0] for x in gan.d_losses], color='black', linewidth=0.25)\n",
    "\n",
    "plt.plot([x[1] for x in gan.d_losses], color='green', linewidth=0.25)\n",
    "plt.plot([x[2] for x in gan.d_losses], color='red', linewidth=0.25)\n",
    "plt.plot([x[0] for x in gan.g_losses], color='orange', linewidth=0.25)\n",
    "\n",
    "plt.xlabel('batch', fontsize=18)\n",
    "plt.ylabel('loss', fontsize=16)\n",
    "\n",
    "plt.xlim(0, 2000)\n",
    "plt.ylim(0, 2)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#n_to_show = 10\n",
    "#example_idx = np.random.choice(range(len(x_test)), n_to_show)\n",
    "#example_images = x_test[example_idx]\n",
    "#example_test   = y_test[example_idx]\n",
    "\n",
    "#gan.generator()\n",
    "\n",
    "#z_points = gan.discriminator.predict(example_images)\n",
    "#print('z_points: ', z_points)\n",
    "#reconst_images = AE.decoder.predict(z_points)\n",
    "#print('reconstituted: {}'.format(reconst_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.01123055  0.00792482 -0.00472485  0.01926836  0.01925022  0.03880921\n",
      "   0.06427465  0.00533733  0.00663657  0.01958878  0.00632452  0.0160875\n",
      "   0.01363848 -0.01098616  0.00472126  0.02013531  0.0325086   0.06336999\n",
      "   0.06557898  0.01705048 -0.01801371 -0.01359054  0.04054878 -0.0169384\n",
      "   0.01189579  0.072663    0.08333021  0.15131882  0.04134703  0.05476469\n",
      "   0.02475159  0.06754696  0.02407375  0.0419841   0.06013798]]\n",
      "[[0.58968204]]\n",
      "Prob Sum:  1.0193834\n"
     ]
    }
   ],
   "source": [
    "test_gen = gan.generator.predict([list(np.random.random(z_num))])\n",
    "print(test_gen)\n",
    "print(gan.discriminator.predict(test_gen))\n",
    "print('Prob Sum: ', np.sum(test_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
